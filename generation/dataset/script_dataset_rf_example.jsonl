{"script_name": "include_expansion", "definition_description": "Provides include file expansion for the interpreter, returning the encoded file path and the expanded text.", "parameters": {"macro": "The macro for which the include expansion is provided."}, "values": "Returns a two-element array containing the encoded file path and the include-expanded text.", "script_paradigm": "include_expansion(macro)", "examples": [{"query": "How to get the include expansion for a given macro?", "answer": "include_expansion(macro)"}], "reference": "If the object is not owned by the script, this method will do nothing. destroyed? Signature : [const] bool destroyed? Description : Returns a value indicating whether the object was already destroyed Use of this method is deprecated. Use _destroyed? instead This method returns true, if the object was destroyed, either explicitly or by the C++ side.\nThe latter may happen, if the object is owned by a C++ object which got destroyed itself. dup Signature : [const] new MacroInterpreter ptr dup Description : Creates a copy of self Python specific notes: This method also implements '__copy__' and '__deepcopy__'. executable Signature : [virtual,const] Executable ptr executable (const Macro ptr macro) Description : Returns the executable object which implements the macro execution macro : The macro to execute This method must be reimplemented to return an Executable object for the actual implementation. The system will use this function to execute the script when a macro with interpreter type 'dsl' and the name of this interpreter is run. This method has been introduced in version 0.27 and replaces the 'execute' method. include_expansion Signature : string[] include_expansion ( Macro ptr macro) Description : Provides include expansion as defined by the interpreter The return value will be a two-element array with the encoded file path and the include-expanded text. This method has been introduced in version 0.28.12. is_const_object? Signature : [const] bool is_const_object? Description : Returns a value indicating whether the reference is a const reference Use of this method is deprecated. Use _is_const_object? instead This method returns true, if self is a const reference.\nIn that case, only const methods may be called on self. new Signature : [static] new MacroInterpreter ptr new Description : Creates a new object of this class Python specific notes: This method is the default initializer of the object. register Signature : void register (string name) Description : Registers the macro interpreter name : The interpreter name. This is an arbitrary string which should be unique. Registration of the interpreter makes the object known to the system. After registration, macros whose interpreter is set to 'dsl' can use this object to run the script. For executing a script, the system will call the interpreter's execute method. storage_scheme= Signature : void storage_scheme= ( Macro::Format scheme) Description : Sets the storage scheme (the format as which the macro is stored) This value indicates how files for this DSL macro type shall be stored. The value can be one of the constants PlainTextFormat , PlainTextWithHashAnnotationsFormat and MacroFormat . Use this attribute setter in the initializer before registering the interpreter. Before version 0.25 this attribute was a re-implementable method. It has been turned into an attribute for performance reasons in version 0.25. Python specific notes: The object exposes a writable attribute 'storage_scheme'. This is the setter. suffix= Signature : void suffix= (string suffix) Description : Sets the file suffix This string defines which file suffix to associate with the DSL macro. If an empty string is given (the default) no particular suffix is assciated with that macro type and \"lym\" is assumed. \nUse this attribute setter in the initializer before registering the interpreter. Before version 0.25 this attribute was a re-implementable method. It has been turned into an attribute for performance reasons in version 0.25. Python specific notes: The object exposes a writable attribute 'suffix'. This is the setter. supports_include_expansion= Signature : void supports_include_expansion= (bool flag) Description : Sets a value indicating whether this interpreter supports the default include file expansion scheme. If this value is set to true (the default), lines like '# %include ...' will be substituted by the content of the file following the '%include' keyword.", "source": "klayout"}
{"script_name": "no_inline", "definition_description": "This script specifies that a module or function should not be inlined into other modules or functions that use it, potentially reducing the size of the final executable.", "parameters": {"module_name": "The name of the module that should not be inlined.", "task_name": "The name of the task that should not be inlined.", "func_name": "The name of the function that should not be inlined."}, "values": "module_name: <modulename>, task_name: <taskname>, func_name: <funcname>", "script_paradigm": "no_inline [-module <module_name>] -task <task_name>\nno_inline [-module <module_name>] -function <func_name>", "examples": [{"query": "How to prevent inlining of a module named 'my_module'?", "answer": "no_inline -module my_module"}, {"query": "How to prevent inlining of the function 'task_1' in module 'my_module'?", "answer": "no_inline -module my_module -function task_1"}], "reference": "Verilator, Release Devel 5.031\nno_inline -module \"<modulename>\"\nSpeciﬁes the module should not be inlined into any modules that use this module.\nSame as /\n*verilator&32;no_inline_module*/ metacomment.\nno_inline [-module \"<modulename>\"] -task \"<taskname>\"\nno_inline [-module \"<modulename>\"] -function \"<funcname>\"\nSpecify the function or task should not be inlined into where it is used. This may reduce the size of the ﬁnal\nexecutable when a task is used a very large number of times. For this ﬂag to work, the task and tasks below it\nmust be pure; they cannot reference any variables outside the task itself.\nSame as /*verilator&32;no_inline_task*/ metacomment.\nlint_on\n[-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\"] [-contents \"<wildcard>\"] [-match \"<wildcard\nEnable/disables the speciﬁed lint warning, in the speciﬁed ﬁlename (or wildcard with ‘*’ or ‘?’, or all ﬁles if\nomitted) and range of line numbers (or all lines if omitted).\nWith lint_off using “*” will override any lint_on directives in the source, i.e. the warning will still not be printed.\nIf the -rule is omitted, all lint warnings (see list in -Wno-lint) are enabled/disabled. This will override all\nlater lint warning enables for the speciﬁed region.\nIf -contents is provided, the input ﬁles must contain the given wildcard (with ‘*’ or ‘?’), and are waived in\ncase they match, provided the -rule, -file, and -contents also match. The wildcard should be designed\nto match a single line; it is unspeciﬁed if the wildcard is allowed to match across multiple lines. The input\ncontents does not include --std standard ﬁles, nor conﬁguration ﬁles (with verilator_config). Typical\nuse for this is to match a version number present in the Verilog sources, so that the waiver will only apply to that\nversion of the sources.\nIf -match is provided, the linter warnings are matched against the given wildcard (with ‘*’ or ‘?’), and are\nwaived in case they match, provided the -rule, -file, and -contents also match. The wildcard is com-\npared across the entire multi-line message; see --waiver-multiline.\nBefore version 4.026, -rule was named -msg, and -msg remained a deprecated alias until Version 5.000.\npublic [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rd [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rw [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\" \"@\nSets the variable to be public.\nSame as /*verilator&32;public*/ or /*verilator&32;\npublic_flat*/, etc., metacomments. See also VPI Example.\nprofile_data -mtask \"<mtask_hash>\" -cost <cost_value>\nFeeds proﬁle-guided optimization data into the Verilator algorithms in order to improve model runtime perfor-\nmance. This option is not expected to be used by users directly. See Thread Proﬁle-Guided Optimization.\nsc_bv -module \"<modulename>\" [-task \"<taskname>\"] -var \"<signame>\"\nsc_bv -module \"<modulename>\" [-function \"<funcname>\"] -var \"<signame>\"\nSets the port to be of sc_bv<{width}> type, instead of bool, uint32_t, or uint64_t.\nSame as /\n*verilator&32;sc_bv*/ metacomment.\nsformat [-module \"<modulename>\"] [-task \"<taskname>\"] -var \"<signame>\"\nsformat [-module \"<modulename>\"] [-function \"<funcname>\"] -var \"<signame>\"\nMust be applied to the ﬁnal argument of type input string of a function or task to indicate that the function\n12.2. Conﬁguration Files\n95", "source": "verilator"}
{"script_name": "lint_on / lint_off", "definition_description": "This script enables or disables specific lint warnings in specified files or line ranges. It can be used to manage linting warnings, including waiving warnings based on rule or content.", "parameters": {"rule": "The lint warning rule to enable or disable.", "file_name": "The name of the file to apply the lint rule.", "line_range": "The range of line numbers where the rule should apply.", "contents": "The content pattern to match in the files for applying the lint rule.", "match": "The pattern to match against the lint warnings message."}, "values": "rule: <message>, file_name: <filename>, line_range: <line>, contents: <wildcard>, match: <wildcard>", "script_paradigm": "lint_on [-rule <rule>] [-file <file_name>] [-lines <line_range>]\nlint_off [-rule <rule>] [-file <file_name>] [-lines <line_range>]", "examples": [{"query": "How to disable a lint warning for a specific rule 'RULE_001' in file 'my_file.v' on lines 10 to 20?", "answer": "lint_off -rule RULE_001 -file my_file.v -lines 10-20"}, {"query": "How to enable lint warnings for all rules in 'my_file.v'?", "answer": "lint_on -file my_file.v"}], "reference": "Verilator, Release Devel 5.031\nno_inline -module \"<modulename>\"\nSpeciﬁes the module should not be inlined into any modules that use this module.\nSame as /\n*verilator&32;no_inline_module*/ metacomment.\nno_inline [-module \"<modulename>\"] -task \"<taskname>\"\nno_inline [-module \"<modulename>\"] -function \"<funcname>\"\nSpecify the function or task should not be inlined into where it is used. This may reduce the size of the ﬁnal\nexecutable when a task is used a very large number of times. For this ﬂag to work, the task and tasks below it\nmust be pure; they cannot reference any variables outside the task itself.\nSame as /*verilator&32;no_inline_task*/ metacomment.\nlint_on\n[-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\"] [-contents \"<wildcard>\"] [-match \"<wildcard\nEnable/disables the speciﬁed lint warning, in the speciﬁed ﬁlename (or wildcard with ‘*’ or ‘?’, or all ﬁles if\nomitted) and range of line numbers (or all lines if omitted).\nWith lint_off using “*” will override any lint_on directives in the source, i.e. the warning will still not be printed.\nIf the -rule is omitted, all lint warnings (see list in -Wno-lint) are enabled/disabled. This will override all\nlater lint warning enables for the speciﬁed region.\nIf -contents is provided, the input ﬁles must contain the given wildcard (with ‘*’ or ‘?’), and are waived in\ncase they match, provided the -rule, -file, and -contents also match. The wildcard should be designed\nto match a single line; it is unspeciﬁed if the wildcard is allowed to match across multiple lines. The input\ncontents does not include --std standard ﬁles, nor conﬁguration ﬁles (with verilator_config). Typical\nuse for this is to match a version number present in the Verilog sources, so that the waiver will only apply to that\nversion of the sources.\nIf -match is provided, the linter warnings are matched against the given wildcard (with ‘*’ or ‘?’), and are\nwaived in case they match, provided the -rule, -file, and -contents also match. The wildcard is com-\npared across the entire multi-line message; see --waiver-multiline.\nBefore version 4.026, -rule was named -msg, and -msg remained a deprecated alias until Version 5.000.\npublic [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rd [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rw [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\" \"@\nSets the variable to be public.\nSame as /*verilator&32;public*/ or /*verilator&32;\npublic_flat*/, etc., metacomments. See also VPI Example.\nprofile_data -mtask \"<mtask_hash>\" -cost <cost_value>\nFeeds proﬁle-guided optimization data into the Verilator algorithms in order to improve model runtime perfor-\nmance. This option is not expected to be used by users directly. See Thread Proﬁle-Guided Optimization.\nsc_bv -module \"<modulename>\" [-task \"<taskname>\"] -var \"<signame>\"\nsc_bv -module \"<modulename>\" [-function \"<funcname>\"] -var \"<signame>\"\nSets the port to be of sc_bv<{width}> type, instead of bool, uint32_t, or uint64_t.\nSame as /\n*verilator&32;sc_bv*/ metacomment.\nsformat [-module \"<modulename>\"] [-task \"<taskname>\"] -var \"<signame>\"\nsformat [-module \"<modulename>\"] [-function \"<funcname>\"] -var \"<signame>\"\nMust be applied to the ﬁnal argument of type input string of a function or task to indicate that the function\n12.2. Conﬁguration Files\n95", "source": "verilator"}
{"script_name": "public", "definition_description": "This script sets a variable to be publicly accessible, similar to the /*verilator&32;public*/ metacomment.", "parameters": {"module_name": "The name of the module where the variable is defined.", "task_name": "The name of the task where the variable is used.", "func_name": "The name of the function where the variable is used.", "signal_name": "The name of the variable to be made public."}, "values": "module_name: <modulename>, task_name: <taskname>, func_name: <funcname>, signal_name: <signame>", "script_paradigm": "public [-module <module_name>] [-task <task_name>] -var <signal_name>", "examples": [{"query": "How to make a signal 'my_signal' public in task 'my_task' in module 'my_module'?", "answer": "public -module my_module -task my_task -var my_signal"}], "reference": "Verilator, Release Devel 5.031\nno_inline -module \"<modulename>\"\nSpeciﬁes the module should not be inlined into any modules that use this module.\nSame as /\n*verilator&32;no_inline_module*/ metacomment.\nno_inline [-module \"<modulename>\"] -task \"<taskname>\"\nno_inline [-module \"<modulename>\"] -function \"<funcname>\"\nSpecify the function or task should not be inlined into where it is used. This may reduce the size of the ﬁnal\nexecutable when a task is used a very large number of times. For this ﬂag to work, the task and tasks below it\nmust be pure; they cannot reference any variables outside the task itself.\nSame as /*verilator&32;no_inline_task*/ metacomment.\nlint_on\n[-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\"] [-contents \"<wildcard>\"] [-match \"<wildcard\nEnable/disables the speciﬁed lint warning, in the speciﬁed ﬁlename (or wildcard with ‘*’ or ‘?’, or all ﬁles if\nomitted) and range of line numbers (or all lines if omitted).\nWith lint_off using “*” will override any lint_on directives in the source, i.e. the warning will still not be printed.\nIf the -rule is omitted, all lint warnings (see list in -Wno-lint) are enabled/disabled. This will override all\nlater lint warning enables for the speciﬁed region.\nIf -contents is provided, the input ﬁles must contain the given wildcard (with ‘*’ or ‘?’), and are waived in\ncase they match, provided the -rule, -file, and -contents also match. The wildcard should be designed\nto match a single line; it is unspeciﬁed if the wildcard is allowed to match across multiple lines. The input\ncontents does not include --std standard ﬁles, nor conﬁguration ﬁles (with verilator_config). Typical\nuse for this is to match a version number present in the Verilog sources, so that the waiver will only apply to that\nversion of the sources.\nIf -match is provided, the linter warnings are matched against the given wildcard (with ‘*’ or ‘?’), and are\nwaived in case they match, provided the -rule, -file, and -contents also match. The wildcard is com-\npared across the entire multi-line message; see --waiver-multiline.\nBefore version 4.026, -rule was named -msg, and -msg remained a deprecated alias until Version 5.000.\npublic [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rd [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rw [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\" \"@\nSets the variable to be public.\nSame as /*verilator&32;public*/ or /*verilator&32;\npublic_flat*/, etc., metacomments. See also VPI Example.\nprofile_data -mtask \"<mtask_hash>\" -cost <cost_value>\nFeeds proﬁle-guided optimization data into the Verilator algorithms in order to improve model runtime perfor-\nmance. This option is not expected to be used by users directly. See Thread Proﬁle-Guided Optimization.\nsc_bv -module \"<modulename>\" [-task \"<taskname>\"] -var \"<signame>\"\nsc_bv -module \"<modulename>\" [-function \"<funcname>\"] -var \"<signame>\"\nSets the port to be of sc_bv<{width}> type, instead of bool, uint32_t, or uint64_t.\nSame as /\n*verilator&32;sc_bv*/ metacomment.\nsformat [-module \"<modulename>\"] [-task \"<taskname>\"] -var \"<signame>\"\nsformat [-module \"<modulename>\"] [-function \"<funcname>\"] -var \"<signame>\"\nMust be applied to the ﬁnal argument of type input string of a function or task to indicate that the function\n12.2. Conﬁguration Files\n95", "source": "verilator"}
{"script_name": "sc_bv", "definition_description": "This script sets the port to be of sc_bv<{width}> type instead of the default types like bool, uint32_t, or uint64_t.", "parameters": {"module_name": "The name of the module to apply the sc_bv type.", "task_name": "The name of the task to apply the sc_bv type.", "func_name": "The name of the function to apply the sc_bv type.", "signal_name": "The name of the variable to be set to sc_bv."}, "values": "module_name: <modulename>, task_name: <taskname>, func_name: <funcname>, signal_name: <signame>", "script_paradigm": "sc_bv -module <module_name> [-task <task_name>] -var <signal_name>\nsc_bv -module <module_name> [-function <func_name>] -var <signal_name>", "examples": [{"query": "How to set the signal 'my_signal' as sc_bv in function 'my_func' of module 'my_module'?", "answer": "sc_bv -module my_module -function my_func -var my_signal"}], "reference": "Verilator, Release Devel 5.031\nno_inline -module \"<modulename>\"\nSpeciﬁes the module should not be inlined into any modules that use this module.\nSame as /\n*verilator&32;no_inline_module*/ metacomment.\nno_inline [-module \"<modulename>\"] -task \"<taskname>\"\nno_inline [-module \"<modulename>\"] -function \"<funcname>\"\nSpecify the function or task should not be inlined into where it is used. This may reduce the size of the ﬁnal\nexecutable when a task is used a very large number of times. For this ﬂag to work, the task and tasks below it\nmust be pure; they cannot reference any variables outside the task itself.\nSame as /*verilator&32;no_inline_task*/ metacomment.\nlint_on\n[-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\"] [-contents \"<wildcard>\"] [-match \"<wildcard\nEnable/disables the speciﬁed lint warning, in the speciﬁed ﬁlename (or wildcard with ‘*’ or ‘?’, or all ﬁles if\nomitted) and range of line numbers (or all lines if omitted).\nWith lint_off using “*” will override any lint_on directives in the source, i.e. the warning will still not be printed.\nIf the -rule is omitted, all lint warnings (see list in -Wno-lint) are enabled/disabled. This will override all\nlater lint warning enables for the speciﬁed region.\nIf -contents is provided, the input ﬁles must contain the given wildcard (with ‘*’ or ‘?’), and are waived in\ncase they match, provided the -rule, -file, and -contents also match. The wildcard should be designed\nto match a single line; it is unspeciﬁed if the wildcard is allowed to match across multiple lines. The input\ncontents does not include --std standard ﬁles, nor conﬁguration ﬁles (with verilator_config). Typical\nuse for this is to match a version number present in the Verilog sources, so that the waiver will only apply to that\nversion of the sources.\nIf -match is provided, the linter warnings are matched against the given wildcard (with ‘*’ or ‘?’), and are\nwaived in case they match, provided the -rule, -file, and -contents also match. The wildcard is com-\npared across the entire multi-line message; see --waiver-multiline.\nBefore version 4.026, -rule was named -msg, and -msg remained a deprecated alias until Version 5.000.\npublic [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rd [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rw [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\" \"@\nSets the variable to be public.\nSame as /*verilator&32;public*/ or /*verilator&32;\npublic_flat*/, etc., metacomments. See also VPI Example.\nprofile_data -mtask \"<mtask_hash>\" -cost <cost_value>\nFeeds proﬁle-guided optimization data into the Verilator algorithms in order to improve model runtime perfor-\nmance. This option is not expected to be used by users directly. See Thread Proﬁle-Guided Optimization.\nsc_bv -module \"<modulename>\" [-task \"<taskname>\"] -var \"<signame>\"\nsc_bv -module \"<modulename>\" [-function \"<funcname>\"] -var \"<signame>\"\nSets the port to be of sc_bv<{width}> type, instead of bool, uint32_t, or uint64_t.\nSame as /\n*verilator&32;sc_bv*/ metacomment.\nsformat [-module \"<modulename>\"] [-task \"<taskname>\"] -var \"<signame>\"\nsformat [-module \"<modulename>\"] [-function \"<funcname>\"] -var \"<signame>\"\nMust be applied to the ﬁnal argument of type input string of a function or task to indicate that the function\n12.2. Conﬁguration Files\n95", "source": "verilator"}
{"script_name": "ShapeStatistics", "definition_description": "This script counts the number of selected paths, boxes, polygons, and text objects in the current layout view.", "parameters": {"app": "The application instance to access KLayout's main window.", "mw": "The main window of the application to interact with the current view.", "lv": "The current layout view that holds the selected objects."}, "values": "app: <Application.instance>, mw: <app.main_window>, lv: <mw.current_view>", "script_paradigm": "module MyMacro\n\n  include RBA\n\n  app = Application.instance\n  mw = app.main_window\n\n  lv = mw.current_view\n  if lv == nil\n    raise 'Shape Statistics: No view selected'\n  end\n\n  paths = 0\n  polygons = 0\n  boxes = 0\n  texts = 0\n\n  lv.each_object_selected do |sel|\n\n    shape = sel.shape\n\n    if shape.is_path?\n      paths += 1\n    elsif shape.is_box?\n      boxes += 1\n    elsif shape.is_polygon?\n      polygons += 1\n    elsif shape.is_text?\n      texts += 1\n    end\n\n  end\n\n  s = \"Paths: #{paths}\\n\"\n  s += \"Polygons: #{polygons}\\n\"\n  s += \"Boxes: #{boxes}\\n\"\n  s += \"Texts: #{texts}\\n\"\n\n  MessageBox::info('Shape Statistics', s, MessageBox::Ok)\n\nend", "examples": [{"query": "How to count selected shapes in a layout view using the ShapeStatistics script?", "answer": "module MyMacro\n\n  include RBA\n\n  app = Application.instance\n  mw = app.main_window\n\n  lv = mw.current_view\n  if lv == nil\n    raise 'Shape Statistics: No view selected'\n  end\n\n  paths = 0\n  polygons = 0\n  boxes = 0\n  texts = 0\n\n  lv.each_object_selected do |sel|\n\n    shape = sel.shape\n\n    if shape.is_path?\n      paths += 1\n    elsif shape.is_box?\n      boxes += 1\n    elsif shape.is_polygon?\n      polygons += 1\n    elsif shape.is_text?\n      texts += 1\n    end\n\n  end\n\n  s = \"Paths: #{paths}\\n\"\n  s += \"Polygons: #{polygons}\\n\"\n  s += \"Boxes: #{boxes}\\n\"\n  s += \"Texts: #{texts}\\n\"\n\n  MessageBox::info('Shape Statistics', s, MessageBox::Ok)\n\nend"}], "reference": "KLayout Documentation (Qt 5): Main Index » Programming scripts » Introduction\n\nIntroduction\n\nThis chapter is about programming extensions for KLayout using the integrated Ruby API (RBA) or Python API (pya).\n\nTo use RBA scripts, KLayout must be compiled with the Ruby interpreter. Check under \"Help/About\" whether support is available. If there is, the \"Build options\" will include a \"Ruby\" or \"Python\" interpreter or both. RBA scripts require a Ruby interpreter. To use pya scripts, Python support must be included.\n\nKLayout comes with the Qt library included into the Ruby or Python API. This means, KLayout scripts can access the full Qt API if Qt binding is available. Check whether \"Qt bindings for scripts\" is included in the build options on the \"Help/About\" page.\n\nBasically there are scripts and macros:\n\nScripts are simple text files which are prepared externally and KLayout acts as an interpreter for these scripts. A special case of scripts is included code, while is loaded into other scripts or macros using \"require\" on Ruby or \"import\" on Python. Scripts have been the only way to code Ruby functionality in version 0.21 and earlier.\n\nMacros are special XML files which contain Ruby code plus some additional information required to link them into the system, i.e. automatically execute them on startup or provide menu entries for them. They can load normal \".rb\" or \".py\" files to implement libraries of classes in the usual way. Macros are managed and developed conveniently in the integrated macro development environment along with the supporting files. This method is the preferred way of creating application extensions and is described in this chapter.\n\nBefore you start, please make yourself familiar with the macro development integrated environment (About Macro Development). This documentation also assumes that you familiar with the Ruby programming language. There are numerous books and tutorials about Ruby. The most famous one is the \"pickaxe book\" (Programming Ruby - The Pragmatic Programmers Guide) by Dave Thomas. If you are familiar with Ruby there is a technical article about the way Ruby and KLayout's core are integrated (The Ruby Language Binding). There are special articles about the integrated Qt binding (The Qt Binding) and PCell programming (Coding PCells In Ruby). If you want to use Python, please read the python implementation article (Using Python) for details about how to translate Ruby samples into Python and specific details of the Python integration.\n\nAn introduction into the basic concepts of the KLayout API are given in the article about the application API (The Application API) and about the database API (The Database API).\n\nA First Sample\n\nThe first sample is already a complete macro which counts all selected paths, boxes, polygons or text objects. It demonstrates how to set up a macro, how to deal with the selection and how to access the layout database.\n\nHere is the code:\n\nmodule MyMacro\n\n  include RBA\n\n  app = Application.instance\n  mw = app.main_window\n\n  lv = mw.current_view\n  if lv == nil\n    raise \"Shape Statistics: No view selected\"\n  end\n\n  paths = 0\n  polygons = 0\n  boxes = 0\n  texts = 0\n\n  lv.each_object_selected do |sel|\n\n    shape = sel.shape\n\n    if shape.is_path?\n      paths += 1\n    elsif shape.is_box?\n      boxes += 1\n    elsif shape.is_polygon?\n      polygons += 1\n    elsif shape.is_text?\n      texts += 1\n    end\n\n  end\n\n  s = \"Paths: #{paths}\\n\"\n  s += \"Polygons: #{polygons}\\n\"\n  s += \"Boxes: #{boxes}\\n\"\n  s += \"Texts: #{texts}\\n\"\n\n  MessageBox::info(\"Shape Statistics\", s, MessageBox::Ok)\n\nend\n\nTo run the macro, create a new macro in the macro development IDE: choose \"Macros/Macro Development\". Create a new macro using the \"+\" button. Rename the macro to a suitable name. Copy the code above into the text. Load a layout, select some objects and in the macro development IDE press F5. A message box will appear the tells us how may boxes, polygons etc. we have selected.", "source": "klayout"}
{"script_name": "transformed", "definition_description": "This script transforms the ruler or marker with the given simple transformation.", "parameters": {"t": "The simple transformation to apply to the ruler or marker."}, "values": "t: <DTrans>", "script_paradigm": "transformed -t <t>", "examples": [{"query": "How to apply a simple transformation to the ruler?", "answer": "transformed -t DTrans"}], "reference": "0) Returns the formatted text for the y-axis label [const] string to_s Returns the string representation of the ruler [const] Annotation transformed (const DTrans t) Transforms the ruler or marker with the given simple transformation [const] Annotation transformed (const DCplxTrans t) Transforms the ruler or marker with the given complex transformation [const] Annotation transformed (const ICplxTrans t) Transforms the ruler or marker with the given complex transformation [const] int xlabel_xalign Gets the horizontal alignment type of the x axis label void xlabel_xalign= (int align) Sets the horizontal alignment type of the x axis label [const] int xlabel_yalign Gets the vertical alignment type of the x axis label void xlabel_yalign= (int align) Sets the vertical alignment type of the x axis label [const] int ylabel_xalign Gets the horizontal alignment type of the y axis label void ylabel_xalign= (int align) Sets the horizontal alignment type of the y axis label [const] int ylabel_yalign Gets the vertical alignment type of the y axis label void ylabel_yalign= (int align) Sets the vertical alignment type of the y axis label", "source": "klayout"}
{"script_name": "xlabel_xalign", "definition_description": "This script sets the horizontal alignment type of the x-axis label.", "parameters": {"align": "The alignment type to set for the x-axis label."}, "values": "align: <int>", "script_paradigm": "xlabel_xalign= -align <align>", "examples": [{"query": "How to set the horizontal alignment of the x-axis label to 1?", "answer": "xlabel_xalign= -align 1"}], "reference": "0) Returns the formatted text for the y-axis label [const] string to_s Returns the string representation of the ruler [const] Annotation transformed (const DTrans t) Transforms the ruler or marker with the given simple transformation [const] Annotation transformed (const DCplxTrans t) Transforms the ruler or marker with the given complex transformation [const] Annotation transformed (const ICplxTrans t) Transforms the ruler or marker with the given complex transformation [const] int xlabel_xalign Gets the horizontal alignment type of the x axis label void xlabel_xalign= (int align) Sets the horizontal alignment type of the x axis label [const] int xlabel_yalign Gets the vertical alignment type of the x axis label void xlabel_yalign= (int align) Sets the vertical alignment type of the x axis label [const] int ylabel_xalign Gets the horizontal alignment type of the y axis label void ylabel_xalign= (int align) Sets the horizontal alignment type of the y axis label [const] int ylabel_yalign Gets the vertical alignment type of the y axis label void ylabel_yalign= (int align) Sets the vertical alignment type of the y axis label", "source": "klayout"}
{"script_name": "ylabel_xalign", "definition_description": "This script sets the horizontal alignment type of the y-axis label.", "parameters": {"align": "The alignment type to set for the y-axis label."}, "values": "align: <int>", "script_paradigm": "ylabel_xalign= -align <align>", "examples": [{"query": "How to set the horizontal alignment of the y-axis label to 3?", "answer": "ylabel_xalign= -align 3"}], "reference": "0) Returns the formatted text for the y-axis label [const] string to_s Returns the string representation of the ruler [const] Annotation transformed (const DTrans t) Transforms the ruler or marker with the given simple transformation [const] Annotation transformed (const DCplxTrans t) Transforms the ruler or marker with the given complex transformation [const] Annotation transformed (const ICplxTrans t) Transforms the ruler or marker with the given complex transformation [const] int xlabel_xalign Gets the horizontal alignment type of the x axis label void xlabel_xalign= (int align) Sets the horizontal alignment type of the x axis label [const] int xlabel_yalign Gets the vertical alignment type of the x axis label void xlabel_yalign= (int align) Sets the vertical alignment type of the x axis label [const] int ylabel_xalign Gets the horizontal alignment type of the y axis label void ylabel_xalign= (int align) Sets the horizontal alignment type of the y axis label [const] int ylabel_yalign Gets the vertical alignment type of the y axis label void ylabel_yalign= (int align) Sets the vertical alignment type of the y axis label", "source": "klayout"}
{"script_name": "Flatten", "definition_description": "This script flattens the design hierarchy unless specified with the -noflatten flag.", "parameters": {"noflatten": "If specified, disables the flattening of the design hierarchy"}, "values": "noflatten: <disable flattening>", "script_paradigm": "flatten [unless -noflatten]", "examples": [{"query": "How to flatten the design hierarchy?", "answer": "flatten"}, {"query": "How to flatten the design hierarchy without flattening the submodules?", "answer": "flatten -noflatten"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "MapRAM", "definition_description": "This script maps memory cells in the design using the specified library map files.", "parameters": {"memory_libmap": "The library file for mapping memory blocks", "no_auto_block": "Disables automatic block generation if specified"}, "values": "memory_libmap: <+/efinix/brams.txt>, no_auto_block: <disable automatic block generation>", "script_paradigm": "memory_libmap -lib <memory_libmap> [-no-auto-block]", "examples": [{"query": "How to map memory using the brams library?", "answer": "memory_libmap -lib +/efinix/brams.txt"}, {"query": "How to map memory and disable auto block generation?", "answer": "memory_libmap -lib +/efinix/brams.txt -no-auto-block"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "Techmap", "definition_description": "This script applies a technology mapping transformation to the design using specified map files.", "parameters": {"map_files": "The files that contain the mapping definitions"}, "values": "map_files: <+/techmap.v, +/efinix/arith_map.v>", "script_paradigm": "techmap -map <map_files>", "examples": [{"query": "How to apply techmap with arith_map and techmap files?", "answer": "techmap -map +/techmap.v -map +/efinix/arith_map.v"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "DffLegalize", "definition_description": "This script legalizes the DFF cells in the design, replacing unsupported types with valid ones.", "parameters": {"cells": "The cells to be legalized, specified with wildcards"}, "values": "cells: <$_DFFE_????_, $_SDFFE_????_, $_SDFFCE_????_, $_DLATCH_?_>", "script_paradigm": "dfflegalize -cell <cells>", "examples": [{"query": "How to legalize DFF cells in the design?", "answer": "dfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -cell $_DLATCH_?_ x"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "MapFFRAM", "definition_description": "This script applies optimizations and mapping transformations to memory elements and flip-flops.", "parameters": {"opt_flags": "Optimization flags to control the mapping process"}, "values": "opt_flags: <undriven, fine, fast, mux_undef>", "script_paradigm": "opt -undriven -fine\nmemory_map\nopt -undriven -fine", "examples": [{"query": "How to apply optimizations to flip-flops and memory?", "answer": "opt -undriven -fine\nmemory_map\nopt -undriven -fine"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "Polygon", "definition_description": "This class represents a polygon with an outer hull and zero or more holes, where the hull contour is oriented clockwise and the holes are counterclockwise.", "parameters": {"hull": "An array of points that defines the outer boundary of the polygon.", "hole1, hole2, ...": "Arrays of points that define the holes within the polygon (optional)."}, "values": "hull: [RBA::Point::new(x, y), ...], hole: [RBA::Point::new(x, y), ...]", "script_paradigm": "RBA::Polygon::new(hull) \n poly.insert_hole(hole1) \n poly.insert_hole(hole2)", "examples": [{"query": "How to create a polygon with an outer contour and two holes?", "answer": "hull = [ RBA::Point::new(0, 0), RBA::Point::new(6000, 0), RBA::Point::new(6000, 3000), RBA::Point::new(0, 3000) ]\nhole1 = [ RBA::Point::new(1000, 1000), RBA::Point::new(2000, 1000), RBA::Point::new(2000, 2000), RBA::Point::new(1000, 2000) ]\nhole2 = [ RBA::Point::new(3000, 1000), RBA::Point::new(4000, 1000), RBA::Point::new(4000, 2000), RBA::Point::new(3000, 2000) ]\npoly = RBA::Polygon::new(hull)\npoly.insert_hole(hole1)\npoly.insert_hole(hole2)"}, {"query": "How to get the area of a polygon?", "answer": "poly.area  # -> 16000000"}, {"query": "How to get the bounding box of a polygon?", "answer": "poly.bbox  # -> (0,0;6000,3000)"}], "reference": "KLayout Documentation (Qt 5): Main Index » Class Index » API reference - Class Polygon\n\nAPI reference - Class Polygon\n\nNotation used in Ruby API documentation\n\nModule: db\n\nDescription: A polygon class\n\nPublic constructors\n\nPublic methods\n\nPublic static methods and constants\n\nDeprecated methods (protected, public, static, non-static and constructors)\n\nDetailed description\n\nA polygon consists of an outer hull and zero to many holes. Each contour consists of several points. The point list is normalized such that the leftmost, lowest point is the first one. The orientation is normalized such that the orientation of the hull contour is clockwise, while the orientation of the holes is counterclockwise.\n\nIt is in no way checked that the contours are not overlapping. This must be ensured by the user of the object when filling the contours.\n\nA polygon can be asked for the number of holes using the holes method. each_point_hull delivers the points of the hull contour. each_point_hole delivers the points of a specific hole. each_edge delivers the edges (point-to-point connections) of both hull and holes. bbox delivers the bounding box, area the area and perimeter the perimeter of the polygon.\n\nHere's an example of how to create a polygon:\n\nhull =  [ RBA::Point::new(0, 0),       RBA::Point::new(6000, 0), \n          RBA::Point::new(6000, 3000), RBA::Point::new(0, 3000) ]\nhole1 = [ RBA::Point::new(1000, 1000), RBA::Point::new(2000, 1000), \n          RBA::Point::new(2000, 2000), RBA::Point::new(1000, 2000) ]\nhole2 = [ RBA::Point::new(3000, 1000), RBA::Point::new(4000, 1000), \n          RBA::Point::new(4000, 2000), RBA::Point::new(3000, 2000) ]\npoly = RBA::Polygon::new(hull)\npoly.insert_hole(hole1)\npoly.insert_hole(hole2)\n\n# ask the polygon for some properties\npoly.holes      # -> 2\npoly.area       # -> 16000000\npoly.perimeter  # -> 26000\npoly.bbox       # -> (0,0;6000,3000)\n\nThe Polygon class stores coordinates in integer format. A class that stores floating-point coordinates is DPolygon.\n\nSee The Database API for more details about the database objects.\n\nPublic constructors\n\nnew Polygon ptr new (const DPolygon dpolygon) Creates an integer coordinate polygon from a floating-point coordinate polygon new Polygon ptr new Creates an empty (invalid) polygon new Polygon ptr new (const SimplePolygon sp) Creates a polygon from a simple polygon new Polygon ptr new (Point[] pts, bool raw = false) Creates a polygon from a point array for the hull new Polygon ptr new (const Box box) Creates a polygon from a box\n\nPublic methods", "source": "klayout"}
{"script_name": "load.tcl", "definition_description": "This script loads the necessary files and sets up the layout for verification in Magic.", "parameters": {"lef_file": "The path to the LEF file for standard cell definitions", "def_file": "The path to the DEF file for routed design", "grid_size_x": "The grid size in the X direction for layout", "grid_size_y": "The grid size in the Y direction for layout"}, "values": "lef_file: /usr/local/share/qflow/tech/osu035/osu035_stdcells.lef, def_file: map9v3.def, grid_size_x: 1.6um, grid_size_y: 2.0um", "script_paradigm": "lef read <lef_file>\ndef read <def_file>\ngrid <grid_size_x> <grid_size_y>", "examples": [{"query": "How to load a LEF file and a DEF file with a 1.6um x 2.0um grid?", "answer": "lef read /usr/local/share/qflow/tech/osu035/osu035_stdcells.lef\ndef read map9v3.def\ngrid 1.6um 2.0um"}], "reference": "Verifying the Layout with Netgen\n\nA synthesized circuit is supposed to be correct by design, but it is always a good idea to check the circuit both by LVS and by simulation.\n\nTo run this tutorial, you will need to have the tool netgen 1.5 installed on your system. Make sure that it is compiled with Tcl/Tk support, or else you will have to refer to the netgen documentation for doing a comparison without using the \"lvs\" command.\n\nAfter running qflow through the detailed routing, use Magic to read in the circuit. There is a limitation of the layout tool in which it understands of the cell bounding boxes defined in the LEF file for standard cell placement, but this understanding does not transfer to layout files in the standard database format. The best way to ensure that the physical layout view matches the abstract LEF view is to do the following:\n\nMagic will need access to the technology file for the process used by the OSU035 standard cells, which is the scalable-CMOS rules from MOSIS with a few modifications. The modified technology file is included with the qflow distribution. More recent revisions of qflow (from 1.0.13) will install a startup script \".magicrc\" in the layout directory. This startup script is responsible for loading the correct technology file from the qflow install directory. For versions of qflow prior to 1.0.13, you will need to copy the techfile SCN4M_SUBM.20.tech from the qflow install directory (/usr/local/share/qflow/tech/osu035/) to the local layout directory.\n\nStart Magic, for example, \"magic -d XR\" in the layout directory (or just \"magic\" if you don't have libcairo support).\n\nLoad the abstract LEF views, using:\n\nlef read /usr/local/share/qflow/tech/osu035/osu035_stdcells.lef\n\nThere will be a number of warnings related to statements that the LEF reader in magic doesn't handle; these can be ignored.\n\nLoad the routed DEF file, using:\n\ndef read map9v3.def\n\nIf you wish to see the routing grid, use\n\ngrid 1.6um 2.0um\n\nAll of the steps from the \"lef read\" command up to and including the \"grid\" command are included in the script file \"load.tcl\" in the download sections at the top of the tutorial. If you downloaded this file, put it in the layout directory. Then, start Magic and type into the console:\n\nsource load.tcl\n\nand proceed from the next step.\n\nSave the top-level design. In this case, you do not want to save the abstract views, although it can be helpful to keep the database versions of the abstract files in a separate directory and use the \"addpath\" command (see below) to switch between the abstract and physical views. To write the database for just the top-level cell, do:\n\nwriteall force map9v3\n\nThe circuit above was routed with qflow version 1.1.55 using power striping as described above, and routing on the first three layers only.\n\nNow quit Magic to lose the abstract cell views (say \"Yes\" to the prompt, you really do want to exit!)\n\nIf you have downloaded the OSU standard cell set, skip this step and go to the next one. Otherwise, download the file osu035_stdcells.gds2 from the download list at the top of the page (put it in the layout subdirectory). I recommend downloading the OSU standard cell set from the OSU website to get the most up-to-date version. However, the version posted here will suffice for the tutorial.\n\nBecause there are a lot of standard cells, you may want to keep these layout views in a subdirectory of the layout directory, so from the layout directory, do:\n\nmkdir digital cp .magicrc digital cd digital\n\nStart magic without specifying a file to load:\n\nmagic -d XR\n\nThen load the GDS file, and save all of the standard cells:\n\ngds read osu035_stdcells.gds2 writeall force quit", "source": "qflow"}
{"script_name": "save_top_level.tcl", "definition_description": "This script saves the top-level design after loading the layout and standard cells.", "parameters": {"top_level_cell": "The name of the top-level cell to be saved"}, "values": "top_level_cell: map9v3", "script_paradigm": "writeall force <top_level_cell>", "examples": [{"query": "How to save the top-level cell after loading the layout?", "answer": "writeall force map9v3"}], "reference": "Verifying the Layout with Netgen\n\nA synthesized circuit is supposed to be correct by design, but it is always a good idea to check the circuit both by LVS and by simulation.\n\nTo run this tutorial, you will need to have the tool netgen 1.5 installed on your system. Make sure that it is compiled with Tcl/Tk support, or else you will have to refer to the netgen documentation for doing a comparison without using the \"lvs\" command.\n\nAfter running qflow through the detailed routing, use Magic to read in the circuit. There is a limitation of the layout tool in which it understands of the cell bounding boxes defined in the LEF file for standard cell placement, but this understanding does not transfer to layout files in the standard database format. The best way to ensure that the physical layout view matches the abstract LEF view is to do the following:\n\nMagic will need access to the technology file for the process used by the OSU035 standard cells, which is the scalable-CMOS rules from MOSIS with a few modifications. The modified technology file is included with the qflow distribution. More recent revisions of qflow (from 1.0.13) will install a startup script \".magicrc\" in the layout directory. This startup script is responsible for loading the correct technology file from the qflow install directory. For versions of qflow prior to 1.0.13, you will need to copy the techfile SCN4M_SUBM.20.tech from the qflow install directory (/usr/local/share/qflow/tech/osu035/) to the local layout directory.\n\nStart Magic, for example, \"magic -d XR\" in the layout directory (or just \"magic\" if you don't have libcairo support).\n\nLoad the abstract LEF views, using:\n\nlef read /usr/local/share/qflow/tech/osu035/osu035_stdcells.lef\n\nThere will be a number of warnings related to statements that the LEF reader in magic doesn't handle; these can be ignored.\n\nLoad the routed DEF file, using:\n\ndef read map9v3.def\n\nIf you wish to see the routing grid, use\n\ngrid 1.6um 2.0um\n\nAll of the steps from the \"lef read\" command up to and including the \"grid\" command are included in the script file \"load.tcl\" in the download sections at the top of the tutorial. If you downloaded this file, put it in the layout directory. Then, start Magic and type into the console:\n\nsource load.tcl\n\nand proceed from the next step.\n\nSave the top-level design. In this case, you do not want to save the abstract views, although it can be helpful to keep the database versions of the abstract files in a separate directory and use the \"addpath\" command (see below) to switch between the abstract and physical views. To write the database for just the top-level cell, do:\n\nwriteall force map9v3\n\nThe circuit above was routed with qflow version 1.1.55 using power striping as described above, and routing on the first three layers only.\n\nNow quit Magic to lose the abstract cell views (say \"Yes\" to the prompt, you really do want to exit!)\n\nIf you have downloaded the OSU standard cell set, skip this step and go to the next one. Otherwise, download the file osu035_stdcells.gds2 from the download list at the top of the page (put it in the layout subdirectory). I recommend downloading the OSU standard cell set from the OSU website to get the most up-to-date version. However, the version posted here will suffice for the tutorial.\n\nBecause there are a lot of standard cells, you may want to keep these layout views in a subdirectory of the layout directory, so from the layout directory, do:\n\nmkdir digital cp .magicrc digital cd digital\n\nStart magic without specifying a file to load:\n\nmagic -d XR\n\nThen load the GDS file, and save all of the standard cells:\n\ngds read osu035_stdcells.gds2 writeall force quit", "source": "qflow"}
{"script_name": "Application.execute", "definition_description": "This method runs the application. It is called implicitly when the application is started, but can also be used explicitly for running Ruby scripts.", "parameters": {}, "values": "None", "script_paradigm": "Application#execute", "examples": [{"query": "How to run the application explicitly?", "answer": "Application#execute"}], "reference": "KLayout Documentation (Qt 5): Main Index » Programming scripts » The Application API\n\nThe Application API\n\nThe Application class\n\nThe MainWindow class\n\nThe LayoutView class\n\nThe CellView class\n\nThe Image class\n\nThe Annotation class\n\nThe Marker class\n\nThe Plugin and PluginFactory classes\n\nThis section covers the basic application API. The application API consists of the main application class and several classes that represent the user interface. This sections presents a selection of classes that make up the application API. These classes provide the main entry points into the application API. Further classes are documented in RBA Class Index.\n\nAll classes discussed herein are contained in the RBA namespace. In you code you either have to use qualified names (i.e. RBA::Application) or include the RBA module in you macro's namespace.\n\nThe Application class\n\nThe Application class is documented in detail in Application. It represents the application and because there is just one application, there also is just one instance of the application object. That instance can be obtained through the \"instance\" class method:\n\nApplication::instance\n\nThe application object is the main entry point into the API. It offers several methods and attributes. In particular:\n\nApplication#application_data_path: returns the user-local storage path. This is where KLayout saves user-specific files, for example the configuration file.\n\nApplication#execute: runs the application. Normally, this method is called implicitly when the application is started. It is possible to use KLayout as a Ruby interpreter by supplying a Ruby script on the command line with the \"-r\" option. Such scripts must run the application explicitly if they want to.\n\nApplication#exit: exits the application. This method unconditionally terminates the application in a clean way.\n\nApplication#get_config and Application#set_config: read and write the configuration database. The configuration database is a storage of name/value pairs which is stored in the configuration file. These methods can be used to manipulate that storage. Use the Application#get_config_names method to retrieve the names of the configuration parameters stored inside the configuration database. Use the Application#commit_config method to activate settings that have been made with \"set_config\".\n\nApplication#inst_path: returns the installation path. That is where the executable is located.\n\nApplication#is_editable?: returns true, if KLayout runs in editable mode.\n\nApplication#klayout_path: returns the KLAYOUT_PATH value. This is the search path where KLayout looks for library files or macros. This method delivers the application data path and can be used to look up files required by the macro.\n\nApplication#main_window: delivers the MainWindow object which represents the application's main window. See below for a description of that class.\n\nApplication#process_events: process pending events. If that method is called periodically during long operations, the application will be able to process events and thus handle clicks on a \"Stop\" button for example. Please note that calling this method is not safe in every context, because not every execution context is reentrant.\n\nApplication#read_config and Application#write_config: reads and writes the configuration database from a file.\n\nApplication#version: delivers KLayout's version string. This string can be used to switch the implementation of a script depending on KLayout's version.\n\nThe MainWindow class\n\nThe MainWindow class is documented in detail in MainWindow. It represents the main application window. The main window instance can be obtained with:\n\nApplication::instance.main_window\n\nThe main window object is the entry point to all user-interface related objects. It offers a couple of methods. In particular:\n\nMainWindow#cancel: cancels any pending operation (i.e. dragging of an object in move mode) and resets the mode to the default mode (Select). Use this method to establish a known user interface state.", "source": "klayout"}
{"script_name": "restructure", "definition_description": "This script restructures the design in either area or delay mode based on the selected target. It optimizes the design according to area or timing requirements.", "parameters": {"slack_threshold": "The setup timing slack value below which timing paths need to be analyzed for restructuring. Default is 0.", "depth_threshold": "The path depth above which a timing path is considered for restructuring. Default is 16.", "target": "Defines the focus of restructuring, either 'area' or 'delay'. Default is 'area'.", "abc_logfile": "The output file to save ABC logs.", "liberty_file": "The liberty file containing the description of cells used in the design. Passed to ABC for processing.", "tielo_port": "The pin name for the TIELO port, used in the restructuring process.", "tiehi_port": "The pin name for the TIEHI port, used in the restructuring process.", "work_dir": "The directory for storing temporary files. Defaults to the current working directory if not provided."}, "values": "slack_threshold: <float>, depth_threshold: <integer>, target: <area|delay>, abc_logfile: <file_path>, liberty_file: <file_path>, tielo_port: <pin_name>, tiehi_port: <pin_name>, work_dir: <directory_path>", "script_paradigm": "restructure -liberty_file <liberty_file> -target <target> -tielo_port <tielo_port> -tiehi_port <tiehi_port> [-slack_threshold <slack_threshold>] [-depth_threshold <depth_threshold>] [-abc_logfile <abc_logfile>] [-work_dir <work_dir>]", "examples": [{"query": "How to restructure in area mode with a specific liberty file and tie ports?", "answer": "restructure -liberty_file ckt.lib -target area -tielo_port ABC -tiehi_port DEF"}, {"query": "How to restructure in delay mode with slack threshold and depth threshold?", "answer": "restructure -liberty_file ckt.lib -target delay -tielo_port ABC -tiehi_port DEF -slack_threshold 1 -depth_threshold 2"}], "reference": "title: restructure(2)\ndate: 24/09/08\n\nNAME\nrestructure - restructure\nSYNOPSIS\nrestructure \n    [-slack_threshold slack_val]\n    [-depth_threshold depth_threshold]\n    [-target area|delay]\n    [-abc_logfile logfile]\n    [-liberty_file liberty_file]\n    [-tielo_port  tielo_pin_name]\n    [-tiehi_port tiehi_pin_name]\n    [-work_dir work_dir]\nDESCRIPTION\nRestructuring can be done in two modes: area or delay.\n\n\nMethod 1: Area Mode\nExample: restructure -liberty_file ckt.lib -target area -tielo_pin ABC -tiehi_pin DEF\n\n\nMethod 2: Timing Mode\nExample: restructure -liberty_file ckt.lib -target delay -tielo_pin ABC -tiehi_pin DEF -slack_threshold 1 -depth_threshold 2\n\n\nOPTIONS\n-liberty_file:  Liberty file with description of cells used in design. This is passed to ABC.\n-target:  Either area or delay. In area mode, the focus is area reduction, and timing may degrade. In delay mode, delay is likely reduced, but the area may increase. The default value is area.\n-slack_threshold:  Specifies a (setup) timing slack value below which timing paths need to be analyzed for restructuring. The default value is 0, and the allowed values are floats [0, MAX_FLOAT].\n-depth_threshold:  Specifies the path depth above which a timing path would be considered for restructuring. The default value is 16, and the allowed values are [0, MAX_INT].\n-abc_logfile:  Output file to save abc logs to.\n-work_dir:  Name of the working directory for temporary files. If not provided, run directory would be used.\nARGUMENTS\nThis command has no arguments.\nEXAMPLES\nSEE ALSO", "source": "OpenROAD"}
{"script_name": "EdgePairs", "definition_description": "This script creates a hierarchical edge pair collection from shapes in a specified layout layer, supporting hierarchical operations. The transformation is useful to scale to a specific database unit.", "parameters": {"layout": "The layout object containing the shapes", "cell": "The index of the initial cell in the layout", "layer": "The index of the layer from which shapes will be taken", "dbu": "The target database unit for scaling (optional, defaults to 1)"}, "values": "layout: <layout_object>, cell: <cell_index>, layer: <layer_index>, dbu: <target_database_unit>", "script_paradigm": "r = RBA::EdgePairs::new(layout.begin_shapes(cell, layer), RBA::ICplxTrans::new(layout.dbu / dbu))", "examples": [{"query": "How to create an edge pair collection with a scaling transformation to a target database unit?", "answer": "r = RBA::EdgePairs::new(layout.begin_shapes(cell, layer), RBA::ICplxTrans::new(layout.dbu / dbu))"}, {"query": "How to create a basic edge pair collection without scaling?", "answer": "r = RBA::EdgePairs::new(layout.begin_shapes(cell, layer))"}], "reference": "The transformation is useful to scale to a specific database unit for example.\nEdge pairs in layout objects are somewhat special as most formats don't support reading or writing of edge pairs. Still they are useful objects and can be created and manipulated inside layouts. layout = ... # a layout\ncell   = ... # the index of the initial cell\nlayer  = ... # the index of the layer from where to take the shapes from\ndbu    = 0.1 # the target database unit\nr = RBA::EdgePairs::new(layout.begin_shapes(cell, layer), RBA::ICplxTrans::new(layout.dbu / dbu)) This constructor has been introduced in version 0.26. Python specific notes: This method is the default initializer of the object. (7) Signature : [static] new EdgePairs ptr new (const RecursiveShapeIterator shape_iterator, DeepShapeStore dss) Description : Creates a hierarchical edge pair collection from an original layer This constructor creates an edge pair collection from the shapes delivered by the given recursive shape iterator.\nThis version will create a hierarchical edge pair collection which supports hierarchical operations.\nEdge pairs in layout objects are somewhat special as most formats don't support reading or writing of edge pairs. Still they are useful objects and can be created and manipulated inside layouts. dss    = RBA::DeepShapeStore::new\nlayout = ... # a layout\ncell   = ... # the index of the initial cell\nlayer  = ... # the index of the layer from where to take the shapes from\nr = RBA::EdgePairs::new(layout.begin_shapes(cell, layer)) This constructor has been introduced in version 0.26. Python specific notes: This method is the default initializer of the object. (8) Signature : [static] new EdgePairs ptr new (const RecursiveShapeIterator shape_iterator, DeepShapeStore dss, const ICplxTrans trans) Description : Creates a hierarchical edge pair collection from an original layer with a transformation This constructor creates an edge pair collection from the shapes delivered by the given recursive shape iterator.\nThis version will create a hierarchical edge pair collection which supports hierarchical operations.\nThe transformation is useful to scale to a specific database unit for example.\nEdge pairs in layout objects are somewhat special as most formats don't support reading or writing of edge pairs. Still they are useful objects and can be created and manipulated inside layouts. dss    = RBA::DeepShapeStore::new\nlayout = ... # a layout\ncell   = ... # the index of the initial cell\nlayer  = ... # the index of the layer from where to take the shapes from\ndbu    = 0.1 # the target database unit", "source": "klayout"}
{"script_name": "Yosys Verilog Synthesis", "definition_description": "This script performs synthesis of Verilog code to generate optimized gate-level representations for FPGAs and ASICs, utilizing ABC for logic optimization and LUT/cell mapping.", "parameters": {"verilog_file": "The Verilog file to be synthesized", "target_device": "The target device for the synthesis (e.g., Xilinx, Lattice)", "optimization_passes": "The number of coarse- and fine-grained optimization passes to be applied"}, "values": "verilog_file: <file.v>, target_device: <xilinx_7_series>, optimization_passes: <5>", "script_paradigm": "yosys -s <verilog_file> -target <target_device> -passes <optimization_passes>", "examples": [{"query": "How to synthesize a Verilog file for a Xilinx 7-series device with 3 optimization passes?", "answer": "yosys -s design.v -target xilinx_7_series -passes 3"}, {"query": "How to perform synthesis for a Lattice FPGA with 5 optimization passes?", "answer": "yosys -s design.v -target lattice -passes 5"}], "reference": "enabling downstream experiments to be made with larger and\nmore complex benchmarks not otherwise supported.\nPlace-and-route: Versatile Place and Route (VPR) has been\na mainstay of academic research (and even a number of\ncommercial ventures!) since its inception over 20 years ago, and\nis packaged as part of the VTR project [1]. VTR architectures\nare described theoretically using the XML format, detailing\nthe (proportional) makeup and layout of soft and hard blocks\non the targeted FPGA, using architectural parameters such as\nnumber of LUT inputs, as well as their local and global routing\nconnectivities. Importantly, and in contrast to nextpnr and to\nvendor tools, VPR’s ability to target procedurally generated\narchitectures enables new architectures to be designed and limit\nstudies to be made — for example, to measure architectural\nefﬁciency by determining the smallest FPGA that a benchmark\ncan ﬁt on, or to quantify the performance of routing algorithms\nby determining the minimum routing channel width necessary\n— studies that cannot be made when supporting only a ﬁxed\nset of discretely-sized devices.\nCommercial architecture support: A number of projects\nexist for open-source support of real-world devices. These\ninclude VTR-to-Bitstream [3] that overrides VTR’s procedural\ncapabilities with actual device data to support a Xilinx Virtex-6\ndevice, as well as frameworks such as RapidSmith [5] that\nprovide a sandbox, inclusive of simple packing, placement and\nrouting algorithms, for experimenting with multiple Xilinx de-\nvice families. However, such projects are not solely the domain\nof academics as evidenced by RapidWright [6] from Xilinx\nResearch Labs that provides an “escape-hatch” into Vivado.\nIII. YOSYS – VERILOG SYNTHESIS\nYosys [7] is an open-source framework for Verilog synthesis\nand veriﬁcation. It supports all commonly-used synthesisable\nfeatures of Verilog-2005, and can target both FPGAs and\nASICs. Yosys uses ABC [8] for logic optimisation and LUT/cell\nmapping; combined with custom coarse-grained optimisations\nand dedicated passes for inferring and mapping block- and\ndistributed-RAM, ﬂip-ﬂops and arithmetic structures.\nA typical FPGA ﬂow, after logic elaboration, would perform\nsome coarse-grain optimisations and map the results to a set of\ngeneric hard-logic cells. Generic passes are then used to infer\nblock-RAM, ﬂip-ﬂops supporting clock-enables and set-resets,\narithmetic logic and more, followed by architecture-speciﬁc\ntechnology mapping. Any remaining coarse-grain cells are\nconverted to gates by Yosys and then mapped to LUTs by\nABC. Further architecture-speciﬁc rules then map generic LUT\nand ﬂip-ﬂop cells to the target device’s primitives.\nCoarse- and ﬁne-grained cells are mapped (even recursively)\naccording to a Verilog description. As an example, Figure 2\nshows how a generic 8-input LUT can be transformed into two\nLUT7s plus a dedicated multiplexer, and from there onto a total\nof four LUT6s and three muxes when synthesising for Xilinx\n7-series. This capability gives Yosys a high degree of ﬂexibility,\nwhile reducing the effort for targeting new architectures. Yosys\ncurrently supports synthesis for the Xilinx 7-series, Lattice\n// Apply these mapping rules to Yosys’ generic LUT cells\nmodule \\$lut (A, Y);\nparameter WIDTH = 0; // Number of LUT inputs\nparameter LUT = 0;\n// LUT mask contents\ninput [WIDTH-1:0] A; // LUT input signals\noutput Y;\n// LUT output signal\ngenerate\nwire T0, T1;\nif (WIDTH == 8) begin\n// Map a generic 8-input LUT to two generic 7-inputs\n\\$lut #(.WIDTH(7), .LUT(LUT[127:0]) fpga_lut_0 (\n.O(T0), .A(A[6:0]));\n\\$lut #(.WIDTH(7), .LUT(LUT[255:128])) fpga_lut_1 (\n.O(T1), .A(A[6:0]));\n// ... plus a target-specific mux primitive\nMUXF8 fpga_mux_0 (.O(Y), .I0(T0), .I1(T1), .S(A[7]));\nend else if (WIDTH == 7) begin\n// Decompose a generic 7-input LUT into two target-\nspecific 6-input LUTs, plus another specialised mux\nLUT6 #(.INIT(LUT[63:0])) fpga_lut_0 (.O(T0),\n.I0(A[0]), .I1(A[1]), .I2(A[2]),\n.I3(A[3]), .I4(A[4]), .I5(A[5]));\nLUT6 #(.INIT(LUT[127:64])) fpga_lut_1 (.O(T1),\n.I0(A[0]), .I1(A[1]), .I2(A[2]),", "source": "yosys_hq"}
{"script_name": "Timing Analysis with Multiple Process Corners", "definition_description": "This script performs timing analysis across different process corners and applies derating for early and late timing conditions.", "parameters": {"wc": "The slow process corner library file.", "typ": "The typical process corner library file.", "bc": "The fast process corner library file."}, "values": "wc: <example1_slow.lib>, typ: <example1_typ.lib>, bc: <example1_fast.lib>", "script_paradigm": "define_corners <wc> <typ> <bc>\nread_liberty -corner <wc> <example1_slow.lib>\nread_liberty -corner <typ> <example1_typ.lib>\nread_liberty -corner <bc> <example1_fast.lib>\nread_verilog <example1.v>\nlink_design <top>\nset_timing_derate -early 0.9\nset_timing_derate -late 1.1\ncreate_clock -name <clk> -period 10 {clk1 clk2 clk3}\nset_input_delay -clock <clk> 0 {in1 in2}\nreport_checks -path_delay min_max\nreport_checks -corner <typ>", "examples": [{"query": "How to perform timing analysis with three process corners (wc, typ, bc)?", "answer": "define_corners wc typ bc\nread_liberty -corner wc example1_slow.lib\nread_liberty -corner typ example1_typ.lib\nread_liberty -corner bc example1_fast.lib\nread_verilog example1.v\nlink_design top\nset_timing_derate -early 0.9\nset_timing_derate -late 1.1\ncreate_clock -name clk -period 10 {clk1 clk2 clk3}\nset_input_delay -clock clk 0 {in1 in2}\nreport_checks -path_delay min_max\nreport_checks -corner typ"}], "reference": "read_liberty example1_slow.lib\nread_verilog example1.v\nlink_design top\nread_sdf example1.sdf\ncreate_clock -name clk -period 10 {clk1 clk2 clk3}\nset_input_delay -clock clk 0 {in1 in2}\nreport_checks\nThis example can be found in examples/sdf_delays.tcl.\nTiming Analysis with Multiple Process Corners\nAn example command script using three process corners and +/-10% min/max derating is shown below.\ndefine_corners wc typ bc\nread_liberty -corner wc  example1_slow.lib\nread_liberty -corner typ example1_typ.lib\nread_liberty -corner bc  example1_fast.lib\nread_verilog example1.v\nlink_design top\nset_timing_derate -early 0.9\nset_timing_derate -late 1.1\ncreate_clock -name clk -period 10 {clk1 clk2 clk3}\nset_input_delay -clock clk 0 {in1 in2}\nreport_checks -path_delay min_max\nreport_checks -corner typ\nThis example can be found in examples/spef_parasitics.tcl. Other examples can be found in the \nexamples directory.\nPower Analysis\nOpenSTA also supports static power analysis with the report_power command. Probabalistic switching \nactivities are propagated from the input ports to determine switching activities for internal pins.\nread_liberty sky130hd_tt.lib\nread_verilog gcd_sky130hd.v\nlink_design gcd\nread_sdc gcd_sky130hd.sdc\nread_spef gcd_sky130hd.spef\nset_power_activity -input -activity 0.1\nset_power_activity -input_port reset -activity 0\nreport_power\nIn this example the activity for all inputs is set to 0.1, and then the activity for the reset signal is set to zero \nbecause it does not switch during steady state operation.", "source": "OpenSTA"}
{"script_name": "Power Analysis", "definition_description": "This script performs static power analysis by calculating switching activities and generating power reports.", "parameters": {"input_activity": "The general activity level for input signals.", "reset_activity": "The activity level for the reset signal."}, "values": "input_activity: <0.1>, reset_activity: <0>", "script_paradigm": "read_liberty <sky130hd_tt.lib>\nread_verilog <gcd_sky130hd.v>\nlink_design <gcd>\nread_sdc <gcd_sky130hd.sdc>\nread_spef <gcd_sky130hd.spef>\nset_power_activity -input -activity <0.1>\nset_power_activity -input_port reset -activity <0>\nreport_power", "examples": [{"query": "How to perform power analysis with a specific input activity and reset signal activity?", "answer": "read_liberty sky130hd_tt.lib\nread_verilog gcd_sky130hd.v\nlink_design gcd\nread_sdc gcd_sky130hd.sdc\nread_spef gcd_sky130hd.spef\nset_power_activity -input -activity 0.1\nset_power_activity -input_port reset -activity 0\nreport_power"}], "reference": "read_liberty example1_slow.lib\nread_verilog example1.v\nlink_design top\nread_sdf example1.sdf\ncreate_clock -name clk -period 10 {clk1 clk2 clk3}\nset_input_delay -clock clk 0 {in1 in2}\nreport_checks\nThis example can be found in examples/sdf_delays.tcl.\nTiming Analysis with Multiple Process Corners\nAn example command script using three process corners and +/-10% min/max derating is shown below.\ndefine_corners wc typ bc\nread_liberty -corner wc  example1_slow.lib\nread_liberty -corner typ example1_typ.lib\nread_liberty -corner bc  example1_fast.lib\nread_verilog example1.v\nlink_design top\nset_timing_derate -early 0.9\nset_timing_derate -late 1.1\ncreate_clock -name clk -period 10 {clk1 clk2 clk3}\nset_input_delay -clock clk 0 {in1 in2}\nreport_checks -path_delay min_max\nreport_checks -corner typ\nThis example can be found in examples/spef_parasitics.tcl. Other examples can be found in the \nexamples directory.\nPower Analysis\nOpenSTA also supports static power analysis with the report_power command. Probabalistic switching \nactivities are propagated from the input ports to determine switching activities for internal pins.\nread_liberty sky130hd_tt.lib\nread_verilog gcd_sky130hd.v\nlink_design gcd\nread_sdc gcd_sky130hd.sdc\nread_spef gcd_sky130hd.spef\nset_power_activity -input -activity 0.1\nset_power_activity -input_port reset -activity 0\nreport_power\nIn this example the activity for all inputs is set to 0.1, and then the activity for the reset signal is set to zero \nbecause it does not switch during steady state operation.", "source": "OpenSTA"}
{"script_name": "GlobalRouter", "definition_description": "This script performs global routing tasks and manages various related operations in the OpenROAD tool.", "parameters": {"parameter1": "Description of parameter1", "parameter2": "Description of parameter2"}, "values": "parameter1: <value>, parameter2: <value>", "script_paradigm": "global_router -param1 <parameter1> -param2 <parameter2>", "examples": [{"query": "How to run global router with parameters?", "answer": "global_router -param1 value1 -param2 value2"}], "reference": "| GRT | 0019 | GlobalRouter.cpp:3063 | INFO |- |\n| GRT | 0020 | GlobalRouter.cpp:3785 | INFO |- |\n| GRT | 0021 | GlobalRouter.cpp:3786 | INFO |- |\n| GRT | 0022 | GlobalRouter.cpp:3787 | INFO |- |\n| GRT | 0023 | GlobalRouter.cpp:3788 | INFO |- |\n| GRT | 0025 | MakeWireParasitics.cpp:240 | WARN |- |\n| GRT | 0026 | MakeWireParasitics.cpp:338 | WARN |- |\n| GRT | 0027 | RepairAntennas.cpp:463 | WARN |- |\n| GRT | 0028 | GlobalRouter.cpp:3554 | ERROR |- |\n| GRT | 0029 | GlobalRouter.cpp:3161 | ERROR |- |\n| GRT | 0030 | GlobalRouter.cpp:1562 | WARN |- |\n| GRT | 0031 | GlobalRouter.cpp:2363 | WARN |- |\n| GRT | 0033 | GlobalRouter.cpp:2634 | WARN |- |\n| GRT | 0034 | GlobalRouter.cpp:3112 | WARN |- |\n| GRT | 0035 | GlobalRouter.cpp:3144 | WARN |- |\n| GRT | 0036 | GlobalRouter.cpp:3207 | WARN |- |\n| GRT | 0037 | GlobalRouter.cpp:3343 | WARN |- |\n| GRT | 0038 | GlobalRouter.cpp:3500 | WARN |- |\n| GRT | 0039 | GlobalRouter.cpp:3537 | WARN |- |\n| GRT | 0041 | GlobalRouter.cpp:3642 | WARN |- |\n| GRT | 0042 | GlobalRouter.cpp:3232 | ERROR |- |\n| GRT | 0043 | GlobalRouter.cpp:3718 | INFO |- |\n| GRT | 0044 | GlobalRouter.tcl:66 | ERROR |- |\n| GRT | 0045 | GlobalRouter.tcl:361 | ERROR |- |\n| GRT | 0047 | GlobalRouter.tcl:80 | ERROR |- |\n| GRT | 0048 | GlobalRouter.tcl:88 | ERROR |- |\n| GRT | 0051 | GlobalRouter.tcl:231 | ERROR |- |\n| GRT | 0052 | GlobalRouter.tcl:235 | ERROR |- |\n| GRT | 0053 | GlobalRouter.cpp:3800 | INFO |- |\n| GRT | 0054 | GlobalRouter.cpp:369 | INFO |- |\n| GRT | 0055 | GlobalRouter.tcl:246 | ERROR |- |\n| GRT | 0057 | GlobalRouter.tcl:590 | ERROR |- |\n| GRT | 0059 | GlobalRouter.tcl:503 | ERROR |- |\n| GRT | 0062 | GlobalRouter.tcl:546 | ERROR |- |\n| GRT | 0063 | GlobalRouter.tcl:553 | ERROR |- |\n| GRT | 0064 | GlobalRouter.tcl:559 | ERROR |- |\n| GRT | 0065 | GlobalRouter.tcl:563 | ERROR |- |\n| GRT | 0066 | GlobalRouter.tcl:567 | ERROR |- |\n| GRT | 0067 | GlobalRouter.tcl:571 | ERROR |- |\n| GRT | 0068 | RepairAntennas.cpp:188 | ERROR |- |\n| GRT | 0069 | GlobalRouter.tcl:326 | ERROR |- |\n| GRT | 0070 | GlobalRouter.cpp:521 | ERROR |- |\n| GRT | 0071 | GlobalRouter.cpp:1199 | ERROR |- |\n| GRT | 0072 | GlobalRouter.cpp:1417 | ERROR |- |\n| GRT | 0073 | GlobalRouter.tcl:339 | ERROR |- |\n| GRT | 0074 | GlobalRouter.cpp:2108 | ERROR |- |\n| GRT | 0075 | GlobalRouter.cpp:2086 | ERROR |- |\n| GRT | 0076 | GlobalRouter.cpp:2164 | ERROR |- |\n| GRT | 0078 | GlobalRouter.cpp:2248 | ERROR |- |\n| GRT | 0079 | GlobalRouter.cpp:2350 | ERROR |- |\n| GRT | 0080 | GlobalRouter.cpp:2379 | ERROR |- |\n| GRT | 0084 | GlobalRouter.cpp:512 | ERROR |- |\n| GRT | 0085 | GlobalRouter.cpp:507 | ERROR |- |\n| GRT | 0086 | GlobalRouter.cpp:2892 | ERROR |- |\n| GRT | 0088 | GlobalRouter.cpp:2907 | INFO |- |\n| GRT | 0090 | GlobalRouter.cpp:2967 | ERROR |- |\n| GRT | 0094 | GlobalRouter.cpp:3568 | ERROR |- |\n| GRT | 0096 | GlobalRouter.cpp:3852 | INFO |- |\n| GRT | 0101 | FastRoute.cpp:1050 | INFO |- |\n| GRT | 0103 | FastRoute.cpp:1184 | INFO |- |\n| GRT | 0104 | GlobalRouter.tcl:312 | ERROR |- |\n| GRT | 0111 | FastRoute.cpp:1357 | INFO |- |\n| GRT | 0112 | FastRoute.cpp:1358 | INFO |- |\n| GRT | 0113 | FastRoute.cpp:396 | WARN |- |\n| GRT | 0114 | FastRoute.cpp:426 | WARN |- |\n| GRT | 0115 | GlobalRouter.cpp:291 | WARN |- |\n| GRT | 0118 | GlobalRouter.cpp:1750 | ERROR |Helpful Information-Do refer to the GUI guide and global routing debugging tips. |\n| GRT | 0119 | GlobalRouter.cpp:1743 | ERROR |Helpful Information-Do refer to the GUI guide and global routing debugging tips. |\n| GRT | 0120 | heatMapRudy.cpp:122 | WARN |- |\n| GRT | 0122 | RipUp.cpp:450 | ERROR |- |\n| GRT | 0123 | RipUp.cpp:572 | ERROR |- |\n| GRT | 0125 | maze.cpp:820 | ERROR |- |\n| GRT | 0126 | GlobalRouter.cpp:541 | ERROR |- |\n| GRT | 0146 | GlobalRouter.tcl:286 | WARN |- |\n| GRT | 0149 | utility.cpp:2060 | ERROR |- |\n| GRT | 0150 | maze.cpp:1838 | ERROR |- |\n| GRT | 0164 | utility.cpp:1764 | WARN |- |\n| GRT | 0165 | utility.cpp:1778 | WARN |- |\n| GRT | 0166 | utility.cpp:1794 | WARN |- |\n| GRT | 0167 | utility.cpp:1808 | WARN |- |\n| GRT | 0169 | maze.cpp:1020 | ERROR |- |", "source": "OpenROAD"}
{"script_name": "MakeWireParasitics", "definition_description": "This script generates wire parasitics for the design.", "parameters": {"parameter1": "Description of the wire parameter", "parameter2": "Description of the parasitic model"}, "values": "parameter1: <value>, parameter2: <value>", "script_paradigm": "make_wire_parasitics -param1 <parameter1> -param2 <parameter2>", "examples": [{"query": "How to set wire parasitics for a design?", "answer": "make_wire_parasitics -param1 wire1 -param2 model1"}], "reference": "| GRT | 0019 | GlobalRouter.cpp:3063 | INFO |- |\n| GRT | 0020 | GlobalRouter.cpp:3785 | INFO |- |\n| GRT | 0021 | GlobalRouter.cpp:3786 | INFO |- |\n| GRT | 0022 | GlobalRouter.cpp:3787 | INFO |- |\n| GRT | 0023 | GlobalRouter.cpp:3788 | INFO |- |\n| GRT | 0025 | MakeWireParasitics.cpp:240 | WARN |- |\n| GRT | 0026 | MakeWireParasitics.cpp:338 | WARN |- |\n| GRT | 0027 | RepairAntennas.cpp:463 | WARN |- |\n| GRT | 0028 | GlobalRouter.cpp:3554 | ERROR |- |\n| GRT | 0029 | GlobalRouter.cpp:3161 | ERROR |- |\n| GRT | 0030 | GlobalRouter.cpp:1562 | WARN |- |\n| GRT | 0031 | GlobalRouter.cpp:2363 | WARN |- |\n| GRT | 0033 | GlobalRouter.cpp:2634 | WARN |- |\n| GRT | 0034 | GlobalRouter.cpp:3112 | WARN |- |\n| GRT | 0035 | GlobalRouter.cpp:3144 | WARN |- |\n| GRT | 0036 | GlobalRouter.cpp:3207 | WARN |- |\n| GRT | 0037 | GlobalRouter.cpp:3343 | WARN |- |\n| GRT | 0038 | GlobalRouter.cpp:3500 | WARN |- |\n| GRT | 0039 | GlobalRouter.cpp:3537 | WARN |- |\n| GRT | 0041 | GlobalRouter.cpp:3642 | WARN |- |\n| GRT | 0042 | GlobalRouter.cpp:3232 | ERROR |- |\n| GRT | 0043 | GlobalRouter.cpp:3718 | INFO |- |\n| GRT | 0044 | GlobalRouter.tcl:66 | ERROR |- |\n| GRT | 0045 | GlobalRouter.tcl:361 | ERROR |- |\n| GRT | 0047 | GlobalRouter.tcl:80 | ERROR |- |\n| GRT | 0048 | GlobalRouter.tcl:88 | ERROR |- |\n| GRT | 0051 | GlobalRouter.tcl:231 | ERROR |- |\n| GRT | 0052 | GlobalRouter.tcl:235 | ERROR |- |\n| GRT | 0053 | GlobalRouter.cpp:3800 | INFO |- |\n| GRT | 0054 | GlobalRouter.cpp:369 | INFO |- |\n| GRT | 0055 | GlobalRouter.tcl:246 | ERROR |- |\n| GRT | 0057 | GlobalRouter.tcl:590 | ERROR |- |\n| GRT | 0059 | GlobalRouter.tcl:503 | ERROR |- |\n| GRT | 0062 | GlobalRouter.tcl:546 | ERROR |- |\n| GRT | 0063 | GlobalRouter.tcl:553 | ERROR |- |\n| GRT | 0064 | GlobalRouter.tcl:559 | ERROR |- |\n| GRT | 0065 | GlobalRouter.tcl:563 | ERROR |- |\n| GRT | 0066 | GlobalRouter.tcl:567 | ERROR |- |\n| GRT | 0067 | GlobalRouter.tcl:571 | ERROR |- |\n| GRT | 0068 | RepairAntennas.cpp:188 | ERROR |- |\n| GRT | 0069 | GlobalRouter.tcl:326 | ERROR |- |\n| GRT | 0070 | GlobalRouter.cpp:521 | ERROR |- |\n| GRT | 0071 | GlobalRouter.cpp:1199 | ERROR |- |\n| GRT | 0072 | GlobalRouter.cpp:1417 | ERROR |- |\n| GRT | 0073 | GlobalRouter.tcl:339 | ERROR |- |\n| GRT | 0074 | GlobalRouter.cpp:2108 | ERROR |- |\n| GRT | 0075 | GlobalRouter.cpp:2086 | ERROR |- |\n| GRT | 0076 | GlobalRouter.cpp:2164 | ERROR |- |\n| GRT | 0078 | GlobalRouter.cpp:2248 | ERROR |- |\n| GRT | 0079 | GlobalRouter.cpp:2350 | ERROR |- |\n| GRT | 0080 | GlobalRouter.cpp:2379 | ERROR |- |\n| GRT | 0084 | GlobalRouter.cpp:512 | ERROR |- |\n| GRT | 0085 | GlobalRouter.cpp:507 | ERROR |- |\n| GRT | 0086 | GlobalRouter.cpp:2892 | ERROR |- |\n| GRT | 0088 | GlobalRouter.cpp:2907 | INFO |- |\n| GRT | 0090 | GlobalRouter.cpp:2967 | ERROR |- |\n| GRT | 0094 | GlobalRouter.cpp:3568 | ERROR |- |\n| GRT | 0096 | GlobalRouter.cpp:3852 | INFO |- |\n| GRT | 0101 | FastRoute.cpp:1050 | INFO |- |\n| GRT | 0103 | FastRoute.cpp:1184 | INFO |- |\n| GRT | 0104 | GlobalRouter.tcl:312 | ERROR |- |\n| GRT | 0111 | FastRoute.cpp:1357 | INFO |- |\n| GRT | 0112 | FastRoute.cpp:1358 | INFO |- |\n| GRT | 0113 | FastRoute.cpp:396 | WARN |- |\n| GRT | 0114 | FastRoute.cpp:426 | WARN |- |\n| GRT | 0115 | GlobalRouter.cpp:291 | WARN |- |\n| GRT | 0118 | GlobalRouter.cpp:1750 | ERROR |Helpful Information-Do refer to the GUI guide and global routing debugging tips. |\n| GRT | 0119 | GlobalRouter.cpp:1743 | ERROR |Helpful Information-Do refer to the GUI guide and global routing debugging tips. |\n| GRT | 0120 | heatMapRudy.cpp:122 | WARN |- |\n| GRT | 0122 | RipUp.cpp:450 | ERROR |- |\n| GRT | 0123 | RipUp.cpp:572 | ERROR |- |\n| GRT | 0125 | maze.cpp:820 | ERROR |- |\n| GRT | 0126 | GlobalRouter.cpp:541 | ERROR |- |\n| GRT | 0146 | GlobalRouter.tcl:286 | WARN |- |\n| GRT | 0149 | utility.cpp:2060 | ERROR |- |\n| GRT | 0150 | maze.cpp:1838 | ERROR |- |\n| GRT | 0164 | utility.cpp:1764 | WARN |- |\n| GRT | 0165 | utility.cpp:1778 | WARN |- |\n| GRT | 0166 | utility.cpp:1794 | WARN |- |\n| GRT | 0167 | utility.cpp:1808 | WARN |- |\n| GRT | 0169 | maze.cpp:1020 | ERROR |- |", "source": "OpenROAD"}
{"script_name": "RepairAntennas", "definition_description": "This script performs antenna repair for the design.", "parameters": {"parameter1": "Description of the antenna model", "parameter2": "Description of the repair method"}, "values": "parameter1: <value>, parameter2: <value>", "script_paradigm": "repair_antenna -param1 <parameter1> -param2 <parameter2>", "examples": [{"query": "How to repair antennas using a specific method?", "answer": "repair_antenna -param1 modelA -param2 method1"}], "reference": "| GRT | 0019 | GlobalRouter.cpp:3063 | INFO |- |\n| GRT | 0020 | GlobalRouter.cpp:3785 | INFO |- |\n| GRT | 0021 | GlobalRouter.cpp:3786 | INFO |- |\n| GRT | 0022 | GlobalRouter.cpp:3787 | INFO |- |\n| GRT | 0023 | GlobalRouter.cpp:3788 | INFO |- |\n| GRT | 0025 | MakeWireParasitics.cpp:240 | WARN |- |\n| GRT | 0026 | MakeWireParasitics.cpp:338 | WARN |- |\n| GRT | 0027 | RepairAntennas.cpp:463 | WARN |- |\n| GRT | 0028 | GlobalRouter.cpp:3554 | ERROR |- |\n| GRT | 0029 | GlobalRouter.cpp:3161 | ERROR |- |\n| GRT | 0030 | GlobalRouter.cpp:1562 | WARN |- |\n| GRT | 0031 | GlobalRouter.cpp:2363 | WARN |- |\n| GRT | 0033 | GlobalRouter.cpp:2634 | WARN |- |\n| GRT | 0034 | GlobalRouter.cpp:3112 | WARN |- |\n| GRT | 0035 | GlobalRouter.cpp:3144 | WARN |- |\n| GRT | 0036 | GlobalRouter.cpp:3207 | WARN |- |\n| GRT | 0037 | GlobalRouter.cpp:3343 | WARN |- |\n| GRT | 0038 | GlobalRouter.cpp:3500 | WARN |- |\n| GRT | 0039 | GlobalRouter.cpp:3537 | WARN |- |\n| GRT | 0041 | GlobalRouter.cpp:3642 | WARN |- |\n| GRT | 0042 | GlobalRouter.cpp:3232 | ERROR |- |\n| GRT | 0043 | GlobalRouter.cpp:3718 | INFO |- |\n| GRT | 0044 | GlobalRouter.tcl:66 | ERROR |- |\n| GRT | 0045 | GlobalRouter.tcl:361 | ERROR |- |\n| GRT | 0047 | GlobalRouter.tcl:80 | ERROR |- |\n| GRT | 0048 | GlobalRouter.tcl:88 | ERROR |- |\n| GRT | 0051 | GlobalRouter.tcl:231 | ERROR |- |\n| GRT | 0052 | GlobalRouter.tcl:235 | ERROR |- |\n| GRT | 0053 | GlobalRouter.cpp:3800 | INFO |- |\n| GRT | 0054 | GlobalRouter.cpp:369 | INFO |- |\n| GRT | 0055 | GlobalRouter.tcl:246 | ERROR |- |\n| GRT | 0057 | GlobalRouter.tcl:590 | ERROR |- |\n| GRT | 0059 | GlobalRouter.tcl:503 | ERROR |- |\n| GRT | 0062 | GlobalRouter.tcl:546 | ERROR |- |\n| GRT | 0063 | GlobalRouter.tcl:553 | ERROR |- |\n| GRT | 0064 | GlobalRouter.tcl:559 | ERROR |- |\n| GRT | 0065 | GlobalRouter.tcl:563 | ERROR |- |\n| GRT | 0066 | GlobalRouter.tcl:567 | ERROR |- |\n| GRT | 0067 | GlobalRouter.tcl:571 | ERROR |- |\n| GRT | 0068 | RepairAntennas.cpp:188 | ERROR |- |\n| GRT | 0069 | GlobalRouter.tcl:326 | ERROR |- |\n| GRT | 0070 | GlobalRouter.cpp:521 | ERROR |- |\n| GRT | 0071 | GlobalRouter.cpp:1199 | ERROR |- |\n| GRT | 0072 | GlobalRouter.cpp:1417 | ERROR |- |\n| GRT | 0073 | GlobalRouter.tcl:339 | ERROR |- |\n| GRT | 0074 | GlobalRouter.cpp:2108 | ERROR |- |\n| GRT | 0075 | GlobalRouter.cpp:2086 | ERROR |- |\n| GRT | 0076 | GlobalRouter.cpp:2164 | ERROR |- |\n| GRT | 0078 | GlobalRouter.cpp:2248 | ERROR |- |\n| GRT | 0079 | GlobalRouter.cpp:2350 | ERROR |- |\n| GRT | 0080 | GlobalRouter.cpp:2379 | ERROR |- |\n| GRT | 0084 | GlobalRouter.cpp:512 | ERROR |- |\n| GRT | 0085 | GlobalRouter.cpp:507 | ERROR |- |\n| GRT | 0086 | GlobalRouter.cpp:2892 | ERROR |- |\n| GRT | 0088 | GlobalRouter.cpp:2907 | INFO |- |\n| GRT | 0090 | GlobalRouter.cpp:2967 | ERROR |- |\n| GRT | 0094 | GlobalRouter.cpp:3568 | ERROR |- |\n| GRT | 0096 | GlobalRouter.cpp:3852 | INFO |- |\n| GRT | 0101 | FastRoute.cpp:1050 | INFO |- |\n| GRT | 0103 | FastRoute.cpp:1184 | INFO |- |\n| GRT | 0104 | GlobalRouter.tcl:312 | ERROR |- |\n| GRT | 0111 | FastRoute.cpp:1357 | INFO |- |\n| GRT | 0112 | FastRoute.cpp:1358 | INFO |- |\n| GRT | 0113 | FastRoute.cpp:396 | WARN |- |\n| GRT | 0114 | FastRoute.cpp:426 | WARN |- |\n| GRT | 0115 | GlobalRouter.cpp:291 | WARN |- |\n| GRT | 0118 | GlobalRouter.cpp:1750 | ERROR |Helpful Information-Do refer to the GUI guide and global routing debugging tips. |\n| GRT | 0119 | GlobalRouter.cpp:1743 | ERROR |Helpful Information-Do refer to the GUI guide and global routing debugging tips. |\n| GRT | 0120 | heatMapRudy.cpp:122 | WARN |- |\n| GRT | 0122 | RipUp.cpp:450 | ERROR |- |\n| GRT | 0123 | RipUp.cpp:572 | ERROR |- |\n| GRT | 0125 | maze.cpp:820 | ERROR |- |\n| GRT | 0126 | GlobalRouter.cpp:541 | ERROR |- |\n| GRT | 0146 | GlobalRouter.tcl:286 | WARN |- |\n| GRT | 0149 | utility.cpp:2060 | ERROR |- |\n| GRT | 0150 | maze.cpp:1838 | ERROR |- |\n| GRT | 0164 | utility.cpp:1764 | WARN |- |\n| GRT | 0165 | utility.cpp:1778 | WARN |- |\n| GRT | 0166 | utility.cpp:1794 | WARN |- |\n| GRT | 0167 | utility.cpp:1808 | WARN |- |\n| GRT | 0169 | maze.cpp:1020 | ERROR |- |", "source": "OpenROAD"}
{"script_name": "FastRoute", "definition_description": "This script runs the FastRoute algorithm for routing tasks.", "parameters": {"parameter1": "Description of the routing mode", "parameter2": "Description of the routing parameters"}, "values": "parameter1: <value>, parameter2: <value>", "script_paradigm": "fast_route -mode <parameter1> -params <parameter2>", "examples": [{"query": "How to run FastRoute with a specific mode?", "answer": "fast_route -mode modeA -params params1"}], "reference": "| GRT | 0019 | GlobalRouter.cpp:3063 | INFO |- |\n| GRT | 0020 | GlobalRouter.cpp:3785 | INFO |- |\n| GRT | 0021 | GlobalRouter.cpp:3786 | INFO |- |\n| GRT | 0022 | GlobalRouter.cpp:3787 | INFO |- |\n| GRT | 0023 | GlobalRouter.cpp:3788 | INFO |- |\n| GRT | 0025 | MakeWireParasitics.cpp:240 | WARN |- |\n| GRT | 0026 | MakeWireParasitics.cpp:338 | WARN |- |\n| GRT | 0027 | RepairAntennas.cpp:463 | WARN |- |\n| GRT | 0028 | GlobalRouter.cpp:3554 | ERROR |- |\n| GRT | 0029 | GlobalRouter.cpp:3161 | ERROR |- |\n| GRT | 0030 | GlobalRouter.cpp:1562 | WARN |- |\n| GRT | 0031 | GlobalRouter.cpp:2363 | WARN |- |\n| GRT | 0033 | GlobalRouter.cpp:2634 | WARN |- |\n| GRT | 0034 | GlobalRouter.cpp:3112 | WARN |- |\n| GRT | 0035 | GlobalRouter.cpp:3144 | WARN |- |\n| GRT | 0036 | GlobalRouter.cpp:3207 | WARN |- |\n| GRT | 0037 | GlobalRouter.cpp:3343 | WARN |- |\n| GRT | 0038 | GlobalRouter.cpp:3500 | WARN |- |\n| GRT | 0039 | GlobalRouter.cpp:3537 | WARN |- |\n| GRT | 0041 | GlobalRouter.cpp:3642 | WARN |- |\n| GRT | 0042 | GlobalRouter.cpp:3232 | ERROR |- |\n| GRT | 0043 | GlobalRouter.cpp:3718 | INFO |- |\n| GRT | 0044 | GlobalRouter.tcl:66 | ERROR |- |\n| GRT | 0045 | GlobalRouter.tcl:361 | ERROR |- |\n| GRT | 0047 | GlobalRouter.tcl:80 | ERROR |- |\n| GRT | 0048 | GlobalRouter.tcl:88 | ERROR |- |\n| GRT | 0051 | GlobalRouter.tcl:231 | ERROR |- |\n| GRT | 0052 | GlobalRouter.tcl:235 | ERROR |- |\n| GRT | 0053 | GlobalRouter.cpp:3800 | INFO |- |\n| GRT | 0054 | GlobalRouter.cpp:369 | INFO |- |\n| GRT | 0055 | GlobalRouter.tcl:246 | ERROR |- |\n| GRT | 0057 | GlobalRouter.tcl:590 | ERROR |- |\n| GRT | 0059 | GlobalRouter.tcl:503 | ERROR |- |\n| GRT | 0062 | GlobalRouter.tcl:546 | ERROR |- |\n| GRT | 0063 | GlobalRouter.tcl:553 | ERROR |- |\n| GRT | 0064 | GlobalRouter.tcl:559 | ERROR |- |\n| GRT | 0065 | GlobalRouter.tcl:563 | ERROR |- |\n| GRT | 0066 | GlobalRouter.tcl:567 | ERROR |- |\n| GRT | 0067 | GlobalRouter.tcl:571 | ERROR |- |\n| GRT | 0068 | RepairAntennas.cpp:188 | ERROR |- |\n| GRT | 0069 | GlobalRouter.tcl:326 | ERROR |- |\n| GRT | 0070 | GlobalRouter.cpp:521 | ERROR |- |\n| GRT | 0071 | GlobalRouter.cpp:1199 | ERROR |- |\n| GRT | 0072 | GlobalRouter.cpp:1417 | ERROR |- |\n| GRT | 0073 | GlobalRouter.tcl:339 | ERROR |- |\n| GRT | 0074 | GlobalRouter.cpp:2108 | ERROR |- |\n| GRT | 0075 | GlobalRouter.cpp:2086 | ERROR |- |\n| GRT | 0076 | GlobalRouter.cpp:2164 | ERROR |- |\n| GRT | 0078 | GlobalRouter.cpp:2248 | ERROR |- |\n| GRT | 0079 | GlobalRouter.cpp:2350 | ERROR |- |\n| GRT | 0080 | GlobalRouter.cpp:2379 | ERROR |- |\n| GRT | 0084 | GlobalRouter.cpp:512 | ERROR |- |\n| GRT | 0085 | GlobalRouter.cpp:507 | ERROR |- |\n| GRT | 0086 | GlobalRouter.cpp:2892 | ERROR |- |\n| GRT | 0088 | GlobalRouter.cpp:2907 | INFO |- |\n| GRT | 0090 | GlobalRouter.cpp:2967 | ERROR |- |\n| GRT | 0094 | GlobalRouter.cpp:3568 | ERROR |- |\n| GRT | 0096 | GlobalRouter.cpp:3852 | INFO |- |\n| GRT | 0101 | FastRoute.cpp:1050 | INFO |- |\n| GRT | 0103 | FastRoute.cpp:1184 | INFO |- |\n| GRT | 0104 | GlobalRouter.tcl:312 | ERROR |- |\n| GRT | 0111 | FastRoute.cpp:1357 | INFO |- |\n| GRT | 0112 | FastRoute.cpp:1358 | INFO |- |\n| GRT | 0113 | FastRoute.cpp:396 | WARN |- |\n| GRT | 0114 | FastRoute.cpp:426 | WARN |- |\n| GRT | 0115 | GlobalRouter.cpp:291 | WARN |- |\n| GRT | 0118 | GlobalRouter.cpp:1750 | ERROR |Helpful Information-Do refer to the GUI guide and global routing debugging tips. |\n| GRT | 0119 | GlobalRouter.cpp:1743 | ERROR |Helpful Information-Do refer to the GUI guide and global routing debugging tips. |\n| GRT | 0120 | heatMapRudy.cpp:122 | WARN |- |\n| GRT | 0122 | RipUp.cpp:450 | ERROR |- |\n| GRT | 0123 | RipUp.cpp:572 | ERROR |- |\n| GRT | 0125 | maze.cpp:820 | ERROR |- |\n| GRT | 0126 | GlobalRouter.cpp:541 | ERROR |- |\n| GRT | 0146 | GlobalRouter.tcl:286 | WARN |- |\n| GRT | 0149 | utility.cpp:2060 | ERROR |- |\n| GRT | 0150 | maze.cpp:1838 | ERROR |- |\n| GRT | 0164 | utility.cpp:1764 | WARN |- |\n| GRT | 0165 | utility.cpp:1778 | WARN |- |\n| GRT | 0166 | utility.cpp:1794 | WARN |- |\n| GRT | 0167 | utility.cpp:1808 | WARN |- |\n| GRT | 0169 | maze.cpp:1020 | ERROR |- |", "source": "OpenROAD"}
{"script_name": "PolygonComparison", "definition_description": "This script allows comparison between two polygons, checking if they are equal, less than, or not equal to each other.", "parameters": {"polygon": "The polygon to compare with the current one"}, "values": "polygon: <SimplePolygon>", "script_paradigm": "bool operator!=(const SimplePolygon p); bool operator<(const SimplePolygon p); bool operator==(const SimplePolygon p);", "examples": [{"query": "How to check if two polygons are not equal?", "answer": "bool result = polygon1 != polygon2;"}, {"query": "How to check if one polygon is less than another?", "answer": "bool result = polygon1 < polygon2;"}], "reference": "[const] bool != (const SimplePolygon p) Returns a value indicating whether self is not equal to p [const] SimplePolygon * (double f) Scales the polygon by some factor [const] bool < (const SimplePolygon p) Returns a value indicating whether self is less than p [const] bool == (const SimplePolygon p) Returns a value indicating whether self is equal to p [const] SimplePolygon ptr _const_cast Returns a non-const reference to self. void _create Ensures the C++ object is created void _destroy Explicitly destroys the object [const] bool _destroyed? Returns a value indicating whether the object was already destroyed [const] bool _is_const_object? Returns a value indicating whether the reference is a const reference void _manage Marks the object as managed by the script side. void _unmanage Marks the object as no longer owned by the script side. [const] long area Gets the area of the polygon [const] long area2 Gets the double area of the polygon void assign (const SimplePolygon other) Assigns another object to self [const] Box bbox Returns the bounding box of the simple polygon [const] SimplePolygon[] break (unsigned long max_vertex_count, double max_area_ratio) Splits the polygon into parts with a maximum vertex count and area ratio void compress (bool remove_reflected) Compressed the simple polygon. [const] new SimplePolygon ptr dup Creates a copy of self [const,iter] Edge each_edge Iterates over the edges that make up the simple polygon [const,iter] Point each_point Iterates over the points that make up the simple polygon [const] variant[] extract_rad Extracts the corner radii from a rounded polygon [const] unsigned long hash Computes a hash value [const] bool inside? (Point p) Gets a value indicating whether the given point is inside the polygon [const] bool is_box? Returns a value indicating whether the polygon is a simple box. [const] bool is_empty? Returns a value indicating whether the polygon is empty [const] bool is_halfmanhattan? Returns a value indicating whether the polygon is half-manhattan [const] bool is_rectilinear? Returns a value indicating whether the polygon is rectilinear [const] Polygon minkowski_sum (const Edge e, bool resolve_holes) Computes the Minkowski sum of a polygon and an edge [const] Polygon minkowski_sum (const SimplePolygon p, bool resolve_holes) Computes the Minkowski sum of a polygon and a polygon [const] Polygon minkowski_sum (const Box b, bool resolve_holes) Computes the Minkowski sum of a polygon and a box [const] Polygon minkowski_sum (Point[] c, bool resolve_holes) Computes the Minkowski sum of a polygon and a contour of points (a trace) SimplePolygon move (const Vector p) Moves the simple polygon. SimplePolygon move (int x, int y) Moves the polygon. [const] SimplePolygon moved (const Vector p) Returns the moved simple polygon [const] SimplePolygon moved (int x, int y) Returns the moved polygon (does not modify self) [const] unsigned long num_points Gets the number of points [const] unsigned long perimeter Gets the perimeter of the polygon [const] Point point (unsigned long p) Gets a specific point of the contour@param p The index of the point to get void points= (Point[] pts) Sets the points of the simple polygon [const] SimplePolygon round_corners (double rinner, double router, unsigned int n) Rounds the corners of the polygon void set_points (Point[] pts, bool raw = false) Sets the points of the simple polygon [const] SimplePolygon[] split Splits the polygon into two or more parts [const] DSimplePolygon to_dtype (double dbu = 1) Converts the polygon to a floating-point coordinate polygon [const] string to_s Returns a string representing the polygon [const] bool touches? (const Box box) Returns true, if the polygon touches the given box. [const] bool touches? (const Edge edge) Returns true, if the polygon touches the given edge. [const] bool touches? (const Polygon polygon) Returns true, if the polygon touches the other polygon. [const] bool touches? (const SimplePolygon simple_polygon) Returns true, if the polygon touches the other polygon. SimplePolygon ptr transform (const", "source": "klayout"}
{"script_name": "PolygonScaling", "definition_description": "This script scales a polygon by a specified factor.", "parameters": {"factor": "The factor by which the polygon will be scaled"}, "values": "factor: <double>", "script_paradigm": "SimplePolygon* operator(double f);", "examples": [{"query": "How to scale a polygon by a factor of 2?", "answer": "SimplePolygon* scaled_polygon = polygon.scale(2);"}], "reference": "[const] bool != (const SimplePolygon p) Returns a value indicating whether self is not equal to p [const] SimplePolygon * (double f) Scales the polygon by some factor [const] bool < (const SimplePolygon p) Returns a value indicating whether self is less than p [const] bool == (const SimplePolygon p) Returns a value indicating whether self is equal to p [const] SimplePolygon ptr _const_cast Returns a non-const reference to self. void _create Ensures the C++ object is created void _destroy Explicitly destroys the object [const] bool _destroyed? Returns a value indicating whether the object was already destroyed [const] bool _is_const_object? Returns a value indicating whether the reference is a const reference void _manage Marks the object as managed by the script side. void _unmanage Marks the object as no longer owned by the script side. [const] long area Gets the area of the polygon [const] long area2 Gets the double area of the polygon void assign (const SimplePolygon other) Assigns another object to self [const] Box bbox Returns the bounding box of the simple polygon [const] SimplePolygon[] break (unsigned long max_vertex_count, double max_area_ratio) Splits the polygon into parts with a maximum vertex count and area ratio void compress (bool remove_reflected) Compressed the simple polygon. [const] new SimplePolygon ptr dup Creates a copy of self [const,iter] Edge each_edge Iterates over the edges that make up the simple polygon [const,iter] Point each_point Iterates over the points that make up the simple polygon [const] variant[] extract_rad Extracts the corner radii from a rounded polygon [const] unsigned long hash Computes a hash value [const] bool inside? (Point p) Gets a value indicating whether the given point is inside the polygon [const] bool is_box? Returns a value indicating whether the polygon is a simple box. [const] bool is_empty? Returns a value indicating whether the polygon is empty [const] bool is_halfmanhattan? Returns a value indicating whether the polygon is half-manhattan [const] bool is_rectilinear? Returns a value indicating whether the polygon is rectilinear [const] Polygon minkowski_sum (const Edge e, bool resolve_holes) Computes the Minkowski sum of a polygon and an edge [const] Polygon minkowski_sum (const SimplePolygon p, bool resolve_holes) Computes the Minkowski sum of a polygon and a polygon [const] Polygon minkowski_sum (const Box b, bool resolve_holes) Computes the Minkowski sum of a polygon and a box [const] Polygon minkowski_sum (Point[] c, bool resolve_holes) Computes the Minkowski sum of a polygon and a contour of points (a trace) SimplePolygon move (const Vector p) Moves the simple polygon. SimplePolygon move (int x, int y) Moves the polygon. [const] SimplePolygon moved (const Vector p) Returns the moved simple polygon [const] SimplePolygon moved (int x, int y) Returns the moved polygon (does not modify self) [const] unsigned long num_points Gets the number of points [const] unsigned long perimeter Gets the perimeter of the polygon [const] Point point (unsigned long p) Gets a specific point of the contour@param p The index of the point to get void points= (Point[] pts) Sets the points of the simple polygon [const] SimplePolygon round_corners (double rinner, double router, unsigned int n) Rounds the corners of the polygon void set_points (Point[] pts, bool raw = false) Sets the points of the simple polygon [const] SimplePolygon[] split Splits the polygon into two or more parts [const] DSimplePolygon to_dtype (double dbu = 1) Converts the polygon to a floating-point coordinate polygon [const] string to_s Returns a string representing the polygon [const] bool touches? (const Box box) Returns true, if the polygon touches the given box. [const] bool touches? (const Edge edge) Returns true, if the polygon touches the given edge. [const] bool touches? (const Polygon polygon) Returns true, if the polygon touches the other polygon. [const] bool touches? (const SimplePolygon simple_polygon) Returns true, if the polygon touches the other polygon. SimplePolygon ptr transform (const", "source": "klayout"}
{"script_name": "PolygonArea", "definition_description": "This script calculates the area or double area of a polygon.", "parameters": {}, "values": "none", "script_paradigm": "long area; long area2;", "examples": [{"query": "How to get the area of a polygon?", "answer": "long area = polygon.area;"}, {"query": "How to get the double area of a polygon?", "answer": "long double_area = polygon.area2;"}], "reference": "[const] bool != (const SimplePolygon p) Returns a value indicating whether self is not equal to p [const] SimplePolygon * (double f) Scales the polygon by some factor [const] bool < (const SimplePolygon p) Returns a value indicating whether self is less than p [const] bool == (const SimplePolygon p) Returns a value indicating whether self is equal to p [const] SimplePolygon ptr _const_cast Returns a non-const reference to self. void _create Ensures the C++ object is created void _destroy Explicitly destroys the object [const] bool _destroyed? Returns a value indicating whether the object was already destroyed [const] bool _is_const_object? Returns a value indicating whether the reference is a const reference void _manage Marks the object as managed by the script side. void _unmanage Marks the object as no longer owned by the script side. [const] long area Gets the area of the polygon [const] long area2 Gets the double area of the polygon void assign (const SimplePolygon other) Assigns another object to self [const] Box bbox Returns the bounding box of the simple polygon [const] SimplePolygon[] break (unsigned long max_vertex_count, double max_area_ratio) Splits the polygon into parts with a maximum vertex count and area ratio void compress (bool remove_reflected) Compressed the simple polygon. [const] new SimplePolygon ptr dup Creates a copy of self [const,iter] Edge each_edge Iterates over the edges that make up the simple polygon [const,iter] Point each_point Iterates over the points that make up the simple polygon [const] variant[] extract_rad Extracts the corner radii from a rounded polygon [const] unsigned long hash Computes a hash value [const] bool inside? (Point p) Gets a value indicating whether the given point is inside the polygon [const] bool is_box? Returns a value indicating whether the polygon is a simple box. [const] bool is_empty? Returns a value indicating whether the polygon is empty [const] bool is_halfmanhattan? Returns a value indicating whether the polygon is half-manhattan [const] bool is_rectilinear? Returns a value indicating whether the polygon is rectilinear [const] Polygon minkowski_sum (const Edge e, bool resolve_holes) Computes the Minkowski sum of a polygon and an edge [const] Polygon minkowski_sum (const SimplePolygon p, bool resolve_holes) Computes the Minkowski sum of a polygon and a polygon [const] Polygon minkowski_sum (const Box b, bool resolve_holes) Computes the Minkowski sum of a polygon and a box [const] Polygon minkowski_sum (Point[] c, bool resolve_holes) Computes the Minkowski sum of a polygon and a contour of points (a trace) SimplePolygon move (const Vector p) Moves the simple polygon. SimplePolygon move (int x, int y) Moves the polygon. [const] SimplePolygon moved (const Vector p) Returns the moved simple polygon [const] SimplePolygon moved (int x, int y) Returns the moved polygon (does not modify self) [const] unsigned long num_points Gets the number of points [const] unsigned long perimeter Gets the perimeter of the polygon [const] Point point (unsigned long p) Gets a specific point of the contour@param p The index of the point to get void points= (Point[] pts) Sets the points of the simple polygon [const] SimplePolygon round_corners (double rinner, double router, unsigned int n) Rounds the corners of the polygon void set_points (Point[] pts, bool raw = false) Sets the points of the simple polygon [const] SimplePolygon[] split Splits the polygon into two or more parts [const] DSimplePolygon to_dtype (double dbu = 1) Converts the polygon to a floating-point coordinate polygon [const] string to_s Returns a string representing the polygon [const] bool touches? (const Box box) Returns true, if the polygon touches the given box. [const] bool touches? (const Edge edge) Returns true, if the polygon touches the given edge. [const] bool touches? (const Polygon polygon) Returns true, if the polygon touches the other polygon. [const] bool touches? (const SimplePolygon simple_polygon) Returns true, if the polygon touches the other polygon. SimplePolygon ptr transform (const", "source": "klayout"}
{"script_name": "PolygonBoundingBox", "definition_description": "This script returns the bounding box of the polygon.", "parameters": {}, "values": "none", "script_paradigm": "Box bbox;", "examples": [{"query": "How to get the bounding box of a polygon?", "answer": "Box bbox = polygon.bbox;"}], "reference": "[const] bool != (const SimplePolygon p) Returns a value indicating whether self is not equal to p [const] SimplePolygon * (double f) Scales the polygon by some factor [const] bool < (const SimplePolygon p) Returns a value indicating whether self is less than p [const] bool == (const SimplePolygon p) Returns a value indicating whether self is equal to p [const] SimplePolygon ptr _const_cast Returns a non-const reference to self. void _create Ensures the C++ object is created void _destroy Explicitly destroys the object [const] bool _destroyed? Returns a value indicating whether the object was already destroyed [const] bool _is_const_object? Returns a value indicating whether the reference is a const reference void _manage Marks the object as managed by the script side. void _unmanage Marks the object as no longer owned by the script side. [const] long area Gets the area of the polygon [const] long area2 Gets the double area of the polygon void assign (const SimplePolygon other) Assigns another object to self [const] Box bbox Returns the bounding box of the simple polygon [const] SimplePolygon[] break (unsigned long max_vertex_count, double max_area_ratio) Splits the polygon into parts with a maximum vertex count and area ratio void compress (bool remove_reflected) Compressed the simple polygon. [const] new SimplePolygon ptr dup Creates a copy of self [const,iter] Edge each_edge Iterates over the edges that make up the simple polygon [const,iter] Point each_point Iterates over the points that make up the simple polygon [const] variant[] extract_rad Extracts the corner radii from a rounded polygon [const] unsigned long hash Computes a hash value [const] bool inside? (Point p) Gets a value indicating whether the given point is inside the polygon [const] bool is_box? Returns a value indicating whether the polygon is a simple box. [const] bool is_empty? Returns a value indicating whether the polygon is empty [const] bool is_halfmanhattan? Returns a value indicating whether the polygon is half-manhattan [const] bool is_rectilinear? Returns a value indicating whether the polygon is rectilinear [const] Polygon minkowski_sum (const Edge e, bool resolve_holes) Computes the Minkowski sum of a polygon and an edge [const] Polygon minkowski_sum (const SimplePolygon p, bool resolve_holes) Computes the Minkowski sum of a polygon and a polygon [const] Polygon minkowski_sum (const Box b, bool resolve_holes) Computes the Minkowski sum of a polygon and a box [const] Polygon minkowski_sum (Point[] c, bool resolve_holes) Computes the Minkowski sum of a polygon and a contour of points (a trace) SimplePolygon move (const Vector p) Moves the simple polygon. SimplePolygon move (int x, int y) Moves the polygon. [const] SimplePolygon moved (const Vector p) Returns the moved simple polygon [const] SimplePolygon moved (int x, int y) Returns the moved polygon (does not modify self) [const] unsigned long num_points Gets the number of points [const] unsigned long perimeter Gets the perimeter of the polygon [const] Point point (unsigned long p) Gets a specific point of the contour@param p The index of the point to get void points= (Point[] pts) Sets the points of the simple polygon [const] SimplePolygon round_corners (double rinner, double router, unsigned int n) Rounds the corners of the polygon void set_points (Point[] pts, bool raw = false) Sets the points of the simple polygon [const] SimplePolygon[] split Splits the polygon into two or more parts [const] DSimplePolygon to_dtype (double dbu = 1) Converts the polygon to a floating-point coordinate polygon [const] string to_s Returns a string representing the polygon [const] bool touches? (const Box box) Returns true, if the polygon touches the given box. [const] bool touches? (const Edge edge) Returns true, if the polygon touches the given edge. [const] bool touches? (const Polygon polygon) Returns true, if the polygon touches the other polygon. [const] bool touches? (const SimplePolygon simple_polygon) Returns true, if the polygon touches the other polygon. SimplePolygon ptr transform (const", "source": "klayout"}
{"script_name": "PolygonDuplication", "definition_description": "This script creates a copy of the current polygon.", "parameters": {}, "values": "none", "script_paradigm": "SimplePolygon* dup();", "examples": [{"query": "How to create a copy of a polygon?", "answer": "SimplePolygon* new_polygon = polygon.dup();"}], "reference": "[const] bool != (const SimplePolygon p) Returns a value indicating whether self is not equal to p [const] SimplePolygon * (double f) Scales the polygon by some factor [const] bool < (const SimplePolygon p) Returns a value indicating whether self is less than p [const] bool == (const SimplePolygon p) Returns a value indicating whether self is equal to p [const] SimplePolygon ptr _const_cast Returns a non-const reference to self. void _create Ensures the C++ object is created void _destroy Explicitly destroys the object [const] bool _destroyed? Returns a value indicating whether the object was already destroyed [const] bool _is_const_object? Returns a value indicating whether the reference is a const reference void _manage Marks the object as managed by the script side. void _unmanage Marks the object as no longer owned by the script side. [const] long area Gets the area of the polygon [const] long area2 Gets the double area of the polygon void assign (const SimplePolygon other) Assigns another object to self [const] Box bbox Returns the bounding box of the simple polygon [const] SimplePolygon[] break (unsigned long max_vertex_count, double max_area_ratio) Splits the polygon into parts with a maximum vertex count and area ratio void compress (bool remove_reflected) Compressed the simple polygon. [const] new SimplePolygon ptr dup Creates a copy of self [const,iter] Edge each_edge Iterates over the edges that make up the simple polygon [const,iter] Point each_point Iterates over the points that make up the simple polygon [const] variant[] extract_rad Extracts the corner radii from a rounded polygon [const] unsigned long hash Computes a hash value [const] bool inside? (Point p) Gets a value indicating whether the given point is inside the polygon [const] bool is_box? Returns a value indicating whether the polygon is a simple box. [const] bool is_empty? Returns a value indicating whether the polygon is empty [const] bool is_halfmanhattan? Returns a value indicating whether the polygon is half-manhattan [const] bool is_rectilinear? Returns a value indicating whether the polygon is rectilinear [const] Polygon minkowski_sum (const Edge e, bool resolve_holes) Computes the Minkowski sum of a polygon and an edge [const] Polygon minkowski_sum (const SimplePolygon p, bool resolve_holes) Computes the Minkowski sum of a polygon and a polygon [const] Polygon minkowski_sum (const Box b, bool resolve_holes) Computes the Minkowski sum of a polygon and a box [const] Polygon minkowski_sum (Point[] c, bool resolve_holes) Computes the Minkowski sum of a polygon and a contour of points (a trace) SimplePolygon move (const Vector p) Moves the simple polygon. SimplePolygon move (int x, int y) Moves the polygon. [const] SimplePolygon moved (const Vector p) Returns the moved simple polygon [const] SimplePolygon moved (int x, int y) Returns the moved polygon (does not modify self) [const] unsigned long num_points Gets the number of points [const] unsigned long perimeter Gets the perimeter of the polygon [const] Point point (unsigned long p) Gets a specific point of the contour@param p The index of the point to get void points= (Point[] pts) Sets the points of the simple polygon [const] SimplePolygon round_corners (double rinner, double router, unsigned int n) Rounds the corners of the polygon void set_points (Point[] pts, bool raw = false) Sets the points of the simple polygon [const] SimplePolygon[] split Splits the polygon into two or more parts [const] DSimplePolygon to_dtype (double dbu = 1) Converts the polygon to a floating-point coordinate polygon [const] string to_s Returns a string representing the polygon [const] bool touches? (const Box box) Returns true, if the polygon touches the given box. [const] bool touches? (const Edge edge) Returns true, if the polygon touches the given edge. [const] bool touches? (const Polygon polygon) Returns true, if the polygon touches the other polygon. [const] bool touches? (const SimplePolygon simple_polygon) Returns true, if the polygon touches the other polygon. SimplePolygon ptr transform (const", "source": "klayout"}
{"script_name": "PolygonMovement", "definition_description": "This script moves the polygon by a specified vector or by x, y coordinates.", "parameters": {"x": "The x-coordinate to move the polygon", "y": "The y-coordinate to move the polygon", "vector": "The vector to move the polygon by"}, "values": "x: <int>, y: <int>, vector: <Vector>", "script_paradigm": "SimplePolygon move(int x, int y); SimplePolygon move(Vector p); SimplePolygon moved(int x, int y); SimplePolygon moved(Vector p);", "examples": [{"query": "How to move a polygon by (10, 20) coordinates?", "answer": "SimplePolygon moved_polygon = polygon.move(10, 20);"}, {"query": "How to move a polygon by a vector?", "answer": "Vector move_vector(10, 20); SimplePolygon moved_polygon = polygon.move(move_vector);"}], "reference": "[const] bool != (const SimplePolygon p) Returns a value indicating whether self is not equal to p [const] SimplePolygon * (double f) Scales the polygon by some factor [const] bool < (const SimplePolygon p) Returns a value indicating whether self is less than p [const] bool == (const SimplePolygon p) Returns a value indicating whether self is equal to p [const] SimplePolygon ptr _const_cast Returns a non-const reference to self. void _create Ensures the C++ object is created void _destroy Explicitly destroys the object [const] bool _destroyed? Returns a value indicating whether the object was already destroyed [const] bool _is_const_object? Returns a value indicating whether the reference is a const reference void _manage Marks the object as managed by the script side. void _unmanage Marks the object as no longer owned by the script side. [const] long area Gets the area of the polygon [const] long area2 Gets the double area of the polygon void assign (const SimplePolygon other) Assigns another object to self [const] Box bbox Returns the bounding box of the simple polygon [const] SimplePolygon[] break (unsigned long max_vertex_count, double max_area_ratio) Splits the polygon into parts with a maximum vertex count and area ratio void compress (bool remove_reflected) Compressed the simple polygon. [const] new SimplePolygon ptr dup Creates a copy of self [const,iter] Edge each_edge Iterates over the edges that make up the simple polygon [const,iter] Point each_point Iterates over the points that make up the simple polygon [const] variant[] extract_rad Extracts the corner radii from a rounded polygon [const] unsigned long hash Computes a hash value [const] bool inside? (Point p) Gets a value indicating whether the given point is inside the polygon [const] bool is_box? Returns a value indicating whether the polygon is a simple box. [const] bool is_empty? Returns a value indicating whether the polygon is empty [const] bool is_halfmanhattan? Returns a value indicating whether the polygon is half-manhattan [const] bool is_rectilinear? Returns a value indicating whether the polygon is rectilinear [const] Polygon minkowski_sum (const Edge e, bool resolve_holes) Computes the Minkowski sum of a polygon and an edge [const] Polygon minkowski_sum (const SimplePolygon p, bool resolve_holes) Computes the Minkowski sum of a polygon and a polygon [const] Polygon minkowski_sum (const Box b, bool resolve_holes) Computes the Minkowski sum of a polygon and a box [const] Polygon minkowski_sum (Point[] c, bool resolve_holes) Computes the Minkowski sum of a polygon and a contour of points (a trace) SimplePolygon move (const Vector p) Moves the simple polygon. SimplePolygon move (int x, int y) Moves the polygon. [const] SimplePolygon moved (const Vector p) Returns the moved simple polygon [const] SimplePolygon moved (int x, int y) Returns the moved polygon (does not modify self) [const] unsigned long num_points Gets the number of points [const] unsigned long perimeter Gets the perimeter of the polygon [const] Point point (unsigned long p) Gets a specific point of the contour@param p The index of the point to get void points= (Point[] pts) Sets the points of the simple polygon [const] SimplePolygon round_corners (double rinner, double router, unsigned int n) Rounds the corners of the polygon void set_points (Point[] pts, bool raw = false) Sets the points of the simple polygon [const] SimplePolygon[] split Splits the polygon into two or more parts [const] DSimplePolygon to_dtype (double dbu = 1) Converts the polygon to a floating-point coordinate polygon [const] string to_s Returns a string representing the polygon [const] bool touches? (const Box box) Returns true, if the polygon touches the given box. [const] bool touches? (const Edge edge) Returns true, if the polygon touches the given edge. [const] bool touches? (const Polygon polygon) Returns true, if the polygon touches the other polygon. [const] bool touches? (const SimplePolygon simple_polygon) Returns true, if the polygon touches the other polygon. SimplePolygon ptr transform (const", "source": "klayout"}
{"script_name": "FillerCellInsertion", "definition_description": "This script inserts filler cells into the design to ensure that all areas of the layout are filled properly, preventing any design issues related to incomplete filling.", "parameters": {"filler_master": "A list of filler cell types to be inserted into the design"}, "values": "filler_master: [FILLCELL_X1, FILLCELL_X2, FILLCELL_X4, FILLCELL_X8, FILLCELL_X16]", "script_paradigm": "set filler_master [list FILLCELL_X1 FILLCELL_X2 FILLCELL_X4 FILLCELL_X8 FILLCELL_X16]\nfiller_placement $filler_master", "examples": [{"query": "How to insert a set of filler cells using the available types?", "answer": "set filler_master [list FILLCELL_X1 FILLCELL_X2 FILLCELL_X4 FILLCELL_X8 FILLCELL_X16]\nfiller_placement $filler_master"}], "reference": "Run following commands for filler cell insertion:\nset filler_master [list FILLCELL_X1 FILLCELL_X2 FILLCELL_X4 FILLCELL_X8 FILLCELL_X16]\nfiller_placement $filler_master\nView the resulting fill cell insertion as follows:\n\nFiller cells removed with remove_fillers command.\nGlobal Routing\nThe global router analyzes available routing resources and automatically\nallocates them to avoid any  H/V  overflow violations for optimal routing. \nIt generates a congestion report for GCells showing total resources, demand,\nutilization, location and the H/V violation status. If there are no violations\nreported then the design can proceed to detail routing.\nRefer to the built-in example here.\nLaunch OpenROAD GUI by running the following command(s) in the terminal in OpenROAD tool root directory:\nshell\ncd ../tools/OpenROAD/src/grt/test/\nopenroad -gui\nTo run the global routing, run the following commands in Tcl Commands of\nGUI:\ntcl\nsource gcd.tcl\nRouting resource and congestion analysis done with below log:\n```\n[INFO GRT-0096] Final congestion report:\nLayer         Resource        Demand        Usage (%)    Max H / Max V / Total Overflow\n\nmetal1           31235          1651            5.29%             0 /  0 /  0\nmetal2           24628          1652            6.71%             0 /  0 /  0\nmetal3           33120            40            0.12%             0 /  0 /  0\nmetal4           15698             0            0.00%             0 /  0 /  0\nmetal5           15404             0            0.00%             0 /  0 /  0\nmetal6           15642             0            0.00%             0 /  0 /  0\nmetal7            4416             0            0.00%             0 /  0 /  0\nmetal8            4512             0            0.00%             0 /  0 /  0\nmetal9            2208             0            0.00%             0 /  0 /  0\nmetal10           2256             0            0.00%             0 /  0 /  0\n\nTotal           149119          3343            2.24%             0 /  0 /  0\n[INFO GRT-0018] Total wirelength: 10598 um\n[INFO GRT-0014] Routed nets: 563\n```\nView the resulting global routing in GUI as follows:\n\nDetail Routing\nTritonRoute is an open-source detailed router for modern industrial designs.\nThe router consists of several main building blocks, including pin access\nanalysis, track assignment, initial detailed routing, search and repair, and a DRC engine.\nRefer to the built-in example here.\nLaunch OpenROAD GUI by running the following command(s) in the terminal in OpenROAD tool root directory:\nshell\ncd ../tools/OpenROAD/src/drt/test/\nopenroad -gui\nTo run the detail routing, run the following commands in Tcl Commands of\nGUI:\ntcl\nread_lef Nangate45/Nangate45_tech.lef\nread_lef Nangate45/Nangate45_stdcell.lef\nread_def gcd_nangate45_preroute.def\nread_guides gcd_nangate45.route_guide\nset_thread_count [expr [exec getconf _NPROCESSORS_ONLN] / 4]\ndetailed_route -output_drc results/gcd_nangate45.output.drc.rpt \\\n               -output_maze results/gcd_nangate45.output.maze.log \\\n               -verbose 1\nwrite_db gcd_nangate45.odb\nFor successful routing, DRT will end with 0 violations.\nLog as follows:\n```\n[INFO DRT-0199]   Number of violations = 0.\n[INFO DRT-0267] cpu time = 00:00:00, elapsed time = 00:00:00, memory = 674.22 (MB), peak = 686.08 (MB)\nTotal wire length = 5680 um.\nTotal wire length on LAYER metal1 = 19 um.\nTotal wire length on LAYER metal2 = 2798 um.\nTotal wire length on LAYER metal3 = 2614 um.\nTotal wire length on LAYER metal4 = 116 um.\nTotal wire length on LAYER metal5 = 63 um.\nTotal wire length on LAYER metal6 = 36 um.\nTotal wire length on LAYER metal7 = 32 um.\nTotal wire length on LAYER metal8 = 0 um.\nTotal wire length on LAYER metal9 = 0 um.\nTotal wire length on LAYER metal10 = 0 um.\nTotal number of vias = 2223.\nUp-via summary (total 2223):.\n\nactive       0\n metal1    1151\n metal2    1037\n metal3      22\n metal4       7\n metal5       4\n metal6       2\n metal7       0\n metal8       0\n metal9       0\n\n       2223\n\n[INFO DRT-0198] Complete detail routing.\n```\nView the resulting detail routing in GUI as follows:", "source": "OpenROAD_flow_script"}
{"script_name": "GlobalRouting", "definition_description": "This script performs global routing by analyzing available routing resources and generating a congestion report for GCells, which helps avoid H/V overflow violations during routing.", "parameters": {"congestion_report": "The report generated showing the resource utilization and overflow status for global routing layers"}, "values": "congestion_report: [INFO GRT-0096] Final congestion report", "script_paradigm": "source gcd.tcl", "examples": [{"query": "How to execute the global routing and analyze congestion?", "answer": "source gcd.tcl"}], "reference": "Run following commands for filler cell insertion:\nset filler_master [list FILLCELL_X1 FILLCELL_X2 FILLCELL_X4 FILLCELL_X8 FILLCELL_X16]\nfiller_placement $filler_master\nView the resulting fill cell insertion as follows:\n\nFiller cells removed with remove_fillers command.\nGlobal Routing\nThe global router analyzes available routing resources and automatically\nallocates them to avoid any  H/V  overflow violations for optimal routing. \nIt generates a congestion report for GCells showing total resources, demand,\nutilization, location and the H/V violation status. If there are no violations\nreported then the design can proceed to detail routing.\nRefer to the built-in example here.\nLaunch OpenROAD GUI by running the following command(s) in the terminal in OpenROAD tool root directory:\nshell\ncd ../tools/OpenROAD/src/grt/test/\nopenroad -gui\nTo run the global routing, run the following commands in Tcl Commands of\nGUI:\ntcl\nsource gcd.tcl\nRouting resource and congestion analysis done with below log:\n```\n[INFO GRT-0096] Final congestion report:\nLayer         Resource        Demand        Usage (%)    Max H / Max V / Total Overflow\n\nmetal1           31235          1651            5.29%             0 /  0 /  0\nmetal2           24628          1652            6.71%             0 /  0 /  0\nmetal3           33120            40            0.12%             0 /  0 /  0\nmetal4           15698             0            0.00%             0 /  0 /  0\nmetal5           15404             0            0.00%             0 /  0 /  0\nmetal6           15642             0            0.00%             0 /  0 /  0\nmetal7            4416             0            0.00%             0 /  0 /  0\nmetal8            4512             0            0.00%             0 /  0 /  0\nmetal9            2208             0            0.00%             0 /  0 /  0\nmetal10           2256             0            0.00%             0 /  0 /  0\n\nTotal           149119          3343            2.24%             0 /  0 /  0\n[INFO GRT-0018] Total wirelength: 10598 um\n[INFO GRT-0014] Routed nets: 563\n```\nView the resulting global routing in GUI as follows:\n\nDetail Routing\nTritonRoute is an open-source detailed router for modern industrial designs.\nThe router consists of several main building blocks, including pin access\nanalysis, track assignment, initial detailed routing, search and repair, and a DRC engine.\nRefer to the built-in example here.\nLaunch OpenROAD GUI by running the following command(s) in the terminal in OpenROAD tool root directory:\nshell\ncd ../tools/OpenROAD/src/drt/test/\nopenroad -gui\nTo run the detail routing, run the following commands in Tcl Commands of\nGUI:\ntcl\nread_lef Nangate45/Nangate45_tech.lef\nread_lef Nangate45/Nangate45_stdcell.lef\nread_def gcd_nangate45_preroute.def\nread_guides gcd_nangate45.route_guide\nset_thread_count [expr [exec getconf _NPROCESSORS_ONLN] / 4]\ndetailed_route -output_drc results/gcd_nangate45.output.drc.rpt \\\n               -output_maze results/gcd_nangate45.output.maze.log \\\n               -verbose 1\nwrite_db gcd_nangate45.odb\nFor successful routing, DRT will end with 0 violations.\nLog as follows:\n```\n[INFO DRT-0199]   Number of violations = 0.\n[INFO DRT-0267] cpu time = 00:00:00, elapsed time = 00:00:00, memory = 674.22 (MB), peak = 686.08 (MB)\nTotal wire length = 5680 um.\nTotal wire length on LAYER metal1 = 19 um.\nTotal wire length on LAYER metal2 = 2798 um.\nTotal wire length on LAYER metal3 = 2614 um.\nTotal wire length on LAYER metal4 = 116 um.\nTotal wire length on LAYER metal5 = 63 um.\nTotal wire length on LAYER metal6 = 36 um.\nTotal wire length on LAYER metal7 = 32 um.\nTotal wire length on LAYER metal8 = 0 um.\nTotal wire length on LAYER metal9 = 0 um.\nTotal wire length on LAYER metal10 = 0 um.\nTotal number of vias = 2223.\nUp-via summary (total 2223):.\n\nactive       0\n metal1    1151\n metal2    1037\n metal3      22\n metal4       7\n metal5       4\n metal6       2\n metal7       0\n metal8       0\n metal9       0\n\n       2223\n\n[INFO DRT-0198] Complete detail routing.\n```\nView the resulting detail routing in GUI as follows:", "source": "OpenROAD_flow_script"}
{"script_name": "DetailRouting", "definition_description": "This script performs detailed routing using TritonRoute, an open-source router, to complete pin access analysis, track assignment, and other routing operations while ensuring no violations occur.", "parameters": {"lef_file": "LEF file for the technology or standard cell library", "def_file": "DEF file for the pre-routed design", "route_guide": "File specifying the routing guide for the design", "output_drc": "Output file for the DRC (Design Rule Check) results", "output_maze": "Output file for the maze routing log", "verbose": "Flag to control the verbosity of the output logs"}, "values": "lef_file: Nangate45/Nangate45_tech.lef, def_file: gcd_nangate45_preroute.def, route_guide: gcd_nangate45.route_guide", "script_paradigm": "read_lef Nangate45/Nangate45_tech.lef\nread_lef Nangate45/Nangate45_stdcell.lef\nread_def gcd_nangate45_preroute.def\nread_guides gcd_nangate45.route_guide\nset_thread_count [expr [exec getconf _NPROCESSORS_ONLN] / 4]\ndetailed_route -output_drc results/gcd_nangate45.output.drc.rpt -output_maze results/gcd_nangate45.output.maze.log -verbose 1\nwrite_db gcd_nangate45.odb", "examples": [{"query": "How to run detail routing with the provided LEF, DEF, and guide files?", "answer": "read_lef Nangate45/Nangate45_tech.lef\nread_lef Nangate45/Nangate45_stdcell.lef\nread_def gcd_nangate45_preroute.def\nread_guides gcd_nangate45.route_guide\nset_thread_count [expr [exec getconf _NPROCESSORS_ONLN] / 4]\ndetailed_route -output_drc results/gcd_nangate45.output.drc.rpt -output_maze results/gcd_nangate45.output.maze.log -verbose 1\nwrite_db gcd_nangate45.odb"}], "reference": "Run following commands for filler cell insertion:\nset filler_master [list FILLCELL_X1 FILLCELL_X2 FILLCELL_X4 FILLCELL_X8 FILLCELL_X16]\nfiller_placement $filler_master\nView the resulting fill cell insertion as follows:\n\nFiller cells removed with remove_fillers command.\nGlobal Routing\nThe global router analyzes available routing resources and automatically\nallocates them to avoid any  H/V  overflow violations for optimal routing. \nIt generates a congestion report for GCells showing total resources, demand,\nutilization, location and the H/V violation status. If there are no violations\nreported then the design can proceed to detail routing.\nRefer to the built-in example here.\nLaunch OpenROAD GUI by running the following command(s) in the terminal in OpenROAD tool root directory:\nshell\ncd ../tools/OpenROAD/src/grt/test/\nopenroad -gui\nTo run the global routing, run the following commands in Tcl Commands of\nGUI:\ntcl\nsource gcd.tcl\nRouting resource and congestion analysis done with below log:\n```\n[INFO GRT-0096] Final congestion report:\nLayer         Resource        Demand        Usage (%)    Max H / Max V / Total Overflow\n\nmetal1           31235          1651            5.29%             0 /  0 /  0\nmetal2           24628          1652            6.71%             0 /  0 /  0\nmetal3           33120            40            0.12%             0 /  0 /  0\nmetal4           15698             0            0.00%             0 /  0 /  0\nmetal5           15404             0            0.00%             0 /  0 /  0\nmetal6           15642             0            0.00%             0 /  0 /  0\nmetal7            4416             0            0.00%             0 /  0 /  0\nmetal8            4512             0            0.00%             0 /  0 /  0\nmetal9            2208             0            0.00%             0 /  0 /  0\nmetal10           2256             0            0.00%             0 /  0 /  0\n\nTotal           149119          3343            2.24%             0 /  0 /  0\n[INFO GRT-0018] Total wirelength: 10598 um\n[INFO GRT-0014] Routed nets: 563\n```\nView the resulting global routing in GUI as follows:\n\nDetail Routing\nTritonRoute is an open-source detailed router for modern industrial designs.\nThe router consists of several main building blocks, including pin access\nanalysis, track assignment, initial detailed routing, search and repair, and a DRC engine.\nRefer to the built-in example here.\nLaunch OpenROAD GUI by running the following command(s) in the terminal in OpenROAD tool root directory:\nshell\ncd ../tools/OpenROAD/src/drt/test/\nopenroad -gui\nTo run the detail routing, run the following commands in Tcl Commands of\nGUI:\ntcl\nread_lef Nangate45/Nangate45_tech.lef\nread_lef Nangate45/Nangate45_stdcell.lef\nread_def gcd_nangate45_preroute.def\nread_guides gcd_nangate45.route_guide\nset_thread_count [expr [exec getconf _NPROCESSORS_ONLN] / 4]\ndetailed_route -output_drc results/gcd_nangate45.output.drc.rpt \\\n               -output_maze results/gcd_nangate45.output.maze.log \\\n               -verbose 1\nwrite_db gcd_nangate45.odb\nFor successful routing, DRT will end with 0 violations.\nLog as follows:\n```\n[INFO DRT-0199]   Number of violations = 0.\n[INFO DRT-0267] cpu time = 00:00:00, elapsed time = 00:00:00, memory = 674.22 (MB), peak = 686.08 (MB)\nTotal wire length = 5680 um.\nTotal wire length on LAYER metal1 = 19 um.\nTotal wire length on LAYER metal2 = 2798 um.\nTotal wire length on LAYER metal3 = 2614 um.\nTotal wire length on LAYER metal4 = 116 um.\nTotal wire length on LAYER metal5 = 63 um.\nTotal wire length on LAYER metal6 = 36 um.\nTotal wire length on LAYER metal7 = 32 um.\nTotal wire length on LAYER metal8 = 0 um.\nTotal wire length on LAYER metal9 = 0 um.\nTotal wire length on LAYER metal10 = 0 um.\nTotal number of vias = 2223.\nUp-via summary (total 2223):.\n\nactive       0\n metal1    1151\n metal2    1037\n metal3      22\n metal4       7\n metal5       4\n metal6       2\n metal7       0\n metal8       0\n metal9       0\n\n       2223\n\n[INFO DRT-0198] Complete detail routing.\n```\nView the resulting detail routing in GUI as follows:", "source": "OpenROAD_flow_script"}
{"script_name": "GitQuickstart", "definition_description": "This tutorial provides basic instructions for setting up and using Git to contribute to the OpenROAD-flow-scripts repository, including forking, creating branches, committing, pushing changes, and submitting a pull request.", "parameters": {"repository_url": "The URL of the GitHub repository to clone", "branch_name": "The name of the feature branch to be created", "commit_message": "The message describing the changes made in the commit"}, "values": "repository_url: https://github.com/your-user-name/OpenROAD-flow-scripts.git, branch_name: shiny-new-feature, commit_message: your commit message goes here", "script_paradigm": "# Clone the repository\n git clone <repository_url>\n cd OpenROAD-flow-scripts\n git remote add upstream https://github.com/The-OpenROAD-Project/OpenROAD-flow-scripts.git\n git fetch upstream\n # Create a new branch\n git checkout master && git branch <branch_name>\n git checkout <branch_name>\n # Commit changes\n git add path/to/file-to-be-added.py\n git commit -s -m <commit_message>\n # Push changes\n git push origin <branch_name>", "examples": [{"query": "How to clone a repository and create a new feature branch named shiny-new-feature?", "answer": "git clone https://github.com/your-user-name/OpenROAD-flow-scripts.git\n cd OpenROAD-flow-scripts\n git remote add upstream https://github.com/The-OpenROAD-Project/OpenROAD-flow-scripts.git\n git fetch upstream\n git checkout master && git branch shiny-new-feature\n git checkout shiny-new-feature"}, {"query": "How to commit changes to a feature branch with a message?", "answer": "git add path/to/file-to-be-added.py\n git commit -s -m 'your commit message goes here'"}, {"query": "How to push changes to GitHub on the shiny-new-feature branch?", "answer": "git push origin shiny-new-feature"}], "reference": "Git Quickstart\nThis tutorial serves as a quickstart to Git and contributing to our repository. If you have not already set up OpenROAD-flow-scripts, please follow the instructions here. \n{tip} This basic tutorial gives instruction for basic password Git authentication.\nIf you would like to setup SSH authentication, please follow this [guide](https://help.github.com/set-up-git-redirect).\nForking\nYou will need your own fork to work on the code. Go to the OpenROAD-flow-scripts project\npage and hit the Fork button. You will\nwant to clone your fork to your machine:\nshell\ngit clone https://github.com/your-user-name/OpenROAD-flow-scripts.git\ncd OpenROAD-flow-scripts\ngit remote add upstream https://github.com/The-OpenROAD-Project/OpenROAD-flow-scripts.git\ngit fetch upstream\nThis creates the directory OpenROAD-flow-scripts and connects your repository to\nthe upstream (master project) OpenROAD-flow-scripts repository.\nCreating a branch\nYou want your master branch to reflect only production-ready code, so create a\nfeature branch for making your changes. For example:\n```shell\ngit checkout master && git branch shiny-new-feature\ngit checkout shiny-new-feature\nOr equivalently,\ngit checkout master && checkout -b shiny-new-feature \n```\nThis changes your working directory to the shiny-new-feature branch.  Keep any\nchanges in this branch specific to one bug or feature so it is clear\nwhat the branch brings to OpenROAD-flow-scripts. You can have many shiny-new-features\nand switch in between them using the git checkout command.\nWhen creating this branch, make sure your master branch is up to date with\nthe latest upstream master version. To update your local master branch, you\ncan do:\nshell\ngit checkout master\ngit pull upstream master\nWhen you want to update the feature branch with changes in master after\nyou created the branch, check the section on \nupdating a PR.\nCommitting your code\nKeep style fixes to a separate commit to make your pull request more readable. Once you've made changes, you can see them by typing:\nshell\ngit status\nIf you have created a new file, it is not being tracked by git. Add it by typing:\nshell\ngit add path/to/file-to-be-added.py\nDoing git status again should give something like:\n```shell\nOn branch shiny-new-feature\n\nmodified:   /relative/path/to/file-you-added.py\n\n```\nFinally, commit your changes to your local repository with an explanatory commit\nmessage. Do note the -s option is needed for developer signoff. \nshell\ngit commit -s -m \"your commit message goes here\"\nPushing your changes\nWhen you want your changes to appear publicly on your GitHub page, push your\nforked feature branch's commits:\nshell\ngit push origin shiny-new-feature\nHere origin is the default name given to your remote repository on GitHub.\nYou can see the remote repositories:\nshell\ngit remote -v\nIf you added the upstream repository as described above you will see something\nlike:\nshell\norigin  https://github.com/your-user-name/OpenROAD-flow-scripts.git (fetch)\norigin  https://github.com/your-user-name/OpenROAD-flow-scripts.git (push)\nupstream        https://github.com/The-OpenROAD-Project/OpenROAD-flow-scripts.git (fetch)\nupstream        https://github.com/The-OpenROAD-Project/OpenROAD-flow-scripts.git (push)\nNow your code is on GitHub, but it is not yet a part of the OpenROAD-flow-scripts project. For that to\nhappen, a pull request needs to be submitted on GitHub.\nReview your code\nWhen you're ready to ask for a code review, file a pull request. Before you do, once\nagain make sure that you have followed all the guidelines outlined in the Developer's Guide\nregarding code style, tests, performance tests, and documentation. You should also\ndouble check your branch changes against the branch it was based on:\n\nNavigate to your repository on GitHub -- https://github.com/your-user-name/OpenROAD-flow-scripts\nClick on Branches\nClick on the Compare button for your feature branch\nSelect the base and compare branches, if necessary. This will be master and\n   shiny-new-feature, respectively.", "source": "OpenROAD_flow_script"}
{"script_name": "AddNewPlatform", "definition_description": "This script adds a new platform to the OpenROAD flow by editing Makefile and creating the necessary directories and configuration files.", "parameters": {"platform_name": "The name of the new platform to be added", "design_name": "The name of the design to be used with the new platform"}, "values": "platform_name: <MyNewPlatform>, design_name: <gcd>", "script_paradigm": "mkdir flow/platforms/<platform_name>\nmkdir -p flow/designs/<platform_name>/<design_name>\ntouch flow/designs/<platform_name>/<design_name>/config.mk\ntouch flow/designs/<platform_name>/<design_name>/constraint.sdc", "examples": [{"query": "How to add a new platform named MyNewPlatform with a design gcd?", "answer": "mkdir flow/platforms/MyNewPlatform\nmkdir -p flow/designs/MyNewPlatform/gcd\ntouch flow/designs/MyNewPlatform/gcd/config.mk\ntouch flow/designs/MyNewPlatform/gcd/constraint.sdc"}], "reference": "Adding a New Platform to OpenROAD\nSetup\nThis section describes the necessary files and  directories needed to build\nthe platform.  All files and directories made/edited are independent of\neach other unless otherwise stated.\nMakefile\nMake the following edits  to the Makefile (located in flow/Makefile)\nso that OpenROAD can run the flow on a design using the new platform.\nAt the beginning of the Makefile, there is a block of DESIGN_CONFIG\nvariables that are commented out. These variables tell OpenROAD which\ndesign to run and on what platform. DESIGN_CONFIG specifically points\nto a config.mk file located in the designs directory for the respective\nplatform. It is not required to add a DESIGN_CONFIG variable for a design\nin the respective platform directly into the Makefile. It is merely a\nconvenience to add a DESIGN_CONFIG variable in the Makefile and can\ninstead be set when invoking make. OpenROAD has multiple Verilog designs\nalready made which can be used with any platform (see flow/designs/src\nfor a list of usable designs). For example, a DESIGN_CONFIG variable\nusing the gcd design on a new platform would look as follows:\n{code-block} Makefile\n:caption: Makefile\nDESIGN_CONFIG=./designs/MyNewPlatform/gcd/config.mk\nThe config.mk file will be generated later in the Design\nDirectory section of this document.\nPlatform Directory\nCreate a directory for the new technology inside flow/platforms to contain\nthe necessary files for the OpenROAD flow.\nshell\nmkdir flow/platforms/MyNewPlatform\n(content:design:directory)=\nDesign Directory\nThe design directory contains the configuration files for all the designs of\na specific platform. Create a directory for the new platform in flow/designs\nto contain the relevant files and directories for all the designs for the\nflow in that specific platform. Each design requires its own config.mk\nand constraint.sdc files.\n:::{tip}\nFollow the steps below to create the necessary directories and files.\nNote gcd is just an example and not a required name.\nshell\nmkdir -p flow/designs/MyNewPlatform/gcd\ntouch flow/designs/MyNewPlatform/gcd/config.mk\ntouch flow/designs/MyNewPlatform/gcd/constraint.sdc\nThis creates two directories MyNewPlatform and gcd and two empty files\nconfig.mk and constraint.sdc in flow/designs/MyNewPlatform/gcd.\n:::\nPlatform Configuration\nThis section describes the necessary files in the platform directory needed\nfor the OpenROAD flow. Specifically the config.mk file in the platform\ndirectory has all of the configuration variables that the flow uses. Refer\nto the OpenROAD-flow-scripts documentation for a full list of configuration\nvariables that can be set.\nRefer to the Flow variables document for details on how to use\nenvironment variables in OpenROAD-flow-scripts to configure platform and design specific parameters.\nFor an example of a platform config.mk file, refer to\nflow/platforms/sky130hd/config.mk.\nDesign Configuration\nThis section describes files in the design directory.\nconfig.mk\nThe config.mk file describes design-specific variables.\nFor Example:\nDESIGN_NAME\n    PLATFORM\n    VERILOG_FILES\n    SDC_FILE\n    CORE_UTILIZATION\n    CORE_ASPECT_RATIO\n    CORE_MARGIN\n    PLACE_DENSITY\nAlternatively, DIE_AREA and CORE_AREA can be specified instead of\nCORE_UTILIZATION, CORE_ASPECT_RATIO, and CORE_MARGIN. For a complete\ndescriptor of all variables see here.\nFollowing is a sample config.mk file for the gcd design:\n```{code-block} shell\n:caption: config.mk\nexport DESIGN_NAME     = gcd\nexport PLATFORM        = sky130hd\nexport VERILOG_FILES = $(sort $(wildcard ./designs/src/$(DESIGN_NAME)/*.v))\nexport SDC_FILE = ./designs/$(PLATFORM)/$(DESIGN_NAME)/constraint.sdc\nexport CORE_UTILIZATION  = 30\nexport CORE_ASPECT_RATIO = 1\nexport CORE_MARGIN       = 2\nexport PLACE_DENSITY     = 0.70\n```\nconstraint.sdc\nThe constraint.sdc file defines timing constraints for the design. The\ncreate_clock command allows you to define clocks that are either connected\nto nets or are virtual and can be customized. The units for create_clock\nneed to be consistent with the liberty time units. Here’s an example of", "source": "OpenROAD_flow_script"}
{"script_name": "SetPlatformConfig", "definition_description": "This script sets up the configuration file for the new platform in the OpenROAD flow.", "parameters": {"platform_name": "The name of the platform", "config_variables": "The configuration variables specific to the platform"}, "values": "platform_name: <MyNewPlatform>, config_variables: <DESIGN_NAME, PLATFORM, VERILOG_FILES, SDC_FILE, CORE_UTILIZATION, CORE_ASPECT_RATIO, CORE_MARGIN, PLACE_DENSITY>", "script_paradigm": "export DESIGN_NAME = <design_name>\nexport PLATFORM = <platform_name>\nexport VERILOG_FILES = $(sort $(wildcard ./designs/src/$(DESIGN_NAME)/*.v))\nexport SDC_FILE = ./designs/$(PLATFORM)/$(DESIGN_NAME)/constraint.sdc\nexport CORE_UTILIZATION = <core_utilization>\nexport CORE_ASPECT_RATIO = <core_aspect_ratio>\nexport CORE_MARGIN = <core_margin>\nexport PLACE_DENSITY = <place_density>", "examples": [{"query": "How to configure the platform MyNewPlatform for a design gcd?", "answer": "export DESIGN_NAME = gcd\nexport PLATFORM = MyNewPlatform\nexport VERILOG_FILES = $(sort $(wildcard ./designs/src/$(DESIGN_NAME)/*.v))\nexport SDC_FILE = ./designs/$(PLATFORM)/$(DESIGN_NAME)/constraint.sdc\nexport CORE_UTILIZATION = 30\nexport CORE_ASPECT_RATIO = 1\nexport CORE_MARGIN = 2\nexport PLACE_DENSITY = 0.70"}], "reference": "Adding a New Platform to OpenROAD\nSetup\nThis section describes the necessary files and  directories needed to build\nthe platform.  All files and directories made/edited are independent of\neach other unless otherwise stated.\nMakefile\nMake the following edits  to the Makefile (located in flow/Makefile)\nso that OpenROAD can run the flow on a design using the new platform.\nAt the beginning of the Makefile, there is a block of DESIGN_CONFIG\nvariables that are commented out. These variables tell OpenROAD which\ndesign to run and on what platform. DESIGN_CONFIG specifically points\nto a config.mk file located in the designs directory for the respective\nplatform. It is not required to add a DESIGN_CONFIG variable for a design\nin the respective platform directly into the Makefile. It is merely a\nconvenience to add a DESIGN_CONFIG variable in the Makefile and can\ninstead be set when invoking make. OpenROAD has multiple Verilog designs\nalready made which can be used with any platform (see flow/designs/src\nfor a list of usable designs). For example, a DESIGN_CONFIG variable\nusing the gcd design on a new platform would look as follows:\n{code-block} Makefile\n:caption: Makefile\nDESIGN_CONFIG=./designs/MyNewPlatform/gcd/config.mk\nThe config.mk file will be generated later in the Design\nDirectory section of this document.\nPlatform Directory\nCreate a directory for the new technology inside flow/platforms to contain\nthe necessary files for the OpenROAD flow.\nshell\nmkdir flow/platforms/MyNewPlatform\n(content:design:directory)=\nDesign Directory\nThe design directory contains the configuration files for all the designs of\na specific platform. Create a directory for the new platform in flow/designs\nto contain the relevant files and directories for all the designs for the\nflow in that specific platform. Each design requires its own config.mk\nand constraint.sdc files.\n:::{tip}\nFollow the steps below to create the necessary directories and files.\nNote gcd is just an example and not a required name.\nshell\nmkdir -p flow/designs/MyNewPlatform/gcd\ntouch flow/designs/MyNewPlatform/gcd/config.mk\ntouch flow/designs/MyNewPlatform/gcd/constraint.sdc\nThis creates two directories MyNewPlatform and gcd and two empty files\nconfig.mk and constraint.sdc in flow/designs/MyNewPlatform/gcd.\n:::\nPlatform Configuration\nThis section describes the necessary files in the platform directory needed\nfor the OpenROAD flow. Specifically the config.mk file in the platform\ndirectory has all of the configuration variables that the flow uses. Refer\nto the OpenROAD-flow-scripts documentation for a full list of configuration\nvariables that can be set.\nRefer to the Flow variables document for details on how to use\nenvironment variables in OpenROAD-flow-scripts to configure platform and design specific parameters.\nFor an example of a platform config.mk file, refer to\nflow/platforms/sky130hd/config.mk.\nDesign Configuration\nThis section describes files in the design directory.\nconfig.mk\nThe config.mk file describes design-specific variables.\nFor Example:\nDESIGN_NAME\n    PLATFORM\n    VERILOG_FILES\n    SDC_FILE\n    CORE_UTILIZATION\n    CORE_ASPECT_RATIO\n    CORE_MARGIN\n    PLACE_DENSITY\nAlternatively, DIE_AREA and CORE_AREA can be specified instead of\nCORE_UTILIZATION, CORE_ASPECT_RATIO, and CORE_MARGIN. For a complete\ndescriptor of all variables see here.\nFollowing is a sample config.mk file for the gcd design:\n```{code-block} shell\n:caption: config.mk\nexport DESIGN_NAME     = gcd\nexport PLATFORM        = sky130hd\nexport VERILOG_FILES = $(sort $(wildcard ./designs/src/$(DESIGN_NAME)/*.v))\nexport SDC_FILE = ./designs/$(PLATFORM)/$(DESIGN_NAME)/constraint.sdc\nexport CORE_UTILIZATION  = 30\nexport CORE_ASPECT_RATIO = 1\nexport CORE_MARGIN       = 2\nexport PLACE_DENSITY     = 0.70\n```\nconstraint.sdc\nThe constraint.sdc file defines timing constraints for the design. The\ncreate_clock command allows you to define clocks that are either connected\nto nets or are virtual and can be customized. The units for create_clock\nneed to be consistent with the liberty time units. Here’s an example of", "source": "OpenROAD_flow_script"}
{"script_name": "ContributeScripts", "definition_description": "This script outlines the procedures for contributing scripts and code to the OpenROAD project.", "parameters": {"script_type": "The type of script being contributed (e.g., design, PDK, utility scripts)", "license_type": "The licensing under which the script is shared, preferably BSD3"}, "values": "script_type: <design or utility>, license_type: <BSD3>", "script_paradigm": "Add contribution details to the OpenROAD-flow-scripts repo", "examples": [{"query": "How do I contribute a new utility script with BSD3 license?", "answer": "Add the script to the OpenROAD-flow-scripts repo with a BSD3 license."}, {"query": "What should I do if I want to contribute a design?", "answer": "Include the design in the appropriate directory within the OpenROAD-flow-scripts repo."}], "reference": "Getting Involved\nThank you for taking the time to read this document and to contribute.\nThe OpenROAD project will not reach all of its objectives without help!\nPossible ways to contribute in the scope of OpenROAD Flow:\n\nOpen-source PDK information\nOpen-source Designs\nUseful scripts\nStar our project and repos so we can see the number of people\n    who are interested\n\nLicensing Contributions\nAs much as possible, all contributions should be licensed using the BSD3\nlicense. You can propose another license if you must, but contributions\nmade with BSD3 fit best with the spirit of OpenROAD's permissive open-source\nphilosophy. We do have exceptions in the project, but over time we hope\nthat all contributions will be BSD3, or some other permissive license such as MIT\nor Apache2.0.\nContributing Open Source PDK information and Designs\nIf you have new design or PDK information to contribute, please add this\nto the repo\nOpenROAD-flow-scripts.\nIn the\nflow directory\nyou will see a directory for\ndesigns\nwith Makefiles to run them, and one for PDK\nplatforms\nused by the designs. If you add a new PDK platform, be sure to add at\nleast one design that uses it.\nContributing Scripts and Code\nWe follow the Google C++ style guide.\nIf you find code in our project that does not follow this guide, then within each file that\nyou edit, follow the style in that file.\nPlease pay careful attention to the\ntool checklist for all code. If you want\nto add or improve functionality in OpenROAD, please start with the\ntop-level app repo. You\ncan see in the src directory that submodules exist pointing to tested\nversions of the other relevant repos in the project. Please look at the\ntool workflow in the developer guide document\nto work with the app and its submodule repos in an efficient way.\nPlease run clang-format on all the C++ source files that you change, before\ncommitting. In the root directory of the OpenROAD repository there is the\nfile .clang-format that defines all coding formatting rules.\nPlease pay attention to the\ntest directory\nand be sure to add tests for any code changes that you make, using open-source\nPDK and design information. We provide the nangate45 PDK in\nthe OpenROAD-flow-scripts repo to help with this. Pull requests with\ncode changes are unlikely to be accepted without accompanying test\ncases. There are many\nexamples\ntests. Each repo has a test directory as well with tests you should run\nand add to if you modify something in one of the submodules.\nFor changes that claim to improve QoR or PPA, please run many tests and\nensure that the improvement is not design-specific. There are designs in\nthe\nOpenROAD-flow-scripts\nrepo which can be used unless the improvement is technology-specific.\nDo not add runtime or build dependencies without serious thought. For a\nproject like OpenROAD with many application subcomponents, the software\narchitecture can quickly get out of control. Changes with lots of new\ndependencies which are not necessary are less likely to be integrated.\nIf you want to add Tcl code to define a new tool command, look at pdngen\nas an example of how to do so. Take a look at the\nCMakeLists file\nwhich automatically sources the Tcl code and the\nTcl file\nitself.\nTo accept contributions, we require each commit to be made with a DCO (Developer\nCertificate of Origin) attached.\nWhen you commit you add the -s flag to your commit. For example:\nshell\ngit commit -s -m \"test dco with -s\"\nThis will append a statement to your commit comment that attests to the DCO. GitHub\nhas built in the -s option to its command line since use of this is so\npervasive. The promise is very basic, certifying that you know that you\nhave the right to commit the code. Please read the  full statement\nhere.\nQuestions\nPlease refer to our FAQs.", "source": "OpenROAD_flow_script"}
{"script_name": "CommitsWithDCO", "definition_description": "This script provides guidelines for making commits with a Developer Certificate of Origin (DCO).", "parameters": {"commit_message": "The message describing the changes made in the commit", "dco_flag": "The flag to append to the commit for certifying the DCO"}, "values": "commit_message: <Your commit message>, dco_flag: < -s >", "script_paradigm": "git commit -s -m <commit_message>", "examples": [{"query": "How do I commit changes while certifying DCO?", "answer": "git commit -s -m 'your commit message here'"}, {"query": "What do I include in my commit to satisfy DCO requirements?", "answer": "Add the -s flag to your git commit command."}], "reference": "Getting Involved\nThank you for taking the time to read this document and to contribute.\nThe OpenROAD project will not reach all of its objectives without help!\nPossible ways to contribute in the scope of OpenROAD Flow:\n\nOpen-source PDK information\nOpen-source Designs\nUseful scripts\nStar our project and repos so we can see the number of people\n    who are interested\n\nLicensing Contributions\nAs much as possible, all contributions should be licensed using the BSD3\nlicense. You can propose another license if you must, but contributions\nmade with BSD3 fit best with the spirit of OpenROAD's permissive open-source\nphilosophy. We do have exceptions in the project, but over time we hope\nthat all contributions will be BSD3, or some other permissive license such as MIT\nor Apache2.0.\nContributing Open Source PDK information and Designs\nIf you have new design or PDK information to contribute, please add this\nto the repo\nOpenROAD-flow-scripts.\nIn the\nflow directory\nyou will see a directory for\ndesigns\nwith Makefiles to run them, and one for PDK\nplatforms\nused by the designs. If you add a new PDK platform, be sure to add at\nleast one design that uses it.\nContributing Scripts and Code\nWe follow the Google C++ style guide.\nIf you find code in our project that does not follow this guide, then within each file that\nyou edit, follow the style in that file.\nPlease pay careful attention to the\ntool checklist for all code. If you want\nto add or improve functionality in OpenROAD, please start with the\ntop-level app repo. You\ncan see in the src directory that submodules exist pointing to tested\nversions of the other relevant repos in the project. Please look at the\ntool workflow in the developer guide document\nto work with the app and its submodule repos in an efficient way.\nPlease run clang-format on all the C++ source files that you change, before\ncommitting. In the root directory of the OpenROAD repository there is the\nfile .clang-format that defines all coding formatting rules.\nPlease pay attention to the\ntest directory\nand be sure to add tests for any code changes that you make, using open-source\nPDK and design information. We provide the nangate45 PDK in\nthe OpenROAD-flow-scripts repo to help with this. Pull requests with\ncode changes are unlikely to be accepted without accompanying test\ncases. There are many\nexamples\ntests. Each repo has a test directory as well with tests you should run\nand add to if you modify something in one of the submodules.\nFor changes that claim to improve QoR or PPA, please run many tests and\nensure that the improvement is not design-specific. There are designs in\nthe\nOpenROAD-flow-scripts\nrepo which can be used unless the improvement is technology-specific.\nDo not add runtime or build dependencies without serious thought. For a\nproject like OpenROAD with many application subcomponents, the software\narchitecture can quickly get out of control. Changes with lots of new\ndependencies which are not necessary are less likely to be integrated.\nIf you want to add Tcl code to define a new tool command, look at pdngen\nas an example of how to do so. Take a look at the\nCMakeLists file\nwhich automatically sources the Tcl code and the\nTcl file\nitself.\nTo accept contributions, we require each commit to be made with a DCO (Developer\nCertificate of Origin) attached.\nWhen you commit you add the -s flag to your commit. For example:\nshell\ngit commit -s -m \"test dco with -s\"\nThis will append a statement to your commit comment that attests to the DCO. GitHub\nhas built in the -s option to its command line since use of this is so\npervasive. The promise is very basic, certifying that you know that you\nhave the right to commit the code. Please read the  full statement\nhere.\nQuestions\nPlease refer to our FAQs.", "source": "OpenROAD_flow_script"}
{"script_name": "FollowCodingGuidelines", "definition_description": "This script specifies the coding style and testing requirements for contributions to OpenROAD.", "parameters": {"coding_guide": "The style guide to follow for code contributions, specifically the Google C++ style guide", "test_directory": "The directory where tests corresponding to the changes should be added"}, "values": "coding_guide: <Google C++ style>, test_directory: <test>", "script_paradigm": "Ensure code meets the guidelines from <coding_guide> and add tests in <test_directory>", "examples": [{"query": "How do I ensure my changes follow coding standards?", "answer": "Edit your code according to the Google C++ style guide and run clang-format."}, {"query": "Where do I add tests for my contributions?", "answer": "Add tests in the <test_directory> corresponding to your changes."}], "reference": "Getting Involved\nThank you for taking the time to read this document and to contribute.\nThe OpenROAD project will not reach all of its objectives without help!\nPossible ways to contribute in the scope of OpenROAD Flow:\n\nOpen-source PDK information\nOpen-source Designs\nUseful scripts\nStar our project and repos so we can see the number of people\n    who are interested\n\nLicensing Contributions\nAs much as possible, all contributions should be licensed using the BSD3\nlicense. You can propose another license if you must, but contributions\nmade with BSD3 fit best with the spirit of OpenROAD's permissive open-source\nphilosophy. We do have exceptions in the project, but over time we hope\nthat all contributions will be BSD3, or some other permissive license such as MIT\nor Apache2.0.\nContributing Open Source PDK information and Designs\nIf you have new design or PDK information to contribute, please add this\nto the repo\nOpenROAD-flow-scripts.\nIn the\nflow directory\nyou will see a directory for\ndesigns\nwith Makefiles to run them, and one for PDK\nplatforms\nused by the designs. If you add a new PDK platform, be sure to add at\nleast one design that uses it.\nContributing Scripts and Code\nWe follow the Google C++ style guide.\nIf you find code in our project that does not follow this guide, then within each file that\nyou edit, follow the style in that file.\nPlease pay careful attention to the\ntool checklist for all code. If you want\nto add or improve functionality in OpenROAD, please start with the\ntop-level app repo. You\ncan see in the src directory that submodules exist pointing to tested\nversions of the other relevant repos in the project. Please look at the\ntool workflow in the developer guide document\nto work with the app and its submodule repos in an efficient way.\nPlease run clang-format on all the C++ source files that you change, before\ncommitting. In the root directory of the OpenROAD repository there is the\nfile .clang-format that defines all coding formatting rules.\nPlease pay attention to the\ntest directory\nand be sure to add tests for any code changes that you make, using open-source\nPDK and design information. We provide the nangate45 PDK in\nthe OpenROAD-flow-scripts repo to help with this. Pull requests with\ncode changes are unlikely to be accepted without accompanying test\ncases. There are many\nexamples\ntests. Each repo has a test directory as well with tests you should run\nand add to if you modify something in one of the submodules.\nFor changes that claim to improve QoR or PPA, please run many tests and\nensure that the improvement is not design-specific. There are designs in\nthe\nOpenROAD-flow-scripts\nrepo which can be used unless the improvement is technology-specific.\nDo not add runtime or build dependencies without serious thought. For a\nproject like OpenROAD with many application subcomponents, the software\narchitecture can quickly get out of control. Changes with lots of new\ndependencies which are not necessary are less likely to be integrated.\nIf you want to add Tcl code to define a new tool command, look at pdngen\nas an example of how to do so. Take a look at the\nCMakeLists file\nwhich automatically sources the Tcl code and the\nTcl file\nitself.\nTo accept contributions, we require each commit to be made with a DCO (Developer\nCertificate of Origin) attached.\nWhen you commit you add the -s flag to your commit. For example:\nshell\ngit commit -s -m \"test dco with -s\"\nThis will append a statement to your commit comment that attests to the DCO. GitHub\nhas built in the -s option to its command line since use of this is so\npervasive. The promise is very basic, certifying that you know that you\nhave the right to commit the code. Please read the  full statement\nhere.\nQuestions\nPlease refer to our FAQs.", "source": "OpenROAD_flow_script"}
{"script_name": "DistributedAutotuning", "definition_description": "This script runs the Autotuning process using distributed resources on Google Cloud Platform (GCP) with Ray.", "parameters": {"design": "The name of the design for Autotuning", "platform": "The name of the platform for Autotuning", "config": "Configuration file that sets which knobs to use for Autotuning", "experiment": "Experiment name, used to prefix FLOW_VARIANT and set Ray log destination", "resume": "Flag to resume the previous run", "git_clean": "Flag to clean binaries and build files, may lose previous data", "git_clone": "Flag to force a new git clone, may lose previous data", "git_clone_args": "Additional git clone arguments", "git_latest": "Flag to use the latest version of OpenROAD app", "git_or_branch": "OpenROAD app branch to use", "git_orfs_branch": "OpenROAD-flow-scripts branch to use", "git_url": "OpenROAD-flow-scripts repository URL", "build_args": "Additional arguments for ./build_openroad.sh", "algorithm": "Search algorithm to use for Autotuning", "eval": "Evaluation function to use with the search algorithm", "samples": "Number of samples for tuning", "iterations": "Number of iterations for tuning", "resources_per_trial": "Number of CPUs to request for each tuning job", "reference": "Reference file for use with PPAImprov", "perturbation": "Perturbation interval for PopulationBasedTraining", "seed": "Random seed for reproducibility", "jobs": "Maximum number of concurrent jobs", "openroad_threads": "Maximum number of threads usable", "server": "The address of the Ray server to connect", "port": "The port of the Ray server to connect"}, "values": "design: <gcd>, platform: <sky130hd>, config: <distributed-sweep-example.json>, experiment: <sweep>, resume: <False>, git_clean: <False>, git_clone: <False>, git_clone_args: <None>, git_latest: <False>, git_or_branch: <None>, git_orfs_branch: <None>, git_url: <None>, build_args: <None>, algorithm: <population-based-training>, eval: <None>, samples: <10>, iterations: <50>, resources_per_trial: <4>, reference: <None>, perturbation: <0.1>, seed: <42>, jobs: <5>, openroad_threads: <8>, server: <None>, port: <None>", "script_paradigm": "python3 distributed.py --design <design> --platform <platform> --config <config> --experiment <experiment> --resume <resume> --git_clean <git_clean> --git_clone <git_clone> --git_clone_args <git_clone_args> --git_latest <git_latest> --git_or_branch <git_or_branch> --git_orfs_branch <git_orfs_branch> --git_url <git_url> --build_args <build_args> --algorithm <algorithm> --eval <eval> --samples <samples> --iterations <iterations> --resources_per_trial <resources_per_trial> --reference <reference> --perturbation <perturbation> --seed <seed> --jobs <jobs> --openroad_threads <openroad_threads> --server <server> --port <port>", "examples": [{"query": "How to run distributed autotuning for gcd design with sky130hd platform?", "answer": "python3 distributed.py --design gcd --platform sky130hd --config distributed-sweep-example.json --experiment sweep"}, {"query": "How to resume previous autotuning job with additional resources?", "answer": "python3 distributed.py --design gcd --platform sky130hd --config distributed-sweep-example.json --experiment sweep --resume True --resources_per_trial 8"}], "reference": "Example:\nshell\npython3 distributed.py --design gcd --platform sky130hd \\\n                       --config distributed-sweep-example.json \\\n                       sweep\nGoogle Cloud Platform (GCP) distribution with Ray\nGCP Setup Tutorial coming soon.\nList of input arguments\n| Argument                      | Description                                                                                           |\n|-------------------------------|-------------------------------------------------------------------------------------------------------|\n| --design                    | Name of the design for Autotuning.                                                                    |\n| --platform                  | Name of the platform for Autotuning.                                                                  |\n| --config                    | Configuration file that sets which knobs to use for Autotuning.                                       |\n| --experiment                | Experiment name. This parameter is used to prefix the FLOW_VARIANT and to set the Ray log destination.|\n| --resume                    | Resume previous run.                                                                                  |\n| --git_clean                 | Clean binaries and build files. WARNING: may lose previous data.                                  |\n| --git_clone                 | Force new git clone. WARNING: may lose previous data.                                             |\n| --git_clone_args            | Additional git clone arguments.                                                                       |\n| --git_latest                | Use latest version of OpenROAD app.                                                                   |\n| --git_or_branch             | OpenROAD app branch to use.                                                                           |\n| --git_orfs_branch           | OpenROAD-flow-scripts branch to use.                                                                  |\n| --git_url                   | OpenROAD-flow-scripts repo URL to use.                                                                |\n| --build_args                | Additional arguments given to ./build_openroad.sh                                                     |\n| --algorithm                 | Search algorithm to use for Autotuning.                                                               |\n| --eval                      | Evalaute function to use with search algorithm.  \\                                                    |\n| --samples                   | Number of samples for tuning.                                                                         |\n| --iterations                | Number of iterations for tuning.                                                                      |\n| --resources_per_trial       | Number of CPUs to request for each tuning job.                                                        |\n| --reference                 | Reference file for use with PPAImprov.                                                                |\n| --perturbation              | Perturbation interval for PopulationBasedTraining                                                     |\n| --seed                      | Random seed.                                                                                          |\n| --jobs                      | Max number of concurrent jobs.                                                                        |\n| --openroad_threads          | Max number of threads usable.                                                                         |\n| --server                    | The address of Ray server to connect.                                                                 |\n| --port                      | The port of Ray server to connect.                                                                    |", "source": "OpenROAD_flow_script"}
{"script_name": "create_clock", "definition_description": "This command is used to define clocks in the design, specifying the clock's period and associated ports.", "parameters": {"clock_port": "The port associated with the clock (e.g., clk).", "clock_period": "The period of the clock, defined in consistent time units (e.g., nanoseconds)."}, "values": "clock_port: <clk>, clock_period: <8.4ns>", "script_paradigm": "create_clock [get_ports <clock_port>] -period <clock_period>", "examples": [{"query": "How to define a clock with a period of 8.4ns on the port clk?", "answer": "create_clock [get_ports clk] -period 8.4ns"}], "reference": "export SDC_FILE = ./designs/$(PLATFORM)/$(DESIGN_NAME)/constraint.sdc\nexport CORE_UTILIZATION  = 30\nexport CORE_ASPECT_RATIO = 1\nexport CORE_MARGIN       = 2\nexport PLACE_DENSITY     = 0.70\n```\nconstraint.sdc\nThe constraint.sdc file defines timing constraints for the design. The\ncreate_clock command allows you to define clocks that are either connected\nto nets or are virtual and can be customized. The units for create_clock\nneed to be consistent with the liberty time units. Here’s an example of\na constraint.sdc file which defines a clock clk with a period of 8.4\nnanoseconds (nanoseconds being consistent with the liberty time units).\n{code-block} tcl\n:caption: constraint.sdc\ncreate_clock [get_ports clk] -period 8.4  #Units are in nanoseconds\nRefer to the\nOpenSTA\nUser Guide for the full documentation of the create_clock command.\nLiberty, LEF, and GDS Files\nThe liberty, LEF, and GDS files do not technically have to reside inside the\nplatform directory of respective technology as long as the paths set in the\nconfig.mk file point to the correct files. However, it is good practice to\nhave all relevant files in one localized directory. The .lib, .lef, and\n.gds reside in directories named respectively for the specific technology.\nFor example:\nshell\nmdkir flow/platforms/MyNewPlatform/lib\nmdkir flow/platforms/MyNewPlatform/lef\nmdkir flow/platforms/MyNewPlatform/gds\nA merged GDS file may be used instead of adding every individual .gds\nfile from the standard cell library.\nOnce the liberty file, tech and macro LEF files, and either the merged\nstandard cell GDS or individual standard cell GDS files have been generated,\nplace them in their respective directories and set the lib, lef, and\ngds variables in the platform config.mk file to the correct paths.\nClock Gates\nYosys cannot (currently) infer clock gates automatically. However, users can\nmanually instantiate clock gates in their RTL using a generic interface. The\npurpose of this interface is to separate platform-specific RTL (also called\n\"hardened\" RTL) from platform-independent RTL (generic RTL).\nThis file is only required if you want to instantiate clock gates in your\ndesign.\nTo create this module, a gated clock standard cell is required. This standard\ncell is used to create the generic module OPENROAD_CLKGATE, as shown below.\n```{code-block} verilog\n:caption: cells_clkgate.v\nmodule OPENROAD_CLKGATE (CK, E, GCK);\n  input  CK;\n  input  E;\n  output GCK;\n latch (.CLK(CK), .GATE(E), .GCLK(GCK));\nendmodule\n```\nAn example instantiation of this module in a user design is shown below.\n```{code-block} verilog\n:caption: buffer.v\n// This is not a platform file, this is an example user design\nmodule buffer (clk, enable, in, out);\ninput        clk, enable;\ninput  [7:0] in,\noutput [7:0] out\nreg  [15:0] buffer_reg;\nwire        gck; // Gated clock\nOPENROAD_CLKGATE clkgate (.CK(clk), .E(enable), .GCK(gck));\n// Buffer does not change if enable is low\nalways @(posedge gck) begin\n  buffer_reg[15:8] <= in;\n  buffer_reg[ 7:0] <= buffer_reg[15:8];\nend\nassign out = buffer_reg[ 7:0];\n```\nLatches\nYosys can automatically infer latches from RTL, however it requires a behavioral\nVerilog module. Example latch definitions are provided below. DLATCH_P is an\nactive-high level-sensitive latch and DLATCH_N is an active-low\nlevel-sensitive latch.\nThis file is only required if you want to infer latches for your design.\n```{code-block} verilog\n:caption: cells_latch.v\nmodule $DLATCH_P(input E, input D, output Q);\n   TECHMAP_REPLACE (\n    .D (D),\n    .G (E),\n    .Q (Q)\n  );\nendmodule\nmodule $DLATCH_N(input E, input D, output Q);\n   TECHMAP_REPLACE (\n    .D  (D),\n    .GN (E),\n    .Q  (Q)\n  );\nendmodule\n```\nFastRoute Configuration\nFastRoute is the tool used to global-route the design. FastRoute requires a\nTcl file to set which routing layers will be used for signals, adjust routing\nlayer resources, set which routing heuristic to use when routing, etc. It’s\nrecommended to use the default fastroute.tcl due to its simplicity and\neffectiveness. Following is the default FastRoute configuration file.\n{code-block} tcl", "source": "OpenROAD_flow_script"}
{"script_name": "FastRoute Configuration", "definition_description": "This script configures FastRoute for global routing, setting routing layers, resources, and heuristics.", "parameters": {"routing_layers": "Defines which routing layers will be used for signals.", "routing_heuristic": "Specifies the routing heuristic to use for the global route."}, "values": "routing_layers: <default>, routing_heuristic: <default>", "script_paradigm": "source fastroute.tcl", "examples": [{"query": "How to use the default FastRoute configuration?", "answer": "source fastroute.tcl"}], "reference": "export SDC_FILE = ./designs/$(PLATFORM)/$(DESIGN_NAME)/constraint.sdc\nexport CORE_UTILIZATION  = 30\nexport CORE_ASPECT_RATIO = 1\nexport CORE_MARGIN       = 2\nexport PLACE_DENSITY     = 0.70\n```\nconstraint.sdc\nThe constraint.sdc file defines timing constraints for the design. The\ncreate_clock command allows you to define clocks that are either connected\nto nets or are virtual and can be customized. The units for create_clock\nneed to be consistent with the liberty time units. Here’s an example of\na constraint.sdc file which defines a clock clk with a period of 8.4\nnanoseconds (nanoseconds being consistent with the liberty time units).\n{code-block} tcl\n:caption: constraint.sdc\ncreate_clock [get_ports clk] -period 8.4  #Units are in nanoseconds\nRefer to the\nOpenSTA\nUser Guide for the full documentation of the create_clock command.\nLiberty, LEF, and GDS Files\nThe liberty, LEF, and GDS files do not technically have to reside inside the\nplatform directory of respective technology as long as the paths set in the\nconfig.mk file point to the correct files. However, it is good practice to\nhave all relevant files in one localized directory. The .lib, .lef, and\n.gds reside in directories named respectively for the specific technology.\nFor example:\nshell\nmdkir flow/platforms/MyNewPlatform/lib\nmdkir flow/platforms/MyNewPlatform/lef\nmdkir flow/platforms/MyNewPlatform/gds\nA merged GDS file may be used instead of adding every individual .gds\nfile from the standard cell library.\nOnce the liberty file, tech and macro LEF files, and either the merged\nstandard cell GDS or individual standard cell GDS files have been generated,\nplace them in their respective directories and set the lib, lef, and\ngds variables in the platform config.mk file to the correct paths.\nClock Gates\nYosys cannot (currently) infer clock gates automatically. However, users can\nmanually instantiate clock gates in their RTL using a generic interface. The\npurpose of this interface is to separate platform-specific RTL (also called\n\"hardened\" RTL) from platform-independent RTL (generic RTL).\nThis file is only required if you want to instantiate clock gates in your\ndesign.\nTo create this module, a gated clock standard cell is required. This standard\ncell is used to create the generic module OPENROAD_CLKGATE, as shown below.\n```{code-block} verilog\n:caption: cells_clkgate.v\nmodule OPENROAD_CLKGATE (CK, E, GCK);\n  input  CK;\n  input  E;\n  output GCK;\n latch (.CLK(CK), .GATE(E), .GCLK(GCK));\nendmodule\n```\nAn example instantiation of this module in a user design is shown below.\n```{code-block} verilog\n:caption: buffer.v\n// This is not a platform file, this is an example user design\nmodule buffer (clk, enable, in, out);\ninput        clk, enable;\ninput  [7:0] in,\noutput [7:0] out\nreg  [15:0] buffer_reg;\nwire        gck; // Gated clock\nOPENROAD_CLKGATE clkgate (.CK(clk), .E(enable), .GCK(gck));\n// Buffer does not change if enable is low\nalways @(posedge gck) begin\n  buffer_reg[15:8] <= in;\n  buffer_reg[ 7:0] <= buffer_reg[15:8];\nend\nassign out = buffer_reg[ 7:0];\n```\nLatches\nYosys can automatically infer latches from RTL, however it requires a behavioral\nVerilog module. Example latch definitions are provided below. DLATCH_P is an\nactive-high level-sensitive latch and DLATCH_N is an active-low\nlevel-sensitive latch.\nThis file is only required if you want to infer latches for your design.\n```{code-block} verilog\n:caption: cells_latch.v\nmodule $DLATCH_P(input E, input D, output Q);\n   TECHMAP_REPLACE (\n    .D (D),\n    .G (E),\n    .Q (Q)\n  );\nendmodule\nmodule $DLATCH_N(input E, input D, output Q);\n   TECHMAP_REPLACE (\n    .D  (D),\n    .GN (E),\n    .Q  (Q)\n  );\nendmodule\n```\nFastRoute Configuration\nFastRoute is the tool used to global-route the design. FastRoute requires a\nTcl file to set which routing layers will be used for signals, adjust routing\nlayer resources, set which routing heuristic to use when routing, etc. It’s\nrecommended to use the default fastroute.tcl due to its simplicity and\neffectiveness. Following is the default FastRoute configuration file.\n{code-block} tcl", "source": "OpenROAD_flow_script"}
{"script_name": "Clock Gate Instantiation", "definition_description": "This script demonstrates the manual instantiation of a clock gate in RTL code, used to create gated clocks in the design.", "parameters": {"clk": "The clock signal to be gated.", "enable": "The signal that controls the gating (enables or disables the clock).", "gck": "The output gated clock signal."}, "values": "clk: <clk>, enable: <enable>, gck: <gck>", "script_paradigm": "OPENROAD_CLKGATE clkgate (.CK(<clk>), .E(<enable>), .GCK(<gck>));", "examples": [{"query": "How to instantiate a clock gate for a signal clk with an enable signal?", "answer": "OPENROAD_CLKGATE clkgate (.CK(clk), .E(enable), .GCK(gck));"}], "reference": "export SDC_FILE = ./designs/$(PLATFORM)/$(DESIGN_NAME)/constraint.sdc\nexport CORE_UTILIZATION  = 30\nexport CORE_ASPECT_RATIO = 1\nexport CORE_MARGIN       = 2\nexport PLACE_DENSITY     = 0.70\n```\nconstraint.sdc\nThe constraint.sdc file defines timing constraints for the design. The\ncreate_clock command allows you to define clocks that are either connected\nto nets or are virtual and can be customized. The units for create_clock\nneed to be consistent with the liberty time units. Here’s an example of\na constraint.sdc file which defines a clock clk with a period of 8.4\nnanoseconds (nanoseconds being consistent with the liberty time units).\n{code-block} tcl\n:caption: constraint.sdc\ncreate_clock [get_ports clk] -period 8.4  #Units are in nanoseconds\nRefer to the\nOpenSTA\nUser Guide for the full documentation of the create_clock command.\nLiberty, LEF, and GDS Files\nThe liberty, LEF, and GDS files do not technically have to reside inside the\nplatform directory of respective technology as long as the paths set in the\nconfig.mk file point to the correct files. However, it is good practice to\nhave all relevant files in one localized directory. The .lib, .lef, and\n.gds reside in directories named respectively for the specific technology.\nFor example:\nshell\nmdkir flow/platforms/MyNewPlatform/lib\nmdkir flow/platforms/MyNewPlatform/lef\nmdkir flow/platforms/MyNewPlatform/gds\nA merged GDS file may be used instead of adding every individual .gds\nfile from the standard cell library.\nOnce the liberty file, tech and macro LEF files, and either the merged\nstandard cell GDS or individual standard cell GDS files have been generated,\nplace them in their respective directories and set the lib, lef, and\ngds variables in the platform config.mk file to the correct paths.\nClock Gates\nYosys cannot (currently) infer clock gates automatically. However, users can\nmanually instantiate clock gates in their RTL using a generic interface. The\npurpose of this interface is to separate platform-specific RTL (also called\n\"hardened\" RTL) from platform-independent RTL (generic RTL).\nThis file is only required if you want to instantiate clock gates in your\ndesign.\nTo create this module, a gated clock standard cell is required. This standard\ncell is used to create the generic module OPENROAD_CLKGATE, as shown below.\n```{code-block} verilog\n:caption: cells_clkgate.v\nmodule OPENROAD_CLKGATE (CK, E, GCK);\n  input  CK;\n  input  E;\n  output GCK;\n latch (.CLK(CK), .GATE(E), .GCLK(GCK));\nendmodule\n```\nAn example instantiation of this module in a user design is shown below.\n```{code-block} verilog\n:caption: buffer.v\n// This is not a platform file, this is an example user design\nmodule buffer (clk, enable, in, out);\ninput        clk, enable;\ninput  [7:0] in,\noutput [7:0] out\nreg  [15:0] buffer_reg;\nwire        gck; // Gated clock\nOPENROAD_CLKGATE clkgate (.CK(clk), .E(enable), .GCK(gck));\n// Buffer does not change if enable is low\nalways @(posedge gck) begin\n  buffer_reg[15:8] <= in;\n  buffer_reg[ 7:0] <= buffer_reg[15:8];\nend\nassign out = buffer_reg[ 7:0];\n```\nLatches\nYosys can automatically infer latches from RTL, however it requires a behavioral\nVerilog module. Example latch definitions are provided below. DLATCH_P is an\nactive-high level-sensitive latch and DLATCH_N is an active-low\nlevel-sensitive latch.\nThis file is only required if you want to infer latches for your design.\n```{code-block} verilog\n:caption: cells_latch.v\nmodule $DLATCH_P(input E, input D, output Q);\n   TECHMAP_REPLACE (\n    .D (D),\n    .G (E),\n    .Q (Q)\n  );\nendmodule\nmodule $DLATCH_N(input E, input D, output Q);\n   TECHMAP_REPLACE (\n    .D  (D),\n    .GN (E),\n    .Q  (Q)\n  );\nendmodule\n```\nFastRoute Configuration\nFastRoute is the tool used to global-route the design. FastRoute requires a\nTcl file to set which routing layers will be used for signals, adjust routing\nlayer resources, set which routing heuristic to use when routing, etc. It’s\nrecommended to use the default fastroute.tcl due to its simplicity and\neffectiveness. Following is the default FastRoute configuration file.\n{code-block} tcl", "source": "OpenROAD_flow_script"}
{"script_name": "Latch Inference", "definition_description": "This script is used to automatically infer latches from RTL using specific Verilog modules for active-high and active-low latches.", "parameters": {"E": "The enable signal that controls the latch.", "D": "The data input to the latch.", "Q": "The data output from the latch."}, "values": "E: <E>, D: <D>, Q: <Q>", "script_paradigm": "module $DLATCH_P(input <E>, input <D>, output <Q>); TECHMAP_REPLACE (.D (<D>), .G (<E>), .Q (<Q>)); endmodule", "examples": [{"query": "How to infer an active-high latch in Verilog?", "answer": "module $DLATCH_P(input E, input D, output Q); TECHMAP_REPLACE (.D (D), .G (E), .Q (Q)); endmodule"}], "reference": "export SDC_FILE = ./designs/$(PLATFORM)/$(DESIGN_NAME)/constraint.sdc\nexport CORE_UTILIZATION  = 30\nexport CORE_ASPECT_RATIO = 1\nexport CORE_MARGIN       = 2\nexport PLACE_DENSITY     = 0.70\n```\nconstraint.sdc\nThe constraint.sdc file defines timing constraints for the design. The\ncreate_clock command allows you to define clocks that are either connected\nto nets or are virtual and can be customized. The units for create_clock\nneed to be consistent with the liberty time units. Here’s an example of\na constraint.sdc file which defines a clock clk with a period of 8.4\nnanoseconds (nanoseconds being consistent with the liberty time units).\n{code-block} tcl\n:caption: constraint.sdc\ncreate_clock [get_ports clk] -period 8.4  #Units are in nanoseconds\nRefer to the\nOpenSTA\nUser Guide for the full documentation of the create_clock command.\nLiberty, LEF, and GDS Files\nThe liberty, LEF, and GDS files do not technically have to reside inside the\nplatform directory of respective technology as long as the paths set in the\nconfig.mk file point to the correct files. However, it is good practice to\nhave all relevant files in one localized directory. The .lib, .lef, and\n.gds reside in directories named respectively for the specific technology.\nFor example:\nshell\nmdkir flow/platforms/MyNewPlatform/lib\nmdkir flow/platforms/MyNewPlatform/lef\nmdkir flow/platforms/MyNewPlatform/gds\nA merged GDS file may be used instead of adding every individual .gds\nfile from the standard cell library.\nOnce the liberty file, tech and macro LEF files, and either the merged\nstandard cell GDS or individual standard cell GDS files have been generated,\nplace them in their respective directories and set the lib, lef, and\ngds variables in the platform config.mk file to the correct paths.\nClock Gates\nYosys cannot (currently) infer clock gates automatically. However, users can\nmanually instantiate clock gates in their RTL using a generic interface. The\npurpose of this interface is to separate platform-specific RTL (also called\n\"hardened\" RTL) from platform-independent RTL (generic RTL).\nThis file is only required if you want to instantiate clock gates in your\ndesign.\nTo create this module, a gated clock standard cell is required. This standard\ncell is used to create the generic module OPENROAD_CLKGATE, as shown below.\n```{code-block} verilog\n:caption: cells_clkgate.v\nmodule OPENROAD_CLKGATE (CK, E, GCK);\n  input  CK;\n  input  E;\n  output GCK;\n latch (.CLK(CK), .GATE(E), .GCLK(GCK));\nendmodule\n```\nAn example instantiation of this module in a user design is shown below.\n```{code-block} verilog\n:caption: buffer.v\n// This is not a platform file, this is an example user design\nmodule buffer (clk, enable, in, out);\ninput        clk, enable;\ninput  [7:0] in,\noutput [7:0] out\nreg  [15:0] buffer_reg;\nwire        gck; // Gated clock\nOPENROAD_CLKGATE clkgate (.CK(clk), .E(enable), .GCK(gck));\n// Buffer does not change if enable is low\nalways @(posedge gck) begin\n  buffer_reg[15:8] <= in;\n  buffer_reg[ 7:0] <= buffer_reg[15:8];\nend\nassign out = buffer_reg[ 7:0];\n```\nLatches\nYosys can automatically infer latches from RTL, however it requires a behavioral\nVerilog module. Example latch definitions are provided below. DLATCH_P is an\nactive-high level-sensitive latch and DLATCH_N is an active-low\nlevel-sensitive latch.\nThis file is only required if you want to infer latches for your design.\n```{code-block} verilog\n:caption: cells_latch.v\nmodule $DLATCH_P(input E, input D, output Q);\n   TECHMAP_REPLACE (\n    .D (D),\n    .G (E),\n    .Q (Q)\n  );\nendmodule\nmodule $DLATCH_N(input E, input D, output Q);\n   TECHMAP_REPLACE (\n    .D  (D),\n    .GN (E),\n    .Q  (Q)\n  );\nendmodule\n```\nFastRoute Configuration\nFastRoute is the tool used to global-route the design. FastRoute requires a\nTcl file to set which routing layers will be used for signals, adjust routing\nlayer resources, set which routing heuristic to use when routing, etc. It’s\nrecommended to use the default fastroute.tcl due to its simplicity and\neffectiveness. Following is the default FastRoute configuration file.\n{code-block} tcl", "source": "OpenROAD_flow_script"}
{"script_name": "CheckMetricsAgainstGolden", "definition_description": "This script checks key metrics such as worst slack and number of DRCs to ensure that changes made to the design do not degrade performance in comparison to the 'golden' execution values.", "parameters": {"design_directory": "The directory containing the design files to be evaluated", "clean_metadata": "Flag to indicate if metadata should be cleared before re-running the check"}, "values": "design_directory: <path/to/design>, clean_metadata: <yes/no>", "script_paradigm": "cd OpenROAD-flow-scripts/flow; make [clean_metadata] metadata", "examples": [{"query": "How to check metrics for the design in the directory /path/to/design without clearing metadata?", "answer": "cd OpenROAD-flow-scripts/flow; make metadata"}, {"query": "How to check metrics and clear metadata for the design in /path/to/design?", "answer": "cd OpenROAD-flow-scripts/flow; make clean_metadata metadata"}], "reference": "Metrics\nThe OpenROAD-flow-scripts\nrepository contains source files (e.g., LEF/DEF, Verilog, SDC, Liberty,\nRC extraction) and configuration files (e.g. config.mk) that enable the user to run\na small set of example designs through our complete RTL-to-GDS flow.\nTo keep track of the quality of the results, we maintain inside each\ndesign folder two files:\n\n\nmetadata-base-ok.json which contains all the relevant\ninformation extracted from the \"golden\" execution of the flow (i.e.,\nlast known good result).\n\n\nrules.json which holds a set of rules that we use to\nevaluate new executions when a change is made.\n\n\nChecking against golden\nThe evaluation checks for key metrics (e.g., worst slack, number of\nDRCs) to ensure that changes do not degrade too much with respect to the\n\"golden\" values.\nAfter you make a significant change, e.g., fixing a bug in a piece of\ncode, or changing some configuration variable\n(PLACE_DENSITY), you should review the results and compare\nthem with the \"golden\". To perform the check, you will need to run the\nfollowing command:\n``` shell\ncd OpenROAD-flow-scripts/flow\nthe clean_metadata is only required if you need to re-run\nmake [clean_metadata] metadata\n```\nIf the command above yields any error message, please review to\nmake sure the change in metrics is expected and justifiable. If so,\nproceed to the next section to update the \"golden\" reference.\nUpdate process\nUpdate of the reference files is mandatory if any metrics became worse\nthan the values limited by the rules.json (see previous\nsection on how to perform the check). Also, it is a good idea to update\nthe \"golden\" files if your changes have improved a metric, to ensure that\nthe improvement will not be lost in the future.\nTo update all the reference files:\nshell\ncd OpenROAD-flow-scripts/flow\nmake update_ok\nIn case you have a special reason to only update one of the files, you\ncan do so with the following commands:\n``` shell\nupdate metadata-base-ok.json file for the design\nmake update_metadata\nupdate rules.json file for the design\nthis will use the current (+ a padding) metadata-base-ok.json\nthe padding ensures that small changes do not break the flow\nmake update_rules\n```", "source": "OpenROAD_flow_script"}
{"script_name": "UpdateGoldenReference", "definition_description": "This script updates the 'golden' reference files, either for the entire set or specific files, based on the latest results of the metrics check.", "parameters": {"update_all": "Flag to indicate if all reference files (metadata-base-ok.json and rules.json) should be updated", "update_metadata": "Flag to update only the metadata-base-ok.json file", "update_rules": "Flag to update only the rules.json file"}, "values": "update_all: <yes/no>, update_metadata: <yes/no>, update_rules: <yes/no>", "script_paradigm": "cd OpenROAD-flow-scripts/flow; make update_ok | make update_metadata | make update_rules", "examples": [{"query": "How to update all reference files after a successful metric check?", "answer": "cd OpenROAD-flow-scripts/flow; make update_ok"}, {"query": "How to update only the metadata-base-ok.json file?", "answer": "cd OpenROAD-flow-scripts/flow; make update_metadata"}, {"query": "How to update only the rules.json file?", "answer": "cd OpenROAD-flow-scripts/flow; make update_rules"}], "reference": "Metrics\nThe OpenROAD-flow-scripts\nrepository contains source files (e.g., LEF/DEF, Verilog, SDC, Liberty,\nRC extraction) and configuration files (e.g. config.mk) that enable the user to run\na small set of example designs through our complete RTL-to-GDS flow.\nTo keep track of the quality of the results, we maintain inside each\ndesign folder two files:\n\n\nmetadata-base-ok.json which contains all the relevant\ninformation extracted from the \"golden\" execution of the flow (i.e.,\nlast known good result).\n\n\nrules.json which holds a set of rules that we use to\nevaluate new executions when a change is made.\n\n\nChecking against golden\nThe evaluation checks for key metrics (e.g., worst slack, number of\nDRCs) to ensure that changes do not degrade too much with respect to the\n\"golden\" values.\nAfter you make a significant change, e.g., fixing a bug in a piece of\ncode, or changing some configuration variable\n(PLACE_DENSITY), you should review the results and compare\nthem with the \"golden\". To perform the check, you will need to run the\nfollowing command:\n``` shell\ncd OpenROAD-flow-scripts/flow\nthe clean_metadata is only required if you need to re-run\nmake [clean_metadata] metadata\n```\nIf the command above yields any error message, please review to\nmake sure the change in metrics is expected and justifiable. If so,\nproceed to the next section to update the \"golden\" reference.\nUpdate process\nUpdate of the reference files is mandatory if any metrics became worse\nthan the values limited by the rules.json (see previous\nsection on how to perform the check). Also, it is a good idea to update\nthe \"golden\" files if your changes have improved a metric, to ensure that\nthe improvement will not be lost in the future.\nTo update all the reference files:\nshell\ncd OpenROAD-flow-scripts/flow\nmake update_ok\nIn case you have a special reason to only update one of the files, you\ncan do so with the following commands:\n``` shell\nupdate metadata-base-ok.json file for the design\nmake update_metadata\nupdate rules.json file for the design\nthis will use the current (+ a padding) metadata-base-ok.json\nthe padding ensures that small changes do not break the flow\nmake update_rules\n```", "source": "OpenROAD_flow_script"}
{"script_name": "PolygonSplitting", "definition_description": "This script splits a polygon into multiple parts based on a maximum vertex count and area ratio.", "parameters": {"max_vertex_count": "The maximum number of vertices in each split polygon", "max_area_ratio": "The maximum area ratio for the split polygons"}, "values": "max_vertex_count: <unsigned long>, max_area_ratio: <double>", "script_paradigm": "SimplePolygon[] split(unsigned long max_vertex_count, double max_area_ratio);", "examples": [{"query": "How to split a polygon with a max of 100 vertices and 0.5 area ratio?", "answer": "SimplePolygon[] split_polygons = polygon.split(100, 0.5);"}], "reference": "[const] bool != (const SimplePolygon p) Returns a value indicating whether self is not equal to p [const] SimplePolygon * (double f) Scales the polygon by some factor [const] bool < (const SimplePolygon p) Returns a value indicating whether self is less than p [const] bool == (const SimplePolygon p) Returns a value indicating whether self is equal to p [const] SimplePolygon ptr _const_cast Returns a non-const reference to self. void _create Ensures the C++ object is created void _destroy Explicitly destroys the object [const] bool _destroyed? Returns a value indicating whether the object was already destroyed [const] bool _is_const_object? Returns a value indicating whether the reference is a const reference void _manage Marks the object as managed by the script side. void _unmanage Marks the object as no longer owned by the script side. [const] long area Gets the area of the polygon [const] long area2 Gets the double area of the polygon void assign (const SimplePolygon other) Assigns another object to self [const] Box bbox Returns the bounding box of the simple polygon [const] SimplePolygon[] break (unsigned long max_vertex_count, double max_area_ratio) Splits the polygon into parts with a maximum vertex count and area ratio void compress (bool remove_reflected) Compressed the simple polygon. [const] new SimplePolygon ptr dup Creates a copy of self [const,iter] Edge each_edge Iterates over the edges that make up the simple polygon [const,iter] Point each_point Iterates over the points that make up the simple polygon [const] variant[] extract_rad Extracts the corner radii from a rounded polygon [const] unsigned long hash Computes a hash value [const] bool inside? (Point p) Gets a value indicating whether the given point is inside the polygon [const] bool is_box? Returns a value indicating whether the polygon is a simple box. [const] bool is_empty? Returns a value indicating whether the polygon is empty [const] bool is_halfmanhattan? Returns a value indicating whether the polygon is half-manhattan [const] bool is_rectilinear? Returns a value indicating whether the polygon is rectilinear [const] Polygon minkowski_sum (const Edge e, bool resolve_holes) Computes the Minkowski sum of a polygon and an edge [const] Polygon minkowski_sum (const SimplePolygon p, bool resolve_holes) Computes the Minkowski sum of a polygon and a polygon [const] Polygon minkowski_sum (const Box b, bool resolve_holes) Computes the Minkowski sum of a polygon and a box [const] Polygon minkowski_sum (Point[] c, bool resolve_holes) Computes the Minkowski sum of a polygon and a contour of points (a trace) SimplePolygon move (const Vector p) Moves the simple polygon. SimplePolygon move (int x, int y) Moves the polygon. [const] SimplePolygon moved (const Vector p) Returns the moved simple polygon [const] SimplePolygon moved (int x, int y) Returns the moved polygon (does not modify self) [const] unsigned long num_points Gets the number of points [const] unsigned long perimeter Gets the perimeter of the polygon [const] Point point (unsigned long p) Gets a specific point of the contour@param p The index of the point to get void points= (Point[] pts) Sets the points of the simple polygon [const] SimplePolygon round_corners (double rinner, double router, unsigned int n) Rounds the corners of the polygon void set_points (Point[] pts, bool raw = false) Sets the points of the simple polygon [const] SimplePolygon[] split Splits the polygon into two or more parts [const] DSimplePolygon to_dtype (double dbu = 1) Converts the polygon to a floating-point coordinate polygon [const] string to_s Returns a string representing the polygon [const] bool touches? (const Box box) Returns true, if the polygon touches the given box. [const] bool touches? (const Edge edge) Returns true, if the polygon touches the given edge. [const] bool touches? (const Polygon polygon) Returns true, if the polygon touches the other polygon. [const] bool touches? (const SimplePolygon simple_polygon) Returns true, if the polygon touches the other polygon. SimplePolygon ptr transform (const", "source": "klayout"}
{"script_name": "PolygonTouchCheck", "definition_description": "This script checks whether the polygon touches another polygon, edge, or box.", "parameters": {"object": "The object (box, edge, or polygon) to check for touching"}, "values": "object: <Box/Edge/Polygon>", "script_paradigm": "bool touches(Box box); bool touches(Edge edge); bool touches(Polygon polygon); bool touches(SimplePolygon simple_polygon);", "examples": [{"query": "How to check if a polygon touches a box?", "answer": "bool result = polygon.touches(box);"}, {"query": "How to check if a polygon touches another polygon?", "answer": "bool result = polygon.touches(another_polygon);"}], "reference": "[const] bool != (const SimplePolygon p) Returns a value indicating whether self is not equal to p [const] SimplePolygon * (double f) Scales the polygon by some factor [const] bool < (const SimplePolygon p) Returns a value indicating whether self is less than p [const] bool == (const SimplePolygon p) Returns a value indicating whether self is equal to p [const] SimplePolygon ptr _const_cast Returns a non-const reference to self. void _create Ensures the C++ object is created void _destroy Explicitly destroys the object [const] bool _destroyed? Returns a value indicating whether the object was already destroyed [const] bool _is_const_object? Returns a value indicating whether the reference is a const reference void _manage Marks the object as managed by the script side. void _unmanage Marks the object as no longer owned by the script side. [const] long area Gets the area of the polygon [const] long area2 Gets the double area of the polygon void assign (const SimplePolygon other) Assigns another object to self [const] Box bbox Returns the bounding box of the simple polygon [const] SimplePolygon[] break (unsigned long max_vertex_count, double max_area_ratio) Splits the polygon into parts with a maximum vertex count and area ratio void compress (bool remove_reflected) Compressed the simple polygon. [const] new SimplePolygon ptr dup Creates a copy of self [const,iter] Edge each_edge Iterates over the edges that make up the simple polygon [const,iter] Point each_point Iterates over the points that make up the simple polygon [const] variant[] extract_rad Extracts the corner radii from a rounded polygon [const] unsigned long hash Computes a hash value [const] bool inside? (Point p) Gets a value indicating whether the given point is inside the polygon [const] bool is_box? Returns a value indicating whether the polygon is a simple box. [const] bool is_empty? Returns a value indicating whether the polygon is empty [const] bool is_halfmanhattan? Returns a value indicating whether the polygon is half-manhattan [const] bool is_rectilinear? Returns a value indicating whether the polygon is rectilinear [const] Polygon minkowski_sum (const Edge e, bool resolve_holes) Computes the Minkowski sum of a polygon and an edge [const] Polygon minkowski_sum (const SimplePolygon p, bool resolve_holes) Computes the Minkowski sum of a polygon and a polygon [const] Polygon minkowski_sum (const Box b, bool resolve_holes) Computes the Minkowski sum of a polygon and a box [const] Polygon minkowski_sum (Point[] c, bool resolve_holes) Computes the Minkowski sum of a polygon and a contour of points (a trace) SimplePolygon move (const Vector p) Moves the simple polygon. SimplePolygon move (int x, int y) Moves the polygon. [const] SimplePolygon moved (const Vector p) Returns the moved simple polygon [const] SimplePolygon moved (int x, int y) Returns the moved polygon (does not modify self) [const] unsigned long num_points Gets the number of points [const] unsigned long perimeter Gets the perimeter of the polygon [const] Point point (unsigned long p) Gets a specific point of the contour@param p The index of the point to get void points= (Point[] pts) Sets the points of the simple polygon [const] SimplePolygon round_corners (double rinner, double router, unsigned int n) Rounds the corners of the polygon void set_points (Point[] pts, bool raw = false) Sets the points of the simple polygon [const] SimplePolygon[] split Splits the polygon into two or more parts [const] DSimplePolygon to_dtype (double dbu = 1) Converts the polygon to a floating-point coordinate polygon [const] string to_s Returns a string representing the polygon [const] bool touches? (const Box box) Returns true, if the polygon touches the given box. [const] bool touches? (const Edge edge) Returns true, if the polygon touches the given edge. [const] bool touches? (const Polygon polygon) Returns true, if the polygon touches the other polygon. [const] bool touches? (const SimplePolygon simple_polygon) Returns true, if the polygon touches the other polygon. SimplePolygon ptr transform (const", "source": "klayout"}
{"script_name": "clock_tree_synthesis", "definition_description": "This script performs clock tree synthesis (CTS) by constructing a clock tree based on specified parameters, improving clock distribution and timing performance.", "parameters": {"wire_unit": "The minimum unit distance between buffers for a specific wire. If not set, it defaults to ten times the height of the root buffer.", "buf_list": "A Tcl list of master cells (buffers) considered when making wire segments. It provides the candidate buffers for the tree construction.", "root_buf": "The master cell of the buffer that serves as the root for the clock tree. If omitted, the first cell from the -buf_list is used.", "clk_nets": "Names of the clock roots. If omitted, the script attempts to automatically detect the clock roots.", "distance_between_buffers": "The distance in microns between buffers when constructing the clock tree. This simplifies the algorithm by using fewer segments.", "branching_point_buffers_distance": "Distance (in microns) between buffers that determines when a buffer will be inserted at the branch end-point. Requires -distance_between_buffers.", "clustering_exponent": "Determines the power used on the difference between sink and means in the CKMeans clustering algorithm. The default is 4.", "clustering_unbalance_ratio": "Determines each cluster's maximum capacity during CKMeans clustering. The default value is 0.6.", "sink_clustering_enable": "Enables the pre-clustering of sinks to form sub-trees before building the H-tree structure.", "sink_clustering_size": "Specifies the maximum number of sinks per cluster. The default is 20.", "sink_clustering_max_diameter": "Maximum diameter (in microns) of a sink cluster. The default is 50.", "balance_levels": "Attempts to maintain similar numbers of levels across non-register cells, like clock-gates or inverters. Default is False.", "num_static_layers": "Sets the number of static layers for the tree. Default is 0.", "sink_clustering_buffer": "Specifies the sink clustering buffer(s) to use.", "obstruction_aware": "Enables obstruction-aware buffering to avoid placing buffers on blockages or hard macros. Default is False.", "apply_ndr": "Applies non-default rules for clock nets, except leaf-level nets. Default is False.", "dont_use_dummy_load": "Prevents using dummy buffer or inverter cells at clock tree leaves to balance loads. Default is False.", "sink_buffer_max_cap_derate": "Controls automatic buffer selection based on maximum capacitance derating. The default is 0.01."}, "values": {"wire_unit": "<value>", "buf_list": "<list of buffers>", "root_buf": "<root buffer>", "clk_nets": "<clock root names>", "distance_between_buffers": "<distance in microns>", "branching_point_buffers_distance": "<distance in microns>", "clustering_exponent": "<integer>", "clustering_unbalance_ratio": "<float>", "sink_clustering_enable": "<bool>", "sink_clustering_size": "<integer>", "sink_clustering_max_diameter": "<integer>", "balance_levels": "<bool>", "num_static_layers": "<integer>", "sink_clustering_buffer": "<buffer>", "obstruction_aware": "<bool>", "apply_ndr": "<bool>", "dont_use_dummy_load": "<bool>", "sink_buffer_max_cap_derate": "<float>"}, "script_paradigm": "clock_tree_synthesis -wire_unit <wire_unit> -buf_list <buf_list> -root_buf <root_buf> -clk_nets <clk_nets> -distance_between_buffers <distance_between_buffers> -branching_point_buffers_distance <branching_point_buffers_distance> -clustering_exponent <clustering_exponent> -clustering_unbalance_ratio <clustering_unbalance_ratio> -sink_clustering_enable <sink_clustering_enable> -sink_clustering_size <sink_clustering_size> -sink_clustering_max_diameter <sink_clustering_max_diameter> -balance_levels <balance_levels> -num_static_layers <num_static_layers> -sink_clustering_buffer <sink_clustering_buffer> -obstruction_aware <obstruction_aware> -apply_ndr <apply_ndr> -dont_use_dummy_load <dont_use_dummy_load> -sink_buffer_max_cap_derate <sink_buffer_max_cap_derate>", "examples": [{"query": "How to perform clock tree synthesis with default settings and specific buffer list?", "answer": "clock_tree_synthesis -buf_list {BUFXX, BUFYY} -root_buf BUFXX -distance_between_buffers 100"}, {"query": "How to enable sink clustering with a maximum diameter of 60 microns and 30 sinks per cluster?", "answer": "clock_tree_synthesis -sink_clustering_enable True -sink_clustering_max_diameter 60 -sink_clustering_size 30"}, {"query": "How to prevent dummy loads at clock tree leaves and use obstruction-aware buffering?", "answer": "clock_tree_synthesis -dont_use_dummy_load True -obstruction_aware True"}], "reference": "NAME\nclock_tree_synthesis - clock tree synthesis\nSYNOPSIS\nclock_tree_synthesis \n    [-wire_unit wire_unit]\n    [-buf_list ]\n    [-root_buf root_buf]\n    [-clk_nets ]\n    [-tree_buf ]\n    [-distance_between_buffers]\n    [-branching_point_buffers_distance]\n    [-clustering_exponent]\n    [-clustering_unbalance_ratio]\n    [-sink_clustering_size cluster_size]\n    [-sink_clustering_max_diameter max_diameter]\n    [-sink_clustering_enable]\n    [-balance_levels]\n    [-sink_clustering_levels levels]\n    [-num_static_layers]\n    [-sink_clustering_buffer]\n    [-obstruction_aware]\n    [-apply_ndr]\n    [-insertion_delay]\n    [-dont_use_dummy_load]\n    [-sink_buffer_max_cap_derate derate_value]\n    [-delay_buffer_derate derate_value]\nDESCRIPTION\nPerform clock tree synthesis.\nOPTIONS\n-buf_list:  Tcl list of master cells (buffers) that will be considered when making the wire segments (e.g. {BUFXX, BUFYY}).\n-root_buffer:  The master cell of the buffer that serves as root for the clock tree. If this parameter is omitted, the first master cell from -buf_list is taken.\n-wire_unit:  Minimum unit distance between buffers for a specific wire. If this parameter is omitted, the code gets the value from ten times the height of -root_buffer.\n-distance_between_buffers:  Distance (in microns) between buffers that cts should use when creating the tree. When using this parameter, the clock tree algorithm is simplified and only uses a fraction of the segments from the LUT.\n-branching_point_buffers_distance:  Distance (in microns) that a branch has to have in order for a buffer to be inserted on a branch end-point. This requires the -distance_between_buffers value to be set.\n-clustering_exponent:  Value that determines the power used on the difference between sink and means on the CKMeans clustering algorithm. The default value is 4, and the allowed values are integers [0, MAX_INT].\n-clustering_unbalance_ratio:  Value determines each cluster's maximum capacity during CKMeans. A value of 0.5 (i.e., 50%) means that each cluster will have exactly half of all sinks for a specific region (half for each branch). The default value is 0.6, and the allowed values are floats [0, 1.0].\n-sink_clustering_enable:  Enables pre-clustering of sinks to create one level of sub-tree before building H-tree. Each cluster is driven by buffer which becomes end point of H-tree structure.\n-sink_clustering_size:  Specifies the maximum number of sinks per cluster. The default value is 20, and the allowed values are integers [0, MAX_INT].\n-sink_clustering_max_diameter:  Specifies maximum diameter (in microns) of sink cluster. The default value is 50, and the allowed values are integers [0, MAX_INT].\n-balance_levels:  Attempt to keep a similar number of levels in the clock tree across non-register cells (e.g., clock-gate or inverter). The default value is False, and the allowed values are bool.\n-clk_nets:  String containing the names of the clock roots. If this parameter is omitted, cts looks for the clock roots automatically.\n-num_static_layers:  Set the number of static layers. The default value is 0, and the allowed values are integers [0, MAX_INT].\n-sink_clustering_buffer:  Set the sink clustering buffer(s) to be used.\n-obstruction_aware:  Enables obstruction-aware buffering such that clock buffers are not placed on top of blockages or hard macros. This option may reduce legalizer displacement, leading to better latency, skew or timing QoR.  The default value is False, and the allowed values are bool.\n-apply_ndr:  Applies 2X spacing non-default rule to all clock nets except leaf-level nets. The default value is False.\n-dont_use_dummy_load:  Don't apply dummy buffer or inverter cells at clock tree leaves to balance loads. The default values is False.\n-sink_buffer_max_cap_derate:  Use this option to control automatic buffer selection. To favor strong(weak) drive strength buffers use a small(large) value.  The default value is 0.01, meaning that buffers are selected by derating max cap limit by 0.01. The value of 1.0 means no derating of max cap limit.", "source": "OpenROAD"}
{"script_name": "TilingProcessor_execute", "definition_description": "This script sets up and executes the tiling processor to perform XOR operations between two layouts and store the results in a report database.", "parameters": {"ly1": "The first layout for the XOR operation", "ly2": "The second layout for the XOR operation", "rdb": "The report database to store the results", "output_cell": "The output cell in the report database", "output_cat1": "The first output category in the report database", "output_cat2": "The second output category in the report database", "tile_size_x": "The width of each tile in the tiling operation", "tile_size_y": "The height of each tile in the tiling operation", "job_description": "A description of the job to be executed"}, "values": "ly1: <first_layout>, ly2: <second_layout>, rdb: <report_db>, output_cell: <output_cell>, output_cat1: <output_category1>, output_cat2: <output_category2>, tile_size_x: <50.0>, tile_size_y: <50.0>, job_description: <description>", "script_paradigm": "ly1 = ... # first layout\nly2 = ... # second layout\n\nrdb = RBA::ReportDatabase::new(\"xor\")\noutput_cell = rdb.create_cell(ly1.top_cell.name)\noutput_cat1 = rdb.create_category(\"XOR 1-10\")\noutput_cat2 = rdb.create_category(\"XOR 2-11\")\n\ntp = RBA::TilingProcessor::new\ntp.input(\"a1\", ly1, ly1.top_cell.cell_index, RBA::LayerInfo::new(1, 0))\ntp.input(\"a2\", ly1, ly1.top_cell.cell_index, RBA::LayerInfo::new(2, 0))\ntp.input(\"b1\", ly2, ly2.top_cell.cell_index, RBA::LayerInfo::new(11, 0))\ntp.input(\"b2\", ly2, ly2.top_cell.cell_index, RBA::LayerInfo::new(12, 0))\ntp.output(\"o1\", rdb, output_cell, output_cat1)\ntp.output(\"o2\", rdb, output_cell, output_cat2)\ntp.queue(\"_output(o1, a1 ^ b1)\")\ntp.queue(\"_output(o2, a2 ^ b2)\")\ntp.tile_size(50.0, 50.0)\ntp.execute(\"Job description\")", "examples": [{"query": "How to execute a tiling processor with XOR operations between two layouts?", "answer": "ly1 = ... # first layout\nly2 = ... # second layout\n\nrdb = RBA::ReportDatabase::new(\"xor\")\noutput_cell = rdb.create_cell(ly1.top_cell.name)\noutput_cat1 = rdb.create_category(\"XOR 1-10\")\noutput_cat2 = rdb.create_category(\"XOR 2-11\")\n\ntp = RBA::TilingProcessor::new\ntp.input(\"a1\", ly1, ly1.top_cell.cell_index, RBA::LayerInfo::new(1, 0))\ntp.input(\"a2\", ly1, ly1.top_cell.cell_index, RBA::LayerInfo::new(2, 0))\ntp.input(\"b1\", ly2, ly2.top_cell.cell_index, RBA::LayerInfo::new(11, 0))\ntp.input(\"b2\", ly2, ly2.top_cell.cell_index, RBA::LayerInfo::new(12, 0))\ntp.output(\"o1\", rdb, output_cell, output_cat1)\ntp.output(\"o2\", rdb, output_cell, output_cat2)\ntp.queue(\"_output(o1, a1 ^ b1)\")\ntp.queue(\"_output(o2, a2 ^ b2)\")\ntp.tile_size(50.0, 50.0)\ntp.execute(\"Job description\")"}], "reference": "Once the tiling processor has been set up, the operation can be launched using TilingProcessor#execute.\n\nThis is some sample code. It performs two XOR operations between two layouts and delivers the results to a report database:\n\nly1 = ... # first layout\nly2 = ... # second layout\n\nrdb = RBA::ReportDatabase::new(\"xor\")\noutput_cell = rdb.create_cell(ly1.top_cell.name)\noutput_cat1 = rbd.create_category(\"XOR 1-10\")\noutput_cat2 = rbd.create_category(\"XOR 2-11\")\n\ntp = RBA::TilingProcessor::new\ntp.input(\"a1\", ly1, ly1.top_cell.cell_index, RBA::LayerInfo::new(1, 0))\ntp.input(\"a2\", ly1, ly1.top_cell.cell_index, RBA::LayerInfo::new(2, 0))\ntp.input(\"b1\", ly2, ly2.top_cell.cell_index, RBA::LayerInfo::new(11, 0))\ntp.input(\"b2\", ly2, ly2.top_cell.cell_index, RBA::LayerInfo::new(12, 0))\ntp.output(\"o1\", rdb, output_cell, output_cat1)\ntp.output(\"o2\", rdb, output_cell, output_cat2)\ntp.queue(\"_output(o1, a1 ^ b1)\")\ntp.queue(\"_output(o2, a2 ^ b2)\")\ntp.tile_size(50.0, 50.0)\ntp.execute(\"Job description\")\n\nThis class has been introduced in version 0.23.\n\nPublic constructors\n\nnew TilingProcessor ptr new Creates a new object of this class\n\nPublic methods", "source": "klayout"}
{"script_name": "fill", "definition_description": "Fills the polygons of the layer with a regular pattern of shapes.", "parameters": {"hstep": "Specifies the horizontal step pitch of the pattern. x must be a positive value.", "vstep": "Specifies the vertical step pitch of the pattern. y must be a positive value.", "origin": "Specifies a fixed point to align the pattern with. Defines the reference point for one pattern cell.", "auto_origin": "Allows the algorithm to automatically choose the origin for better fill coverage.", "multi_origin": "Allows the algorithm to repeat the fill with different origins until no further fill cell can be fitted.", "fill_pattern": "Specifies the fill pattern used for the fill operation."}, "values": "hstep: <x>, vstep: <y>, origin: <x, y>, auto_origin: <true/false>, multi_origin: <true/false>, fill_pattern: <pattern>", "script_paradigm": "layer.fill(<options>)", "examples": [{"query": "How to fill a layer with a regular pattern and a horizontal step of 5?", "answer": "layer.fill(hstep(5))"}, {"query": "How to fill a layer with a pattern and auto_origin enabled?", "answer": "layer.fill(auto_origin(true))"}, {"query": "How to fill a layer with a specific fill pattern?", "answer": "layer.fill(fill_pattern('FILL_CELL'))"}], "reference": ":bottom or :b : the bottom line\n\n:top or :t : the top line\n\n:left or :l : the left line\n\n:right or :r : the right line\n\nDots are represented by small (2x2 DBU) boxes or point-like edges with edge output. Lines are represented by narrow or flat (2 DBU) boxes or edges for edge output. Edges will follow the orientation convention for the corresponding edges - i.e. \"inside\" of the bounding box is on the right side of the edge.\n\nThe following additional option controls the output format:\n\nas_boxes : with this option, small boxes will be produced as markers\n\nas_dots or as_edges : with this option, point-like edges will be produced for dots and edges will be produced for line-like selections\n\nThe following table shows a few applications:\n\n\"extents\" - Returns the bounding box of each input object\n\nUsage:\n\nlayer.extents([ enlargement ])\n\nApplies to edge layers, polygon layers on edge pair collections. Returns a polygon layer consisting of boxes for each input object. The boxes enclose the original object.\n\nMerged semantics applies, so the box encloses the merged polygons or edges unless raw mode is chosen (see raw).\n\nThe enlargement parameter specifies an optional enlargement which will make zero width/zero height object render valid polygons (i.e. horizontal/vertical edges).\n\nThe following images show the effect of the extents method:\n\n\"fill\" - Fills the region with regular pattern of shapes\n\nUsage:\n\nlayer.fill([ options ])\n\nThis method will attempt to fill the polygons of the layer with a regular pattern of shapes.\n\nThe fill function currently is not available in deep mode.\n\nOptions are:\n\nhstep(x) or hstep(x, y) : specifies the horizontal step pitch of the pattern. x must be a positive value. A vertical displacement component can be specified too, which results in a skewed pattern.\n\nvstep(y) or vstep(x, y) : specifies the vertical step pitch of the pattern. y must be a positive value. A horizontal displacement component can be specified too, which results in a skewed pattern.\n\norigin(x, y) : specifies a fixed point to align the pattern with. This point specifies the location of the reference point for one pattern cell.\n\nauto_origin : lets the algorithm choose the origin. This may result is a slightly better fill coverage as the algorithm is able to determine a pattern origin per island to fill.\n\nmulti_origin : lets the algorithm choose the origin and repeats the fill with different origins until no further fill cell can be fitted.\n\nfill_pattern(..) : specifies the fill pattern.\n\n\"fill_pattern\" generates a fill pattern object. This object is used for configuring the fill pattern content. Fill pattern need to be named. The name will be used for generating the fill cell.\n\nTo provide a fill pattern, create a fill pattern object and add shapes to it. The following example creates a fill pattern named \"FILL_CELL\" and adds a 1x1 micron box on layer 1/0:\n\np = fill_pattern(\"FILL_CELL\")\np.shape(1, 0, box(0.0, 0.0, 1.0, 1.0))\n\nSee box for details about the box specification. You can also add paths or polygons with path or polygon.\n\nA more compact way of writing this is:\n\np = fill_pattern(\"FILL_CELL\").shape(1, 0, box(0.0, 0.0, 1.0, 1.0))\n\nThe \"shape\" method takes several forms:\n\nshape(layer, object, object ...) (1)\n\nshape(layer, datatype, object, object ...) (2)\n\nshape(name, object, object ...) (3)\n\nshape(layer_info, object, object ...) (4)\n\nThe first form takes a GDS2 layer number. The datatype is assumed to be 0. The second form takes a GDS layer and datatype number. The third form takes a layer name for layout systems with named layers (like Magic, CIF or DXF). The forth form takes a LayerInfo object to specify the layer. All forms take one to many geometry objects which are written to the respective layer. Geometry objects can either be created using the generator functions (box, polygon, path). The core classes DBox, DPolygon, DPath or DText are also accepted as geometry objects.", "source": "klayout"}
{"script_name": "new", "definition_description": "This method creates an edge pair object either from an existing edge pair or a default constructor.", "parameters": {"dedge_pair": "The DEdgePair to initialize from (for version 0.25 and later).", "first": "The first edge in the edge pair (used with second).", "second": "The second edge in the edge pair (used with first).", "symmetric": "Indicates if the edge pair is symmetric or not."}, "values": "dedge_pair: <DEdgePair>, first: <Edge>, second: <Edge>, symmetric: <bool>", "script_paradigm": "new EdgePair ptr new (const DEdgePair dedge_pair), new EdgePair ptr new (const Edge first, const Edge second, bool symmetric = false)", "examples": [{"query": "How to create a new edge pair from two edges?", "answer": "new EdgePair ptr new (first, second, symmetric);"}], "reference": "If the object is not owned by the script, this method will do nothing. destroyed? Signature : [const] bool destroyed? Description : Returns a value indicating whether the object was already destroyed Use of this method is deprecated. Use _destroyed? instead This method returns true, if the object was destroyed, either explicitly or by the C++ side.\nThe latter may happen, if the object is owned by a C++ object which got destroyed itself. distance Signature : [const] unsigned int distance Description : Gets the distance of the edges in the edge pair The distance between the two edges is defined as the minimum distance between any two points on the two edges. This attribute has been introduced in version 0.28.14. dup Signature : [const] new EdgePair ptr dup Description : Creates a copy of self Python specific notes: This method also implements '__copy__' and '__deepcopy__'. first Signature : [const] Edge first Description : Gets the first edge Python specific notes: The object exposes a readable attribute 'first'. This is the getter. first= Signature : void first= (const Edge edge) Description : Sets the first edge Python specific notes: The object exposes a writable attribute 'first'. This is the setter. from_s Signature : [static] new EdgePair ptr from_s (string s) Description : Creates an object from a string Creates the object from a string representation (as returned by to_s ) This method has been added in version 0.23. greater Signature : [const] Edge greater Description : Gets the 'greater' edge for symmetric edge pairs As first and second edges are commutable for symmetric edge pairs (see symmetric? ), this accessor allows retrieving a 'second' edge in a way independent on the actual assignment. This read-only attribute has been introduced in version 0.27. hash Signature : [const] unsigned long hash Description : Computes a hash value Returns a hash value for the given edge pair. This method enables edge pairs as hash keys. This method has been introduced in version 0.25. Python specific notes: This method is also available as 'hash(object)'. is_const_object? Signature : [const] bool is_const_object? Description : Returns a value indicating whether the reference is a const reference Use of this method is deprecated. Use _is_const_object? instead This method returns true, if self is a const reference.\nIn that case, only const methods may be called on self. lesser Signature : [const] Edge lesser Description : Gets the 'lesser' edge for symmetric edge pairs As first and second edges are commutable for symmetric edge pairs (see symmetric? ), this accessor allows retrieving a 'first' edge in a way independent on the actual assignment. This read-only attribute has been introduced in version 0.27. new (1) Signature : [static] new EdgePair ptr new (const DEdgePair dedge_pair) Description : Creates an integer coordinate edge pair from a floating-point coordinate edge pair This constructor has been introduced in version 0.25 and replaces the previous static method 'from_dedge_pair'. Python specific notes: This method is the default initializer of the object. (2) Signature : [static] new EdgePair ptr new Description : Default constructor This constructor creates an default edge pair. Python specific notes: This method is the default initializer of the object. (3) Signature : [static] new EdgePair ptr new (const Edge first, const Edge second, bool symmetric = false) Description : Constructor from two edges This constructor creates an edge pair from the two edges given.\nSee symmetric? for a description of this attribute. Python specific notes: This method is the default initializer of the object. normalized Signature : [const] EdgePair normalized Description : Normalizes the edge pair This method normalized the edge pair such that when connecting the edges at their", "source": "klayout"}
{"script_name": "map_props", "definition_description": "This script maps key values in the properties of a layer, modifying them as needed.", "parameters": {"key_map": "A dictionary mapping property keys from one value to another"}, "values": "key_map: { 2 => 1 }", "script_paradigm": "layer1 = input(1, 0, enable_properties)\nlayer1_mapped = layer1.map_props({ 2 => 1 })", "examples": [{"query": "How to map key 2 to 1 and ignore other keys?", "answer": "layer1 = input(1, 0, enable_properties)\nlayer1_mapped = layer1.map_props({ 2 => 1 })"}], "reference": "For example to map key 2 to 1 (integer name keys) and ignore other keys, use:\n\nlayer1 = input(1, 0, enable_properties)\nlayer1_mapped = layer1.map_props({ 2 => 1 })\n\nSee also select_props and remove_props.\n\n\"merge\" - Merges the layer (modifies the layer)\n\nUsage:\n\nlayer.merge([overlap_count])\n\nLike merged, but modifies the input and returns a reference to the new layer.\n\n\"merged\" - Returns the merged layer\n\nUsage:\n\nlayer.merged([overlap_count])\n\nReturns the merged input. Usually, merging is done implicitly using the clean state (which is default). However, in raw state, merging can be enforced by using this method. In addition, this method allows specification of a minimum overlap count, i.e. only where at least the given number of polygons overlap, output is produced. See sized for an application of that.\n\nThis method works both on edge or polygon layers. Edge merging forms single, continuous edges from coincident and connected individual edges.\n\nA version that modifies the input layer is merge.\n\nThe following images show the effect of various forms of the \"merged\" method:\n\n\"middle\" - Returns the center points of the bounding boxes of the polygons\n\nUsage:\n\nlayer.middle([ options ])\n\nThis method produces markers on the centers of the polygon's bounding box centers. These markers can be point-like edges or small 2x2 DBU boxes. The latter is the default. A more generic function is extent_refs. \"middle\" is basically a synonym for \"extent_refs(:center)\".\n\nThe options available are:\n\nas_boxes : with this option, small boxes will be produced as markers\n\nas_dots : with this option, point-like edges will be produced instead of small boxes\n\nThe following image shows the effect of this method\n\n\"move\" - Moves (shifts, translates) a layer (modifies the layer)\n\nUsage:\n\nlayer.move(dx, dy)\n\nMoved the input by the given distance. The layer that this method is called upon is modified and the modified version is returned for further processing.\n\nShift distances can be given as floating-point values (in micron) or integer values (in database units). To explicitly specify the unit, use the unit denominators.\n\n\"moved\" - Moves (shifts, translates) a layer\n\nUsage:\n\nlayer.moved(dx, dy)\n\nMoves the input layer by the given distance (x, y) and returns the moved layer. The layer that this method is called upon is not modified.\n\nShift distances can be given as floating-point values (in micron) or integer values (in database units). To explicitly specify the unit, use the unit denominators.\n\nThe following images shows the effect of the \"moved\" method:\n\n\"nets\" - Pulls net shapes from selected or all nets, optionally annotating nets with properties\n\nUsage:\n\nlayer.nets\n\nlayer.nets(net_filter)\n\nlayer.nets(net_object)\n\nlayer.nets(circuit_filter, net_filter)\n\nlayer.nets(netter, ...)\n\nlayer.nets(prop(key), ...)\n\nlayer.nets(prop(key), ...)\n\nThis method needs a layer that has been used in a connect statement. It will take the shapes corresponding to this layer for all or selected nets and attach the net identity in form of a user property.\n\nThis way, the resulting shapes can be used in property-constrained boolean operations or DRC checks to implement operations in connected or non-connected mode.\n\nA glob-style name pattern can be supplied to filter nets. Nets are always complete - subnets from subcircuits are not selected. The net name is taken from the net's home circuit (to topmost location where all net connections are formed). You can specify a circuit filter to select nets from certain circuits only or give a Circuit object explicitly. You can also specify Net objects directly.\n\nconnect(metal1, via1)\nconnect(via1, metal2)\n\nmetal1_all_nets = metal1.nets\nmetal1_vdd      = metal1.nets(\"VDD\")\nmetal1_vdd      = metal1.nets(\"TOPLEVEL\", \"VDD\")\n\nBy default, the property key used for the net identity is numerical 0 (integer). You can change the key by giving a property key with the \"prop\" qualifier. Using \"nil\" for the key will disable properties:\n\nmetal1_vdd = metal1.nets(\"VDD\", prop(1))\n# disables properties:\nmetal1_vdd = metal1.nets(\"VDD\", prop(nil))", "source": "klayout"}
{"script_name": "merge", "definition_description": "This script merges the layer and modifies the input layer, returning a reference to the new layer.", "parameters": {"overlap_count": "The minimum number of overlapping polygons required to produce output"}, "values": "overlap_count: [optional]", "script_paradigm": "layer.merge([overlap_count])", "examples": [{"query": "How to merge a layer with an overlap count of 2?", "answer": "layer.merge([2])"}], "reference": "For example to map key 2 to 1 (integer name keys) and ignore other keys, use:\n\nlayer1 = input(1, 0, enable_properties)\nlayer1_mapped = layer1.map_props({ 2 => 1 })\n\nSee also select_props and remove_props.\n\n\"merge\" - Merges the layer (modifies the layer)\n\nUsage:\n\nlayer.merge([overlap_count])\n\nLike merged, but modifies the input and returns a reference to the new layer.\n\n\"merged\" - Returns the merged layer\n\nUsage:\n\nlayer.merged([overlap_count])\n\nReturns the merged input. Usually, merging is done implicitly using the clean state (which is default). However, in raw state, merging can be enforced by using this method. In addition, this method allows specification of a minimum overlap count, i.e. only where at least the given number of polygons overlap, output is produced. See sized for an application of that.\n\nThis method works both on edge or polygon layers. Edge merging forms single, continuous edges from coincident and connected individual edges.\n\nA version that modifies the input layer is merge.\n\nThe following images show the effect of various forms of the \"merged\" method:\n\n\"middle\" - Returns the center points of the bounding boxes of the polygons\n\nUsage:\n\nlayer.middle([ options ])\n\nThis method produces markers on the centers of the polygon's bounding box centers. These markers can be point-like edges or small 2x2 DBU boxes. The latter is the default. A more generic function is extent_refs. \"middle\" is basically a synonym for \"extent_refs(:center)\".\n\nThe options available are:\n\nas_boxes : with this option, small boxes will be produced as markers\n\nas_dots : with this option, point-like edges will be produced instead of small boxes\n\nThe following image shows the effect of this method\n\n\"move\" - Moves (shifts, translates) a layer (modifies the layer)\n\nUsage:\n\nlayer.move(dx, dy)\n\nMoved the input by the given distance. The layer that this method is called upon is modified and the modified version is returned for further processing.\n\nShift distances can be given as floating-point values (in micron) or integer values (in database units). To explicitly specify the unit, use the unit denominators.\n\n\"moved\" - Moves (shifts, translates) a layer\n\nUsage:\n\nlayer.moved(dx, dy)\n\nMoves the input layer by the given distance (x, y) and returns the moved layer. The layer that this method is called upon is not modified.\n\nShift distances can be given as floating-point values (in micron) or integer values (in database units). To explicitly specify the unit, use the unit denominators.\n\nThe following images shows the effect of the \"moved\" method:\n\n\"nets\" - Pulls net shapes from selected or all nets, optionally annotating nets with properties\n\nUsage:\n\nlayer.nets\n\nlayer.nets(net_filter)\n\nlayer.nets(net_object)\n\nlayer.nets(circuit_filter, net_filter)\n\nlayer.nets(netter, ...)\n\nlayer.nets(prop(key), ...)\n\nlayer.nets(prop(key), ...)\n\nThis method needs a layer that has been used in a connect statement. It will take the shapes corresponding to this layer for all or selected nets and attach the net identity in form of a user property.\n\nThis way, the resulting shapes can be used in property-constrained boolean operations or DRC checks to implement operations in connected or non-connected mode.\n\nA glob-style name pattern can be supplied to filter nets. Nets are always complete - subnets from subcircuits are not selected. The net name is taken from the net's home circuit (to topmost location where all net connections are formed). You can specify a circuit filter to select nets from certain circuits only or give a Circuit object explicitly. You can also specify Net objects directly.\n\nconnect(metal1, via1)\nconnect(via1, metal2)\n\nmetal1_all_nets = metal1.nets\nmetal1_vdd      = metal1.nets(\"VDD\")\nmetal1_vdd      = metal1.nets(\"TOPLEVEL\", \"VDD\")\n\nBy default, the property key used for the net identity is numerical 0 (integer). You can change the key by giving a property key with the \"prop\" qualifier. Using \"nil\" for the key will disable properties:\n\nmetal1_vdd = metal1.nets(\"VDD\", prop(1))\n# disables properties:\nmetal1_vdd = metal1.nets(\"VDD\", prop(nil))", "source": "klayout"}
{"script_name": "merged", "definition_description": "This script returns the merged layer without modifying the input, and allows specification of minimum overlap count.", "parameters": {"overlap_count": "The minimum number of overlapping polygons required to produce output"}, "values": "overlap_count: [optional]", "script_paradigm": "layer.merged([overlap_count])", "examples": [{"query": "How to get the merged layer with an overlap count of 3?", "answer": "layer.merged([3])"}], "reference": "For example to map key 2 to 1 (integer name keys) and ignore other keys, use:\n\nlayer1 = input(1, 0, enable_properties)\nlayer1_mapped = layer1.map_props({ 2 => 1 })\n\nSee also select_props and remove_props.\n\n\"merge\" - Merges the layer (modifies the layer)\n\nUsage:\n\nlayer.merge([overlap_count])\n\nLike merged, but modifies the input and returns a reference to the new layer.\n\n\"merged\" - Returns the merged layer\n\nUsage:\n\nlayer.merged([overlap_count])\n\nReturns the merged input. Usually, merging is done implicitly using the clean state (which is default). However, in raw state, merging can be enforced by using this method. In addition, this method allows specification of a minimum overlap count, i.e. only where at least the given number of polygons overlap, output is produced. See sized for an application of that.\n\nThis method works both on edge or polygon layers. Edge merging forms single, continuous edges from coincident and connected individual edges.\n\nA version that modifies the input layer is merge.\n\nThe following images show the effect of various forms of the \"merged\" method:\n\n\"middle\" - Returns the center points of the bounding boxes of the polygons\n\nUsage:\n\nlayer.middle([ options ])\n\nThis method produces markers on the centers of the polygon's bounding box centers. These markers can be point-like edges or small 2x2 DBU boxes. The latter is the default. A more generic function is extent_refs. \"middle\" is basically a synonym for \"extent_refs(:center)\".\n\nThe options available are:\n\nas_boxes : with this option, small boxes will be produced as markers\n\nas_dots : with this option, point-like edges will be produced instead of small boxes\n\nThe following image shows the effect of this method\n\n\"move\" - Moves (shifts, translates) a layer (modifies the layer)\n\nUsage:\n\nlayer.move(dx, dy)\n\nMoved the input by the given distance. The layer that this method is called upon is modified and the modified version is returned for further processing.\n\nShift distances can be given as floating-point values (in micron) or integer values (in database units). To explicitly specify the unit, use the unit denominators.\n\n\"moved\" - Moves (shifts, translates) a layer\n\nUsage:\n\nlayer.moved(dx, dy)\n\nMoves the input layer by the given distance (x, y) and returns the moved layer. The layer that this method is called upon is not modified.\n\nShift distances can be given as floating-point values (in micron) or integer values (in database units). To explicitly specify the unit, use the unit denominators.\n\nThe following images shows the effect of the \"moved\" method:\n\n\"nets\" - Pulls net shapes from selected or all nets, optionally annotating nets with properties\n\nUsage:\n\nlayer.nets\n\nlayer.nets(net_filter)\n\nlayer.nets(net_object)\n\nlayer.nets(circuit_filter, net_filter)\n\nlayer.nets(netter, ...)\n\nlayer.nets(prop(key), ...)\n\nlayer.nets(prop(key), ...)\n\nThis method needs a layer that has been used in a connect statement. It will take the shapes corresponding to this layer for all or selected nets and attach the net identity in form of a user property.\n\nThis way, the resulting shapes can be used in property-constrained boolean operations or DRC checks to implement operations in connected or non-connected mode.\n\nA glob-style name pattern can be supplied to filter nets. Nets are always complete - subnets from subcircuits are not selected. The net name is taken from the net's home circuit (to topmost location where all net connections are formed). You can specify a circuit filter to select nets from certain circuits only or give a Circuit object explicitly. You can also specify Net objects directly.\n\nconnect(metal1, via1)\nconnect(via1, metal2)\n\nmetal1_all_nets = metal1.nets\nmetal1_vdd      = metal1.nets(\"VDD\")\nmetal1_vdd      = metal1.nets(\"TOPLEVEL\", \"VDD\")\n\nBy default, the property key used for the net identity is numerical 0 (integer). You can change the key by giving a property key with the \"prop\" qualifier. Using \"nil\" for the key will disable properties:\n\nmetal1_vdd = metal1.nets(\"VDD\", prop(1))\n# disables properties:\nmetal1_vdd = metal1.nets(\"VDD\", prop(nil))", "source": "klayout"}
{"script_name": "middle", "definition_description": "This script marks the center points of the bounding boxes of polygons.", "parameters": {"options": "Options for how to display the center points, either as small boxes or as point-like edges."}, "values": "options: as_boxes, as_dots", "script_paradigm": "layer.middle([options])", "examples": [{"query": "How to mark the center points with small boxes?", "answer": "layer.middle([as_boxes])"}, {"query": "How to mark the center points with dots?", "answer": "layer.middle([as_dots])"}], "reference": "For example to map key 2 to 1 (integer name keys) and ignore other keys, use:\n\nlayer1 = input(1, 0, enable_properties)\nlayer1_mapped = layer1.map_props({ 2 => 1 })\n\nSee also select_props and remove_props.\n\n\"merge\" - Merges the layer (modifies the layer)\n\nUsage:\n\nlayer.merge([overlap_count])\n\nLike merged, but modifies the input and returns a reference to the new layer.\n\n\"merged\" - Returns the merged layer\n\nUsage:\n\nlayer.merged([overlap_count])\n\nReturns the merged input. Usually, merging is done implicitly using the clean state (which is default). However, in raw state, merging can be enforced by using this method. In addition, this method allows specification of a minimum overlap count, i.e. only where at least the given number of polygons overlap, output is produced. See sized for an application of that.\n\nThis method works both on edge or polygon layers. Edge merging forms single, continuous edges from coincident and connected individual edges.\n\nA version that modifies the input layer is merge.\n\nThe following images show the effect of various forms of the \"merged\" method:\n\n\"middle\" - Returns the center points of the bounding boxes of the polygons\n\nUsage:\n\nlayer.middle([ options ])\n\nThis method produces markers on the centers of the polygon's bounding box centers. These markers can be point-like edges or small 2x2 DBU boxes. The latter is the default. A more generic function is extent_refs. \"middle\" is basically a synonym for \"extent_refs(:center)\".\n\nThe options available are:\n\nas_boxes : with this option, small boxes will be produced as markers\n\nas_dots : with this option, point-like edges will be produced instead of small boxes\n\nThe following image shows the effect of this method\n\n\"move\" - Moves (shifts, translates) a layer (modifies the layer)\n\nUsage:\n\nlayer.move(dx, dy)\n\nMoved the input by the given distance. The layer that this method is called upon is modified and the modified version is returned for further processing.\n\nShift distances can be given as floating-point values (in micron) or integer values (in database units). To explicitly specify the unit, use the unit denominators.\n\n\"moved\" - Moves (shifts, translates) a layer\n\nUsage:\n\nlayer.moved(dx, dy)\n\nMoves the input layer by the given distance (x, y) and returns the moved layer. The layer that this method is called upon is not modified.\n\nShift distances can be given as floating-point values (in micron) or integer values (in database units). To explicitly specify the unit, use the unit denominators.\n\nThe following images shows the effect of the \"moved\" method:\n\n\"nets\" - Pulls net shapes from selected or all nets, optionally annotating nets with properties\n\nUsage:\n\nlayer.nets\n\nlayer.nets(net_filter)\n\nlayer.nets(net_object)\n\nlayer.nets(circuit_filter, net_filter)\n\nlayer.nets(netter, ...)\n\nlayer.nets(prop(key), ...)\n\nlayer.nets(prop(key), ...)\n\nThis method needs a layer that has been used in a connect statement. It will take the shapes corresponding to this layer for all or selected nets and attach the net identity in form of a user property.\n\nThis way, the resulting shapes can be used in property-constrained boolean operations or DRC checks to implement operations in connected or non-connected mode.\n\nA glob-style name pattern can be supplied to filter nets. Nets are always complete - subnets from subcircuits are not selected. The net name is taken from the net's home circuit (to topmost location where all net connections are formed). You can specify a circuit filter to select nets from certain circuits only or give a Circuit object explicitly. You can also specify Net objects directly.\n\nconnect(metal1, via1)\nconnect(via1, metal2)\n\nmetal1_all_nets = metal1.nets\nmetal1_vdd      = metal1.nets(\"VDD\")\nmetal1_vdd      = metal1.nets(\"TOPLEVEL\", \"VDD\")\n\nBy default, the property key used for the net identity is numerical 0 (integer). You can change the key by giving a property key with the \"prop\" qualifier. Using \"nil\" for the key will disable properties:\n\nmetal1_vdd = metal1.nets(\"VDD\", prop(1))\n# disables properties:\nmetal1_vdd = metal1.nets(\"VDD\", prop(nil))", "source": "klayout"}
{"script_name": "moved", "definition_description": "This script moves (shifts) a layer by a given distance, returning the moved layer without modifying the original.", "parameters": {"dx": "The distance to shift in the x-direction", "dy": "The distance to shift in the y-direction"}, "values": "dx: [distance], dy: [distance]", "script_paradigm": "layer.moved(dx, dy)", "examples": [{"query": "How to get a moved layer by 5 database units in x and y directions?", "answer": "layer.moved(5, 5)"}], "reference": "For example to map key 2 to 1 (integer name keys) and ignore other keys, use:\n\nlayer1 = input(1, 0, enable_properties)\nlayer1_mapped = layer1.map_props({ 2 => 1 })\n\nSee also select_props and remove_props.\n\n\"merge\" - Merges the layer (modifies the layer)\n\nUsage:\n\nlayer.merge([overlap_count])\n\nLike merged, but modifies the input and returns a reference to the new layer.\n\n\"merged\" - Returns the merged layer\n\nUsage:\n\nlayer.merged([overlap_count])\n\nReturns the merged input. Usually, merging is done implicitly using the clean state (which is default). However, in raw state, merging can be enforced by using this method. In addition, this method allows specification of a minimum overlap count, i.e. only where at least the given number of polygons overlap, output is produced. See sized for an application of that.\n\nThis method works both on edge or polygon layers. Edge merging forms single, continuous edges from coincident and connected individual edges.\n\nA version that modifies the input layer is merge.\n\nThe following images show the effect of various forms of the \"merged\" method:\n\n\"middle\" - Returns the center points of the bounding boxes of the polygons\n\nUsage:\n\nlayer.middle([ options ])\n\nThis method produces markers on the centers of the polygon's bounding box centers. These markers can be point-like edges or small 2x2 DBU boxes. The latter is the default. A more generic function is extent_refs. \"middle\" is basically a synonym for \"extent_refs(:center)\".\n\nThe options available are:\n\nas_boxes : with this option, small boxes will be produced as markers\n\nas_dots : with this option, point-like edges will be produced instead of small boxes\n\nThe following image shows the effect of this method\n\n\"move\" - Moves (shifts, translates) a layer (modifies the layer)\n\nUsage:\n\nlayer.move(dx, dy)\n\nMoved the input by the given distance. The layer that this method is called upon is modified and the modified version is returned for further processing.\n\nShift distances can be given as floating-point values (in micron) or integer values (in database units). To explicitly specify the unit, use the unit denominators.\n\n\"moved\" - Moves (shifts, translates) a layer\n\nUsage:\n\nlayer.moved(dx, dy)\n\nMoves the input layer by the given distance (x, y) and returns the moved layer. The layer that this method is called upon is not modified.\n\nShift distances can be given as floating-point values (in micron) or integer values (in database units). To explicitly specify the unit, use the unit denominators.\n\nThe following images shows the effect of the \"moved\" method:\n\n\"nets\" - Pulls net shapes from selected or all nets, optionally annotating nets with properties\n\nUsage:\n\nlayer.nets\n\nlayer.nets(net_filter)\n\nlayer.nets(net_object)\n\nlayer.nets(circuit_filter, net_filter)\n\nlayer.nets(netter, ...)\n\nlayer.nets(prop(key), ...)\n\nlayer.nets(prop(key), ...)\n\nThis method needs a layer that has been used in a connect statement. It will take the shapes corresponding to this layer for all or selected nets and attach the net identity in form of a user property.\n\nThis way, the resulting shapes can be used in property-constrained boolean operations or DRC checks to implement operations in connected or non-connected mode.\n\nA glob-style name pattern can be supplied to filter nets. Nets are always complete - subnets from subcircuits are not selected. The net name is taken from the net's home circuit (to topmost location where all net connections are formed). You can specify a circuit filter to select nets from certain circuits only or give a Circuit object explicitly. You can also specify Net objects directly.\n\nconnect(metal1, via1)\nconnect(via1, metal2)\n\nmetal1_all_nets = metal1.nets\nmetal1_vdd      = metal1.nets(\"VDD\")\nmetal1_vdd      = metal1.nets(\"TOPLEVEL\", \"VDD\")\n\nBy default, the property key used for the net identity is numerical 0 (integer). You can change the key by giving a property key with the \"prop\" qualifier. Using \"nil\" for the key will disable properties:\n\nmetal1_vdd = metal1.nets(\"VDD\", prop(1))\n# disables properties:\nmetal1_vdd = metal1.nets(\"VDD\", prop(nil))", "source": "klayout"}
{"script_name": "nets", "definition_description": "This script pulls net shapes from selected or all nets, optionally annotating nets with properties.", "parameters": {"net_filter": "A filter to select specific nets based on name or other criteria", "net_object": "A specific Net object to pull shapes from", "circuit_filter": "A filter for selecting nets from specific circuits", "prop": "A property key to annotate the nets with"}, "values": "net_filter: [string or pattern], net_object: [Net object], circuit_filter: [Circuit filter], prop: [key or nil]", "script_paradigm": "layer.nets(net_filter)\nlayer.nets(net_object)\nlayer.nets(circuit_filter, net_filter)\nlayer.nets(prop(key), ...)", "examples": [{"query": "How to pull net shapes for the net 'VDD' from metal1?", "answer": "metal1_vdd = metal1.nets('VDD')"}, {"query": "How to disable properties when pulling nets for 'VDD'?", "answer": "metal1_vdd = metal1.nets('VDD', prop(nil))"}], "reference": "For example to map key 2 to 1 (integer name keys) and ignore other keys, use:\n\nlayer1 = input(1, 0, enable_properties)\nlayer1_mapped = layer1.map_props({ 2 => 1 })\n\nSee also select_props and remove_props.\n\n\"merge\" - Merges the layer (modifies the layer)\n\nUsage:\n\nlayer.merge([overlap_count])\n\nLike merged, but modifies the input and returns a reference to the new layer.\n\n\"merged\" - Returns the merged layer\n\nUsage:\n\nlayer.merged([overlap_count])\n\nReturns the merged input. Usually, merging is done implicitly using the clean state (which is default). However, in raw state, merging can be enforced by using this method. In addition, this method allows specification of a minimum overlap count, i.e. only where at least the given number of polygons overlap, output is produced. See sized for an application of that.\n\nThis method works both on edge or polygon layers. Edge merging forms single, continuous edges from coincident and connected individual edges.\n\nA version that modifies the input layer is merge.\n\nThe following images show the effect of various forms of the \"merged\" method:\n\n\"middle\" - Returns the center points of the bounding boxes of the polygons\n\nUsage:\n\nlayer.middle([ options ])\n\nThis method produces markers on the centers of the polygon's bounding box centers. These markers can be point-like edges or small 2x2 DBU boxes. The latter is the default. A more generic function is extent_refs. \"middle\" is basically a synonym for \"extent_refs(:center)\".\n\nThe options available are:\n\nas_boxes : with this option, small boxes will be produced as markers\n\nas_dots : with this option, point-like edges will be produced instead of small boxes\n\nThe following image shows the effect of this method\n\n\"move\" - Moves (shifts, translates) a layer (modifies the layer)\n\nUsage:\n\nlayer.move(dx, dy)\n\nMoved the input by the given distance. The layer that this method is called upon is modified and the modified version is returned for further processing.\n\nShift distances can be given as floating-point values (in micron) or integer values (in database units). To explicitly specify the unit, use the unit denominators.\n\n\"moved\" - Moves (shifts, translates) a layer\n\nUsage:\n\nlayer.moved(dx, dy)\n\nMoves the input layer by the given distance (x, y) and returns the moved layer. The layer that this method is called upon is not modified.\n\nShift distances can be given as floating-point values (in micron) or integer values (in database units). To explicitly specify the unit, use the unit denominators.\n\nThe following images shows the effect of the \"moved\" method:\n\n\"nets\" - Pulls net shapes from selected or all nets, optionally annotating nets with properties\n\nUsage:\n\nlayer.nets\n\nlayer.nets(net_filter)\n\nlayer.nets(net_object)\n\nlayer.nets(circuit_filter, net_filter)\n\nlayer.nets(netter, ...)\n\nlayer.nets(prop(key), ...)\n\nlayer.nets(prop(key), ...)\n\nThis method needs a layer that has been used in a connect statement. It will take the shapes corresponding to this layer for all or selected nets and attach the net identity in form of a user property.\n\nThis way, the resulting shapes can be used in property-constrained boolean operations or DRC checks to implement operations in connected or non-connected mode.\n\nA glob-style name pattern can be supplied to filter nets. Nets are always complete - subnets from subcircuits are not selected. The net name is taken from the net's home circuit (to topmost location where all net connections are formed). You can specify a circuit filter to select nets from certain circuits only or give a Circuit object explicitly. You can also specify Net objects directly.\n\nconnect(metal1, via1)\nconnect(via1, metal2)\n\nmetal1_all_nets = metal1.nets\nmetal1_vdd      = metal1.nets(\"VDD\")\nmetal1_vdd      = metal1.nets(\"TOPLEVEL\", \"VDD\")\n\nBy default, the property key used for the net identity is numerical 0 (integer). You can change the key by giving a property key with the \"prop\" qualifier. Using \"nil\" for the key will disable properties:\n\nmetal1_vdd = metal1.nets(\"VDD\", prop(1))\n# disables properties:\nmetal1_vdd = metal1.nets(\"VDD\", prop(nil))", "source": "klayout"}
{"script_name": "$_SDFFCE_PP1P_", "definition_description": "This script defines a positive edge D-type flip-flop with active-high reset and enable signals. The flip-flop stores the input data (D) on the rising edge of the clock (C), and if the enable (E) is high, the reset (R) has priority to set the output (Q) to 1.", "parameters": {"D": "Data input for the flip-flop", "C": "Clock input, the flip-flop triggers on the positive edge", "R": "Reset input, active high, has priority over the enable signal", "E": "Enable input, if high, the flip-flop stores the data", "Q": "Output of the flip-flop, holds the stored data"}, "values": "D: <data_input>, C: <clock_input>, R: <reset_input>, E: <enable_input>, Q: <output>", "script_paradigm": "always @(posedge C) begin if (E == 1) begin if (R == 1) Q <= 1; else Q <= D; end end", "examples": [{"query": "How does the $_SDFFCE_PP1P_ flip-flop behave when E is 1 and R is 1?", "answer": "Q <= 1"}, {"query": "What happens to Q when R is 0 and E is 1?", "answer": "Q <= D"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nListing 9.203: simcells.v\n3289\nmodule \\$_SDFFCE_PP1P_ (D, C, R, E, Q);\n3290\ninput D, C, R, E;\n3291\noutput reg Q;\n3292\nalways @(posedge C) begin\n3293\nif (E == 1) begin\n3294\nif (R == 1)\n3295\nQ <= 1;\n3296\nelse\n3297\nQ <= D;\n3298\nend\n3299\nend\n3300\nendmodule\nyosys> help $_SDFFE_NN0N_\nA negative edge D-type flip-flop with negative polarity synchronous reset and negative polarity clock\nenable (with reset having priority).\nTruth table:\nD C R E | Q\n---------+---\n- \\ 0 - | 0\nd \\ - 0 | d\n- - - - | q\nSimulation model (verilog)\nListing 9.204: simcells.v\n2484\nmodule \\$_SDFFE_NN0N_ (D, C, R, E, Q);\n2485\ninput D, C, R, E;\n2486\noutput reg Q;\n2487\nalways @(negedge C) begin\n2488\nif (R == 0)\n2489\nQ <= 0;\n2490\nelse if (E == 0)\n2491\nQ <= D;\n2492\nend\n2493\nendmodule\nyosys> help $_SDFFE_NN0P_\nA negative edge D-type flip-flop with negative polarity synchronous reset and positive polarity clock\nenable (with reset having priority).\nTruth table:\nD C R E | Q\n---------+---\n- \\ 0 - | 0\nd \\ - 1 | d\n- - - - | q\nSimulation model (verilog)\n332\nChapter 9.\nInternal cell library", "source": "yosys_hq"}
{"script_name": "$_SDFFE_NN0N_", "definition_description": "This script defines a negative edge D-type flip-flop with active-low synchronous reset and active-low clock enable. The reset has priority, and if both reset and enable are inactive, the flip-flop stores the input data (D) on the negative edge of the clock.", "parameters": {"D": "Data input for the flip-flop", "C": "Clock input, the flip-flop triggers on the negative edge", "R": "Reset input, active low, has priority over the enable signal", "E": "Enable input, if low, the flip-flop stores the data", "Q": "Output of the flip-flop, holds the stored data"}, "values": "D: <data_input>, C: <clock_input>, R: <reset_input>, E: <enable_input>, Q: <output>", "script_paradigm": "always @(negedge C) begin if (R == 0) Q <= 0; else if (E == 0) Q <= D; end", "examples": [{"query": "What is the output Q when R is 0?", "answer": "Q <= 0"}, {"query": "How does the flip-flop behave when E is 0 and R is 1?", "answer": "Q <= D"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nListing 9.203: simcells.v\n3289\nmodule \\$_SDFFCE_PP1P_ (D, C, R, E, Q);\n3290\ninput D, C, R, E;\n3291\noutput reg Q;\n3292\nalways @(posedge C) begin\n3293\nif (E == 1) begin\n3294\nif (R == 1)\n3295\nQ <= 1;\n3296\nelse\n3297\nQ <= D;\n3298\nend\n3299\nend\n3300\nendmodule\nyosys> help $_SDFFE_NN0N_\nA negative edge D-type flip-flop with negative polarity synchronous reset and negative polarity clock\nenable (with reset having priority).\nTruth table:\nD C R E | Q\n---------+---\n- \\ 0 - | 0\nd \\ - 0 | d\n- - - - | q\nSimulation model (verilog)\nListing 9.204: simcells.v\n2484\nmodule \\$_SDFFE_NN0N_ (D, C, R, E, Q);\n2485\ninput D, C, R, E;\n2486\noutput reg Q;\n2487\nalways @(negedge C) begin\n2488\nif (R == 0)\n2489\nQ <= 0;\n2490\nelse if (E == 0)\n2491\nQ <= D;\n2492\nend\n2493\nendmodule\nyosys> help $_SDFFE_NN0P_\nA negative edge D-type flip-flop with negative polarity synchronous reset and positive polarity clock\nenable (with reset having priority).\nTruth table:\nD C R E | Q\n---------+---\n- \\ 0 - | 0\nd \\ - 1 | d\n- - - - | q\nSimulation model (verilog)\n332\nChapter 9.\nInternal cell library", "source": "yosys_hq"}
{"script_name": "$_SDFFE_NN0P_", "definition_description": "This script defines a negative edge D-type flip-flop with active-low synchronous reset and positive edge clock enable. The reset has priority, and when enable is high, the flip-flop stores the input data (D) on the negative edge of the clock.", "parameters": {"D": "Data input for the flip-flop", "C": "Clock input, the flip-flop triggers on the negative edge", "R": "Reset input, active low, has priority over the enable signal", "E": "Enable input, if high, the flip-flop stores the data", "Q": "Output of the flip-flop, holds the stored data"}, "values": "D: <data_input>, C: <clock_input>, R: <reset_input>, E: <enable_input>, Q: <output>", "script_paradigm": "always @(negedge C) begin if (R == 0) Q <= 0; else if (E == 1) Q <= D; end", "examples": [{"query": "How does the $_SDFFE_NN0P_ flip-flop behave when R is 0?", "answer": "Q <= 0"}, {"query": "What happens to Q when E is 1 and R is 1?", "answer": "Q <= D"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nListing 9.203: simcells.v\n3289\nmodule \\$_SDFFCE_PP1P_ (D, C, R, E, Q);\n3290\ninput D, C, R, E;\n3291\noutput reg Q;\n3292\nalways @(posedge C) begin\n3293\nif (E == 1) begin\n3294\nif (R == 1)\n3295\nQ <= 1;\n3296\nelse\n3297\nQ <= D;\n3298\nend\n3299\nend\n3300\nendmodule\nyosys> help $_SDFFE_NN0N_\nA negative edge D-type flip-flop with negative polarity synchronous reset and negative polarity clock\nenable (with reset having priority).\nTruth table:\nD C R E | Q\n---------+---\n- \\ 0 - | 0\nd \\ - 0 | d\n- - - - | q\nSimulation model (verilog)\nListing 9.204: simcells.v\n2484\nmodule \\$_SDFFE_NN0N_ (D, C, R, E, Q);\n2485\ninput D, C, R, E;\n2486\noutput reg Q;\n2487\nalways @(negedge C) begin\n2488\nif (R == 0)\n2489\nQ <= 0;\n2490\nelse if (E == 0)\n2491\nQ <= D;\n2492\nend\n2493\nendmodule\nyosys> help $_SDFFE_NN0P_\nA negative edge D-type flip-flop with negative polarity synchronous reset and positive polarity clock\nenable (with reset having priority).\nTruth table:\nD C R E | Q\n---------+---\n- \\ 0 - | 0\nd \\ - 1 | d\n- - - - | q\nSimulation model (verilog)\n332\nChapter 9.\nInternal cell library", "source": "yosys_hq"}
{"script_name": "read_liberty", "definition_description": "This script reads a Liberty format library file, setting the units used by SDC/TCL commands and reporting. It can also infer latches for cells that describe transparent latches.", "parameters": {"file_name": "The name of the Liberty library file to be read", "include_file": "Optional parameter specifying the include file for additional library data", "infer_latches": "Flag to infer latches for cells describing transparent latches"}, "values": "file_name: <file_path>, include_file: <file_path>, infer_latches: <true/false>", "script_paradigm": "read_liberty -file <file_name> [-include_file <include_file>] [-infer_latches <infer_latches>]", "examples": [{"query": "How to read a Liberty file and infer latches?", "answer": "read_liberty -file /path/to/library.lib -infer_latches true"}, {"query": "Read a Liberty file with an included file for additional data", "answer": "read_liberty -file /path/to/library.lib -include_file /path/to/include_file.lib"}], "reference": "The read_liberty command reads a Liberty format library file. The first library that is read sets the units used\nby SDC/TCL commands and reporting. The include_file attribute is supported.\nSome Liberty libraries do not include latch groups for cells that are describe transparent latches. In that \nsituation the -infer_latches command flag can be used to infer the latches. The timing arcs required for a \nlatch to be inferred should look like the following:\ncell (infered_latch) {\n  pin(D) {\n    direction : input ;\n    timing () {\n      related_pin : \"E\" ;\n      timing_type : setup_falling ;\n    }\n    timing () {\n      related_pin : \"E\" ;\n      timing_type : hold_falling ;\n    }\n  }\n  pin(E) {\n    direction : input;\n  }\n  pin(Q) {\n    direction : output ;\n    timing () {\n      related_pin : \"D\" ;\n    }\n    timing () {\n      related_pin : \"E\" ;\n      timing_type : rising_edge ;\n    }\n  }\n}\nIn this example a positive level-sensitive latch is inferred.\nFiles compressed with gzip are automatically uncompressed.\nread_power_activities\n[-scope scope]\n-vcd filename\nscope\nThe VCD scope of the current design to extract simulation data. Typically the \ntest bench name and design under test instance name. Scope levels are \nseparated with ‘/’.\n-vcd filename\nThe name of the VCD file to read.\nThe read_power_activities command reads a VCD (Value Change Dump) file from a Verilog simulation \nand extracts pin activities and duty cycles for use in power estimation. Files compressed with gzip are \nsupported. Annotated activities are propagated to the fanout of the annotated pins.", "source": "OpenSTA"}
{"script_name": "read_power_activities", "definition_description": "This script reads a VCD file from a Verilog simulation, extracting pin activities and duty cycles for power estimation. It supports gzip-compressed files.", "parameters": {"scope": "The VCD scope of the design to extract simulation data", "vcd_file": "The name of the VCD file to read"}, "values": "scope: <scope>, vcd_file: <file_path>", "script_paradigm": "read_power_activities -scope <scope> -vcd <vcd_file>", "examples": [{"query": "How to read a VCD file for simulation data?", "answer": "read_power_activities -scope testbench/design -vcd /path/to/simulation.vcd"}, {"query": "Read a VCD file for a specific test bench scope", "answer": "read_power_activities -scope my_testbench/my_design -vcd /path/to/simulation.vcd"}], "reference": "The read_liberty command reads a Liberty format library file. The first library that is read sets the units used\nby SDC/TCL commands and reporting. The include_file attribute is supported.\nSome Liberty libraries do not include latch groups for cells that are describe transparent latches. In that \nsituation the -infer_latches command flag can be used to infer the latches. The timing arcs required for a \nlatch to be inferred should look like the following:\ncell (infered_latch) {\n  pin(D) {\n    direction : input ;\n    timing () {\n      related_pin : \"E\" ;\n      timing_type : setup_falling ;\n    }\n    timing () {\n      related_pin : \"E\" ;\n      timing_type : hold_falling ;\n    }\n  }\n  pin(E) {\n    direction : input;\n  }\n  pin(Q) {\n    direction : output ;\n    timing () {\n      related_pin : \"D\" ;\n    }\n    timing () {\n      related_pin : \"E\" ;\n      timing_type : rising_edge ;\n    }\n  }\n}\nIn this example a positive level-sensitive latch is inferred.\nFiles compressed with gzip are automatically uncompressed.\nread_power_activities\n[-scope scope]\n-vcd filename\nscope\nThe VCD scope of the current design to extract simulation data. Typically the \ntest bench name and design under test instance name. Scope levels are \nseparated with ‘/’.\n-vcd filename\nThe name of the VCD file to read.\nThe read_power_activities command reads a VCD (Value Change Dump) file from a Verilog simulation \nand extracts pin activities and duty cycles for use in power estimation. Files compressed with gzip are \nsupported. Annotated activities are propagated to the fanout of the annotated pins.", "source": "OpenSTA"}
{"script_name": "gui_zoom_out", "definition_description": "This script zooms out the layout in the graphical user interface (GUI).", "parameters": {"x": "The new x-coordinate of the layout center in microns", "y": "The new y-coordinate of the layout center in microns"}, "values": "x: <value in microns>, y: <value in microns>", "script_paradigm": "gui::zoom_out <x> <y>", "examples": [{"query": "How to zoom out the layout with the center at (100, 200) microns?", "answer": "gui::zoom_out 100 200"}, {"query": "Zoom out the layout with the center at (50, 75) microns", "answer": "gui::zoom_out 50 75"}], "reference": "title: gui_zoom_out(2)\ndate: 24/09/08\n\nNAME\ngui_zoom_out - gui zoom out\nSYNOPSIS\ngui::zoom_out \n    x y\nDESCRIPTION\nTo zoom out the layout:\nOPTIONS\nx, y:   new center of layout in microns\nARGUMENTS\nThis command has no arguments.\nEXAMPLES\nSEE ALSO", "source": "OpenROAD"}
{"script_name": "CheckMetrics", "definition_description": "This script checks the quality of design metrics against 'golden' reference values to ensure no significant degradation after changes.", "parameters": {"clean_metadata": "Optional parameter to clean the metadata before running the check if necessary", "metrics_check": "Triggers the evaluation process to compare current design metrics against the 'golden' metrics"}, "values": "clean_metadata: <clean_metadata>, metrics_check: <metrics_check>", "script_paradigm": "cd OpenROAD-flow-scripts/flow\nmake [clean_metadata] metadata", "examples": [{"query": "How do I check the design metrics after fixing a bug?", "answer": "cd OpenROAD-flow-scripts/flow\nmake metadata"}, {"query": "How do I check the design metrics after making a configuration change?", "answer": "cd OpenROAD-flow-scripts/flow\nmake metadata"}], "reference": "Metrics\nThe OpenROAD-flow-scripts\nrepository contains source files (e.g., LEF/DEF, Verilog, SDC, Liberty,\nRC extraction) and configuration files (e.g. config.mk) that enable the user to run\na small set of example designs through our complete RTL-to-GDS flow.\nTo keep track of the quality of the results, we maintain inside each\ndesign folder two files:\n\n\nmetadata-base-ok.json which contains all the relevant\ninformation extracted from the \"golden\" execution of the flow (i.e.,\nlast known good result).\n\n\nrules.json which holds a set of rules that we use to\nevaluate new executions when a change is made.\n\n\nChecking against golden\nThe evaluation checks for key metrics (e.g., worst slack, number of\nDRCs) to ensure that changes do not degrade too much with respect to the\n\"golden\" values.\nAfter you make a significant change, e.g., fixing a bug in a piece of\ncode, or changing some configuration variable\n(PLACE_DENSITY), you should review the results and compare\nthem with the \"golden\". To perform the check, you will need to run the\nfollowing command:\n``` shell\ncd OpenROAD-flow-scripts/flow\nthe clean_metadata is only required if you need to re-run\nmake [clean_metadata] metadata\n```\nIf the command above yields any error message, please review to\nmake sure the change in metrics is expected and justifiable. If so,\nproceed to the next section to update the \"golden\" reference.\nUpdate process\nUpdate of the reference files is mandatory if any metrics became worse\nthan the values limited by the rules.json (see previous\nsection on how to perform the check). Also, it is a good idea to update\nthe \"golden\" files if your changes have improved a metric, to ensure that\nthe improvement will not be lost in the future.\nTo update all the reference files:\nshell\ncd OpenROAD-flow-scripts/flow\nmake update_ok\nIn case you have a special reason to only update one of the files, you\ncan do so with the following commands:\n``` shell\nupdate metadata-base-ok.json file for the design\nmake update_metadata\nupdate rules.json file for the design\nthis will use the current (+ a padding) metadata-base-ok.json\nthe padding ensures that small changes do not break the flow\nmake update_rules\n```", "source": "OpenROAD_flow_script"}
{"script_name": "UpdateMetrics", "definition_description": "This script updates the reference files if any metrics worsen or improve beyond the set limits, ensuring the 'golden' values are current.", "parameters": {"update_metadata": "Updates the metadata-base-ok.json file for the design", "update_rules": "Updates the rules.json file for the design, including necessary padding to avoid flow issues"}, "values": "update_metadata: <update_metadata>, update_rules: <update_rules>", "script_paradigm": "cd OpenROAD-flow-scripts/flow\nmake update_ok", "examples": [{"query": "How do I update the reference files after a significant design change?", "answer": "cd OpenROAD-flow-scripts/flow\nmake update_ok"}, {"query": "How do I update only the metadata-base-ok.json file?", "answer": "cd OpenROAD-flow-scripts/flow\nmake update_metadata"}, {"query": "How do I update only the rules.json file?", "answer": "cd OpenROAD-flow-scripts/flow\nmake update_rules"}], "reference": "Metrics\nThe OpenROAD-flow-scripts\nrepository contains source files (e.g., LEF/DEF, Verilog, SDC, Liberty,\nRC extraction) and configuration files (e.g. config.mk) that enable the user to run\na small set of example designs through our complete RTL-to-GDS flow.\nTo keep track of the quality of the results, we maintain inside each\ndesign folder two files:\n\n\nmetadata-base-ok.json which contains all the relevant\ninformation extracted from the \"golden\" execution of the flow (i.e.,\nlast known good result).\n\n\nrules.json which holds a set of rules that we use to\nevaluate new executions when a change is made.\n\n\nChecking against golden\nThe evaluation checks for key metrics (e.g., worst slack, number of\nDRCs) to ensure that changes do not degrade too much with respect to the\n\"golden\" values.\nAfter you make a significant change, e.g., fixing a bug in a piece of\ncode, or changing some configuration variable\n(PLACE_DENSITY), you should review the results and compare\nthem with the \"golden\". To perform the check, you will need to run the\nfollowing command:\n``` shell\ncd OpenROAD-flow-scripts/flow\nthe clean_metadata is only required if you need to re-run\nmake [clean_metadata] metadata\n```\nIf the command above yields any error message, please review to\nmake sure the change in metrics is expected and justifiable. If so,\nproceed to the next section to update the \"golden\" reference.\nUpdate process\nUpdate of the reference files is mandatory if any metrics became worse\nthan the values limited by the rules.json (see previous\nsection on how to perform the check). Also, it is a good idea to update\nthe \"golden\" files if your changes have improved a metric, to ensure that\nthe improvement will not be lost in the future.\nTo update all the reference files:\nshell\ncd OpenROAD-flow-scripts/flow\nmake update_ok\nIn case you have a special reason to only update one of the files, you\ncan do so with the following commands:\n``` shell\nupdate metadata-base-ok.json file for the design\nmake update_metadata\nupdate rules.json file for the design\nthis will use the current (+ a padding) metadata-base-ok.json\nthe padding ensures that small changes do not break the flow\nmake update_rules\n```", "source": "OpenROAD_flow_script"}
{"script_name": "EdgeFilter", "definition_description": "This script defines an edge filter used for filtering edges from a collection of edges based on custom selection criteria.", "parameters": {"ref_edge": "The reference edge used to compare with other edges in the collection for filtering."}, "values": "ref_edge: <Edge object>", "script_paradigm": "class ParallelFilter < RBA::EdgeFilter\n  def initialize(ref_edge)\n    self.is_scale_invariant\n    @ref_edge = ref_edge\n  end\n\n  def selected(edge)\n    return edge.is_parallel?(@ref_edge)\n  end\nend\n\nedges = ... # some Edges object\nref_edge = ... # some Edge\nparallel_only = edges.filtered(ParallelFilter::new(ref_edge))", "examples": [{"query": "How to filter edges parallel to a given reference edge?", "answer": "class ParallelFilter < RBA::EdgeFilter\n  def initialize(ref_edge)\n    self.is_scale_invariant\n    @ref_edge = ref_edge\n  end\n\n  def selected(edge)\n    return edge.is_parallel?(@ref_edge)\n  end\nend\n\nedges = ... # some Edges object\nref_edge = ... # some Edge\nparallel_only = edges.filtered(ParallelFilter::new(ref_edge))"}], "reference": "KLayout Documentation (Qt 5): Main Index » Class Index » API reference - Class EdgeFilter\n\nAPI reference - Class EdgeFilter\n\nNotation used in Ruby API documentation\n\nModule: db\n\nDescription: A generic edge filter adaptor\n\nPublic constructors\n\nPublic methods\n\nDeprecated methods (protected, public, static, non-static and constructors)\n\nDetailed description\n\nEdge filters are an efficient way to filter edge from a Edges collection. To apply a filter, derive your own filter class and pass an instance to the Edges#filter or Edges#filtered method.\n\nConceptually, these methods take each edge from the collection and present it to the filter's 'selected' method. Based on the result of this evaluation, the edge is kept or discarded.\n\nThe magic happens when deep mode edge collections are involved. In that case, the filter will use as few calls as possible and exploit the hierarchical compression if possible. It needs to know however, how the filter behaves. You need to configure the filter by calling is_isotropic, is_scale_invariant or is_isotropic_and_scale_invariant before using the filter.\n\nYou can skip this step, but the filter algorithm will assume the worst case then. This usually leads to cell variant formation which is not always desired and blows up the hierarchy.\n\nHere is some example that filters edges parallel to a given one:\n\nclass ParallelFilter < RBA::EdgeFilter\n\n  # Constructor\n  def initialize(ref_edge)\n    self.is_scale_invariant   # orientation matters, but scale does not\n    @ref_edge = ref_edge\n  end\n  \n  # Select only parallel ones\n  def selected(edge)\n    return edge.is_parallel?(@ref_edge)\n  end\n\nend\n\nedges = ... # some Edges object\nref_edge = ... # some Edge\nparallel_only = edges.filtered(ParallelFilter::new(ref_edge))\n\nThis class has been introduced in version 0.29.\n\nPublic constructors\n\nnew EdgeFilter ptr new Creates a new object of this class\n\nPublic methods\n\n[const] EdgeFilter ptr _const_cast Returns a non-const reference to self. void _create Ensures the C++ object is created void _destroy Explicitly destroys the object [const] bool _destroyed? Returns a value indicating whether the object was already destroyed [const] bool _is_const_object? Returns a value indicating whether the reference is a const reference void _manage Marks the object as managed by the script side. void _unmanage Marks the object as no longer owned by the script side. void is_isotropic Indicates that the filter has isotropic properties void is_isotropic_and_scale_invariant Indicates that the filter is isotropic and scale invariant void is_scale_invariant Indicates that the filter is scale invariant void requires_raw_input= (bool flag) Sets a value indicating whether the filter needs raw (unmerged) input [const] bool requires_raw_input? Gets a value indicating whether the filter needs raw (unmerged) input [virtual,const] bool selected (const Edge edge) Selects an edge void wants_variants= (bool flag) Sets a value indicating whether the filter prefers cell variants [const] bool wants_variants? Gets a value indicating whether the filter prefers cell variants\n\nDeprecated methods (protected, public, static, non-static and constructors)\n\nvoid create Use of this method is deprecated. Use _create instead void destroy Use of this method is deprecated. Use _destroy instead [const] bool destroyed? Use of this method is deprecated. Use _destroyed? instead [const] bool is_const_object? Use of this method is deprecated. Use _is_const_object? instead\n\nDetailed description", "source": "klayout"}
{"script_name": "place_pins", "definition_description": "This script is used for placing all pins on a die by specifying horizontal and vertical metal layer tracks for pin placement. Additional options for randomness, spacing, and exclusions are available.", "parameters": {"hor_layers": "The layers to create the metal shapes of pins placed in horizontal tracks. This can be a single layer or a list of layer names.", "ver_layers": "The layers to create the metal shapes of pins placed in vertical tracks. This can be a single layer or a list of layer names.", "random_seed": "Specifies the seed for random operations, used when -random is enabled.", "random": "A flag to enable random pin placement.", "corner_avoidance": "Specifies the distance (in microns) from each corner within which pin placement should be avoided.", "min_distance": "Defines the minimum distance between pins on the die boundary. This can be in microns or tracks, with the default being two routing tracks.", "min_distance_in_tracks": "Flag to set the minimum distance between pins in number of tracks instead of microns.", "exclude": "A region where pins cannot be placed. Can specify edges or specific regions on the die boundary.", "group_pins": "A list of pins that should be placed together on the die boundary.", "annealing": "Flag to enable simulated annealing for pin placement optimization.", "write_pin_placement": "A file to output the generated pin placement in a series of place_pin commands."}, "values": "hor_layers: <layer_names>, ver_layers: <layer_names>, random_seed: <seed>, random: <true/false>, corner_avoidance: <length>, min_distance: <distance>, min_distance_in_tracks: <true/false>, exclude: <region>, group_pins: <pin_list>, annealing: <true/false>, write_pin_placement: <file_name>", "script_paradigm": "place_pins -hor_layers <h_layers> -ver_layers <v_layers> [-random_seed <seed>] [-random] [-corner_avoidance <length>] [-min_distance <distance>] [-min_distance_in_tracks] [-exclude <region>] [-group_pins <pin_list>] [-annealing] [-write_pin_placement <file_name>]", "examples": [{"query": "How to place pins with horizontal layers 'M1' and vertical layers 'M2', and use random placement?", "answer": "place_pins -hor_layers M1 -ver_layers M2 -random"}, {"query": "How to place pins with a corner avoidance of 10 microns and a minimum distance of 5 microns between pins?", "answer": "place_pins -hor_layers M1 -ver_layers M2 -corner_avoidance 10 -min_distance 5"}, {"query": "How to exclude a region from pin placement on the left edge of the die?", "answer": "place_pins -hor_layers M1 -ver_layers M2 -exclude left:50"}], "reference": "title: place_pins(2)\ndate: 24/09/08\n\nNAME\nplace_pins - place pins\nSYNOPSIS\nplace_pins \n    -hor_layers h_layers\n    -ver_layers v_layers\n    [-random_seed seed]\n    [-random]\n    [-corner_avoidance length]\n    [-min_distance distance]\n    [-min_distance_in_tracks]\n    [-exclude region]\n    [-group_pins pin_list]\n    [-annealing]\n    [-write_pin_placement file_name]\nDESCRIPTION\nThe place_pins command places all pins together. Use the following command to perform pin placement:\nDeveloper arguments:\n- -random, -random_seed\nOPTIONS\n-hor_layers:  The layers to create the metal shapes of pins placed in horizontal tracks. It can be a single layer or a list of layer names.\n-ver_layers:  The layers to create the metal shapes of pins placed in vertical tracks. It can be a single layer or a list of layer names.\n-corner_avoidance:  The distance (in microns) from each corner within which pin placement should be avoided.\n-min_distance:  The minimum distance between pins on the die boundary. This distance can be in microns (default) or in number of tracks between each pin. The default value is the length of two routing tracks between each pin.\n-min_distance_in_tracks:  Flag that allows setting the min distance in number of tracks instead of microns.\n-exclude:  A region where pins cannot be placed. Either top|bottom|left|right:edge_interval, which is the edge interval from the selected edge; begin:end for begin-end of all edges.\n-group_pins:  A list of pins to be placed together on the die boundary.\n-annealing:  Flag to enable simulated annealing pin placement.\n-write_pin_placement:  A file with the pin placement generated in the format of multiple calls for the place_pin command.\nARGUMENTS\n-random_seed:  Specify the seed for random operations.\n-random:  When this flag is enabled, the pin placement is random.\nEXAMPLES\nSEE ALSO", "source": "OpenROAD"}
{"script_name": "select_interacting", "definition_description": "Selects the edge pairs from this edge pair collection which overlap or touch polygons from the region.", "parameters": {"other": "The region to check interaction with", "min_count": "Minimum number of edge pairs to select (default is 1)", "max_count": "Maximum number of edge pairs to select (default is unlimited)"}, "values": "other: <Region>, min_count: <1>, max_count: <unlimited>", "script_paradigm": "EdgePairs select_interacting <other>, <min_count>, <max_count>", "examples": [{"query": "How to select edge pairs interacting with polygons in a region?", "answer": "EdgePairs select_interacting <Region>, 1, unlimited"}], "reference": "collection EdgePairs select_interacting (const Region other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which overlap or touch polygons from the region EdgePairs select_not_inside (const Region other) Selects the edge pairs from this edge pair collection which are not inside (completely covered by) polygons from the region EdgePairs select_not_interacting (const Edges other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do not overlap or touch edges from the other edge collection EdgePairs select_not_interacting (const Region other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do not overlap or touch polygons from the region EdgePairs select_not_outside (const Region other) Selects the edge pairs from this edge pair collection which are not outside (partially overlapped by) polygons from the other region EdgePairs select_outside (const Region other) Selects the edge pairs from this edge pair collection which are outside (not overlapped by) polygons from the other region [const] EdgePairs[] split_inside (const Region other) Selects the edge pairs from this edge pair collection which are and are not inside (completely covered by) polygons from the other region [const] EdgePairs[] split_interacting (const Edges other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do and do not interact with edges from the other collection [const] EdgePairs[] split_interacting (const Region other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do and do not interact with polygons from the other region [const] EdgePairs[] split_outside (const Region other) Selects the edge pairs from this edge pair collection which are and are not outside (not overlapped by) polygons from the other region void swap (EdgePairs other) Swap the contents of this collection with the contents of another collection [const] string to_s Converts the edge pair collection to a string [const] string to_s (unsigned long max_count) Converts the edge pair collection to a string EdgePairs transform (const Trans t) Transform the edge pair collection (modifies self) EdgePairs transform (const ICplxTrans t) Transform the edge pair collection with a complex transformation (modifies self) EdgePairs transform (const IMatrix2d t) Transform the edge pair collection (modifies self) EdgePairs transform (const IMatrix3d t) Transform the edge pair collection (modifies self) [const] EdgePairs transformed (const Trans t) Transform the edge pair collection [const] EdgePairs transformed (const ICplxTrans t) Transform the edge pair collection with a complex transformation [const] EdgePairs transformed (const IMatrix2d t) Transform the edge pair collection [const] EdgePairs transformed (const IMatrix3d t) Transform the edge pair collection [const] EdgePairs with_abs_angle (double angle, bool inverse) Filter the edge pairs by orientation of their edges [const] EdgePairs with_abs_angle (double min_angle, double max_angle, bool inverse, bool include_min_angle = true, bool include_max_angle = false) Filter the edge pairs by orientation of their edges [const] EdgePairs with_abs_angle_both (double angle, bool inverse) Filter the edge pairs by orientation of both of their edges [const] EdgePairs with_abs_angle_both (double min_angle, double max_angle, bool inverse, bool include_min_angle = true, bool include_max_angle = false) [const] EdgePairs with_angle (double angle, bool inverse) Filter the edge pairs by orientation of their edges [const] EdgePairs with_angle (double min_angle, double max_angle, bool inverse, bool include_min_angle = true, bool include_max_angle = false) Filter the edge pairs by orientation of their edges [const] EdgePairs with_angle (Edges::EdgeType type, bool inverse) Filter the edge", "source": "klayout"}
{"script_name": "select_not_inside", "definition_description": "Selects the edge pairs from this edge pair collection which are not inside (completely covered by) polygons from the region.", "parameters": {"other": "The region to check for inside condition"}, "values": "other: <Region>", "script_paradigm": "EdgePairs select_not_inside <other>", "examples": [{"query": "How to select edge pairs not inside a region?", "answer": "EdgePairs select_not_inside <Region>"}], "reference": "collection EdgePairs select_interacting (const Region other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which overlap or touch polygons from the region EdgePairs select_not_inside (const Region other) Selects the edge pairs from this edge pair collection which are not inside (completely covered by) polygons from the region EdgePairs select_not_interacting (const Edges other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do not overlap or touch edges from the other edge collection EdgePairs select_not_interacting (const Region other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do not overlap or touch polygons from the region EdgePairs select_not_outside (const Region other) Selects the edge pairs from this edge pair collection which are not outside (partially overlapped by) polygons from the other region EdgePairs select_outside (const Region other) Selects the edge pairs from this edge pair collection which are outside (not overlapped by) polygons from the other region [const] EdgePairs[] split_inside (const Region other) Selects the edge pairs from this edge pair collection which are and are not inside (completely covered by) polygons from the other region [const] EdgePairs[] split_interacting (const Edges other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do and do not interact with edges from the other collection [const] EdgePairs[] split_interacting (const Region other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do and do not interact with polygons from the other region [const] EdgePairs[] split_outside (const Region other) Selects the edge pairs from this edge pair collection which are and are not outside (not overlapped by) polygons from the other region void swap (EdgePairs other) Swap the contents of this collection with the contents of another collection [const] string to_s Converts the edge pair collection to a string [const] string to_s (unsigned long max_count) Converts the edge pair collection to a string EdgePairs transform (const Trans t) Transform the edge pair collection (modifies self) EdgePairs transform (const ICplxTrans t) Transform the edge pair collection with a complex transformation (modifies self) EdgePairs transform (const IMatrix2d t) Transform the edge pair collection (modifies self) EdgePairs transform (const IMatrix3d t) Transform the edge pair collection (modifies self) [const] EdgePairs transformed (const Trans t) Transform the edge pair collection [const] EdgePairs transformed (const ICplxTrans t) Transform the edge pair collection with a complex transformation [const] EdgePairs transformed (const IMatrix2d t) Transform the edge pair collection [const] EdgePairs transformed (const IMatrix3d t) Transform the edge pair collection [const] EdgePairs with_abs_angle (double angle, bool inverse) Filter the edge pairs by orientation of their edges [const] EdgePairs with_abs_angle (double min_angle, double max_angle, bool inverse, bool include_min_angle = true, bool include_max_angle = false) Filter the edge pairs by orientation of their edges [const] EdgePairs with_abs_angle_both (double angle, bool inverse) Filter the edge pairs by orientation of both of their edges [const] EdgePairs with_abs_angle_both (double min_angle, double max_angle, bool inverse, bool include_min_angle = true, bool include_max_angle = false) [const] EdgePairs with_angle (double angle, bool inverse) Filter the edge pairs by orientation of their edges [const] EdgePairs with_angle (double min_angle, double max_angle, bool inverse, bool include_min_angle = true, bool include_max_angle = false) Filter the edge pairs by orientation of their edges [const] EdgePairs with_angle (Edges::EdgeType type, bool inverse) Filter the edge", "source": "klayout"}
{"script_name": "select_not_interacting", "definition_description": "Selects the edge pairs from this edge pair collection which do not overlap or touch edges from the other edge collection.", "parameters": {"other": "The edge collection to check for interaction", "min_count": "Minimum number of edge pairs to select (default is 1)", "max_count": "Maximum number of edge pairs to select (default is unlimited)"}, "values": "other: <Edges>, min_count: <1>, max_count: <unlimited>", "script_paradigm": "EdgePairs select_not_interacting <other>, <min_count>, <max_count>", "examples": [{"query": "How to select edge pairs that do not interact with edges from another collection?", "answer": "EdgePairs select_not_interacting <Edges>, 1, unlimited"}], "reference": "collection EdgePairs select_interacting (const Region other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which overlap or touch polygons from the region EdgePairs select_not_inside (const Region other) Selects the edge pairs from this edge pair collection which are not inside (completely covered by) polygons from the region EdgePairs select_not_interacting (const Edges other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do not overlap or touch edges from the other edge collection EdgePairs select_not_interacting (const Region other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do not overlap or touch polygons from the region EdgePairs select_not_outside (const Region other) Selects the edge pairs from this edge pair collection which are not outside (partially overlapped by) polygons from the other region EdgePairs select_outside (const Region other) Selects the edge pairs from this edge pair collection which are outside (not overlapped by) polygons from the other region [const] EdgePairs[] split_inside (const Region other) Selects the edge pairs from this edge pair collection which are and are not inside (completely covered by) polygons from the other region [const] EdgePairs[] split_interacting (const Edges other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do and do not interact with edges from the other collection [const] EdgePairs[] split_interacting (const Region other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do and do not interact with polygons from the other region [const] EdgePairs[] split_outside (const Region other) Selects the edge pairs from this edge pair collection which are and are not outside (not overlapped by) polygons from the other region void swap (EdgePairs other) Swap the contents of this collection with the contents of another collection [const] string to_s Converts the edge pair collection to a string [const] string to_s (unsigned long max_count) Converts the edge pair collection to a string EdgePairs transform (const Trans t) Transform the edge pair collection (modifies self) EdgePairs transform (const ICplxTrans t) Transform the edge pair collection with a complex transformation (modifies self) EdgePairs transform (const IMatrix2d t) Transform the edge pair collection (modifies self) EdgePairs transform (const IMatrix3d t) Transform the edge pair collection (modifies self) [const] EdgePairs transformed (const Trans t) Transform the edge pair collection [const] EdgePairs transformed (const ICplxTrans t) Transform the edge pair collection with a complex transformation [const] EdgePairs transformed (const IMatrix2d t) Transform the edge pair collection [const] EdgePairs transformed (const IMatrix3d t) Transform the edge pair collection [const] EdgePairs with_abs_angle (double angle, bool inverse) Filter the edge pairs by orientation of their edges [const] EdgePairs with_abs_angle (double min_angle, double max_angle, bool inverse, bool include_min_angle = true, bool include_max_angle = false) Filter the edge pairs by orientation of their edges [const] EdgePairs with_abs_angle_both (double angle, bool inverse) Filter the edge pairs by orientation of both of their edges [const] EdgePairs with_abs_angle_both (double min_angle, double max_angle, bool inverse, bool include_min_angle = true, bool include_max_angle = false) [const] EdgePairs with_angle (double angle, bool inverse) Filter the edge pairs by orientation of their edges [const] EdgePairs with_angle (double min_angle, double max_angle, bool inverse, bool include_min_angle = true, bool include_max_angle = false) Filter the edge pairs by orientation of their edges [const] EdgePairs with_angle (Edges::EdgeType type, bool inverse) Filter the edge", "source": "klayout"}
{"script_name": "transform", "definition_description": "Transforms the edge pair collection with a given transformation.", "parameters": {"t": "The transformation to apply (can be a Trans, ICplxTrans, IMatrix2d, or IMatrix3d)"}, "values": "t: <Trans|ICplxTrans|IMatrix2d|IMatrix3d>", "script_paradigm": "EdgePairs transform <t>", "examples": [{"query": "How to transform an edge pair collection with a specific transformation?", "answer": "EdgePairs transform <Trans>"}], "reference": "collection EdgePairs select_interacting (const Region other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which overlap or touch polygons from the region EdgePairs select_not_inside (const Region other) Selects the edge pairs from this edge pair collection which are not inside (completely covered by) polygons from the region EdgePairs select_not_interacting (const Edges other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do not overlap or touch edges from the other edge collection EdgePairs select_not_interacting (const Region other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do not overlap or touch polygons from the region EdgePairs select_not_outside (const Region other) Selects the edge pairs from this edge pair collection which are not outside (partially overlapped by) polygons from the other region EdgePairs select_outside (const Region other) Selects the edge pairs from this edge pair collection which are outside (not overlapped by) polygons from the other region [const] EdgePairs[] split_inside (const Region other) Selects the edge pairs from this edge pair collection which are and are not inside (completely covered by) polygons from the other region [const] EdgePairs[] split_interacting (const Edges other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do and do not interact with edges from the other collection [const] EdgePairs[] split_interacting (const Region other, unsigned long min_count = 1, unsigned long max_count = unlimited) Selects the edge pairs from this edge pair collection which do and do not interact with polygons from the other region [const] EdgePairs[] split_outside (const Region other) Selects the edge pairs from this edge pair collection which are and are not outside (not overlapped by) polygons from the other region void swap (EdgePairs other) Swap the contents of this collection with the contents of another collection [const] string to_s Converts the edge pair collection to a string [const] string to_s (unsigned long max_count) Converts the edge pair collection to a string EdgePairs transform (const Trans t) Transform the edge pair collection (modifies self) EdgePairs transform (const ICplxTrans t) Transform the edge pair collection with a complex transformation (modifies self) EdgePairs transform (const IMatrix2d t) Transform the edge pair collection (modifies self) EdgePairs transform (const IMatrix3d t) Transform the edge pair collection (modifies self) [const] EdgePairs transformed (const Trans t) Transform the edge pair collection [const] EdgePairs transformed (const ICplxTrans t) Transform the edge pair collection with a complex transformation [const] EdgePairs transformed (const IMatrix2d t) Transform the edge pair collection [const] EdgePairs transformed (const IMatrix3d t) Transform the edge pair collection [const] EdgePairs with_abs_angle (double angle, bool inverse) Filter the edge pairs by orientation of their edges [const] EdgePairs with_abs_angle (double min_angle, double max_angle, bool inverse, bool include_min_angle = true, bool include_max_angle = false) Filter the edge pairs by orientation of their edges [const] EdgePairs with_abs_angle_both (double angle, bool inverse) Filter the edge pairs by orientation of both of their edges [const] EdgePairs with_abs_angle_both (double min_angle, double max_angle, bool inverse, bool include_min_angle = true, bool include_max_angle = false) [const] EdgePairs with_angle (double angle, bool inverse) Filter the edge pairs by orientation of their edges [const] EdgePairs with_angle (double min_angle, double max_angle, bool inverse, bool include_min_angle = true, bool include_max_angle = false) Filter the edge pairs by orientation of their edges [const] EdgePairs with_angle (Edges::EdgeType type, bool inverse) Filter the edge", "source": "klayout"}
{"script_name": "gui_add_ruler", "definition_description": "This script adds a ruler to the layout, either visually using the mouse or through the command.", "parameters": {"x0": "The x-coordinate of the first end point of the ruler in microns", "y0": "The y-coordinate of the first end point of the ruler in microns", "x1": "The x-coordinate of the second end point of the ruler in microns", "y1": "The y-coordinate of the second end point of the ruler in microns", "label": "Text label to be assigned to the ruler", "name": "The name assigned to the ruler", "euclidian": "Set to 1 for Euclidean ruler or 0 for a regular ruler"}, "values": "x0: <x0>, y0: <y0>, x1: <x1>, y1: <y1>, label: <label>, name: <name>, euclidian: <euclidian>", "script_paradigm": "gui::add_ruler <x0> <y0> <x1> <y1> [<label>] [<name>] [<euclidian>]", "examples": [{"query": "How to add a ruler from (0,0) to (10,10) with a label 'Ruler1'?", "answer": "gui::add_ruler 0 0 10 10 Ruler1"}, {"query": "Add a Euclidean ruler from (5,5) to (15,15) with the name 'EuclidianRuler'?", "answer": "gui::add_ruler 5 5 15 15 EuclidianRuler 1"}], "reference": "title: gui_add_ruler(2)\ndate: 24/09/08\n\nNAME\ngui_add_ruler - gui add ruler\nSYNOPSIS\ngui::add_ruler \n    x0 y0 x1 y1\n    [label]\n    [name]\n    [euclidian]\nDESCRIPTION\nTo add a ruler to the layout:\n\n\neither press k and use the mouse to place it visually.\nTo disable snapping for the ruler when adding, hold the Ctrl key, and to allow non-horizontal or vertical snapping when completing the ruler hold the Shift key.\n\n\nor use the command:\n\n\nReturns: name of the newly created ruler.\nOPTIONS\nx0, y0, x1, y1:  first and second end point of the ruler in microns.\nlabel:  text label for the ruler.\nname:  name of the ruler.\neuclidian:  1 for euclidian ruler, and 0 for regular ruler.\nARGUMENTS\nThis command has no arguments.\nEXAMPLES\nSEE ALSO", "source": "OpenROAD"}
{"script_name": "$mul", "definition_description": "This script multiplies two inputs A and B, corresponding to the Verilog '*' operator. It supports both signed and unsigned multiplication based on the configuration of the parameters.", "parameters": {"A_SIGNED": "Indicates whether input A is signed (default: 0).", "B_SIGNED": "Indicates whether input B is signed (default: 0).", "A_WIDTH": "The width of input A in bits.", "B_WIDTH": "The width of input B in bits.", "Y_WIDTH": "The width of output Y in bits."}, "values": "A_SIGNED: <0 or 1>, B_SIGNED: <0 or 1>, A_WIDTH: <bits>, B_WIDTH: <bits>, Y_WIDTH: <bits>", "script_paradigm": "assign Y = $signed(A) * $signed(B); // For signed multiplication\nassign Y = A * B; // For unsigned multiplication", "examples": [{"query": "How to perform signed multiplication for 16-bit inputs A and B?", "answer": "assign Y = $signed(A) * $signed(B);"}, {"query": "Perform unsigned multiplication for 8-bit inputs A and B.", "answer": "assign Y = A * B;"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n1328\n1329\ninput [A_WIDTH-1:0] A;\n1330\ninput [B_WIDTH-1:0] B;\n1331\noutput [Y_WIDTH-1:0] Y;\n1332\n1333\ngenerate\n1334\nif (A_SIGNED && B_SIGNED) begin:BLOCK1\n1335\nlocalparam WIDTH = B_WIDTH >= Y_WIDTH ? B_WIDTH : Y_WIDTH;\n1336\nwire [WIDTH-1:0] B_buf, Y_trunc;\n1337\nassign B_buf = $signed(B);\n1338\nassign Y_trunc = $signed(A) % $signed(B);\n1339\n// flooring mod is the same as truncating mod for positive division␣\n˓→results (A and B have\n1340\n// the same sign), as well as when there's no remainder.\n1341\n// For all other cases, they behave as `floor - trunc = B`\n1342\nassign Y = (A[A_WIDTH-1] == B[B_WIDTH-1]) || Y_trunc == 0 ? Y_trunc :\n˓→$signed(B_buf) + $signed(Y_trunc);\n1343\nend else begin:BLOCK2\n1344\n// no difference between truncating and flooring for unsigned\n1345\nassign Y = A % B;\n1346\nend\n1347\nendgenerate\n1348\n1349\nendmodule\nyosys> help $mul\nMultiplication of inputs ‘A’ and ‘B’. This corresponds to the Verilog ‘*’ operator.\nProperties\nis_evaluable\nSimulation model (verilog)\nListing 9.26: simlib.v\n1037\nmodule \\$mul (A, B, Y);\n1038\n1039\nparameter A_SIGNED = 0;\n1040\nparameter B_SIGNED = 0;\n1041\nparameter A_WIDTH = 0;\n1042\nparameter B_WIDTH = 0;\n1043\nparameter Y_WIDTH = 0;\n1044\n1045\ninput [A_WIDTH-1:0] A;\n1046\ninput [B_WIDTH-1:0] B;\n1047\noutput [Y_WIDTH-1:0] Y;\n1048\n1049\ngenerate\n1050\nif (A_SIGNED && B_SIGNED) begin:BLOCK1\n1051\nassign Y = $signed(A) * $signed(B);\n1052\nend else begin:BLOCK2\n1053\nassign Y = A * B;\n1054\nend\n(continues on next page)\n218\nChapter 9.\nInternal cell library", "source": "yosys_hq"}
{"script_name": "ask_double_ex", "definition_description": "This script opens an input dialog requesting a floating-point value with enhanced capabilities, such as defining a range and decimal precision.", "parameters": {"title": "The title of the input dialog", "label": "The label displayed in the dialog for user guidance", "value": "The default value pre-filled in the input field", "min": "The minimum allowed value for the input", "max": "The maximum allowed value for the input", "digits": "The number of decimal places to display"}, "values": "title: <Dialog Title>, label: <Enter the value here>, value: <0>, min: <-10>, max: <10>, digits: <1>", "script_paradigm": "RBA::InputDialog::ask_double_ex(<title>, <label>, <value>, <min>, <max>, <digits>)", "examples": [{"query": "How to get a double value between -10 and 10 with 1 decimal place, starting at 0?", "answer": "RBA::InputDialog::ask_double_ex('Dialog Title', 'Enter the value here:', 0, -10, 10, 1)"}], "reference": "KLayout Documentation (Qt 5): Main Index » Class Index » API reference - Class InputDialog\n\nAPI reference - Class InputDialog\n\nNotation used in Ruby API documentation\n\nModule: lay\n\nDescription: Various methods to open a dialog requesting data entry\n\nPublic constructors\n\nPublic methods\n\nPublic static methods and constants\n\nDeprecated methods (protected, public, static, non-static and constructors)\n\nDetailed description\n\nThis class provides some basic dialogs to enter a single value. Values can be strings floating-point values, integer values or an item from a list. This functionality is provided through the static (class) methods ask_...\n\nHere are some examples:\n\n# get a double value between -10 and 10 (initial value is 0):\nv = RBA::InputDialog::ask_double_ex(\"Dialog Title\", \"Enter the value here:\", 0, -10, 10, 1)\n# get an item from a list:\nv = RBA::InputDialog::ask_item(\"Dialog Title\", \"Select one:\", [ \"item 1\", \"item 2\", \"item 3\" ], 1)\n\nAll these examples return the \"nil\" value if \"Cancel\" is pressed.\n\nIf you have enabled the Qt binding, you can use QInputDialog directly.\n\nPublic constructors\n\nnew InputDialog ptr new Creates a new object of this class\n\nPublic methods\n\n[const] InputDialog ptr _const_cast Returns a non-const reference to self. void _create Ensures the C++ object is created void _destroy Explicitly destroys the object [const] bool _destroyed? Returns a value indicating whether the object was already destroyed [const] bool _is_const_object? Returns a value indicating whether the reference is a const reference void _manage Marks the object as managed by the script side. void _unmanage Marks the object as no longer owned by the script side. void assign (const InputDialog other) Assigns another object to self [const] new InputDialog ptr dup Creates a copy of self\n\nPublic static methods and constants\n\nvariant ask_double (string title, string label, double value, int digits) Open an input dialog requesting a floating-point value variant ask_double_ex (string title, string label, double value, double min, double max, int digits) Open an input dialog requesting a floating-point value with enhanced capabilities variant ask_int (string title, string label, int value) Open an input dialog requesting an integer value variant ask_int_ex (string title, string label, int value, int min, int max, int step) Open an input dialog requesting an integer value with enhanced capabilities variant ask_item (string title, string label, string[] items, int value) Open an input dialog requesting an item from a list variant ask_string (string title, string label, string value) Open an input dialog requesting a string variant ask_string_password (string title, string label, string value) Open an input dialog requesting a string without showing the actual characters entered\n\nDeprecated methods (protected, public, static, non-static and constructors)\n\nvoid create Use of this method is deprecated. Use _create instead void destroy Use of this method is deprecated. Use _destroy instead [const] bool destroyed? Use of this method is deprecated. Use _destroyed? instead [static] DoubleValue get_double (string title, string label, double value, int digits) Use of this method is deprecated [static] DoubleValue get_double_ex (string title, string label, double value, double min, double max, int digits) Use of this method is deprecated [static] IntValue get_int (string title, string label, int value) Use of this method is deprecated [static] IntValue get_int_ex (string title, string label, int value, int min, int max, int step) Use of this method is deprecated [static] StringValue get_item (string title, string label, string[] items, int value) Use of this method is deprecated [static] StringValue get_string (string title, string label, string value) Use of this method is deprecated [static] StringValue get_string_password (string title, string label, string value) Use of this method is deprecated [const] bool is_const_object? Use of this method is deprecated. Use _is_const_object? instead\n\nDetailed description", "source": "klayout"}
{"script_name": "ask_item", "definition_description": "This script opens an input dialog requesting an item from a predefined list.", "parameters": {"title": "The title of the input dialog", "label": "The label displayed in the dialog for user guidance", "items": "An array of items from which the user can select", "value": "The default index of the item to be selected"}, "values": "title: <Dialog Title>, label: <Select one>, items: <['item 1', 'item 2', 'item 3']>, value: <1>", "script_paradigm": "RBA::InputDialog::ask_item(<title>, <label>, <items>, <value>)", "examples": [{"query": "How to select an item from a list of 3 items with 'item 2' as the default?", "answer": "RBA::InputDialog::ask_item('Dialog Title', 'Select one:', ['item 1', 'item 2', 'item 3'], 1)"}], "reference": "KLayout Documentation (Qt 5): Main Index » Class Index » API reference - Class InputDialog\n\nAPI reference - Class InputDialog\n\nNotation used in Ruby API documentation\n\nModule: lay\n\nDescription: Various methods to open a dialog requesting data entry\n\nPublic constructors\n\nPublic methods\n\nPublic static methods and constants\n\nDeprecated methods (protected, public, static, non-static and constructors)\n\nDetailed description\n\nThis class provides some basic dialogs to enter a single value. Values can be strings floating-point values, integer values or an item from a list. This functionality is provided through the static (class) methods ask_...\n\nHere are some examples:\n\n# get a double value between -10 and 10 (initial value is 0):\nv = RBA::InputDialog::ask_double_ex(\"Dialog Title\", \"Enter the value here:\", 0, -10, 10, 1)\n# get an item from a list:\nv = RBA::InputDialog::ask_item(\"Dialog Title\", \"Select one:\", [ \"item 1\", \"item 2\", \"item 3\" ], 1)\n\nAll these examples return the \"nil\" value if \"Cancel\" is pressed.\n\nIf you have enabled the Qt binding, you can use QInputDialog directly.\n\nPublic constructors\n\nnew InputDialog ptr new Creates a new object of this class\n\nPublic methods\n\n[const] InputDialog ptr _const_cast Returns a non-const reference to self. void _create Ensures the C++ object is created void _destroy Explicitly destroys the object [const] bool _destroyed? Returns a value indicating whether the object was already destroyed [const] bool _is_const_object? Returns a value indicating whether the reference is a const reference void _manage Marks the object as managed by the script side. void _unmanage Marks the object as no longer owned by the script side. void assign (const InputDialog other) Assigns another object to self [const] new InputDialog ptr dup Creates a copy of self\n\nPublic static methods and constants\n\nvariant ask_double (string title, string label, double value, int digits) Open an input dialog requesting a floating-point value variant ask_double_ex (string title, string label, double value, double min, double max, int digits) Open an input dialog requesting a floating-point value with enhanced capabilities variant ask_int (string title, string label, int value) Open an input dialog requesting an integer value variant ask_int_ex (string title, string label, int value, int min, int max, int step) Open an input dialog requesting an integer value with enhanced capabilities variant ask_item (string title, string label, string[] items, int value) Open an input dialog requesting an item from a list variant ask_string (string title, string label, string value) Open an input dialog requesting a string variant ask_string_password (string title, string label, string value) Open an input dialog requesting a string without showing the actual characters entered\n\nDeprecated methods (protected, public, static, non-static and constructors)\n\nvoid create Use of this method is deprecated. Use _create instead void destroy Use of this method is deprecated. Use _destroy instead [const] bool destroyed? Use of this method is deprecated. Use _destroyed? instead [static] DoubleValue get_double (string title, string label, double value, int digits) Use of this method is deprecated [static] DoubleValue get_double_ex (string title, string label, double value, double min, double max, int digits) Use of this method is deprecated [static] IntValue get_int (string title, string label, int value) Use of this method is deprecated [static] IntValue get_int_ex (string title, string label, int value, int min, int max, int step) Use of this method is deprecated [static] StringValue get_item (string title, string label, string[] items, int value) Use of this method is deprecated [static] StringValue get_string (string title, string label, string value) Use of this method is deprecated [static] StringValue get_string_password (string title, string label, string value) Use of this method is deprecated [const] bool is_const_object? Use of this method is deprecated. Use _is_const_object? instead\n\nDetailed description", "source": "klayout"}
{"script_name": "DeviceExtractorMOS4Transistor", "definition_description": "This script extracts a four-terminal MOS transistor device, adding a bulk terminal and corresponding bulk terminal output layer to the standard MOS3 transistor extraction.", "parameters": {"name": "The name of the device extractor to be created", "strict": "A boolean flag indicating whether strict mode is enabled", "factory": "An optional DeviceClassFactory pointer for the device class factory"}, "values": "name: <name>, strict: <false>, factory: <none>", "script_paradigm": "new DeviceExtractorMOS4Transistor <name>, <strict>, <factory>", "examples": [{"query": "How to create a new DeviceExtractorMOS4Transistor with the name 'MOS4_Device' and strict mode enabled?", "answer": "new DeviceExtractorMOS4Transistor 'MOS4_Device', true"}, {"query": "Create a new MOS4 device extractor with the name 'CustomMOS4' and without strict mode?", "answer": "new DeviceExtractorMOS4Transistor 'CustomMOS4', false"}], "reference": "KLayout Documentation (Qt 5): Main Index » Class Index » API reference - Class DeviceExtractorMOS4Transistor\n\nAPI reference - Class DeviceExtractorMOS4Transistor\n\nNotation used in Ruby API documentation\n\nModule: db\n\nDescription: A device extractor for a four-terminal MOS transistor\n\nClass hierarchy: DeviceExtractorMOS4Transistor » DeviceExtractorBase\n\nPublic constructors\n\nPublic methods\n\nDetailed description\n\nThis class supplies the generic extractor for a MOS device. It is based on the DeviceExtractorMOS3Transistor class with the extension of a bulk terminal and corresponding bulk terminal output (annotation) layer.\n\nThe parameters of a MOS4 device are the same than for MOS3 devices. For the device layers the bulk layer is added.\n\n'B' (bulk) - currently this layer is not used and can be empty.\n\nThe bulk terminals are output on this layer:\n\n'tB' - bulk terminal (a copy of the gate shape). Default output is 'B'.\n\nThe bulk terminal layer can be empty. In this case, it needs to be connected to a global net to establish the net connection.\n\nThe device class produced by this extractor is DeviceClassMOS4Transistor.\n\nThis class is a closed one and methods cannot be reimplemented. To reimplement specific methods, see DeviceExtractor.\n\nThis class has been introduced in version 0.26.\n\nPublic constructors\n\nnew DeviceExtractorMOS4Transistor ptr new (string name, bool strict = false, DeviceClassFactory ptr factory = none) Creates a new device extractor with the given name\n\nPublic methods\n\n[const] DeviceExtractorMOS4Transistor ptr _const_cast Returns a non-const reference to self. void _create Ensures the C++ object is created void _destroy Explicitly destroys the object [const] bool _destroyed? Returns a value indicating whether the object was already destroyed [const] bool _is_const_object? Returns a value indicating whether the reference is a const reference void _manage Marks the object as managed by the script side. void _unmanage Marks the object as no longer owned by the script side.\n\nDetailed description", "source": "klayout"}
{"script_name": "report_checks", "definition_description": "This script generates timing reports for path delay checks, including setup and recovery times for the specified paths.", "parameters": {"path_delay_type": "The type of path delay check, such as 'max' for maximum delay check.", "startpoint": "The startpoint of the timing path, typically a flip-flop or register.", "endpoint": "The endpoint of the timing path, which is the destination in the timing analysis.", "path_group": "The group type of the path, such as 'asynchronous' or 'synchronous'.", "path_type": "The type of path, such as 'max' for maximum delay or 'min' for minimum delay."}, "values": "path_delay_type: max, startpoint: system/prci_ctrl_domain/853, endpoint: system/185, path_group: asynchronous, path_type: max", "script_paradigm": "report_checks -path_delay <path_delay_type> -startpoint <startpoint> -endpoint <endpoint> -path_group <path_group> -path_type <path_type>", "examples": [{"query": "How to generate a report for the max delay check from system/prci_ctrl_domain/853 to system/185?", "answer": "report_checks -path_delay max -startpoint system/prci_ctrl_domain/853 -endpoint system/185 -path_group asynchronous -path_type max"}], "reference": "Design area 523197 u^2 13% utilization.\nPerform buffer insertion...\n[INFO RSZ-0058] Using max wire length 162um.\n```\nGlobal route heat map:\n\nDetailed routing without power:\n\nRegarding the long global routing times, I set SKIP_INCREMENTAL_REPAIR=1 in detailed routing, whereas it is a global routing argument. I believe that will take care of the pathologically slow global routing...\n-                'route': ['SKIP_INCREMENTAL_REPAIR=1'],\n+                'grt': ['SKIP_INCREMENTAL_REPAIR=1']\n```\n\n\n\nreport_checks -path_delay max\nStartpoint: system/prci_ctrl_domain/853\n            (rising edge-triggered flip-flop clocked by clock_uncore)\nEndpoint: system/185 (recovery check against rising-edge clock clock_uncore)\nPath Group: asynchronous\nPath Type: max\n\n\n\nDelay    Time   Description\n0.00    0.00   clock clock_uncore (rise edge)\n1973.50 1973.50   clock network delay (propagated)\n   0.00 1973.50 ^ system/prci_ctrl_domain/853/CLK (DFFASRHQNx1_ASAP7_75t_R)\n  87.72 2061.22 v system/prci_ctrl_domain/853/QN (DFFASRHQNx1_ASAP7_75t_R)\n  41.86 2103.08 v load_slew185637/Y (BUFx16f_ASAP7_75t_R)\n  37.04 2140.12 v max_cap185634/Y (BUFx16f_ASAP7_75t_R)\n  36.83 2176.95 v wire185631/Y (BUFx16f_ASAP7_75t_R)\n  41.48 2218.44 v wire185630/Y (BUFx16f_ASAP7_75t_R)\n  47.39 2265.83 v max_length185629/Y (BUFx16f_ASAP7_75t_R)\n  39.69 2305.52 v wire185628/Y (BUFx16f_ASAP7_75t_R)\n  81.35 2386.87 v max_length185627/Y (BUFx16f_ASAP7_75t_R)\n  29.27 2416.13 v load_slew185625/Y (BUFx16f_ASAP7_75t_R)\n  52.11 2468.25 v load_slew185624/Y (BUFx12f_ASAP7_75t_R)\n  43.24 2511.49 v load_slew185618/Y (BUFx16f_ASAP7_75t_R)\n  50.84 2562.32 v load_slew185615/Y (BUFx16f_ASAP7_75t_R)\n  34.35 2596.68 v load_slew185559/Y (BUFx16f_ASAP7_75t_R)\n  34.56 2631.24 v load_slew185558/Y (BUFx16f_ASAP7_75t_R)\n  26.61 2657.85 v load_slew185557/Y (BUFx16f_ASAP7_75t_R)\n  46.26 2704.11 v load_slew185556/Y (BUFx16f_ASAP7_75t_R)\n  51.34 2755.46 v max_length185555/Y (BUFx12f_ASAP7_75t_R)\n  41.44 2796.90 v wire185553/Y (BUFx16f_ASAP7_75t_R)\n  51.64 2848.53 v load_slew185552/Y (BUFx16f_ASAP7_75t_R)\n  34.46 2882.99 v wire185550/Y (BUFx16f_ASAP7_75t_R)\n  51.12 2934.11 v wire185547/Y (BUFx16f_ASAP7_75t_R)\n  64.89 2999.00 v load_slew185546/Y (BUFx16f_ASAP7_75t_R)\n  37.84 3036.83 v wire185534/Y (BUFx16f_ASAP7_75t_R)\n  88.57 3125.41 v wire185533/Y (BUFx3_ASAP7_75t_R)\n  17.20 3142.60 v wire23908/Y (BUFx16f_ASAP7_75t_R)\n 103.84 3246.44 v wire185532/Y (BUFx16f_ASAP7_75t_R)\n  53.90 3300.35 v load_slew185531/Y (BUFx16f_ASAP7_75t_R)\n  35.37 3335.71 v load_slew185522/Y (BUFx16f_ASAP7_75t_R)\n  31.13 3366.84 v load_slew185507/Y (BUFx16f_ASAP7_75t_R)\n  32.21 3399.06 v wire185505/Y (BUFx16f_ASAP7_75t_R)\n  37.17 3436.23 v load_slew185504/Y (BUFx16f_ASAP7_75t_R)\n  25.45 3461.69 v load_slew185494/Y (BUFx16f_ASAP7_75t_R)\n  25.36 3487.04 v wire185486/Y (BUFx16f_ASAP7_75t_R)\n  47.14 3534.18 v wire185485/Y (BUFx16f_ASAP7_75t_R)\n  24.87 3559.05 v max_cap185484/Y (BUFx16f_ASAP7_75t_R)\n  27.89 3586.94 v wire185483/Y (BUFx3_ASAP7_75t_R)\n  16.61 3603.56 v wire19831/Y (BUFx16f_ASAP7_75t_R)\n 105.13 3708.69 v wire185481/Y (BUFx3_ASAP7_75t_R)\n  18.09 3726.78 v wire19408/Y (BUFx16f_ASAP7_75t_R)\n 112.70 3839.48 ^ system/107/Y (INVx1_ASAP7_75t_R)\n   0.03 3839.51 ^ system/185/SETN (DFFASRHQNx1_ASAP7_75t_R)\n        3839.51   data arrival time\n8500.00 8500.00   clock clock_uncore (rise edge)\n1969.03 10469.03   clock network delay (propagated)\n -10.00 10459.03   clock uncertainty\n   0.00 10459.03   clock reconvergence pessimism\n        10459.03 ^ system/185/CLK (DFFASRHQNx1_ASAP7_75t_R)\n   0.82 10459.85   library recovery time\n        10459.85   data required time\n\n    10459.85   data required time\n    -3839.51   data arrival time\n\n\n    6620.34   slack (MET)", "source": "OpenROAD"}
{"script_name": "route", "definition_description": "This script is used to configure global routing options, such as skipping incremental repairs during routing.", "parameters": {"grt": "The global routing options, which include flags like SKIP_INCREMENTAL_REPAIR to optimize routing."}, "values": "grt: SKIP_INCREMENTAL_REPAIR=1", "script_paradigm": "route -grt <grt>", "examples": [{"query": "How to disable incremental repair during global routing?", "answer": "route -grt SKIP_INCREMENTAL_REPAIR=1"}], "reference": "Design area 523197 u^2 13% utilization.\nPerform buffer insertion...\n[INFO RSZ-0058] Using max wire length 162um.\n```\nGlobal route heat map:\n\nDetailed routing without power:\n\nRegarding the long global routing times, I set SKIP_INCREMENTAL_REPAIR=1 in detailed routing, whereas it is a global routing argument. I believe that will take care of the pathologically slow global routing...\n-                'route': ['SKIP_INCREMENTAL_REPAIR=1'],\n+                'grt': ['SKIP_INCREMENTAL_REPAIR=1']\n```\n\n\n\nreport_checks -path_delay max\nStartpoint: system/prci_ctrl_domain/853\n            (rising edge-triggered flip-flop clocked by clock_uncore)\nEndpoint: system/185 (recovery check against rising-edge clock clock_uncore)\nPath Group: asynchronous\nPath Type: max\n\n\n\nDelay    Time   Description\n0.00    0.00   clock clock_uncore (rise edge)\n1973.50 1973.50   clock network delay (propagated)\n   0.00 1973.50 ^ system/prci_ctrl_domain/853/CLK (DFFASRHQNx1_ASAP7_75t_R)\n  87.72 2061.22 v system/prci_ctrl_domain/853/QN (DFFASRHQNx1_ASAP7_75t_R)\n  41.86 2103.08 v load_slew185637/Y (BUFx16f_ASAP7_75t_R)\n  37.04 2140.12 v max_cap185634/Y (BUFx16f_ASAP7_75t_R)\n  36.83 2176.95 v wire185631/Y (BUFx16f_ASAP7_75t_R)\n  41.48 2218.44 v wire185630/Y (BUFx16f_ASAP7_75t_R)\n  47.39 2265.83 v max_length185629/Y (BUFx16f_ASAP7_75t_R)\n  39.69 2305.52 v wire185628/Y (BUFx16f_ASAP7_75t_R)\n  81.35 2386.87 v max_length185627/Y (BUFx16f_ASAP7_75t_R)\n  29.27 2416.13 v load_slew185625/Y (BUFx16f_ASAP7_75t_R)\n  52.11 2468.25 v load_slew185624/Y (BUFx12f_ASAP7_75t_R)\n  43.24 2511.49 v load_slew185618/Y (BUFx16f_ASAP7_75t_R)\n  50.84 2562.32 v load_slew185615/Y (BUFx16f_ASAP7_75t_R)\n  34.35 2596.68 v load_slew185559/Y (BUFx16f_ASAP7_75t_R)\n  34.56 2631.24 v load_slew185558/Y (BUFx16f_ASAP7_75t_R)\n  26.61 2657.85 v load_slew185557/Y (BUFx16f_ASAP7_75t_R)\n  46.26 2704.11 v load_slew185556/Y (BUFx16f_ASAP7_75t_R)\n  51.34 2755.46 v max_length185555/Y (BUFx12f_ASAP7_75t_R)\n  41.44 2796.90 v wire185553/Y (BUFx16f_ASAP7_75t_R)\n  51.64 2848.53 v load_slew185552/Y (BUFx16f_ASAP7_75t_R)\n  34.46 2882.99 v wire185550/Y (BUFx16f_ASAP7_75t_R)\n  51.12 2934.11 v wire185547/Y (BUFx16f_ASAP7_75t_R)\n  64.89 2999.00 v load_slew185546/Y (BUFx16f_ASAP7_75t_R)\n  37.84 3036.83 v wire185534/Y (BUFx16f_ASAP7_75t_R)\n  88.57 3125.41 v wire185533/Y (BUFx3_ASAP7_75t_R)\n  17.20 3142.60 v wire23908/Y (BUFx16f_ASAP7_75t_R)\n 103.84 3246.44 v wire185532/Y (BUFx16f_ASAP7_75t_R)\n  53.90 3300.35 v load_slew185531/Y (BUFx16f_ASAP7_75t_R)\n  35.37 3335.71 v load_slew185522/Y (BUFx16f_ASAP7_75t_R)\n  31.13 3366.84 v load_slew185507/Y (BUFx16f_ASAP7_75t_R)\n  32.21 3399.06 v wire185505/Y (BUFx16f_ASAP7_75t_R)\n  37.17 3436.23 v load_slew185504/Y (BUFx16f_ASAP7_75t_R)\n  25.45 3461.69 v load_slew185494/Y (BUFx16f_ASAP7_75t_R)\n  25.36 3487.04 v wire185486/Y (BUFx16f_ASAP7_75t_R)\n  47.14 3534.18 v wire185485/Y (BUFx16f_ASAP7_75t_R)\n  24.87 3559.05 v max_cap185484/Y (BUFx16f_ASAP7_75t_R)\n  27.89 3586.94 v wire185483/Y (BUFx3_ASAP7_75t_R)\n  16.61 3603.56 v wire19831/Y (BUFx16f_ASAP7_75t_R)\n 105.13 3708.69 v wire185481/Y (BUFx3_ASAP7_75t_R)\n  18.09 3726.78 v wire19408/Y (BUFx16f_ASAP7_75t_R)\n 112.70 3839.48 ^ system/107/Y (INVx1_ASAP7_75t_R)\n   0.03 3839.51 ^ system/185/SETN (DFFASRHQNx1_ASAP7_75t_R)\n        3839.51   data arrival time\n8500.00 8500.00   clock clock_uncore (rise edge)\n1969.03 10469.03   clock network delay (propagated)\n -10.00 10459.03   clock uncertainty\n   0.00 10459.03   clock reconvergence pessimism\n        10459.03 ^ system/185/CLK (DFFASRHQNx1_ASAP7_75t_R)\n   0.82 10459.85   library recovery time\n        10459.85   data required time\n\n    10459.85   data required time\n    -3839.51   data arrival time\n\n\n    6620.34   slack (MET)", "source": "OpenROAD"}
{"script_name": "RunInPlace", "definition_description": "This script sets up Verilator to run in-place directly from the Git directory, without requiring installation.", "parameters": {"VERILATOR_ROOT": "The environment variable pointing to the Verilator Git directory."}, "values": "VERILATOR_ROOT: `pwd`", "script_paradigm": "export VERILATOR_ROOT=`pwd` # For bash, setenv VERILATOR_ROOT `pwd` # For csh", "examples": [{"query": "How to configure Verilator to run in-place from its Git directory?", "answer": "export VERILATOR_ROOT=`pwd` # For bash"}], "reference": "Verilator, Release Devel 5.031\n3.4.4 Auto Conﬁgure\nCreate the conﬁguration script:\nautoconf\n# Create ./configure script\n3.4.5 Eventual Installation Options\nBefore conﬁguring the build, you must decide how you’re going to eventually install Verilator onto your system. Ver-\nilator will be compiling the current value of the environment variables VERILATOR_ROOT, VERILATOR_SOLVER,\nSYSTEMC_INCLUDE, and SYSTEMC_LIBDIR as defaults into the executable, so they must be correct before con-\nﬁguring.\nThese are the installation options:\n1. Run-in-Place from VERILATOR_ROOT\nOur personal favorite is to always run Verilator in-place from its Git directory (don’t run make install). This\nallows the easiest experimentation and upgrading, and allows many versions of Verilator to co-exist on a system.\nexport VERILATOR_ROOT=`pwd`\n# if your shell is bash\nsetenv VERILATOR_ROOT `pwd`\n# if your shell is csh\n./configure\n# Running will use files from $VERILATOR_ROOT, so no install needed\nNote after installing (see Installation),\na calling program or shell must set the environment variable\nVERILATOR_ROOT to point to this Git directory, then execute $VERILATOR_ROOT/bin/verilator, which\nwill ﬁnd the path to all needed ﬁles.\n2. Install into a Speciﬁc Preﬁx\nYou may be an OS package maintainer building a Verilator package, or you may eventually be installing onto a\nproject/company-wide “CAD” tools disk that may support multiple versions of every tool. Tell conﬁgure the eventual\ndestination directory name. We recommend that the destination location include the Verilator version name:\nunset VERILATOR_ROOT\n# if your shell is bash\nunsetenv VERILATOR_ROOT\n# if your shell is csh\n# For the tarball, use the version number instead of git describe\n./configure --prefix /CAD_DISK/verilator/`git describe | sed \"s/verilator_//\"`\nNote after installing (see Installation), you need to add the path to the bin directory to your PATH. Or, if you use\nmodulecmd, you’ll want a module ﬁle like the following:\nset install_root /CAD_DISK/verilator/{version-number-used-above}\nunsetenv VERILATOR_ROOT\nprepend-path PATH $install_root/bin\nprepend-path MANPATH $install_root/man\nprepend-path PKG_CONFIG_PATH $install_root/share/pkgconfig\n3.4. Detailed Build Instructions\n10", "source": "verilator"}
{"script_name": "InstallToPrefix", "definition_description": "This script configures Verilator to install into a specified directory prefix.", "parameters": {"VERILATOR_ROOT": "Unset any existing VERILATOR_ROOT environment variable before installation.", "prefix": "The directory path where Verilator will be installed."}, "values": "VERILATOR_ROOT: unset, prefix: /CAD_DISK/verilator/`git describe | sed \"s/verilator_//\"`", "script_paradigm": "unset VERILATOR_ROOT # For bash, unsetenv VERILATOR_ROOT # For csh, ./configure --prefix /CAD_DISK/verilator/`git describe | sed \"s/verilator_//\"`", "examples": [{"query": "How to install Verilator to a specific directory with versioning?", "answer": "unset VERILATOR_ROOT # For bash, unsetenv VERILATOR_ROOT # For csh, ./configure --prefix /CAD_DISK/verilator/`git describe | sed \"s/verilator_//\"`"}], "reference": "Verilator, Release Devel 5.031\n3.4.4 Auto Conﬁgure\nCreate the conﬁguration script:\nautoconf\n# Create ./configure script\n3.4.5 Eventual Installation Options\nBefore conﬁguring the build, you must decide how you’re going to eventually install Verilator onto your system. Ver-\nilator will be compiling the current value of the environment variables VERILATOR_ROOT, VERILATOR_SOLVER,\nSYSTEMC_INCLUDE, and SYSTEMC_LIBDIR as defaults into the executable, so they must be correct before con-\nﬁguring.\nThese are the installation options:\n1. Run-in-Place from VERILATOR_ROOT\nOur personal favorite is to always run Verilator in-place from its Git directory (don’t run make install). This\nallows the easiest experimentation and upgrading, and allows many versions of Verilator to co-exist on a system.\nexport VERILATOR_ROOT=`pwd`\n# if your shell is bash\nsetenv VERILATOR_ROOT `pwd`\n# if your shell is csh\n./configure\n# Running will use files from $VERILATOR_ROOT, so no install needed\nNote after installing (see Installation),\na calling program or shell must set the environment variable\nVERILATOR_ROOT to point to this Git directory, then execute $VERILATOR_ROOT/bin/verilator, which\nwill ﬁnd the path to all needed ﬁles.\n2. Install into a Speciﬁc Preﬁx\nYou may be an OS package maintainer building a Verilator package, or you may eventually be installing onto a\nproject/company-wide “CAD” tools disk that may support multiple versions of every tool. Tell conﬁgure the eventual\ndestination directory name. We recommend that the destination location include the Verilator version name:\nunset VERILATOR_ROOT\n# if your shell is bash\nunsetenv VERILATOR_ROOT\n# if your shell is csh\n# For the tarball, use the version number instead of git describe\n./configure --prefix /CAD_DISK/verilator/`git describe | sed \"s/verilator_//\"`\nNote after installing (see Installation), you need to add the path to the bin directory to your PATH. Or, if you use\nmodulecmd, you’ll want a module ﬁle like the following:\nset install_root /CAD_DISK/verilator/{version-number-used-above}\nunsetenv VERILATOR_ROOT\nprepend-path PATH $install_root/bin\nprepend-path MANPATH $install_root/man\nprepend-path PKG_CONFIG_PATH $install_root/share/pkgconfig\n3.4. Detailed Build Instructions\n10", "source": "verilator"}
{"script_name": "ShowSelection", "definition_description": "This script displays a schematic of a given selection using GraphViz. The schematic can be customized using various options such as coloring and hiding titles.", "parameters": {"selection": "The selection string or named selection to be displayed", "title_option": "Optional flag to hide the title in the output (use -notitle to hide)", "color_option": "Optional flag to color specific objects in the schematic (use -color <color> <object>)"}, "values": "selection: <selection_string>, title_option: -notitle, color_option: -color <color> <object>", "script_paradigm": "show <selection> <title_option> <color_option>", "examples": [{"query": "How to show a schematic of the addr_gen module without the title?", "answer": "show addr_gen -notitle"}, {"query": "How to show a schematic of the new_cells selection with specific coloring?", "answer": "show @new_cells -color red addr"}, {"query": "How to display a schematic with a highlight on $add and $eq cells?", "answer": "show -notitle t:$add t:$eq"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nxdot instance.\nThe addr_gen at the end tells it we only want the addr_gen module, just like when we called select\n-module addr_gen in Selections intro. That last parameter doesn’t have to be a module name, it can be\nany valid selection string. Remember when we assigned a name to a selection and called it new_cells? We\nsaw in the select -list output that it contained two cells, an $add and an $eq . We can call show on that\nselection just as easily:\n$3_Y\n1\nA\nB\n$3\n$add\nY\naddr\n$2_Y\n255\nA\nB\n$2\n$eq\nY\naddr\n0 -> 31:8\n7:0 - 7:0\nFig. 2.18: Calling show -notitle @new_cells\nWe could have gotten the same output with show -notitle t:$add t:$eq if we didn’t have the named\nselection. By adding the -notitle flag there we can also get rid of the addr_gen title that would have been\nautomatically added. The last two images were both added for this introduction. The next image is the first\none we saw in Synthesis starter: showing the full addr_gen module while also highlighting @new_cells and\nthe two PROC blocks. To achieve this highlight, we make use of the -color option:\nAs described in the the help output for show (or by clicking on the show link), colors are specified as\n-color <color> <object>. Color names for the <color> portion can be found on the GraphViz color docs.\nUnlike the final show parameter which can have be any selection string, the <object> part must be a single\nselection expression or named selection. That means while we can use @new_cells, we couldn’t use t:$eq\nt:$add. In general, if a command lists [selection] as its final parameter it can be any selection string.\nAny selections that are not the final parameter, such as those used in options, must be a single expression\ninstead.\nFor all of the options available to show , check the command reference at show - generate schematics using\ngraphviz.\nã See also\nA look at the show command on the Interactive design investigation page.\n2.3.\nScripting in Yosys\n41", "source": "yosys_hq"}
{"script_name": "xilinx_srl -variable -minlen 3", "definition_description": "This script maps the design to Xilinx SRLs with a minimum length of 3 for better resource optimization.", "parameters": {"minlen": "The minimum length of the shift register LUTs to be used."}, "values": "minlen: 3", "script_paradigm": "xilinx_srl -variable -minlen <minlen>", "examples": [{"query": "How to map the design to Xilinx SRLs with a minimum length of 3?", "answer": "xilinx_srl -variable -minlen 3"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nopt -full\nxilinx_srl -variable -minlen 3\n(skip if '-nosrl')\ntechmap\n-map +/techmap.v -D LUT_SIZE=[46] [-map +/xilinx/mux_map.v] -map +/\n˓→xilinx/arith_map.v\nopt -fast\nmap_cells:\niopadmap -bits -outpad OBUF I:O -inpad IBUF O:I -toutpad OBUFT ~T:I:O -tinoutpad␣\n˓→IOBUF ~T:O:I:IO A:top\n(skip if '-noiopad')\ntechmap -map +/techmap.v -map +/xilinx/cells_map.v\nclean\nmap_ffs:\ndfflegalize -cell $_DFFE_?P?P_ 01 -cell $_SDFFE_?P?P_ 01 -cell $_DLATCH_?P?_ 01 ␣\n˓→\n(for xc6v, xc7, xcu, xcup)\nzinit -all w:* t:$_SDFFE_*\n('-dff' only)\ntechmap -map +/xilinx/ff_map.v\n('-abc9' only)\nmap_luts:\nopt_expr -mux_undef -noclkinv\nabc -luts 2:2,3,6:5[,10,20] [-dff] [-D 1]\n(option for '-nowidelut', '-dff', '-\n˓→retime')\nclean\ntechmap -map +/xilinx/ff_map.v\n(only if not '-abc9')\nxilinx_srl -fixed -minlen 3\n(skip if '-nosrl')\ntechmap -map +/xilinx/lut_map.v -map +/xilinx/cells_map.v -D LUT_WIDTH=[46]\nxilinx_dffopt [-lut4]\nopt_lut_ins -tech xilinx\nfinalize:\nclkbufmap -buf BUFG O:I\n(skip if '-noclkbuf')\nextractinv -inv INV O:I\n(only if '-ise')\nclean\ncheck:\nhierarchy -check\nstat -tech xilinx\ncheck -noinit\nblackbox =A:whitebox\nedif:\nwrite_edif -pvector bra\nblif:\nwrite_blif\njson:\nwrite_json <file-name>\n534\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "techmap", "definition_description": "This script applies a set of technology mappings to the design, including mapping to Xilinx-specific LUTs, arithmetic cells, and mux cells.", "parameters": {"map_file": "The mapping file to be applied to the design.", "LUT_SIZE": "Specifies the size of LUTs to be used during mapping."}, "values": "map_file: +/techmap.v, LUT_SIZE: [46]", "script_paradigm": "techmap -map <map_file> -D LUT_SIZE=[<LUT_SIZE>] [-map <additional_map_file>]", "examples": [{"query": "How to apply a techmap with a LUT size of 46?", "answer": "techmap -map +/techmap.v -D LUT_SIZE=[46]"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nopt -full\nxilinx_srl -variable -minlen 3\n(skip if '-nosrl')\ntechmap\n-map +/techmap.v -D LUT_SIZE=[46] [-map +/xilinx/mux_map.v] -map +/\n˓→xilinx/arith_map.v\nopt -fast\nmap_cells:\niopadmap -bits -outpad OBUF I:O -inpad IBUF O:I -toutpad OBUFT ~T:I:O -tinoutpad␣\n˓→IOBUF ~T:O:I:IO A:top\n(skip if '-noiopad')\ntechmap -map +/techmap.v -map +/xilinx/cells_map.v\nclean\nmap_ffs:\ndfflegalize -cell $_DFFE_?P?P_ 01 -cell $_SDFFE_?P?P_ 01 -cell $_DLATCH_?P?_ 01 ␣\n˓→\n(for xc6v, xc7, xcu, xcup)\nzinit -all w:* t:$_SDFFE_*\n('-dff' only)\ntechmap -map +/xilinx/ff_map.v\n('-abc9' only)\nmap_luts:\nopt_expr -mux_undef -noclkinv\nabc -luts 2:2,3,6:5[,10,20] [-dff] [-D 1]\n(option for '-nowidelut', '-dff', '-\n˓→retime')\nclean\ntechmap -map +/xilinx/ff_map.v\n(only if not '-abc9')\nxilinx_srl -fixed -minlen 3\n(skip if '-nosrl')\ntechmap -map +/xilinx/lut_map.v -map +/xilinx/cells_map.v -D LUT_WIDTH=[46]\nxilinx_dffopt [-lut4]\nopt_lut_ins -tech xilinx\nfinalize:\nclkbufmap -buf BUFG O:I\n(skip if '-noclkbuf')\nextractinv -inv INV O:I\n(only if '-ise')\nclean\ncheck:\nhierarchy -check\nstat -tech xilinx\ncheck -noinit\nblackbox =A:whitebox\nedif:\nwrite_edif -pvector bra\nblif:\nwrite_blif\njson:\nwrite_json <file-name>\n534\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "iopadmap", "definition_description": "This script maps input and output pads to their respective buffer types, such as IBUF, OBUF, and others, for I/O optimization.", "parameters": {"bits": "Specifies the bit size of the pads.", "outpad": "Defines the output pad type.", "inpad": "Defines the input pad type."}, "values": "bits: unspecified, outpad: OBUF, inpad: IBUF", "script_paradigm": "iopadmap -bits <bits> -outpad <outpad> I:O -inpad <inpad> O:I", "examples": [{"query": "How to map input and output pads with IBUF and OBUF?", "answer": "iopadmap -bits <bits> -outpad OBUF I:O -inpad IBUF O:I"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nopt -full\nxilinx_srl -variable -minlen 3\n(skip if '-nosrl')\ntechmap\n-map +/techmap.v -D LUT_SIZE=[46] [-map +/xilinx/mux_map.v] -map +/\n˓→xilinx/arith_map.v\nopt -fast\nmap_cells:\niopadmap -bits -outpad OBUF I:O -inpad IBUF O:I -toutpad OBUFT ~T:I:O -tinoutpad␣\n˓→IOBUF ~T:O:I:IO A:top\n(skip if '-noiopad')\ntechmap -map +/techmap.v -map +/xilinx/cells_map.v\nclean\nmap_ffs:\ndfflegalize -cell $_DFFE_?P?P_ 01 -cell $_SDFFE_?P?P_ 01 -cell $_DLATCH_?P?_ 01 ␣\n˓→\n(for xc6v, xc7, xcu, xcup)\nzinit -all w:* t:$_SDFFE_*\n('-dff' only)\ntechmap -map +/xilinx/ff_map.v\n('-abc9' only)\nmap_luts:\nopt_expr -mux_undef -noclkinv\nabc -luts 2:2,3,6:5[,10,20] [-dff] [-D 1]\n(option for '-nowidelut', '-dff', '-\n˓→retime')\nclean\ntechmap -map +/xilinx/ff_map.v\n(only if not '-abc9')\nxilinx_srl -fixed -minlen 3\n(skip if '-nosrl')\ntechmap -map +/xilinx/lut_map.v -map +/xilinx/cells_map.v -D LUT_WIDTH=[46]\nxilinx_dffopt [-lut4]\nopt_lut_ins -tech xilinx\nfinalize:\nclkbufmap -buf BUFG O:I\n(skip if '-noclkbuf')\nextractinv -inv INV O:I\n(only if '-ise')\nclean\ncheck:\nhierarchy -check\nstat -tech xilinx\ncheck -noinit\nblackbox =A:whitebox\nedif:\nwrite_edif -pvector bra\nblif:\nwrite_blif\njson:\nwrite_json <file-name>\n534\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "dfflegalize", "definition_description": "This script legalizes D flip-flop cells for specific types, ensuring that they comply with the FPGA's required cell structure.", "parameters": {"cell": "The cell type to be legalized.", "params": "Additional parameters to control the legalizing process."}, "values": "cell: $_DFFE_?P?P_, params: 01", "script_paradigm": "dfflegalize -cell <cell> <params>", "examples": [{"query": "How to legalize the D flip-flop cells $_DFFE_?P?P_?", "answer": "dfflegalize -cell $_DFFE_?P?P_ 01"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nopt -full\nxilinx_srl -variable -minlen 3\n(skip if '-nosrl')\ntechmap\n-map +/techmap.v -D LUT_SIZE=[46] [-map +/xilinx/mux_map.v] -map +/\n˓→xilinx/arith_map.v\nopt -fast\nmap_cells:\niopadmap -bits -outpad OBUF I:O -inpad IBUF O:I -toutpad OBUFT ~T:I:O -tinoutpad␣\n˓→IOBUF ~T:O:I:IO A:top\n(skip if '-noiopad')\ntechmap -map +/techmap.v -map +/xilinx/cells_map.v\nclean\nmap_ffs:\ndfflegalize -cell $_DFFE_?P?P_ 01 -cell $_SDFFE_?P?P_ 01 -cell $_DLATCH_?P?_ 01 ␣\n˓→\n(for xc6v, xc7, xcu, xcup)\nzinit -all w:* t:$_SDFFE_*\n('-dff' only)\ntechmap -map +/xilinx/ff_map.v\n('-abc9' only)\nmap_luts:\nopt_expr -mux_undef -noclkinv\nabc -luts 2:2,3,6:5[,10,20] [-dff] [-D 1]\n(option for '-nowidelut', '-dff', '-\n˓→retime')\nclean\ntechmap -map +/xilinx/ff_map.v\n(only if not '-abc9')\nxilinx_srl -fixed -minlen 3\n(skip if '-nosrl')\ntechmap -map +/xilinx/lut_map.v -map +/xilinx/cells_map.v -D LUT_WIDTH=[46]\nxilinx_dffopt [-lut4]\nopt_lut_ins -tech xilinx\nfinalize:\nclkbufmap -buf BUFG O:I\n(skip if '-noclkbuf')\nextractinv -inv INV O:I\n(only if '-ise')\nclean\ncheck:\nhierarchy -check\nstat -tech xilinx\ncheck -noinit\nblackbox =A:whitebox\nedif:\nwrite_edif -pvector bra\nblif:\nwrite_blif\njson:\nwrite_json <file-name>\n534\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "Transformation Objects", "definition_description": "This script provides basic operations for transformation objects, including concatenation, inversion, and application to geometrical objects.", "parameters": {"angle": "The rotation angle in degrees.", "mirror": "A flag indicating whether mirroring is applied along the x-axis.", "displacement": "The displacement vector to be applied in the transformation."}, "values": "angle: <0, 90, 180, 270>, mirror: <False, True>, displacement: <vector>", "script_paradigm": "Transformation objects can be represented as either simple or complex transformations, such as DTrans, Trans, DCplxTrans, and ICplxTrans, with operations like concatenation, inversion, and application to geometrical objects.", "examples": [{"query": "How to apply a 90-degree rotation with no mirroring and a displacement vector to an object?", "answer": "Transformation = Trans(1, False, displacement)"}, {"query": "How to invert a transformation?", "answer": "TI = T.inverted()"}, {"query": "How to apply a transformation to a geometrical object?", "answer": "q = T * p"}], "reference": "m45 == m0 followed by r90\n\nWhen coding transformations, two parameters are used to represent the rotation/mirror part: a rotation angle and a flag indicating mirroring at the x axis. The mirroring is applied before the rotation. In terms of these parameters, the basic transformations are:\n\nRotation angle (degree) Mirror flag = False Mirror flag = True 0 r0 m0 90 r90 m45 180 r180 m90 270 r270 m135\n\nTransformation objects\n\nTransformation objects are convenient objects to operate with. They represent a transformation (technically a matrix) consisting of an angle/mirror and a displacement part. They support some basic operations:\n\nConcatenation: T = T1 * T2 T is transformation T2 applied, then T1 (note this order)\n\nInversion: TI = T.inverted() TI is the inverse of T, i.e. TI * T = T * TI = 1 where 1 is the neutral transformation which does not modify coordinates\n\nApplication to geometrical objects: q = T * p where p is a box, polygon, path, text, point, vector etc. and q is the transformed object\n\nVectors and Points\n\nIn KLayout there are two two-dimensional coordinate objects: the vector and the point. Basically, the vector is the difference between two points:\n\nv = p2 - p1\n\nHere v is a vector object while p1 and p2 are points.\n\nRegarding transformations, vectors and points behave differently. While for a point, the displacement is applied, it is not for vectors. So\n\np' = T * p = M * p + d\nv' = T * v = M * v\n\nHere M is the 2x2 rotation/mirror matrix part of the transformation and d is the displacement vector\n\nThe reason why the displacement is not applied to a vector is seen here:\n\n v' = T * v \n    = T * (p2 - p1) \n    = T * p2 - T * p1\n    = (M * p2 + d) - (M * p1 + d)\n    = M * p2 + d - M * p1 - d\n    = M * p2 - M * p1 \n    = M * (p2 - p1)\n\nwhere the latter simply is:\n\nv' = M * v\n\nSimple transformations\n\nSimple transformations are represented by DTrans or Trans objects. The first operates with floating-point displacements in units of micrometers while the second one with integer displacements in database units. \"DTrans\" objects act on \"D\" type floating-point coordinate shapes (e.g. DBox) while \"Trans\" objects act on the integer coordinate shapes (e.g. Box).\n\nThe basic construction parameters of \"DTrans\" and \"Trans\" are:\n\nTrans(angle, mirror, displacement)\nDTrans(angle, mirror, displacement)\n\n\"displacement\" is a DVector (for DTrans) or a Vector (for Trans).\n\n\"angle\" is the rotation angle in units of 90 degree and \"mirror\" is the mirror flag:\n\nangle mirror = False mirror = True 0 r0 m0 1 r90 m45 2 r180 m90 3 r270 m135\n\nComplex transformations\n\nComplex transformations in addition to the simple transformations feature scaling (magnification) and arbitrary rotation angles. Other than simple transformations they do not necessarily preserve a grid and rounding is implied. Furthermore they imply a shift is physical scale which renders them difficult to use in physical frameworks (e.g. DRC). Hence their use is discouraged for certain applications.\n\nThe basic classes are DCplxTrans for the micrometer-unit (floating-point) version and ICplxTrans for the database-unit (integer) version. The construction parameters are:\n\nICplxTrans(angle, mirror, magnification, displacement)\nDCplxTrans(angle, mirror, magnification, displacement)\n\nHere, \"angle\" is the rotation angle in degree (note the difference to \"Trans\" and \"DTrans\" where the rotation angle is in units for 90 degree. \"magnification\" is a factor (1.0 for \"no change in scale\").\n\nThere are two other variants useful for transforming coordinate systems: CplxTrans takes integer-unit objects and converts them to floating-point unit objects. It can be used to convert from database units to micrometer units when configured with a magnification equal to the database unit value:\n\nT = CplxTrans(magnification: dbu)\nq = T * p\n\nThe other variant is VCplxTrans which converts floating-point unit objects to integer-unit ones. These objects are generated when inverting \"CplxTrans\" objects.", "source": "klayout"}
{"script_name": "Complex Transformations", "definition_description": "This script defines complex transformations that include scaling (magnification) and arbitrary rotation angles, offering both micrometer and database-unit versions.", "parameters": {"angle": "The rotation angle in degrees.", "mirror": "A flag indicating whether mirroring is applied along the x-axis.", "magnification": "The scaling factor, 1.0 for no scale change.", "displacement": "The displacement vector to be applied in the transformation."}, "values": "angle: <real number>, mirror: <False, True>, magnification: <float>, displacement: <vector>", "script_paradigm": "ICplxTrans(angle, mirror, magnification, displacement) or DCplxTrans(angle, mirror, magnification, displacement), for complex transformations with scaling and arbitrary angles.", "examples": [{"query": "How to apply a complex transformation with a 45-degree rotation and a scaling factor of 2.0?", "answer": "Transformation = DCplxTrans(45, False, 2.0, displacement)"}, {"query": "How to apply a transformation with a 90-degree rotation, no mirroring, and no scaling?", "answer": "Transformation = DCplxTrans(90, False, 1.0, displacement)"}], "reference": "m45 == m0 followed by r90\n\nWhen coding transformations, two parameters are used to represent the rotation/mirror part: a rotation angle and a flag indicating mirroring at the x axis. The mirroring is applied before the rotation. In terms of these parameters, the basic transformations are:\n\nRotation angle (degree) Mirror flag = False Mirror flag = True 0 r0 m0 90 r90 m45 180 r180 m90 270 r270 m135\n\nTransformation objects\n\nTransformation objects are convenient objects to operate with. They represent a transformation (technically a matrix) consisting of an angle/mirror and a displacement part. They support some basic operations:\n\nConcatenation: T = T1 * T2 T is transformation T2 applied, then T1 (note this order)\n\nInversion: TI = T.inverted() TI is the inverse of T, i.e. TI * T = T * TI = 1 where 1 is the neutral transformation which does not modify coordinates\n\nApplication to geometrical objects: q = T * p where p is a box, polygon, path, text, point, vector etc. and q is the transformed object\n\nVectors and Points\n\nIn KLayout there are two two-dimensional coordinate objects: the vector and the point. Basically, the vector is the difference between two points:\n\nv = p2 - p1\n\nHere v is a vector object while p1 and p2 are points.\n\nRegarding transformations, vectors and points behave differently. While for a point, the displacement is applied, it is not for vectors. So\n\np' = T * p = M * p + d\nv' = T * v = M * v\n\nHere M is the 2x2 rotation/mirror matrix part of the transformation and d is the displacement vector\n\nThe reason why the displacement is not applied to a vector is seen here:\n\n v' = T * v \n    = T * (p2 - p1) \n    = T * p2 - T * p1\n    = (M * p2 + d) - (M * p1 + d)\n    = M * p2 + d - M * p1 - d\n    = M * p2 - M * p1 \n    = M * (p2 - p1)\n\nwhere the latter simply is:\n\nv' = M * v\n\nSimple transformations\n\nSimple transformations are represented by DTrans or Trans objects. The first operates with floating-point displacements in units of micrometers while the second one with integer displacements in database units. \"DTrans\" objects act on \"D\" type floating-point coordinate shapes (e.g. DBox) while \"Trans\" objects act on the integer coordinate shapes (e.g. Box).\n\nThe basic construction parameters of \"DTrans\" and \"Trans\" are:\n\nTrans(angle, mirror, displacement)\nDTrans(angle, mirror, displacement)\n\n\"displacement\" is a DVector (for DTrans) or a Vector (for Trans).\n\n\"angle\" is the rotation angle in units of 90 degree and \"mirror\" is the mirror flag:\n\nangle mirror = False mirror = True 0 r0 m0 1 r90 m45 2 r180 m90 3 r270 m135\n\nComplex transformations\n\nComplex transformations in addition to the simple transformations feature scaling (magnification) and arbitrary rotation angles. Other than simple transformations they do not necessarily preserve a grid and rounding is implied. Furthermore they imply a shift is physical scale which renders them difficult to use in physical frameworks (e.g. DRC). Hence their use is discouraged for certain applications.\n\nThe basic classes are DCplxTrans for the micrometer-unit (floating-point) version and ICplxTrans for the database-unit (integer) version. The construction parameters are:\n\nICplxTrans(angle, mirror, magnification, displacement)\nDCplxTrans(angle, mirror, magnification, displacement)\n\nHere, \"angle\" is the rotation angle in degree (note the difference to \"Trans\" and \"DTrans\" where the rotation angle is in units for 90 degree. \"magnification\" is a factor (1.0 for \"no change in scale\").\n\nThere are two other variants useful for transforming coordinate systems: CplxTrans takes integer-unit objects and converts them to floating-point unit objects. It can be used to convert from database units to micrometer units when configured with a magnification equal to the database unit value:\n\nT = CplxTrans(magnification: dbu)\nq = T * p\n\nThe other variant is VCplxTrans which converts floating-point unit objects to integer-unit ones. These objects are generated when inverting \"CplxTrans\" objects.", "source": "klayout"}
{"script_name": "Coordinate System Transformations", "definition_description": "This script converts between integer and floating-point coordinate systems using CplxTrans and VCplxTrans objects.", "parameters": {"magnification": "The magnification factor, typically used to convert between database units and micrometer units."}, "values": "magnification: <float>", "script_paradigm": "CplxTrans(magnification: dbu) or VCplxTrans(magnification: dbu) for converting coordinate systems.", "examples": [{"query": "How to convert a coordinate from database units to micrometer units?", "answer": "T = CplxTrans(magnification: dbu)"}, {"query": "How to convert a coordinate from micrometer units to database units?", "answer": "T = VCplxTrans(magnification: dbu)"}], "reference": "m45 == m0 followed by r90\n\nWhen coding transformations, two parameters are used to represent the rotation/mirror part: a rotation angle and a flag indicating mirroring at the x axis. The mirroring is applied before the rotation. In terms of these parameters, the basic transformations are:\n\nRotation angle (degree) Mirror flag = False Mirror flag = True 0 r0 m0 90 r90 m45 180 r180 m90 270 r270 m135\n\nTransformation objects\n\nTransformation objects are convenient objects to operate with. They represent a transformation (technically a matrix) consisting of an angle/mirror and a displacement part. They support some basic operations:\n\nConcatenation: T = T1 * T2 T is transformation T2 applied, then T1 (note this order)\n\nInversion: TI = T.inverted() TI is the inverse of T, i.e. TI * T = T * TI = 1 where 1 is the neutral transformation which does not modify coordinates\n\nApplication to geometrical objects: q = T * p where p is a box, polygon, path, text, point, vector etc. and q is the transformed object\n\nVectors and Points\n\nIn KLayout there are two two-dimensional coordinate objects: the vector and the point. Basically, the vector is the difference between two points:\n\nv = p2 - p1\n\nHere v is a vector object while p1 and p2 are points.\n\nRegarding transformations, vectors and points behave differently. While for a point, the displacement is applied, it is not for vectors. So\n\np' = T * p = M * p + d\nv' = T * v = M * v\n\nHere M is the 2x2 rotation/mirror matrix part of the transformation and d is the displacement vector\n\nThe reason why the displacement is not applied to a vector is seen here:\n\n v' = T * v \n    = T * (p2 - p1) \n    = T * p2 - T * p1\n    = (M * p2 + d) - (M * p1 + d)\n    = M * p2 + d - M * p1 - d\n    = M * p2 - M * p1 \n    = M * (p2 - p1)\n\nwhere the latter simply is:\n\nv' = M * v\n\nSimple transformations\n\nSimple transformations are represented by DTrans or Trans objects. The first operates with floating-point displacements in units of micrometers while the second one with integer displacements in database units. \"DTrans\" objects act on \"D\" type floating-point coordinate shapes (e.g. DBox) while \"Trans\" objects act on the integer coordinate shapes (e.g. Box).\n\nThe basic construction parameters of \"DTrans\" and \"Trans\" are:\n\nTrans(angle, mirror, displacement)\nDTrans(angle, mirror, displacement)\n\n\"displacement\" is a DVector (for DTrans) or a Vector (for Trans).\n\n\"angle\" is the rotation angle in units of 90 degree and \"mirror\" is the mirror flag:\n\nangle mirror = False mirror = True 0 r0 m0 1 r90 m45 2 r180 m90 3 r270 m135\n\nComplex transformations\n\nComplex transformations in addition to the simple transformations feature scaling (magnification) and arbitrary rotation angles. Other than simple transformations they do not necessarily preserve a grid and rounding is implied. Furthermore they imply a shift is physical scale which renders them difficult to use in physical frameworks (e.g. DRC). Hence their use is discouraged for certain applications.\n\nThe basic classes are DCplxTrans for the micrometer-unit (floating-point) version and ICplxTrans for the database-unit (integer) version. The construction parameters are:\n\nICplxTrans(angle, mirror, magnification, displacement)\nDCplxTrans(angle, mirror, magnification, displacement)\n\nHere, \"angle\" is the rotation angle in degree (note the difference to \"Trans\" and \"DTrans\" where the rotation angle is in units for 90 degree. \"magnification\" is a factor (1.0 for \"no change in scale\").\n\nThere are two other variants useful for transforming coordinate systems: CplxTrans takes integer-unit objects and converts them to floating-point unit objects. It can be used to convert from database units to micrometer units when configured with a magnification equal to the database unit value:\n\nT = CplxTrans(magnification: dbu)\nq = T * p\n\nThe other variant is VCplxTrans which converts floating-point unit objects to integer-unit ones. These objects are generated when inverting \"CplxTrans\" objects.", "source": "klayout"}
{"script_name": "RecursiveInstanceIterator", "definition_description": "This script is used to iterate through instances of cells within a layout, delivering instances recursively, either based on selection or specific constraints.", "parameters": {"layout": "The layout object which contains the cell instances.", "cell": "The cell object to start the iteration from.", "box": "An optional search region (bounding box) to confine the iteration within a specific area.", "overlapping": "A flag indicating if overlapping instances should be included (default is false).", "targets": "A list or glob pattern specifying the target cells to be included in the iteration."}, "values": "layout: <layout>, cell: <cell>, box: <box>, overlapping: <true/false>, targets: <target_cells>", "script_paradigm": "iter = RBA::RecursiveInstanceIterator::new(<layout>, <cell>)\niter.unselect_cells(<cell_index>)\niter.select_cells(<cell_name>)", "examples": [{"query": "How to deliver all instances inside 'MACRO' but not of child cells?", "answer": "iter = RBA::RecursiveInstanceIterator::new(layout, cell)\niter.unselect_all_cells\niter.select_cells('MACRO')"}, {"query": "How to deliver instances of 'INV1' only?", "answer": "iter = RBA::RecursiveInstanceIterator::new(layout, cell)\niter.targets = 'INV1'"}, {"query": "How to deliver instances inside a specific search region?", "answer": "iter = RBA::RecursiveInstanceIterator::new(layout, cell, box, true)"}, {"query": "How to use a glob pattern to select cells starting with 'A'?", "answer": "iter = RBA::RecursiveInstanceIterator::new(layout, cell)\niter.select_cells('A*')"}], "reference": "# deliver all instances inside \"MACRO\" and the sub-hierarchy:\niter = RBA::RecursiveInstanceIterator::new(layout, cell)\niter.unselect_cells(cell.cell_index)\niter.select_cells(\"MACRO\")\n...\n\nThe unselect_all_cells and select_all_cells methods turn on the \"stop\" and \"start\" flag for all cells respectively. If you use unselect_all_cells and use select_cells for a specific cell, the iterator will deliver only the instances of the selected cell, not its children. Those are still unselected by unselect_all_cells:\n\n# deliver all instance inside \"MACRO\" but not of child cells:\niter = RBA::RecursiveInstanceIterator::new(layout, cell)\niter.unselect_all_cells\niter.select_cells(\"MACRO\")\n...\n\nCell selection is done using cell indexes or glob pattern. Glob pattern are equivalent to the usual file name wildcards used on various command line shells. For example \"A*\" matches all cells starting with an \"A\". The curly brace notation and character classes are supported as well. For example \"C{125,512}\" matches \"C125\" and \"C512\" and \"[ABC]*\" matches all cells starting with an \"A\", a \"B\" or \"C\". \"[^ABC]*\" matches all cells not starting with one of that letters.\n\nTo confine instance iteration to instances of certain cells, use the targets feature:\n\n# deliver all instance of \"INV1\":\niter = RBA::RecursiveInstanceIterator::new(layout, cell)\niter.targets = \"INV1\"\n...\n\nTargets can be specified either as lists of cell indexes or through a glob pattern.\n\nInstances are always delivered depth-first with child instances before their parents. A default recursive instance iterator will first deliver leaf cells, followed by the parent of these cells.\n\nWhen a search region is used, instances whose bounding box touch or overlap (depending on 'overlapping' flag) will be reported. The instance bounding box taken as reference is computed using all layers of the layout.\n\nThe iterator will deliver the individual elements of instance arrays, confined to the search region if one is given. Consequently the return value (current_inst_element) is an InstElement object which is basically a combination of an Instance object and information about the current array element. inst_cell, inst_trans and inst_dtrans are methods provided for convenience to access the current array member's transformation and the target cell of the current instance.\n\nThe RecursiveInstanceIterator class has been introduced in version 0.27.\n\nPublic constructors\n\nnew RecursiveInstanceIterator ptr new (const Layout layout, const Cell cell) Creates a recursive instance iterator. new RecursiveInstanceIterator ptr new (const Layout layout, const Cell cell, const Box box, bool overlapping = false) Creates a recursive instance iterator with a search region. new RecursiveInstanceIterator ptr new (const Layout layout, const Cell cell, const Region region, bool overlapping) Creates a recursive instance iterator with a search region.\n\nPublic methods", "source": "klayout"}
{"script_name": "write_functional_rosette", "definition_description": "This script generates Rosette-compatible Racket code from the Functional IR.", "parameters": {"selection": "The specific selection of the design to be converted.", "filename": "The name of the file to write the Rosette code to.", "provides": "Optional flag to include 'provide' statement(s) for loading output as a module."}, "values": "selection: <design_selection>, filename: <file_path>, options: -provides", "script_paradigm": "write_functional_rosette [options] <selection> <filename>", "examples": [{"query": "How to generate Rosette code for the design and save it to design.rkt?", "answer": "write_functional_rosette design design.rkt"}, {"query": "How to generate Rosette code with provide statements for the design?", "answer": "write_functional_rosette -provides design design.rkt"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n10.263 write_file - write a text to a file\nyosys> help write_file\nwrite_file [options] output_file [input_file]\nWrite the text from the input file to the output file.\n-a\nAppend to output file (instead of overwriting)\nInside a script the input file can also can a here-document:\nwrite_file hello.txt <<EOT\nHello World!\nEOT\n10.264 write_firrtl - write design to a FIRRTL file\nyosys> help write_firrtl\nwrite_firrtl [options] [filename]\nWrite a FIRRTL netlist of the current design.\nThe following commands are executed by this command:\npmuxtree\nbmuxmap\ndemuxmap\nbwmuxmap\n10.265 write_functional_cxx - convert design to C++ using the func-\ntional backend\nyosys> help write_functional_cxx\nTODO: add help message\n10.266 write_functional_rosette - Generate Rosette compatible Racket\nfrom Functional IR\nyosys> help write_functional_rosette\nwrite_functional_rosette [options] [selection] [filename]\nFunctional Rosette Backend.\n-provides\ninclude 'provide' statement(s) for loading output as a module\n562\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "verilator_gantt", "definition_description": "This script is used to generate a Gantt chart of thread and mtask execution based on Verilator profiling data.", "parameters": {"filename": "The filename to read data from, typically 'profile_exec.dat'. This is optional with a default value.", "help": "Displays a help summary, the program version, and exits.", "no-vcd": "Disables the creation of a .vcd file.", "vcd": "Sets the output filename for the VCD dump, with a default value of 'verilator_gantt.vcd'."}, "values": "filename: <profile_exec.dat>, help: <help>, no-vcd: <true/false>, vcd: <verilator_gantt.vcd>", "script_paradigm": "verilator_gantt <filename> --vcd <filename> --no-vcd --help", "examples": [{"query": "How to generate a Gantt chart without VCD output?", "answer": "verilator_gantt profile_exec.dat --no-vcd"}, {"query": "How to generate a Gantt chart with VCD output in a custom file?", "answer": "verilator_gantt profile_exec.dat --vcd custom_output.vcd"}], "reference": "Verilator, Release Devel 5.031\npredicted_parallelism The number of mtasks Verilator predicted would be active at this time, for best performance\nthis will match the thread count. In GTKWave, use a data format of “analog step” to view this signal.\ncpu#_thread For the given CPU number, the thread number measured to be executing.\nmtask#_cpu For the given mtask id, the CPU it was measured to execute on.\nthread#_mtask For the given thread number, the mtask id it was executing.\npredicted_thread#_mtask For the given thread number, the mtask id Verilator predicted would be executing.\n12.4.3 verilator_gantt Arguments\n<filename>\nThe ﬁlename to read data from; the default is “proﬁle_exec.dat”.\n--help\nDisplays a help summary, the program version, and exits.\n--no-vcd\nDisables creating a .vcd ﬁle.\n--vcd <filename>\nSets the output ﬁlename for vcd dump; the default is “verilator_gantt.vcd”.\n12.5 verilator_profcfunc\nVerilator_profcfunc reads a proﬁle report created by gprof. The names of the functions are then transformed, assuming\nthe user used Verilator’s –prof-cfuncs, and a report printed showing the percentage of the time, etc., in each Verilog\nblock.\nDue to rounding errors in gprof reports, the input report’s percentages may not total 100%. In the verilator_profcfunc\nreport this will get reported as a rounding error.\nFor an overview of the use of verilator_profcfunc, see Code Proﬁling.\n12.5.1 verilator_profcfunc Arguments\n<filename>\nThe gprof-generated ﬁlename to read data from. Typically “gprof.out”.\n--help\nDisplays a help summary, the program version, and exits.\n12.5. verilator_profcfunc\n100", "source": "verilator"}
{"script_name": "SelectCommand", "definition_description": "This script allows you to select cells based on their type or other attributes within the design.", "parameters": {"selection_name": "The name assigned to the selection", "selection_pattern": "The pattern used to match the cells (e.g., type or module)"}, "values": "selection_name: <new_cells>, selection_pattern: <t:*, addr_gen/t:*>", "script_paradigm": "select -set <selection_name> <selection_pattern>", "examples": [{"query": "How to select all cells in the addr_gen module?", "answer": "select -set new_cells addr_gen/t:*"}, {"query": "How to select a specific set of cells (e.g., mux and dff)?", "answer": "select -set new_cells t:$mux t:* dff"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nNext we perform another selection, select t:* . The t: part signifies we are matching on the cell type,\nand the * means to match anything. For this (very simple) selection, we are trying to find all of the cells,\nregardless of their type. The active selection is now shown as [addr_gen]*, indicating some sub-selection of\nthe addr_gen module. This gives us the $add and $eq cells, which we want to highlight for the addr_gen\nmodule after hierarchy image.\nWe can assign a name to a selection with select -set. In our case we are using the name new_cells,\nand telling it to use the current selection, indicated by the % symbol. We can then use this named selection\nby referring to it as @new_cells, which we will see later. Then we clear the selection so that the following\ncommands can operate on the full design. While we split that out for this document, we could have done\nthe same thing in a single line by calling select -set new_cells addr_gen/t:* . If we know we only\nhave the one module in our design, we can even skip the addr_gen/ part. Looking further down the fifo.ys\ncode we can see this with select -set new_cells t:$mux t:* dff. We can also see in that command that\nselections don’t have to be limited to a single statement.\nMany commands also support an optional [selection] argument which can be used to override the currently\nselected objects. We could, for example, call clean addr_gen to have clean operate on just the addr_gen\nmodule.\nDetailed documentation of the select framework can be found under Selections or in the command reference\nat select - modify and view the list of selected objects.\nDisplaying schematics\nWhile the select command is very useful, sometimes nothing beats being able to see a design for yourself.\nThis is where show comes in. Note that this document is just an introduction to the show command, only\ncovering the basics. For more information, including a guide on what the different symbols represent, see A\nlook at the show command and the Interactive design investigation page.\nò Note\nThe show command requires a working installation of GraphViz and xdot for displaying the actual circuit\ndiagrams.\nThis is the first show command we called in fifo.ys, as we saw above. If we look at the log output for this\nimage we see the following:\nyosys> show -format dot -prefix addr_gen_show addr_gen\n4. Generating Graphviz representation of design.\nWriting dot description to `addr_gen_show.dot'.\nDumping module addr_gen to page 1.\nCalling show with -format dot tells it we want to output a .dot file rather than opening it for display. The\n-prefix addr_gen_show option indicates we want the file to be called addr_gen_show.* . Remember, we\ndo this in fifo.ys because we need to store the image for displaying in the documentation you’re reading.\nBut if you just want to display the images locally you can skip these two options. The -format option\ninternally calls the dot command line program from GraphViz to convert to formats other than .dot. Check\nGraphViz output docs for more on available formats.\nò Note\nIf you are using a POSIX based version of Yosys (such as for Mac or Linux), xdot will be opened in the\nbackground and Yosys can continue to be used. If it it still open, future calls to show will use the same\n2.3.\nScripting in Yosys\n39", "source": "yosys_hq"}
{"script_name": "ShowCommand", "definition_description": "This script generates a graphical representation of the design using Graphviz and outputs it in a specific format.", "parameters": {"format": "The format in which the diagram is generated (e.g., dot, png)", "prefix": "The prefix for the output files", "module_name": "The name of the module to visualize"}, "values": "format: <dot>, prefix: <addr_gen_show>, module_name: <addr_gen>", "script_paradigm": "show -format <format> -prefix <prefix> <module_name>", "examples": [{"query": "How to generate a Graphviz representation of the addr_gen module?", "answer": "show -format dot -prefix addr_gen_show addr_gen"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nNext we perform another selection, select t:* . The t: part signifies we are matching on the cell type,\nand the * means to match anything. For this (very simple) selection, we are trying to find all of the cells,\nregardless of their type. The active selection is now shown as [addr_gen]*, indicating some sub-selection of\nthe addr_gen module. This gives us the $add and $eq cells, which we want to highlight for the addr_gen\nmodule after hierarchy image.\nWe can assign a name to a selection with select -set. In our case we are using the name new_cells,\nand telling it to use the current selection, indicated by the % symbol. We can then use this named selection\nby referring to it as @new_cells, which we will see later. Then we clear the selection so that the following\ncommands can operate on the full design. While we split that out for this document, we could have done\nthe same thing in a single line by calling select -set new_cells addr_gen/t:* . If we know we only\nhave the one module in our design, we can even skip the addr_gen/ part. Looking further down the fifo.ys\ncode we can see this with select -set new_cells t:$mux t:* dff. We can also see in that command that\nselections don’t have to be limited to a single statement.\nMany commands also support an optional [selection] argument which can be used to override the currently\nselected objects. We could, for example, call clean addr_gen to have clean operate on just the addr_gen\nmodule.\nDetailed documentation of the select framework can be found under Selections or in the command reference\nat select - modify and view the list of selected objects.\nDisplaying schematics\nWhile the select command is very useful, sometimes nothing beats being able to see a design for yourself.\nThis is where show comes in. Note that this document is just an introduction to the show command, only\ncovering the basics. For more information, including a guide on what the different symbols represent, see A\nlook at the show command and the Interactive design investigation page.\nò Note\nThe show command requires a working installation of GraphViz and xdot for displaying the actual circuit\ndiagrams.\nThis is the first show command we called in fifo.ys, as we saw above. If we look at the log output for this\nimage we see the following:\nyosys> show -format dot -prefix addr_gen_show addr_gen\n4. Generating Graphviz representation of design.\nWriting dot description to `addr_gen_show.dot'.\nDumping module addr_gen to page 1.\nCalling show with -format dot tells it we want to output a .dot file rather than opening it for display. The\n-prefix addr_gen_show option indicates we want the file to be called addr_gen_show.* . Remember, we\ndo this in fifo.ys because we need to store the image for displaying in the documentation you’re reading.\nBut if you just want to display the images locally you can skip these two options. The -format option\ninternally calls the dot command line program from GraphViz to convert to formats other than .dot. Check\nGraphViz output docs for more on available formats.\nò Note\nIf you are using a POSIX based version of Yosys (such as for Mac or Linux), xdot will be opened in the\nbackground and Yosys can continue to be used. If it it still open, future calls to show will use the same\n2.3.\nScripting in Yosys\n39", "source": "yosys_hq"}
{"script_name": "detailed_placement", "definition_description": "This script performs detailed placement of instances to legal locations after global placement.", "parameters": {"max_displacement": "The maximum distance that an instance can be moved during placement (in microns). It can either be a single value for both x and y directions, or two separate values for individual x and y displacements.", "disallow_one_site_gaps": "A flag to disable one-site gap checks during placement.", "report_file_name": "The name of the file where the placement report will be saved (e.g., report.json)."}, "values": "max_displacement: <disp> or <disp_x disp_y>, disallow_one_site_gaps: <true/false>, report_file_name: <filename>", "script_paradigm": "detailed_placement -max_displacement <max_displacement> -disallow_one_site_gaps <disallow_one_site_gaps> -report_file_name <report_file_name>", "examples": [{"query": "How to perform detailed placement with a maximum displacement of 10 microns for both directions?", "answer": "detailed_placement -max_displacement 10"}, {"query": "How to set a different displacement for x and y directions, say 5 microns in x and 8 microns in y?", "answer": "detailed_placement -max_displacement 5 8"}, {"query": "How to disable one-site gap check and save the report to report.json?", "answer": "detailed_placement -disallow_one_site_gaps -report_file_name report.json"}], "reference": "title: detailed_placement(2)\ndate: 24/09/08\n\nNAME\ndetailed_placement - detailed placement\nSYNOPSIS\ndetailed_placement\n    [-max_displacement disp|{disp_x disp_y}]\n    [-disallow_one_site_gaps]\n    [-report_file_name filename]\nDESCRIPTION\nThe detailed_placement command performs detailed placement of instances\nto legal locations after global placement.\nOPTIONS\n-max_displacement:  Max distance that an instance can be moved (in microns) when finding a site where it can be placed. Either set one value for both directions or set {disp_x disp_y} for individual directions. The default values are {0, 0}, and the allowed values within are integers [0, MAX_INT].\n-disallow_one_site_gaps:  Disable one site gap during placement check.\n-report_file_name:  File name for saving the report to (e.g. report.json.)\nARGUMENTS\nThis command has no arguments.\nEXAMPLES\nSEE ALSO", "source": "OpenROAD"}
{"script_name": "fminit", "definition_description": "This script sets initialization values and sequences for formal analysis.", "parameters": {"selection": "The selection criteria for which the initialization is applied.", "seq": "Comma-separated list of values to set the sequence, where 'z represents unconstrained bits.", "set": "Constant value constraint for a signal.", "posedge": "Defines a positive edge clock for the initialization sequence.", "negedge": "Defines a negative edge clock for the initialization sequence."}, "values": "selection: <selection>, seq: <signal>, set: <value>, posedge: <signal>, negedge: <signal>", "script_paradigm": "fminit [options] <selection>", "examples": [{"query": "How to set the init sequence for signal reset?", "answer": "fminit -seq reset, 0, 1, z"}, {"query": "How to add a constant value constraint for signal signal1?", "answer": "fminit -set signal1 0"}, {"query": "How to set a positive edge clock for init sequences?", "answer": "fminit -posedge clk"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n-initeq\nInsert assumptions that initially all FFs in both circuits have the\nsame initial values.\n-anyeq\nDo not duplicate $anyseq/$anyconst cells.\n-fwd\nInsert forward hint assumptions into the combined module.\n-bwd\nInsert backward hint assumptions into the combined module.\n(Backward hints are logically equivalend to fordward hits, but\nsome solvers are faster with bwd hints, or even both -bwd and -fwd.)\n-nop\nDon't insert hint assumptions into the combined module.\n(This should not provide any speedup over the original design, but\nstrangely sometimes it does.)\nIf none of -fwd, -bwd, and -nop is given, then -fwd is used as default.\n10.80 fminit - set init values/sequences for formal\nyosys> help fminit\nfminit [options] <selection>\nThis pass creates init constraints (for example for reset sequences) in a formal\nmodel.\n-seq <signal> <sequence>\nSet sequence using comma-separated list of values, use 'z for\nunconstrained bits. The last value is used for the remainder of the\ntrace.\n-set <signal> <value>\nAdd constant value constraint\n-posedge <signal>\n-negedge <signal>\nSet clock for init sequences\n10.81 formalff - prepare FFs for formal\nyosys> help formalff\n406\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "splitcells", "definition_description": "This script splits multi-bit cells into smaller chunks, based on the usage of the cell output bits.", "parameters": {"options": "Various options to modify the behavior of the split operation", "selection": "The selection of cells to be split, based on their bit usage"}, "values": "options: -format, selection: <cell_selection>", "script_paradigm": "splitcells [options] [selection]", "examples": [{"query": "How to split multi-bit cells with custom format?", "answer": "splitcells -format () mycell"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n10.210 splitcells - split up multi-bit cells\nyosys> help splitcells\nsplitcells [options] [selection]\nThis command splits multi-bit cells into smaller chunks, based on usage of the\ncell output bits.\nThis command operates only in cells such as $or, $and, and $mux, that are easily\ncut into bit-slices.\n-format char1[char2[char3]]\nthe first char is inserted between the cell name and the bit index, the\nsecond char is appended to the cell name. e.g. -format () creates cell\nnames like 'mycell(42)'. the 3rd character is the range separation\ncharacter when creating multi-bit cells. the default is '[]:'.\n10.211 splitnets - split up multi-bit nets\nyosys> help splitnets\nsplitnets [options] [selection]\nThis command splits multi-bit nets into single-bit nets.\n-format char1[char2[char3]]\nthe first char is inserted between the net name and the bit index, the\nsecond char is appended to the netname. e.g. -format () creates net\nnames like 'mysignal(42)'. the 3rd character is the range separation\ncharacter when creating multi-bit wires. the default is '[]:'.\n-ports\nalso split module ports. per default only internal signals are split.\n-driver\ndon't blindly split nets in individual bits. instead look at the driver\nand split nets so that no driver drives only part of a net.\n10.212 sta - perform static timing analysis\nyosys> help sta\nsta [options] [selection]\nThis command performs static timing analysis on the design. (Only considers\npaths within a single module, so the design must be flattened.)\n10.210.\nsplitcells - split up multi-bit cells\n479", "source": "yosys_hq"}
{"script_name": "splitnets", "definition_description": "This script splits multi-bit nets into single-bit nets.", "parameters": {"options": "Various options to customize how the nets are split", "selection": "The nets to be split into single-bit nets"}, "values": "options: -format, -ports, -driver, selection: <net_selection>", "script_paradigm": "splitnets [options] [selection]", "examples": [{"query": "How to split nets with a custom format and split module ports?", "answer": "splitnets -format () -ports mysignal"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n10.210 splitcells - split up multi-bit cells\nyosys> help splitcells\nsplitcells [options] [selection]\nThis command splits multi-bit cells into smaller chunks, based on usage of the\ncell output bits.\nThis command operates only in cells such as $or, $and, and $mux, that are easily\ncut into bit-slices.\n-format char1[char2[char3]]\nthe first char is inserted between the cell name and the bit index, the\nsecond char is appended to the cell name. e.g. -format () creates cell\nnames like 'mycell(42)'. the 3rd character is the range separation\ncharacter when creating multi-bit cells. the default is '[]:'.\n10.211 splitnets - split up multi-bit nets\nyosys> help splitnets\nsplitnets [options] [selection]\nThis command splits multi-bit nets into single-bit nets.\n-format char1[char2[char3]]\nthe first char is inserted between the net name and the bit index, the\nsecond char is appended to the netname. e.g. -format () creates net\nnames like 'mysignal(42)'. the 3rd character is the range separation\ncharacter when creating multi-bit wires. the default is '[]:'.\n-ports\nalso split module ports. per default only internal signals are split.\n-driver\ndon't blindly split nets in individual bits. instead look at the driver\nand split nets so that no driver drives only part of a net.\n10.212 sta - perform static timing analysis\nyosys> help sta\nsta [options] [selection]\nThis command performs static timing analysis on the design. (Only considers\npaths within a single module, so the design must be flattened.)\n10.210.\nsplitcells - split up multi-bit cells\n479", "source": "yosys_hq"}
{"script_name": "sta", "definition_description": "This script performs static timing analysis on the design, considering paths within a single module.", "parameters": {"options": "Various options for configuring static timing analysis", "selection": "The selection of the design to analyze"}, "values": "options: [options], selection: <design_selection>", "script_paradigm": "sta [options] [selection]", "examples": [{"query": "How to perform static timing analysis on the design?", "answer": "sta my_design"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n10.210 splitcells - split up multi-bit cells\nyosys> help splitcells\nsplitcells [options] [selection]\nThis command splits multi-bit cells into smaller chunks, based on usage of the\ncell output bits.\nThis command operates only in cells such as $or, $and, and $mux, that are easily\ncut into bit-slices.\n-format char1[char2[char3]]\nthe first char is inserted between the cell name and the bit index, the\nsecond char is appended to the cell name. e.g. -format () creates cell\nnames like 'mycell(42)'. the 3rd character is the range separation\ncharacter when creating multi-bit cells. the default is '[]:'.\n10.211 splitnets - split up multi-bit nets\nyosys> help splitnets\nsplitnets [options] [selection]\nThis command splits multi-bit nets into single-bit nets.\n-format char1[char2[char3]]\nthe first char is inserted between the net name and the bit index, the\nsecond char is appended to the netname. e.g. -format () creates net\nnames like 'mysignal(42)'. the 3rd character is the range separation\ncharacter when creating multi-bit wires. the default is '[]:'.\n-ports\nalso split module ports. per default only internal signals are split.\n-driver\ndon't blindly split nets in individual bits. instead look at the driver\nand split nets so that no driver drives only part of a net.\n10.212 sta - perform static timing analysis\nyosys> help sta\nsta [options] [selection]\nThis command performs static timing analysis on the design. (Only considers\npaths within a single module, so the design must be flattened.)\n10.210.\nsplitcells - split up multi-bit cells\n479", "source": "yosys_hq"}
{"script_name": "$ge", "definition_description": "This script performs a greater-than-or-equal-to comparison between two inputs A and B. It behaves similarly to the Verilog '>= ' operator.", "parameters": {"A_SIGNED": "Defines whether input A is signed (0 for unsigned, 1 for signed)", "B_SIGNED": "Defines whether input B is signed (0 for unsigned, 1 for signed)", "A_WIDTH": "The width of input A", "B_WIDTH": "The width of input B", "Y_WIDTH": "The width of output Y"}, "values": "A_SIGNED: 0, B_SIGNED: 0, A_WIDTH: 0, B_WIDTH: 0, Y_WIDTH: 0", "script_paradigm": "module $ge (A, B, Y); \n parameter A_SIGNED = <A_SIGNED>; \n parameter B_SIGNED = <B_SIGNED>; \n parameter A_WIDTH = <A_WIDTH>; \n parameter B_WIDTH = <B_WIDTH>; \n parameter Y_WIDTH = <Y_WIDTH>; \n input [A_WIDTH-1:0] A; \n input [B_WIDTH-1:0] B; \n output [Y_WIDTH-1:0] Y; \n generate \n if (A_SIGNED && B_SIGNED) begin:BLOCK1 \n assign Y = $signed(A) >= $signed(B); \n end else begin:BLOCK2 \n assign Y = A >= B; \n end \n endgenerate \nendmodule", "examples": [{"query": "How to perform a comparison of two unsigned inputs A and B?", "answer": "module $ge (A, B, Y); \n parameter A_SIGNED = 0; \n parameter B_SIGNED = 0; \n parameter A_WIDTH = 8; \n parameter B_WIDTH = 8; \n parameter Y_WIDTH = 1; \n input [A_WIDTH-1:0] A; \n input [B_WIDTH-1:0] B; \n output [Y_WIDTH-1:0] Y; \n generate \n if (A_SIGNED && B_SIGNED) begin:BLOCK1 \n assign Y = $signed(A) >= $signed(B); \n end else begin:BLOCK2 \n assign Y = A >= B; \n end \n endgenerate \nendmodule"}, {"query": "How to compare signed inputs A and B?", "answer": "module $ge (A, B, Y); \n parameter A_SIGNED = 1; \n parameter B_SIGNED = 1; \n parameter A_WIDTH = 8; \n parameter B_WIDTH = 8; \n parameter Y_WIDTH = 1; \n input [A_WIDTH-1:0] A; \n input [B_WIDTH-1:0] B; \n output [Y_WIDTH-1:0] Y; \n generate \n if (A_SIGNED && B_SIGNED) begin:BLOCK1 \n assign Y = $signed(A) >= $signed(B); \n end else begin:BLOCK2 \n assign Y = A >= B; \n end \n endgenerate \nendmodule"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n849\nparameter A_SIGNED = 0;\n850\nparameter B_SIGNED = 0;\n851\nparameter A_WIDTH = 0;\n852\nparameter B_WIDTH = 0;\n853\nparameter Y_WIDTH = 0;\n854\n855\ninput [A_WIDTH-1:0] A;\n856\ninput [B_WIDTH-1:0] B;\n857\noutput [Y_WIDTH-1:0] Y;\n858\n859\ngenerate\n860\nif (A_SIGNED && B_SIGNED) begin:BLOCK1\n861\nassign Y = $signed(A) === $signed(B);\n862\nend else begin:BLOCK2\n863\nassign Y = A === B;\n864\nend\n865\nendgenerate\n866\n867\nendmodule\nyosys> help $ge\nA greater-than-or-equal-to comparison between inputs ‘A’ and ‘B’. This corresponds to the Verilog\n‘>=’ operator.\nProperties\nis_evaluable\nSimulation model (verilog)\nListing 9.18: simlib.v\n910\nmodule \\$ge (A, B, Y);\n911\n912\nparameter A_SIGNED = 0;\n913\nparameter B_SIGNED = 0;\n914\nparameter A_WIDTH = 0;\n915\nparameter B_WIDTH = 0;\n916\nparameter Y_WIDTH = 0;\n917\n918\ninput [A_WIDTH-1:0] A;\n919\ninput [B_WIDTH-1:0] B;\n920\noutput [Y_WIDTH-1:0] Y;\n921\n922\ngenerate\n923\nif (A_SIGNED && B_SIGNED) begin:BLOCK1\n924\nassign Y = $signed(A) >= $signed(B);\n925\nend else begin:BLOCK2\n926\nassign Y = A >= B;\n927\nend\n928\nendgenerate\n929\n930\nendmodule\nyosys> help $gt\n9.1.\nWord-level cells\n213", "source": "yosys_hq"}
{"script_name": "DeviceExtractorBJT4Transistor", "definition_description": "This script is used to extract a four-terminal bipolar junction transistor (BJT) device, including a substrate terminal and corresponding output layer.", "parameters": {"name": "The name of the device extractor", "factory": "An optional parameter representing the device class factory, default is none"}, "values": "name: <name>, factory: <none>", "script_paradigm": "new DeviceExtractorBJT4Transistor <name>, <factory>", "examples": [{"query": "How to create a DeviceExtractorBJT4Transistor with name 'bjt4_device'?", "answer": "new DeviceExtractorBJT4Transistor bjt4_device"}, {"query": "Create a DeviceExtractorBJT4Transistor with a specific factory", "answer": "new DeviceExtractorBJT4Transistor bjt4_device, <factory>"}], "reference": "KLayout Documentation (Qt 5): Main Index » Class Index » API reference - Class DeviceExtractorBJT4Transistor\n\nAPI reference - Class DeviceExtractorBJT4Transistor\n\nNotation used in Ruby API documentation\n\nModule: db\n\nDescription: A device extractor for a four-terminal bipolar transistor (BJT)\n\nClass hierarchy: DeviceExtractorBJT4Transistor » DeviceExtractorBJT3Transistor » DeviceExtractorBase\n\nPublic constructors\n\nPublic methods\n\nDetailed description\n\nThis class supplies the generic extractor for a bipolar transistor device. It is based on the DeviceExtractorBJT3Transistor class with the extension of a substrate terminal and corresponding substrate terminal output (annotation) layer.\n\nTwo new layers are introduced:\n\n'S' - the bulk (substrate) layer. Currently this layer is ignored and can be empty.\n\n'tS' - the bulk terminal output layer (defaults to 'S').\n\nThe bulk terminal layer ('tS') can be an empty layer representing the wafer substrate. In this use mode the substrate terminal shapes will be produced on the 'tS' layer. This layer then needs to be connected to a global net to establish the net connection.\n\nThe device class produced by this extractor is DeviceClassBJT4Transistor. The This class is a closed one and methods cannot be reimplemented. To reimplement specific methods, see DeviceExtractor.\n\nThis class has been introduced in version 0.26.\n\nPublic constructors\n\nnew DeviceExtractorBJT4Transistor ptr new (string name, DeviceClassFactory ptr factory = none) Creates a new device extractor with the given name\n\nPublic methods\n\n[const] DeviceExtractorBJT4Transistor ptr _const_cast Returns a non-const reference to self. void _create Ensures the C++ object is created void _destroy Explicitly destroys the object [const] bool _destroyed? Returns a value indicating whether the object was already destroyed [const] bool _is_const_object? Returns a value indicating whether the reference is a const reference void _manage Marks the object as managed by the script side. void _unmanage Marks the object as no longer owned by the script side.\n\nDetailed description", "source": "klayout"}
{"script_name": "SetCellPath", "definition_description": "This script sets the unspecific and specific paths to define the location and context of a cell in the layout.", "parameters": {"unspecific_path": "The path specifying the hierarchy of cells from the top cell down to the context cell, which is used to select the appropriate cell in the cell tree.", "specific_path": "The path specifying a specific instance of a child cell within the context cell, used when embedding layout requires a specific cell instance."}, "values": "unspecific_path: <path>, specific_path: <context_path>", "script_paradigm": "cell_view.path = <unspecific_path>; cell_view.context_path = <specific_path>", "examples": [{"query": "How to set the unspecific path to address a cell in the layout tree?", "answer": "cell_view.path = <path>"}, {"query": "How to set the specific path to a child cell instance in the context layout?", "answer": "cell_view.context_path = <context_path>"}], "reference": "The first part is always the unspecific path. This path specifies, where the cell drawn is located in the cell tree. That has no effect on the drawing, but is determines what entry in the cell tree is selected. Giving a path for that information is required, because a cell can be child of different cells which itself can be children of other cells. The unspecific path lists the top cell and further cells which are all direct or indirect parents of the cell addressed.\n\nThe unspecific path ends at the \"context cell\" which usually is identical to the cell addressed by the cell view. KLayout allows addressing of a specific instance of a direct or indirect child cell as the actual cell. In that case, the specific path comes into play. Bascially that means, that a cell is drawn within a context of embedding layout. The specific path leads from the context cell to the cell view's target cell and consists of specific instances (hence the name \"specific path\"). The \"descend\" and \"ascend\" feature bascially adds or removes instances from that path.\n\nThe unspecific path can be obtained with the CellView#path method, the specific path with the CellView#context_path method. The unspecific path is just an array of cell indexes specifying the top cell and further cells down to the context cell and includes the context cell. The specific path is an array of InstElement objects (InstElement). Each InstElement object describes a specific instantiation (a cell instance plus information when a specific array instance is addressed). When there is no context, the specific path is an empty array. Using the setters CellView#path= and CellView#context_path= these paths can be changed to select a new cell into the layout view.\n\nThe Image class\n\nImages can be placed onto the drawing canvas and display colored or monochrome images below the layout. Images are represented by Image objects (Image). Basically an image is a two-dimensional array of pixel values with a specification how these pixels are to be displayed on the canvas. An image can be created an placed on the canvas like this:\n\nlv = RBA::Application::instance.main_window.current_view\nimage = RBA::Image::new(\"image.png\")\nlv.insert_image(image)\n\nAn image can be configured by using different properties and attributes:\n\nThe images' data can be loaded from a file by using a constructor with a file name. In addition, the image can use data from an array of floating-point values using either a constructor or the Image#set_data method. An image can be colored, in which case three channels are present or it can be monochrome. In the latter case, a single channel is present only. Together with the data, the dimensions of the image have to be specified (width and height in pixel units).\n\nThe image's data can be manipulated per pixel using the Image#get_pixel or Image#set_pixel method.\n\nThe data range for the data stored in the image can be set using the Image#min_value= and Image#max_value= attributes. The data range determines which value is considered \"maximum intensity\" (max_value) and \"zero intensity\" (min_value).\n\nFor monochrome images, a data mapping can be specified. A data mapping converts a monochrome value (a scalar) to a color. Data mapping is specified through a ImageDataMapping object (ImageDataMapping) using the Image#data_mapping method.\n\nThe geometrical properties of an image are encapsulated in a Matrix3d object (Matrix3d). Such a matrix describes the transformation from pixel coordinates to the micron unit space of the canvas. A 3x3 matrix is a generic way to specify a transformation, including translation, rotation, mirror, shear or perspective distortion. The matrix is obtained and set using the Image#matrix attribute. Convenience methods like Image#trans, Image#pixel_width and Image#pixel_height allow accessing sub-aspects of the generic transformation (affine transformation, scaling).", "source": "klayout"}
{"script_name": "InsertImage", "definition_description": "This script inserts an image into the layout view and allows configuration of the image's properties and attributes.", "parameters": {"image_file": "The file name of the image to be loaded.", "image_data": "An array of floating-point values representing the pixel data for the image.", "image_width": "The width of the image in pixel units.", "image_height": "The height of the image in pixel units.", "is_colored": "A boolean value indicating whether the image is colored (3 channels) or monochrome (1 channel)."}, "values": "image_file: <image.png>, image_data: <array>, image_width: <width>, image_height: <height>, is_colored: <true/false>", "script_paradigm": "lv = RBA::Application::instance.main_window.current_view; image = RBA::Image::new(<image_file>); lv.insert_image(image)", "examples": [{"query": "How to insert an image named 'image.png' into the layout view?", "answer": "lv = RBA::Application::instance.main_window.current_view; image = RBA::Image::new('image.png'); lv.insert_image(image)"}, {"query": "Insert a monochrome image with custom pixel data and dimensions (width: 100px, height: 200px).", "answer": "lv = RBA::Application::instance.main_window.current_view; image = RBA::Image::new(<image_data>, 100, 200); lv.insert_image(image)"}], "reference": "The first part is always the unspecific path. This path specifies, where the cell drawn is located in the cell tree. That has no effect on the drawing, but is determines what entry in the cell tree is selected. Giving a path for that information is required, because a cell can be child of different cells which itself can be children of other cells. The unspecific path lists the top cell and further cells which are all direct or indirect parents of the cell addressed.\n\nThe unspecific path ends at the \"context cell\" which usually is identical to the cell addressed by the cell view. KLayout allows addressing of a specific instance of a direct or indirect child cell as the actual cell. In that case, the specific path comes into play. Bascially that means, that a cell is drawn within a context of embedding layout. The specific path leads from the context cell to the cell view's target cell and consists of specific instances (hence the name \"specific path\"). The \"descend\" and \"ascend\" feature bascially adds or removes instances from that path.\n\nThe unspecific path can be obtained with the CellView#path method, the specific path with the CellView#context_path method. The unspecific path is just an array of cell indexes specifying the top cell and further cells down to the context cell and includes the context cell. The specific path is an array of InstElement objects (InstElement). Each InstElement object describes a specific instantiation (a cell instance plus information when a specific array instance is addressed). When there is no context, the specific path is an empty array. Using the setters CellView#path= and CellView#context_path= these paths can be changed to select a new cell into the layout view.\n\nThe Image class\n\nImages can be placed onto the drawing canvas and display colored or monochrome images below the layout. Images are represented by Image objects (Image). Basically an image is a two-dimensional array of pixel values with a specification how these pixels are to be displayed on the canvas. An image can be created an placed on the canvas like this:\n\nlv = RBA::Application::instance.main_window.current_view\nimage = RBA::Image::new(\"image.png\")\nlv.insert_image(image)\n\nAn image can be configured by using different properties and attributes:\n\nThe images' data can be loaded from a file by using a constructor with a file name. In addition, the image can use data from an array of floating-point values using either a constructor or the Image#set_data method. An image can be colored, in which case three channels are present or it can be monochrome. In the latter case, a single channel is present only. Together with the data, the dimensions of the image have to be specified (width and height in pixel units).\n\nThe image's data can be manipulated per pixel using the Image#get_pixel or Image#set_pixel method.\n\nThe data range for the data stored in the image can be set using the Image#min_value= and Image#max_value= attributes. The data range determines which value is considered \"maximum intensity\" (max_value) and \"zero intensity\" (min_value).\n\nFor monochrome images, a data mapping can be specified. A data mapping converts a monochrome value (a scalar) to a color. Data mapping is specified through a ImageDataMapping object (ImageDataMapping) using the Image#data_mapping method.\n\nThe geometrical properties of an image are encapsulated in a Matrix3d object (Matrix3d). Such a matrix describes the transformation from pixel coordinates to the micron unit space of the canvas. A 3x3 matrix is a generic way to specify a transformation, including translation, rotation, mirror, shear or perspective distortion. The matrix is obtained and set using the Image#matrix attribute. Convenience methods like Image#trans, Image#pixel_width and Image#pixel_height allow accessing sub-aspects of the generic transformation (affine transformation, scaling).", "source": "klayout"}
{"script_name": "split_var", "definition_description": "This script breaks a variable into multiple pieces to resolve UNOPTFLAT performance issues, as recommended by Verilator.", "parameters": {"module_name": "The module name to which the variable belongs.", "task_name": "The task name where the variable is used.", "func_name": "The function name where the variable is used.", "var_name": "The name of the variable to be split."}, "values": "module_name: <modulename>, task_name: <taskname>, func_name: <funcname>, var_name: <varname>", "script_paradigm": "split_var [-module <module_name>] [-task <task_name>] [-function <func_name>] -var <var_name>", "examples": [{"query": "How to split the variable data in the module data_module?", "answer": "split_var -module data_module -var data"}, {"query": "How to split the variable signal in the function process_signal?", "answer": "split_var -function process_signal -var signal"}], "reference": "Verilator, Release Devel 5.031\nor task should pass all remaining arguments through $sformatf. This allows the creation of DPI functions with\n$display-like behavior. See the test_regress/t/t_dpi_display.v ﬁle for an example.\nSame as /*verilator&32;sformat*/ metacomment.\nsplit_var [-module \"<modulename>\"] [-task \"<taskname>\"] -var \"<varname>\"\nsplit_var [-module \"<modulename>\"] [-function \"<funcname>\"] -var \"<varname>\"\nBreak the variable into multiple pieces typically to resolve UNOPTFLAT performance issues. Typically the\nvariables to attach this to are recommended by Verilator itself; see UNOPTFLAT.\nSame as /*verilator&32;split_var*/ metacomment.\ntiming_on\n[-file \"<filename>\" [-lines <line> [ - <line>]]]\ntiming_off [-file \"<filename>\" [-lines <line> [ - <line>]]]\nEnables/disables timing constructs for the speciﬁed ﬁle and lines. When disabled, all timing control constructs in\nthe speciﬁed source code locations are ignored the same way as with the --no-timing, and code:fork/join*\nblocks are converted into begin/end blocks.\nSame as /*verilator&32;timing_on*/, /*verilator&32;timing_off*/ metacomments.\ntracing_on\n[-file \"<filename>\" [-lines <line> [ - <line> ]]]\ntracing_off [-file \"<filename>\" [-lines <line> [ - <line> ]]]\ntracing_on\n[-scope \"<scopename>\" [-levels <levels> ]]\ntracing_off [-scope \"<scopename>\" [-levels <levels> ]]\nEnable/disable waveform tracing for all future signals declared in all ﬁles.\nWith -ﬁle, enable/disable waveform tracing in the speciﬁed ﬁlename (or wildcard with ‘*’ or ‘?’), and -line\nrange of line numbers (or all lines if omitted).\nFor tracing_off with -ﬁle, instances below any module in the ﬁles/ranges speciﬁed will also not be traced. To\novercome this feature, use tracing_on on the upper module declaration and on any cells, or use the -scope ﬂavor\nof the command.\nWith -scope enable/disable waveform tracing for the speciﬁed scope (or wildcard with ‘*’ or ‘?’), and optional\n–levels number of levels below. These controls only operate after other ﬁle/line/module-based controls have\nindicated the signal should be traced.\nWith -levels (used with -scope), the number of levels below that scope which the rule is to match, where 0 means\nall levels below, 1 the exact level as the provided scope, and 2 means an additional level of children below the\nprovided scope, etc.\n12.3 verilator_coverage\nVerilator_coverage processes Verilated model-generated coverage reports.\nWith –annotate, it reads the speciﬁed coverage data ﬁle and generates annotated source code with coverage metrics\nannotated. With –annotate-points the coverage points corresponding to each line are also shown.\nAdditional Verilog-XL-style standard arguments specify the search paths necessary to ﬁnd the source code on which\nthe coverage analysis was performed.\nTo ﬁlter those items to be included in coverage, you may read logs/coverage.dat into an editor and do a M-x keep-lines\nto include only those statistics of interest and save to a new .dat ﬁle.\nFor Verilog conditions that should never occur, either add a $stop statement to the appropriate statement block, or see\n/*verilator&32;coverage_off*/. This will remove the coverage points after the model is re-Verilated.\n12.3. verilator_coverage\n96", "source": "verilator"}
{"script_name": "timing_on", "definition_description": "This script enables timing constructs for the specified file and line numbers.", "parameters": {"file_name": "The name of the file where timing constructs are to be enabled.", "line_range": "The range of line numbers where timing constructs are to be enabled."}, "values": "file_name: <filename>, line_range: <line1> - <line2>", "script_paradigm": "timing_on [-file <file_name>] [-lines <line_range>]", "examples": [{"query": "How to enable timing for the file design.v between lines 10 to 20?", "answer": "timing_on -file design.v -lines 10-20"}, {"query": "How to enable timing for all lines in the file simulation.v?", "answer": "timing_on -file simulation.v"}], "reference": "Verilator, Release Devel 5.031\nor task should pass all remaining arguments through $sformatf. This allows the creation of DPI functions with\n$display-like behavior. See the test_regress/t/t_dpi_display.v ﬁle for an example.\nSame as /*verilator&32;sformat*/ metacomment.\nsplit_var [-module \"<modulename>\"] [-task \"<taskname>\"] -var \"<varname>\"\nsplit_var [-module \"<modulename>\"] [-function \"<funcname>\"] -var \"<varname>\"\nBreak the variable into multiple pieces typically to resolve UNOPTFLAT performance issues. Typically the\nvariables to attach this to are recommended by Verilator itself; see UNOPTFLAT.\nSame as /*verilator&32;split_var*/ metacomment.\ntiming_on\n[-file \"<filename>\" [-lines <line> [ - <line>]]]\ntiming_off [-file \"<filename>\" [-lines <line> [ - <line>]]]\nEnables/disables timing constructs for the speciﬁed ﬁle and lines. When disabled, all timing control constructs in\nthe speciﬁed source code locations are ignored the same way as with the --no-timing, and code:fork/join*\nblocks are converted into begin/end blocks.\nSame as /*verilator&32;timing_on*/, /*verilator&32;timing_off*/ metacomments.\ntracing_on\n[-file \"<filename>\" [-lines <line> [ - <line> ]]]\ntracing_off [-file \"<filename>\" [-lines <line> [ - <line> ]]]\ntracing_on\n[-scope \"<scopename>\" [-levels <levels> ]]\ntracing_off [-scope \"<scopename>\" [-levels <levels> ]]\nEnable/disable waveform tracing for all future signals declared in all ﬁles.\nWith -ﬁle, enable/disable waveform tracing in the speciﬁed ﬁlename (or wildcard with ‘*’ or ‘?’), and -line\nrange of line numbers (or all lines if omitted).\nFor tracing_off with -ﬁle, instances below any module in the ﬁles/ranges speciﬁed will also not be traced. To\novercome this feature, use tracing_on on the upper module declaration and on any cells, or use the -scope ﬂavor\nof the command.\nWith -scope enable/disable waveform tracing for the speciﬁed scope (or wildcard with ‘*’ or ‘?’), and optional\n–levels number of levels below. These controls only operate after other ﬁle/line/module-based controls have\nindicated the signal should be traced.\nWith -levels (used with -scope), the number of levels below that scope which the rule is to match, where 0 means\nall levels below, 1 the exact level as the provided scope, and 2 means an additional level of children below the\nprovided scope, etc.\n12.3 verilator_coverage\nVerilator_coverage processes Verilated model-generated coverage reports.\nWith –annotate, it reads the speciﬁed coverage data ﬁle and generates annotated source code with coverage metrics\nannotated. With –annotate-points the coverage points corresponding to each line are also shown.\nAdditional Verilog-XL-style standard arguments specify the search paths necessary to ﬁnd the source code on which\nthe coverage analysis was performed.\nTo ﬁlter those items to be included in coverage, you may read logs/coverage.dat into an editor and do a M-x keep-lines\nto include only those statistics of interest and save to a new .dat ﬁle.\nFor Verilog conditions that should never occur, either add a $stop statement to the appropriate statement block, or see\n/*verilator&32;coverage_off*/. This will remove the coverage points after the model is re-Verilated.\n12.3. verilator_coverage\n96", "source": "verilator"}
{"script_name": "tracing_on", "definition_description": "This script enables waveform tracing for all future signals declared in all files, with options for specific files, line ranges, and module scopes.", "parameters": {"file_name": "The name of the file where waveform tracing is to be enabled.", "line_range": "The range of line numbers where waveform tracing is to be enabled.", "scope_name": "The name of the scope where waveform tracing is to be enabled.", "levels": "The number of levels below the specified scope to include in tracing."}, "values": "file_name: <filename>, line_range: <line1> - <line2>, scope_name: <scopename>, levels: <levels>", "script_paradigm": "tracing_on [-file <file_name>] [-lines <line_range>] [-scope <scope_name>] [-levels <levels>]", "examples": [{"query": "How to enable waveform tracing for all signals in the file testbench.v between lines 5 to 15?", "answer": "tracing_on -file testbench.v -lines 5-15"}, {"query": "How to enable waveform tracing for the top module scope with 2 levels below?", "answer": "tracing_on -scope top -levels 2"}], "reference": "Verilator, Release Devel 5.031\nor task should pass all remaining arguments through $sformatf. This allows the creation of DPI functions with\n$display-like behavior. See the test_regress/t/t_dpi_display.v ﬁle for an example.\nSame as /*verilator&32;sformat*/ metacomment.\nsplit_var [-module \"<modulename>\"] [-task \"<taskname>\"] -var \"<varname>\"\nsplit_var [-module \"<modulename>\"] [-function \"<funcname>\"] -var \"<varname>\"\nBreak the variable into multiple pieces typically to resolve UNOPTFLAT performance issues. Typically the\nvariables to attach this to are recommended by Verilator itself; see UNOPTFLAT.\nSame as /*verilator&32;split_var*/ metacomment.\ntiming_on\n[-file \"<filename>\" [-lines <line> [ - <line>]]]\ntiming_off [-file \"<filename>\" [-lines <line> [ - <line>]]]\nEnables/disables timing constructs for the speciﬁed ﬁle and lines. When disabled, all timing control constructs in\nthe speciﬁed source code locations are ignored the same way as with the --no-timing, and code:fork/join*\nblocks are converted into begin/end blocks.\nSame as /*verilator&32;timing_on*/, /*verilator&32;timing_off*/ metacomments.\ntracing_on\n[-file \"<filename>\" [-lines <line> [ - <line> ]]]\ntracing_off [-file \"<filename>\" [-lines <line> [ - <line> ]]]\ntracing_on\n[-scope \"<scopename>\" [-levels <levels> ]]\ntracing_off [-scope \"<scopename>\" [-levels <levels> ]]\nEnable/disable waveform tracing for all future signals declared in all ﬁles.\nWith -ﬁle, enable/disable waveform tracing in the speciﬁed ﬁlename (or wildcard with ‘*’ or ‘?’), and -line\nrange of line numbers (or all lines if omitted).\nFor tracing_off with -ﬁle, instances below any module in the ﬁles/ranges speciﬁed will also not be traced. To\novercome this feature, use tracing_on on the upper module declaration and on any cells, or use the -scope ﬂavor\nof the command.\nWith -scope enable/disable waveform tracing for the speciﬁed scope (or wildcard with ‘*’ or ‘?’), and optional\n–levels number of levels below. These controls only operate after other ﬁle/line/module-based controls have\nindicated the signal should be traced.\nWith -levels (used with -scope), the number of levels below that scope which the rule is to match, where 0 means\nall levels below, 1 the exact level as the provided scope, and 2 means an additional level of children below the\nprovided scope, etc.\n12.3 verilator_coverage\nVerilator_coverage processes Verilated model-generated coverage reports.\nWith –annotate, it reads the speciﬁed coverage data ﬁle and generates annotated source code with coverage metrics\nannotated. With –annotate-points the coverage points corresponding to each line are also shown.\nAdditional Verilog-XL-style standard arguments specify the search paths necessary to ﬁnd the source code on which\nthe coverage analysis was performed.\nTo ﬁlter those items to be included in coverage, you may read logs/coverage.dat into an editor and do a M-x keep-lines\nto include only those statistics of interest and save to a new .dat ﬁle.\nFor Verilog conditions that should never occur, either add a $stop statement to the appropriate statement block, or see\n/*verilator&32;coverage_off*/. This will remove the coverage points after the model is re-Verilated.\n12.3. verilator_coverage\n96", "source": "verilator"}
{"script_name": "verilator_coverage", "definition_description": "This script processes Verilated model-generated coverage reports, with options to annotate the source code with coverage metrics.", "parameters": {"file_name": "The coverage data file to read and annotate.", "annotate_points": "A flag to display coverage points for each line.", "coverage_file": "The path to the coverage data file."}, "values": "file_name: <filename>, annotate_points: <yes/no>, coverage_file: <coverage_file>", "script_paradigm": "verilator_coverage [-annotate] [-annotate-points] <coverage_file>", "examples": [{"query": "How to process coverage data from the file coverage.dat with annotation?", "answer": "verilator_coverage -annotate coverage.dat"}, {"query": "How to process coverage data without annotating the points?", "answer": "verilator_coverage coverage.dat"}], "reference": "Verilator, Release Devel 5.031\nor task should pass all remaining arguments through $sformatf. This allows the creation of DPI functions with\n$display-like behavior. See the test_regress/t/t_dpi_display.v ﬁle for an example.\nSame as /*verilator&32;sformat*/ metacomment.\nsplit_var [-module \"<modulename>\"] [-task \"<taskname>\"] -var \"<varname>\"\nsplit_var [-module \"<modulename>\"] [-function \"<funcname>\"] -var \"<varname>\"\nBreak the variable into multiple pieces typically to resolve UNOPTFLAT performance issues. Typically the\nvariables to attach this to are recommended by Verilator itself; see UNOPTFLAT.\nSame as /*verilator&32;split_var*/ metacomment.\ntiming_on\n[-file \"<filename>\" [-lines <line> [ - <line>]]]\ntiming_off [-file \"<filename>\" [-lines <line> [ - <line>]]]\nEnables/disables timing constructs for the speciﬁed ﬁle and lines. When disabled, all timing control constructs in\nthe speciﬁed source code locations are ignored the same way as with the --no-timing, and code:fork/join*\nblocks are converted into begin/end blocks.\nSame as /*verilator&32;timing_on*/, /*verilator&32;timing_off*/ metacomments.\ntracing_on\n[-file \"<filename>\" [-lines <line> [ - <line> ]]]\ntracing_off [-file \"<filename>\" [-lines <line> [ - <line> ]]]\ntracing_on\n[-scope \"<scopename>\" [-levels <levels> ]]\ntracing_off [-scope \"<scopename>\" [-levels <levels> ]]\nEnable/disable waveform tracing for all future signals declared in all ﬁles.\nWith -ﬁle, enable/disable waveform tracing in the speciﬁed ﬁlename (or wildcard with ‘*’ or ‘?’), and -line\nrange of line numbers (or all lines if omitted).\nFor tracing_off with -ﬁle, instances below any module in the ﬁles/ranges speciﬁed will also not be traced. To\novercome this feature, use tracing_on on the upper module declaration and on any cells, or use the -scope ﬂavor\nof the command.\nWith -scope enable/disable waveform tracing for the speciﬁed scope (or wildcard with ‘*’ or ‘?’), and optional\n–levels number of levels below. These controls only operate after other ﬁle/line/module-based controls have\nindicated the signal should be traced.\nWith -levels (used with -scope), the number of levels below that scope which the rule is to match, where 0 means\nall levels below, 1 the exact level as the provided scope, and 2 means an additional level of children below the\nprovided scope, etc.\n12.3 verilator_coverage\nVerilator_coverage processes Verilated model-generated coverage reports.\nWith –annotate, it reads the speciﬁed coverage data ﬁle and generates annotated source code with coverage metrics\nannotated. With –annotate-points the coverage points corresponding to each line are also shown.\nAdditional Verilog-XL-style standard arguments specify the search paths necessary to ﬁnd the source code on which\nthe coverage analysis was performed.\nTo ﬁlter those items to be included in coverage, you may read logs/coverage.dat into an editor and do a M-x keep-lines\nto include only those statistics of interest and save to a new .dat ﬁle.\nFor Verilog conditions that should never occur, either add a $stop statement to the appropriate statement block, or see\n/*verilator&32;coverage_off*/. This will remove the coverage points after the model is re-Verilated.\n12.3. verilator_coverage\n96", "source": "verilator"}
{"script_name": "find_timing_paths", "definition_description": "This script is used to find timing paths in the design, including paths based on different clock edges, instances, and constraints.", "parameters": {"from": "List of sources such as clocks, instances, ports, or register pins to find paths from.", "rise_from": "List of sources for paths originating from the rising edge of clocks, instances, or ports.", "fall_from": "List of sources for paths originating from the falling edge of clocks, instances, or ports.", "through": "List of instances, pins, or nets that paths pass through.", "rise_through": "List of instances, pins, or nets for paths passing through the rising edge.", "fall_through": "List of instances, pins, or nets for paths passing through the falling edge.", "to": "List of destinations such as clocks, instances, ports, or pins for paths to be found.", "rise_to": "List of destinations for paths ending at the rising edge of clocks, instances, or ports.", "fall_to": "List of destinations for paths ending at the falling edge of clocks, instances, or ports.", "unconstrained": "Option to include unconstrained paths in the result.", "path_delay": "Defines the path delay type to filter the paths by min, max, or hold checks.", "group_count": "Limits the number of paths in each group.", "endpoint_count": "Limits the number of endpoints in the result.", "unique_paths_to_endpoint": "Limits the result to unique paths to each endpoint.", "corner": "Specifies the corner condition for timing analysis.", "slack_max": "Filters paths with a maximum slack constraint.", "slack_min": "Filters paths with a minimum slack constraint.", "sort_by_slack": "Option to sort paths based on slack values.", "path_group": "Specifies groups of paths to be reported."}, "values": "from: <list_of_sources>, rise_from: <list_of_sources>, fall_from: <list_of_sources>, through: <list_of_instances>, rise_through: <list_of_instances>, fall_through: <list_of_instances>, to: <list_of_destinations>, rise_to: <list_of_destinations>, fall_to: <list_of_destinations>, unconstrained: <true/false>, path_delay: <min|max|min_rise|min_fall|max_rise|max_fall>, group_count: <path_count>, endpoint_count: <endpoint_path_count>, unique_paths_to_endpoint: <true/false>, corner: <corner_condition>, slack_max: <max_slack>, slack_min: <min_slack>, sort_by_slack: <true/false>, path_group: <groups>", "script_paradigm": "find_timing_paths -from <from_list> -rise_from <rise_from_list> -fall_from <fall_from_list> -through <through_list> -rise_through <rise_through_list> -fall_through <fall_through_list> -to <to_list> -rise_to <rise_to_list> -fall_to <fall_to_list> -unconstrained <true/false> -path_delay <min|max|min_rise|min_fall|max_rise|max_fall> -group_count <path_count> -endpoint_count <endpoint_path_count> -unique_paths_to_endpoint <true/false> -corner <corner_condition> -slack_max <max_slack> -slack_min <min_slack> -sort_by_slack <true/false> -path_group <groups>", "examples": [{"query": "How to find timing paths from a list of clocks and report paths with max slack?", "answer": "find_timing_paths -from {clk1 clk2} -slack_max 10ns"}, {"query": "How to find timing paths through a set of pins and include unconstrained paths?", "answer": "find_timing_paths -through {pin1 pin2} -unconstrained true"}], "reference": "find_timing_paths\n[-from from_list\n |-rise_from from_list\n |-fall_from from_list]\n[-through through_list\n |-rise_through through_list\n |-fall_through through_list]\n[-to to_list\n |-rise_to to_list\n |-fall_to to_list]\n[-unconstrained]\n[-path_delay min|min_rise|min_fall\n            |max|max_rise|max_fall\n            |min_max]\n[-group_count path_count]\n[-endpoint_count endpoint_path_count]\n[-unique_paths_to_endpoint]\n[-corner corner]\n[-slack_max max_slack]\n[-slack_min min_slack]\n[-sort_by_slack]\n[-path_group groups]\n-from from_list\nReturn paths from a list of clocks, instances, ports, register clock pins, or \nlatch data pins.\n-rise_from from_list\nReturn paths from the rising edge of clocks, instances, ports, register \nclock pins, or latch data pins.\n-fall_from from_list\nReturn paths from the falling edge of clocks, instances, ports, register \nclock pins, or latch data pins.\n-through through_list\nReturn paths through a list of instances, pins or nets.\n-rise_through through_list\nReturn rising paths through a list of instances, pins or nets.\n-fall_through through_list\nReturn falling paths through a list of instances, pins or nets.\n-to to_list\nReturn paths to a list of clocks, instances, ports or pins.\n-rise_to to_list\nReturn rising paths to a list of clocks, instances, ports or pins.\n-fall_to to_list\nReturn falling paths to a list of clocks, instances, ports or pins.\n-unconstrained\nReport unconstrained paths also.\n-path_delay min\nReturn min path (hold) checks.", "source": "OpenSTA"}
{"script_name": "DensityFill", "definition_description": "This script performs density fill to meet metal density DRC rules, while obeying DRC constraints. It uses a json configuration file to define the fill parameters and layout rules.", "parameters": {"rules_file": "The json file specifying the density fill rules.", "area": "An optional parameter specifying the fill area. If not provided, the core area is used."}, "values": "rules_file: <path_to_json_file>, area: <lx ly ux uy>", "script_paradigm": "density_fill [-rules <rules_file>] [-area <lx ly ux uy>]", "examples": [{"query": "How to perform a density fill using a rules file and default area?", "answer": "density_fill -rules rules.json"}, {"query": "How to perform a density fill with a custom area?", "answer": "density_fill -rules rules.json -area {0 0 100 100}"}], "reference": "Metal fill\nThis module inserts floating metal fill shapes to meet metal density\ndesign rules while obeying DRC constraints. It is driven by a json\nconfiguration file.\nCommands\n{note}\n- Parameters in square brackets `[-param param]` are optional.\n- Parameters without square brackets `-param2 param2` are required.\nDensity Fill\nThis command performs density fill to meet metal density DRC rules.\ntcl\ndensity_fill\n    [-rules rules_file]\n    [-area {lx ly ux uy}]\nOptions\n| Switch Name | Description | \n| ----- | ----- |\n| -rules | Specify json rule file. |\n| -area | Optional. If not specified, the core area will be used. |\nExample scripts\nThe rules json file controls fill and you can see an example\nhere.\nThe schema for the json is:\njson\n{\n  \"layers\": {\n    \"<group_name>\": {\n      \"layers\": \"<list of integer gds layers>\",\n      \"names\": \"<list of name strings>\",\n      \"opc\": {\n        \"datatype\":  \"<list of integer gds datatypes>\",\n        \"width\":   \"<list of widths in microns>\",\n        \"height\":   \"<list of heightsin microns>\",\n        \"space_to_fill\": \"<real: spacing between fills in microns>\",\n        \"space_to_non_fill\": \"<real: spacing to non-fill shapes in microns>\",\n        \"space_line_end\": \"<real: spacing to end of line in microns>\"\n      },\n      \"non-opc\": {\n        \"datatype\":  \"<list of integer gds datatypes>\",\n        \"width\":   \"<list of widths in microns>\",\n        \"height\":   \"<list of heightsin microns>\",\n        \"space_to_fill\": \"<real: spacing between fills in microns>\",\n        \"space_to_non_fill\": \"<real: spacing to non-fill shapes in microns>\"\n      }\n    }, ...\n  }\n}\nThe opc section is optional depending on your process.\nThe width/height lists are effectively parallel arrays of shapes to try\nin left to right order (generally larger to smaller).\nThe layer grouping is for convenience. For example in some technologies many\nlayers have similar rules so it is convenient to have a Mx, Cx group.\nThis all started out in klayout so there are some obsolete fields that the\nparser accepts but ignores (e.g., space_to_outline).\nRegression tests\nThere are a set of regression tests in ./test. For more information, refer to this section. \nSimply run the following script: \nshell\n./test/regression\nLimitations\nFAQs\nCheck out GitHub discussion\nabout this tool.\nLicense\nBSD 3-Clause License. See LICENSE file.", "source": "OpenROAD"}
{"script_name": "global_placement_debug", "definition_description": "This script initiates a debug mode for global placement, allowing real-time visualization of the algorithm's progress on the layout.", "parameters": {"pause": "Number of iterations between pauses during debugging, useful for monitoring the progression of the placement algorithm.", "update": "Defines the frequency (in iterations) at which the tool refreshes its layout output to display the latest state during debugging.", "inst": "Targets a specific instance name for debugging focus. Defaults to no specific instance.", "draw_bins": "Activates visualization of placement bins, showing density and the direction of forces acting on them.", "initial": "Pauses the debug process during the initial placement phase."}, "values": "pause: <integer>, update: <integer>, inst: <string>, draw_bins: <enabled/disabled>, initial: <enabled/disabled>", "script_paradigm": "global_placement_debug -pause <pause> -update <update> -inst <inst> -draw_bins <draw_bins> -initial <initial>", "examples": [{"query": "How to set 5 iterations between pauses and 15 iterations for layout updates during global placement debugging?", "answer": "global_placement_debug -pause 5 -update 15"}, {"query": "How to focus on a specific instance 'my_instance' during global placement debugging?", "answer": "global_placement_debug -inst my_instance"}, {"query": "How to enable the visualization of placement bins during debugging?", "answer": "global_placement_debug -draw_bins enabled"}, {"query": "How to pause during the initial placement phase?", "answer": "global_placement_debug -initial enabled"}], "reference": "title: global_placement_debug(2)\ndate: 24/09/08\n\nNAME\nglobal_placement_debug - global placement debug\nSYNOPSIS\nglobal_placement_debug\n    [-pause] \n    [-update]\n    [-inst]\n    [-draw_bins]\n    [-initial]\nDESCRIPTION\nThe global_placement_debug command initiates a debug mode, enabling real-time visualization of the algorithm's progress on the layout. Use the command prior to executing the global_placement command, for example in the global_place.tcl script.\nOPTIONS\n-pause:  Number of iterations between pauses during debugging. Allows for visualization of the current state. Useful for closely monitoring the progression of the placement algorithm. Allowed values are integers, default is 10.\n-update:  Defines the frequency (in iterations) at which the tool refreshes its layout output to display the latest state during debugging. Allowed values are integers, default is 10. \n-inst:  Targets a specific instance name for debugging focus. Allowed value is a string, the default behavior focuses on no specific instance.\n-draw_bins:  Activates visualization of placement bins, showcasing their density (indicated by the shade of white) and the direction of forces acting on them (depicted in red). The default setting is disabled.\n-initial:  Pauses the debug process during the initial placement phase. The default setting is disabled.\nARGUMENTS\nThis command has no arguments.\nEXAMPLES\nSEE ALSO", "source": "OpenROAD"}
{"script_name": "set_data_check", "definition_description": "This script adds a setup or hold timing check between two pins for timing analysis.", "parameters": {"from_pin": "A pin used as the timing check reference for the 'from' side", "to_pin": "A pin that the setup/hold check is applied to on the 'to' side", "setup": "Optional flag to add a setup timing check", "hold": "Optional flag to add a hold timing check", "clock": "The clock used for the setup/hold check", "margin": "The setup or hold time margin"}, "values": "from_pin: <pin>, to_pin: <pin>, setup: <flag>, hold: <flag>, clock: <clock_name>, margin: <time_margin>", "script_paradigm": "set_data_check -from <from_pin> -to <to_pin> [-setup] [-hold] [-clock <clock>] <margin>", "examples": [{"query": "How to add a setup check from pin A to pin B with a margin of 2ns?", "answer": "set_data_check -from A -to B -setup 2ns"}, {"query": "Add a hold check between pins data_in and data_out with a 1ns margin on clk?", "answer": "set_data_check -from data_in -to data_out -hold -clock clk 1ns"}], "reference": "set_data_check\n[-from|-rise_from|-fall_from from_pin]\n[-to|-rise_to|-fall_to to_pin]\n[-setup]\n[-hold]\n[-clock clock]\nmargin\n-from from_pin\nA pin used as the timing check reference.\n-to to_pin\nA pin that the setup/hold check is applied to.\n-setup\nAdd a setup timing check.\n-hold\nAdd a hold timing check.\n-clock clock\nThe setup/hold check clock.\nmargin\nThe setup or hold time margin.\nThe set_data_check command is used to add a setup or hold timing check between two pins.\nset_disable_inferred_clock_gating objects\nobjects\nA list of clock gating instances, clock gating pins, or clock enable \npins.\nThe set_disable_inferred_clock_gating command disables clock gating checks on a clock gating \ninstance, clock gating pin, or clock gating enable pin.\nset_disable_timing\n[-from from_port]\n[-to to_port]\nobjects\n-from from_port\n-to to_port\nobjects\nA list of instances, ports, pins, cells, cell/port, or library/cell/port.\nThe set_disable_timing command is used to disable paths though pins in the design. There are many \ndifferent forms of the command depending on the objects specified in objects.\nAll timing paths though an instance are disabled when objects contains an instance. Timing checks in the \ninstance are not disabled.", "source": "OpenSTA"}
{"script_name": "set_disable_timing", "definition_description": "This script disables timing paths through specific objects in the design.", "parameters": {"from_port": "A port to disable timing checks from", "to_port": "A port to disable timing checks to", "objects": "A list of instances, ports, pins, or library elements to disable timing for"}, "values": "from_port: <port>, to_port: <port>, objects: <list_of_objects>", "script_paradigm": "set_disable_timing [-from <from_port>] [-to <to_port>] <objects>", "examples": [{"query": "How to disable timing checks from port A to port B for the instance my_instance?", "answer": "set_disable_timing -from A -to B my_instance"}, {"query": "Disable timing for the pin clk_in on the instance clk_driver", "answer": "set_disable_timing clk_in clk_driver"}], "reference": "set_data_check\n[-from|-rise_from|-fall_from from_pin]\n[-to|-rise_to|-fall_to to_pin]\n[-setup]\n[-hold]\n[-clock clock]\nmargin\n-from from_pin\nA pin used as the timing check reference.\n-to to_pin\nA pin that the setup/hold check is applied to.\n-setup\nAdd a setup timing check.\n-hold\nAdd a hold timing check.\n-clock clock\nThe setup/hold check clock.\nmargin\nThe setup or hold time margin.\nThe set_data_check command is used to add a setup or hold timing check between two pins.\nset_disable_inferred_clock_gating objects\nobjects\nA list of clock gating instances, clock gating pins, or clock enable \npins.\nThe set_disable_inferred_clock_gating command disables clock gating checks on a clock gating \ninstance, clock gating pin, or clock gating enable pin.\nset_disable_timing\n[-from from_port]\n[-to to_port]\nobjects\n-from from_port\n-to to_port\nobjects\nA list of instances, ports, pins, cells, cell/port, or library/cell/port.\nThe set_disable_timing command is used to disable paths though pins in the design. There are many \ndifferent forms of the command depending on the objects specified in objects.\nAll timing paths though an instance are disabled when objects contains an instance. Timing checks in the \ninstance are not disabled.", "source": "OpenSTA"}
{"script_name": "round_corners", "definition_description": "Rounds the corners of the polygon with specified inner and outer radii.", "parameters": {"rinner": "The inner radius to round the corners", "router": "The outer radius to round the corners", "n": "The number of segments to approximate the corner"}, "values": "rinner: <double>, router: <double>, n: <unsigned int>", "script_paradigm": "DPolygon.round_corners(rinner, router, n)", "examples": [{"query": "How to round the corners of a polygon with an inner radius of 2.0, an outer radius of 4.0, and 8 segments?", "answer": "polygon.round_corners(2.0, 4.0, 8)"}], "reference": "DPolygon round_corners (double rinner, double router, unsigned int n) Rounds the corners of the polygon void size (double dx, double dy, unsigned int mode) Sizes the polygon (biasing) void size (const Vector dv, unsigned int mode = 2) Sizes the polygon (biasing) void size (double d, unsigned int mode = 2) Sizes the polygon (biasing) [const] DPolygon sized (double dx, double dy, unsigned int mode) Sizes the polygon (biasing) without modifying self [const] DPolygon sized (const Vector dv, unsigned int mode = 2) Sizes the polygon (biasing) without modifying self [const] DPolygon sized (double d, unsigned int mode = 2) Sizes the polygon (biasing) without modifying self void sort_holes Brings the holes in a specific order [const] DPolygon[] split Splits the polygon into two or more parts [const] Polygon to_itype (double dbu = 1) Converts the polygon to an integer coordinate polygon [const] string to_s Returns a string representing the polygon [const] bool touches? (const DBox box) Returns true, if the polygon touches the given box. [const] bool touches? (const DEdge edge) Returns true, if the polygon touches the given edge. [const] bool touches? (const DPolygon polygon) Returns true, if the polygon touches the other polygon. [const] bool touches? (const DSimplePolygon simple_polygon) Returns true, if the polygon touches the other polygon. DPolygon ptr transform (const DCplxTrans t) Transforms the polygon with a complex transformation (in-place) DPolygon ptr transform (const DTrans t) Transforms the polygon (in-place) [const] Polygon transformed (const VCplxTrans t) Transforms the polygon with the given complex transformation [const] DPolygon transformed (const DTrans t) Transforms the polygon [const] DPolygon transformed (const DCplxTrans t) Transforms the polygon with a complex transformation", "source": "klayout"}
{"script_name": "size (double dx, double dy, unsigned int mode)", "definition_description": "Sizes the polygon by applying a bias to its dimensions using specified offsets.", "parameters": {"dx": "The offset for the x-axis", "dy": "The offset for the y-axis", "mode": "The mode used for sizing (biasing)"}, "values": "dx: <double>, dy: <double>, mode: <unsigned int>", "script_paradigm": "polygon.size(dx, dy, mode)", "examples": [{"query": "How to size a polygon with x offset 5.0, y offset 3.0, and mode 1?", "answer": "polygon.size(5.0, 3.0, 1)"}], "reference": "DPolygon round_corners (double rinner, double router, unsigned int n) Rounds the corners of the polygon void size (double dx, double dy, unsigned int mode) Sizes the polygon (biasing) void size (const Vector dv, unsigned int mode = 2) Sizes the polygon (biasing) void size (double d, unsigned int mode = 2) Sizes the polygon (biasing) [const] DPolygon sized (double dx, double dy, unsigned int mode) Sizes the polygon (biasing) without modifying self [const] DPolygon sized (const Vector dv, unsigned int mode = 2) Sizes the polygon (biasing) without modifying self [const] DPolygon sized (double d, unsigned int mode = 2) Sizes the polygon (biasing) without modifying self void sort_holes Brings the holes in a specific order [const] DPolygon[] split Splits the polygon into two or more parts [const] Polygon to_itype (double dbu = 1) Converts the polygon to an integer coordinate polygon [const] string to_s Returns a string representing the polygon [const] bool touches? (const DBox box) Returns true, if the polygon touches the given box. [const] bool touches? (const DEdge edge) Returns true, if the polygon touches the given edge. [const] bool touches? (const DPolygon polygon) Returns true, if the polygon touches the other polygon. [const] bool touches? (const DSimplePolygon simple_polygon) Returns true, if the polygon touches the other polygon. DPolygon ptr transform (const DCplxTrans t) Transforms the polygon with a complex transformation (in-place) DPolygon ptr transform (const DTrans t) Transforms the polygon (in-place) [const] Polygon transformed (const VCplxTrans t) Transforms the polygon with the given complex transformation [const] DPolygon transformed (const DTrans t) Transforms the polygon [const] DPolygon transformed (const DCplxTrans t) Transforms the polygon with a complex transformation", "source": "klayout"}
{"script_name": "get_global_placement_uniform_density", "definition_description": "This script adds padding and retrieves the global placement uniform target density for a design.", "parameters": {"pad_left": "Specifies the padding on the left side of the design", "pad_right": "Specifies the padding on the right side of the design"}, "values": "pad_left: <value>, pad_right: <value>", "script_paradigm": "get_global_placement_uniform_density -pad_left <pad_left> -pad_right <pad_right>", "examples": [{"query": "How to apply padding of 5 units on the left and 10 units on the right?", "answer": "get_global_placement_uniform_density -pad_left 5 -pad_right 10"}], "reference": "Useful Developer Commands\nIf you are a developer, you might find these useful. More details can be found in the source file or the swig file.\n```\nadds padding and gets global placement uniform target density\nget_global_placement_uniform_density -pad_left -pad_right \n``\nExample scripts demonstrating how to rungplon a sample design oncore01` as follows:\nshell\n./test/core01.tcl\nRegression tests\nThere are a set of regression tests in ./test. For more information, refer to this section.\nSimply run the following script:\nshell\n./test/regression\nLimitations\nUsing the Python interface to gpl\nThis API tries to stay close to the API defined in C++ class Replace\nthat is located here.\nWhen initializing a design, a sequence of Python commands might look like\nthe following:\npython\nfrom openroad import Design, Tech\ntech = Tech()\ntech.readLef(...)\ndesign = Design(tech)\ndesign.readDef(...)\ngpl = design.getReplace() \nHere is an example of some options / configurations to the global placer.\n(See Replace.h for a complete list)\npython\ngpl.setInitialPlaceMaxIter(iter)\ngpl.setSkipIoMode(skip_io)\ngpl.setTimingDrivenMode(timing_driven)\ngpl.setTimingNetWeightMax(weight)\nThere are some useful Python functions located in the file\ngrt_aux.py but these are not considered a part of the final\nAPI and they may change.\nFAQs\nCheck out GitHub discussion\nabout this tool.\nReferences", "source": "OpenROAD"}
{"script_name": "gpl_initialization_python", "definition_description": "This script demonstrates how to initialize a design and configure global placement options using Python.", "parameters": {"tech_lef": "The LEF file to read technology information from", "design_def": "The DEF file to read the design information from", "iter": "The maximum number of iterations for the initial placement", "skip_io": "A flag to skip IO placement during the global placement", "timing_driven": "A flag to enable or disable timing-driven placement", "weight": "The maximum weight for the timing net in the placement"}, "values": "tech_lef: <path>, design_def: <path>, iter: <value>, skip_io: <true/false>, timing_driven: <true/false>, weight: <value>", "script_paradigm": "from openroad import Design, Tech\ntech = Tech()\ntech.readLef(<tech_lef>)\ndesign = Design(tech)\ndesign.readDef(<design_def>)\ngpl = design.getReplace()\ngpl.setInitialPlaceMaxIter(<iter>)\ngpl.setSkipIoMode(<skip_io>)\ngpl.setTimingDrivenMode(<timing_driven>)\ngpl.setTimingNetWeightMax(<weight>)", "examples": [{"query": "How to initialize a design with technology file 'tech.lef' and design file 'design.def', set 100 iterations for initial placement, skip IO placement, enable timing-driven mode, and set a maximum timing net weight of 0.5?", "answer": "from openroad import Design, Tech\ntech = Tech()\ntech.readLef('tech.lef')\ndesign = Design(tech)\ndesign.readDef('design.def')\ngpl = design.getReplace()\ngpl.setInitialPlaceMaxIter(100)\ngpl.setSkipIoMode(True)\ngpl.setTimingDrivenMode(True)\ngpl.setTimingNetWeightMax(0.5)"}], "reference": "Useful Developer Commands\nIf you are a developer, you might find these useful. More details can be found in the source file or the swig file.\n```\nadds padding and gets global placement uniform target density\nget_global_placement_uniform_density -pad_left -pad_right \n``\nExample scripts demonstrating how to rungplon a sample design oncore01` as follows:\nshell\n./test/core01.tcl\nRegression tests\nThere are a set of regression tests in ./test. For more information, refer to this section.\nSimply run the following script:\nshell\n./test/regression\nLimitations\nUsing the Python interface to gpl\nThis API tries to stay close to the API defined in C++ class Replace\nthat is located here.\nWhen initializing a design, a sequence of Python commands might look like\nthe following:\npython\nfrom openroad import Design, Tech\ntech = Tech()\ntech.readLef(...)\ndesign = Design(tech)\ndesign.readDef(...)\ngpl = design.getReplace() \nHere is an example of some options / configurations to the global placer.\n(See Replace.h for a complete list)\npython\ngpl.setInitialPlaceMaxIter(iter)\ngpl.setSkipIoMode(skip_io)\ngpl.setTimingDrivenMode(timing_driven)\ngpl.setTimingNetWeightMax(weight)\nThere are some useful Python functions located in the file\ngrt_aux.py but these are not considered a part of the final\nAPI and they may change.\nFAQs\nCheck out GitHub discussion\nabout this tool.\nReferences", "source": "OpenROAD"}
{"script_name": "read_spef", "definition_description": "This script reads the SPEF (Standard Parasitic Exchange Format) files and applies parasitic data to the design, with the option to specify the corner, min/max delay, and parasitic network reduction.", "parameters": {"corner": "Specifies the process corner (e.g., ss, tt, ff) for which the parasitic data is applicable.", "min": "Indicates that the SPEF file should be used for minimum delay calculation.", "max": "Indicates that the SPEF file should be used for maximum delay calculation.", "reduce": "Reduces the parasitic network to the appropriate type, decreasing memory usage.", "coupling_reduction_factor": "Factor used to multiply the coupling capacitors when reducing parasitics.", "path": "Specifies the instance path to the block for parasitic network annotation in hierarchical designs."}, "values": "corner: <ss, tt, ff>, min: <spef1>, max: <spef2>, reduce: <yes>, coupling_reduction_factor: <value>, path: <instance_path>", "script_paradigm": "read_spef -corner <corner> -min <spef_file1> -max <spef_file2> -reduce <yes/no> -coupling_reduction_factor <value> -path <instance_path>", "examples": [{"query": "How to read the SS corner parasitic data for minimum delay calculation?", "answer": "read_spef -corner ss -min spef1"}, {"query": "How to read the TT corner parasitic data for maximum delay calculation?", "answer": "read_spef -corner tt -max spef2"}, {"query": "How to reduce parasitic network and use a coupling reduction factor of 0.8?", "answer": "read_spef -corner ff -reduce yes -coupling_reduction_factor 0.8"}, {"query": "How to read parasitic data for a specific block in a hierarchical design?", "answer": "read_spef -corner ss -path /top/block1"}], "reference": "To use separate parastics for each corner, use the -corner option for each SPEF file.\nread_spef -corner ss spef1\nread_spef -corner tt spef2\nread_spef -corner ff spef3\nTo use separate parastics for each corner and separate min/max delay calculation, use the -corner option \nalong with the -min, and -max options.\nread_spef -corner ss -min spef1\nread_spef -corner ss -max spef2\nread_spef -corner ff -min spef3\nread_spef -corner ff -max spef4\nWith the -reduce option, the current delay calculator reduces the parastic network to the appropriate type and \ndeletes the parasitic network. This substantially reduces the memory required to store the parasitics.\nCoupling capacitors are multiplied by the –coupling_reduction_factor when a parasitic network is \nreduced.\nThe following SPEF constructs are ignored.\n*DESIGN_FLOW (all values are ignored)\n*S slews\n*D driving cell\n*I pin capacitances (library cell capacitances are used instead)\n*Q r_net load poles\n*K r_net load residues\nIf the SPEF file contains triplet values the first value is used.\nParasitic networks (DSPEF) can be annotated on hierarchical blocks using the -path argument to specify the \ninstance path to the block. Parasitic networks in the higher level netlist are stitched together at the hierarchcal \npins of the blocks.\nread_verilog\nfilename\nfilename\nThe name of the verilog file to read.\nThe read_verilog command reads a gate level verilog netlist. After all verilog netlist and Liberty libraries are \nread the design must be linked with the link_design command.\nVerilog 2001 module port declaratations are supported. An example is shown below.\nmodule top (input in1, in2, clk1, clk2, clk3,\n            output out);\nFiles compressed with gzip are automatically uncompressed.", "source": "OpenSTA"}
{"script_name": "RecursiveShapeIterator", "definition_description": "This script demonstrates how to iterate over shapes in a layout using a RecursiveShapeIterator. It allows for filtering shapes by type, setting traversal depth, and specifying regions.", "parameters": {"shape_flags": "Specifies which type of shapes to retrieve (e.g., boxes, texts, etc.)", "max_depth": "Defines the maximum depth of hierarchy traversal. A value of 0 means only the shapes from the initial cell are reported.", "region": "Defines a rectangular region to filter shapes based on whether they touch or overlap the specified box."}, "values": "shape_flags: SBoxes, max_depth: 0, region: <Box object>", "script_paradigm": ["layout = RBA::Application::instance.main_window.current_view.active_cellview.layout", "si = layout.begin_shapes(layout.cell_by_name('TOP'), 0)", "si.shape_flags = RBA::Shapes::SBoxes", "while !si.at_end?", "  puts si.shape.to_s + ' with transformation ' + si.trans.to_s", "  si.next", "end"], "examples": [{"query": "How to iterate over only box shapes in the 'TOP' cell?", "answer": "layout = RBA::Application::instance.main_window.current_view.active_cellview.layout\nsi = layout.begin_shapes(layout.cell_by_name('TOP'), 0)\nsi.shape_flags = RBA::Shapes::SBoxes\nwhile !si.at_end?\n  puts si.shape.to_s + ' with transformation ' + si.trans.to_s\n  si.next\nend"}, {"query": "How to set the maximum depth of iteration to 0?", "answer": "layout = RBA::Application::instance.main_window.current_view.active_cellview.layout\nsi = layout.begin_shapes(layout.cell_by_name('TOP'), 0)\nsi.max_depth = 0\nwhile !si.at_end?\n  puts si.shape.to_s + ' with transformation ' + si.trans.to_s\n  si.next\nend"}, {"query": "How to iterate over shapes inside a specific region in 'TOP' cell?", "answer": "layout = RBA::Application::instance.main_window.current_view.active_cellview.layout\nregion = RBA::Box.new(<x1>, <y1>, <x2>, <y2>)\nsi = layout.begin_shapes_touching(region)\nwhile !si.at_end?\n  puts si.shape.to_s + ' with transformation ' + si.trans.to_s\n  si.next\nend"}], "reference": "A RecursiveShapeIterator can be configured to retrieve only certain type of shapes (i.e. boxes, texts etc.). To do so, set the shape_flags attribute of the shape iterator before using it:\n\nlayout = RBA::Application::instance.main_window.current_view.active_cellview.layout\n# start iterating shapes from cell \"TOP\", layer index 0\nsi = layout.begin_shapes(layout.cell_by_name(\"TOP\"), 0)\nsi.shape_flags = RBA::Shapes::SBoxes\nwhile !si.at_end?\n  puts si.shape.to_s + \" with transformation \" + si.trans.to_s\n  si.next\nend\n\nAlso the maximum depth at which the RecursiveShapeIterator will traverse the hierarchy can be set using the \"max_depth\" attribute. Setting this attribute to 0 will report only shapes from the initial cell. The depth must be set before the first shape is retrieved.\n\nThe RecursiveShapeIterator can also deliver shapes from a region. The region is a rectangle specified in coordinates of the initial cell. To create a RecursiveShapeIterator that only delivers shapes inside that region use the Layout#begin_shapes_touching or Layout#begin_shapes_overlapping methods of the Layout object. These methods expect a Box object that specifies that rectangle. All shapes delivered will either touch or overlap that box when projected into the initial cell.\n\nShape manipulations should be avoided inside loops that iterate over shapes using a RecursiveShapeIterator. The reason is that shape manipulations may invalidate the internal state of the RecursiveShapeIterator. Instead, collect all shape references that need to be manipulated in an array and do the manipulations later.\n\nProperties\n\nAs stated earlier, shapes can carry an arbitrary number of user properties in form of key/value pairs. For efficiency, these properties are not stored directly but in form of a property ID which identifies a unique set of properties. Retrieving a property hence requires an indirection over the property ID:\n\nlayout = RBA::Application::instance.main_window.current_view.active_cellview.layout\n# first shape of cell \"TOP\", layer index 0\nlayer_index = 0\niter = layout.begin_shapes(layout.cell(\"TOP\").cell_index, layer_index)\nshape = iter.shape\n# create a hash from the properties of that shape\nprops = Hash[*layout.properties(shape.prop_id).flatten]\n# print the value of the property with key 1\nputs props[1]\n\nSince that scheme is somewhat tedious to use, a nice shortcut exists by using the \"properties\" method on the shape reference. This method implicitly modifies the property set and assigns a new property ID:\n\nlayout = RBA::Application::instance.main_window.current_view.active_cellview.layout\n# first shape of cell \"TOP\", layer index 0\nlayer_index = 0\niter = layout.begin_shapes(layout.cell(\"TOP\").cell_index, layer_index)\nshape = iter.shape\n# print the value of the property with key 1\nputs shape.properties(1)\n\nChanging a property requires to obtain a new property ID for the changed set:\n\nlayout = RBA::Application::instance.main_window.current_view.active_cellview.layout\n# first shape of cell \"TOP\", layer index 0\nlayer_index = 0\niter = layout.begin_shapes(layout.cell(\"TOP\").cell_index, layer_index)\nshape = iter.shape\ncell = layout.cell(iter.cell_index)\n# create a hash from the properties of that shape\nprops = Hash[*layout.properties(shape.prop_id).flatten]\n# change or add a property with key 1\nprops[1] = \"NewValue\"\n# store the new properties\nshape.prop_id = layout.properties_id(props.to_a)\n\nFor that problem also a shortcut exists. Use the \"set_properties\" method on the shape reference. This method implicitly modifies the property set and assigns a new property ID:\n\nlayout = RBA::Application::instance.main_window.current_view.active_cellview.layout\n# first shape of cell \"TOP\", layer index 0\nlayer_index = 0\niter = layout.begin_shapes(layout.cell(\"TOP\").cell_index, layer_index)\nshape = iter.shape\n# change or add a property with key 1 and value \"NewValue\"\nshape.set_property(1, \"NewValue\")", "source": "klayout"}
{"script_name": "ShapeProperties", "definition_description": "This script shows how to retrieve, modify, and assign properties to shapes using their property ID.", "parameters": {"prop_id": "The property ID that identifies a unique set of properties for a shape", "key": "The key used to access a specific property value", "value": "The value assigned to a property"}, "values": "prop_id: <Property ID>, key: <Integer>, value: <String>", "script_paradigm": ["layout = RBA::Application::instance.main_window.current_view.active_cellview.layout", "iter = layout.begin_shapes(layout.cell('TOP').cell_index, 0)", "shape = iter.shape", "props = Hash[*layout.properties(shape.prop_id).flatten]", "puts props[1]"], "examples": [{"query": "How to print the property value with key 1 for the first shape in 'TOP' cell?", "answer": "layout = RBA::Application::instance.main_window.current_view.active_cellview.layout\niter = layout.begin_shapes(layout.cell('TOP').cell_index, 0)\nshape = iter.shape\nprops = Hash[*layout.properties(shape.prop_id).flatten]\nputs props[1]"}, {"query": "How to modify a property value for the first shape in 'TOP' cell?", "answer": "layout = RBA::Application::instance.main_window.current_view.active_cellview.layout\niter = layout.begin_shapes(layout.cell('TOP').cell_index, 0)\nshape = iter.shape\nprops = Hash[*layout.properties(shape.prop_id).flatten]\nprops[1] = 'NewValue'\nshape.prop_id = layout.properties_id(props.to_a)"}, {"query": "How to set a property directly on a shape?", "answer": "layout = RBA::Application::instance.main_window.current_view.active_cellview.layout\niter = layout.begin_shapes(layout.cell('TOP').cell_index, 0)\nshape = iter.shape\nshape.set_property(1, 'NewValue')"}], "reference": "A RecursiveShapeIterator can be configured to retrieve only certain type of shapes (i.e. boxes, texts etc.). To do so, set the shape_flags attribute of the shape iterator before using it:\n\nlayout = RBA::Application::instance.main_window.current_view.active_cellview.layout\n# start iterating shapes from cell \"TOP\", layer index 0\nsi = layout.begin_shapes(layout.cell_by_name(\"TOP\"), 0)\nsi.shape_flags = RBA::Shapes::SBoxes\nwhile !si.at_end?\n  puts si.shape.to_s + \" with transformation \" + si.trans.to_s\n  si.next\nend\n\nAlso the maximum depth at which the RecursiveShapeIterator will traverse the hierarchy can be set using the \"max_depth\" attribute. Setting this attribute to 0 will report only shapes from the initial cell. The depth must be set before the first shape is retrieved.\n\nThe RecursiveShapeIterator can also deliver shapes from a region. The region is a rectangle specified in coordinates of the initial cell. To create a RecursiveShapeIterator that only delivers shapes inside that region use the Layout#begin_shapes_touching or Layout#begin_shapes_overlapping methods of the Layout object. These methods expect a Box object that specifies that rectangle. All shapes delivered will either touch or overlap that box when projected into the initial cell.\n\nShape manipulations should be avoided inside loops that iterate over shapes using a RecursiveShapeIterator. The reason is that shape manipulations may invalidate the internal state of the RecursiveShapeIterator. Instead, collect all shape references that need to be manipulated in an array and do the manipulations later.\n\nProperties\n\nAs stated earlier, shapes can carry an arbitrary number of user properties in form of key/value pairs. For efficiency, these properties are not stored directly but in form of a property ID which identifies a unique set of properties. Retrieving a property hence requires an indirection over the property ID:\n\nlayout = RBA::Application::instance.main_window.current_view.active_cellview.layout\n# first shape of cell \"TOP\", layer index 0\nlayer_index = 0\niter = layout.begin_shapes(layout.cell(\"TOP\").cell_index, layer_index)\nshape = iter.shape\n# create a hash from the properties of that shape\nprops = Hash[*layout.properties(shape.prop_id).flatten]\n# print the value of the property with key 1\nputs props[1]\n\nSince that scheme is somewhat tedious to use, a nice shortcut exists by using the \"properties\" method on the shape reference. This method implicitly modifies the property set and assigns a new property ID:\n\nlayout = RBA::Application::instance.main_window.current_view.active_cellview.layout\n# first shape of cell \"TOP\", layer index 0\nlayer_index = 0\niter = layout.begin_shapes(layout.cell(\"TOP\").cell_index, layer_index)\nshape = iter.shape\n# print the value of the property with key 1\nputs shape.properties(1)\n\nChanging a property requires to obtain a new property ID for the changed set:\n\nlayout = RBA::Application::instance.main_window.current_view.active_cellview.layout\n# first shape of cell \"TOP\", layer index 0\nlayer_index = 0\niter = layout.begin_shapes(layout.cell(\"TOP\").cell_index, layer_index)\nshape = iter.shape\ncell = layout.cell(iter.cell_index)\n# create a hash from the properties of that shape\nprops = Hash[*layout.properties(shape.prop_id).flatten]\n# change or add a property with key 1\nprops[1] = \"NewValue\"\n# store the new properties\nshape.prop_id = layout.properties_id(props.to_a)\n\nFor that problem also a shortcut exists. Use the \"set_properties\" method on the shape reference. This method implicitly modifies the property set and assigns a new property ID:\n\nlayout = RBA::Application::instance.main_window.current_view.active_cellview.layout\n# first shape of cell \"TOP\", layer index 0\nlayer_index = 0\niter = layout.begin_shapes(layout.cell(\"TOP\").cell_index, layer_index)\nshape = iter.shape\n# change or add a property with key 1 and value \"NewValue\"\nshape.set_property(1, \"NewValue\")", "source": "klayout"}
{"script_name": "synth_sf2", "definition_description": "This script runs synthesis for SmartFusion2 and IGLOO2 FPGAs, generating output files in EDIF, Verilog, or JSON formats, and offers various options for synthesis control.", "parameters": {"top": "Specifies the top module to use for the synthesis process.", "edif": "Writes the synthesized design to the specified EDIF file.", "vlog": "Writes the synthesized design to the specified Verilog file.", "json": "Writes the synthesized design to the specified JSON file.", "run": "Runs only the commands between the specified labels (from_label:to_label).", "noflatten": "Prevents flattening of the design before synthesis.", "noiobs": "Runs synthesis in 'block mode', i.e., does not insert IO buffers.", "clkbuf": "Inserts direct PAD to global_net buffers.", "discard-ffinit": "Discards FF initialization values instead of emitting an error.", "retime": "Runs the 'abc' tool with '-dff -D 1' options for retiming."}, "values": "top: <module>, edif: <file>, vlog: <file>, json: <file>, run: <from_label>:<to_label>, noflatten: <boolean>, noiobs: <boolean>, clkbuf: <boolean>, discard-ffinit: <boolean>, retime: <boolean>", "script_paradigm": "synth_sf2 -top <top> -edif <edif> -vlog <vlog> -json <json> -run <from_label>:<to_label> -noflatten -noiobs -clkbuf -discard-ffinit -retime", "examples": [{"query": "How to run synthesis for a top module 'my_top' and write the output to a Verilog file 'output.v'?", "answer": "synth_sf2 -top my_top -vlog output.v"}, {"query": "How to run synthesis without flattening the design and generate an EDIF file 'design.edif'?", "answer": "synth_sf2 -top my_top -edif design.edif -noflatten"}, {"query": "How to perform synthesis for a specific section of the design from label 'start' to label 'end'?", "answer": "synth_sf2 -top my_top -run start:end"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n10.235 synth_sf2 - synthesis for SmartFusion2 and IGLOO2 FPGAs\nyosys> help synth_sf2\nsynth_sf2 [options]\nThis command runs synthesis for SmartFusion2 and IGLOO2 FPGAs.\n-top <module>\nuse the specified module as top module\n-edif <file>\nwrite the design to the specified EDIF file. writing of an output file\nis omitted if this parameter is not specified.\n-vlog <file>\nwrite the design to the specified Verilog file. writing of an output\nfile is omitted if this parameter is not specified.\n-json <file>\nwrite the design to the specified JSON file. writing of an output file\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-noiobs\nrun synthesis in \"block mode\", i.e. do not insert IO buffers\n-clkbuf\ninsert direct PAD->global_net buffers\n-discard-ffinit\ndiscard FF init value instead of emitting an error\n-retime\nrun 'abc' with '-dff -D 1' options\nThe following commands are executed by this synthesis command:\nbegin:\nread_verilog -lib +/sf2/cells_sim.v\nhierarchy -check -top <top>\nflatten:\n(unless -noflatten)\nproc\nflatten\n(continues on next page)\n10.235.\nsynth_sf2 - synthesis for SmartFusion2 and IGLOO2 FPGAs\n529", "source": "yosys_hq"}
{"script_name": "create_toolbar_button", "definition_description": "This script creates a toolbar button with the specified text and associated script logic.", "parameters": {"name": "The name of the button, used when deleting the button (optional)", "text": "The text to display on the button", "script": "The TCL script to execute when the button is pressed", "echo": "Indicates if the TCL script commands should be echoed in the log (optional)"}, "values": "name: <button_name>, text: <button_text>, script: <tcl_script>, echo: <echo_flag>", "script_paradigm": "create_toolbar_button -name <name> -text <text> -script <script> -echo <echo>", "examples": [{"query": "How to create a toolbar button with text 'Run' and a script to run a command?", "answer": "create_toolbar_button -text Run -script \"run_command\""}, {"query": "Create a toolbar button named 'save_button' with text 'Save' and script 'save_file', with echoing enabled", "answer": "create_toolbar_button -name save_button -text Save -script \"save_file\" -echo"}], "reference": "title: create_toolbar_button(2)\ndate: 24/09/08\n\nNAME\ncreate_toolbar_button - create toolbar button\nSYNOPSIS\ncreate_toolbar_button \n    [-name name]\n    -text button_text\n    -script tcl_script \n    [-echo]\nDESCRIPTION\nThis command creates toolbar button with name set using the\n-text flag and accompanying logic in the -script flag.\nReturns: name of the new button, either name or buttonX.\nOPTIONS\n-name:  The name of the button, used when deleting the button.\n-text:  The text to put on the button.\n-script:  The tcl script to evaluate when the button is pressed.\n-echo:  This indicate that the commands in the tcl_script should be echoed in the log.\nARGUMENTS\nThis command has no arguments.\nEXAMPLES\nSEE ALSO", "source": "OpenROAD"}
{"script_name": "ExpandInputCone", "definition_description": "This script expands the top selection set by selecting only input cones, considering rules similar to the %x expansion.", "parameters": {"num1": "The number of times the expansion should occur. Can be '*' for unlimited expansion.", "num2": "The maximum number of objects to be selected during the expansion.", "rule": "A set of rules specifying which cell ports or wires to include or exclude during the expansion. These rules can specify cell types, ports, or wire names."}, "values": "num1: <num1>, num2: <num2>, rule: <rule>", "script_paradigm": "%ci[<num1>|*][.<num2>][:<rule>[:<rule>..]]", "examples": [{"query": "How to expand the top set by selecting only input cones connected to certain cells?", "answer": "select %ci:* %d"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\ncreate a copy of the top set from the stack and push it\n%x[<num1>|*][.<num2>][:<rule>[:<rule>..]]\nexpand top set <num1> num times according to the specified rules.\n(i.e. select all cells connected to selected wires and select all\nwires connected to selected cells) The rules specify which cell\nports to use for this. the syntax for a rule is a '-' for exclusion\nand a '+' for inclusion, followed by an optional comma separated\nlist of cell types followed by an optional comma separated list of\ncell ports in square brackets. a rule can also be just a cell or wire\nname that limits the expansion (is included but does not go beyond).\nselect at most <num2> objects. a warning message is printed when this\nlimit is reached. When '*' is used instead of <num1> then the process\nis repeated until no further object are selected.\n%ci[<num1>|*][.<num2>][:<rule>[:<rule>..]]\n%co[<num1>|*][.<num2>][:<rule>[:<rule>..]]\nsimilar to %x, but only select input (%ci) or output cones (%co)\n%xe[...] %cie[...] %coe\nlike %x, %ci, and %co but only consider combinatorial cells\n%a\nexpand top set by selecting all wires that are (at least in part)\naliases for selected wires.\n%s\nexpand top set by adding all modules that implement cells in selected\nmodules\n%m\nexpand top set by selecting all modules that contain selected objects\n%M\nselect modules that implement selected cells\n%C\nselect cells that implement selected modules\n%R[<num>]\nselect <num> random objects from top selection (default 1)\nExample: the following command selects all wires that are connected to a\n'GATE' input of a 'SWITCH' cell:\nselect */t:SWITCH %x:+[GATE] */t:SWITCH %d\n10.198.\nselect - modify and view the list of selected objects\n469", "source": "yosys_hq"}
{"script_name": "verimake_partial", "definition_description": "This script is used to handle partial builds in Verilator, optimizing the performance during the simulation process by reducing compilation time.", "parameters": {"source_files": "A list of Verilog source files to be compiled", "output_directory": "The directory where the compiled files and simulation output are stored", "build_type": "Specifies whether the build is partial or full, controlling the extent of the compilation"}, "values": "source_files: <list_of_files>, output_directory: <dir>, build_type: <partial/full>", "script_paradigm": "verimake_partial -source_files <source_files> -output_directory <output_directory> -build_type <build_type>", "examples": [{"query": "How to run a partial build for the Verilog files in the src directory?", "answer": "verimake_partial -source_files src/*.v -output_directory build/ -build_type partial"}, {"query": "Execute a full build and store output in the output directory.", "answer": "verimake_partial -source_files src/*.v -output_directory output/ -build_type full"}], "reference": "Verilator, Release Devel 5.031\n19.1.253 Verilator 1.1 1995-03-30\n• Bug ﬁxes, added verimake_partial script, performance improvements.\n19.1.254 Verilator 1.0c 1994-09-30\n• Initial release of Verilator\n19.1.255 Verilator 0.0 1994-07-08\n• First code written.\n19.1.256 Copyright\nCopyright 2001-2024 by Wilson Snyder. This program is free software; you can redistribute it and/or modify it under\nthe terms of either the GNU Lesser General Public License Version 3 or the Perl Artistic License Version 2.0.\nSPDX-License-Identiﬁer: LGPL-3.0-only OR Artistic-2.0\n19.1. Revision History and Change Log\n243", "source": "verilator"}
{"script_name": "DRC#length", "definition_description": "This script selects edges based on their length.", "parameters": {"length": "The length of the edges to be selected, which can be used for filtering"}, "values": "length: <numeric_value>", "script_paradigm": "out = in.drc(length > <length>)", "examples": [{"query": "How to select edges with a length greater than 10?", "answer": "out = in.drc(length > 10)"}], "reference": "\"DRC#length\": selects edges based on their length\n\n\"DRC#angle\": selects edges based on their orientation\n\nFor example, to select polygons with an area larger than one square micrometer, use:\n\nout = in.drc(area > 1.0)\n\nFor the condition, use the usual numerical bounds like:\n\nout = in.drc(area == 1.0)\nout = in.drc(area <= 1.0)\nout = in.drc(0.2 < area < 1.0)\n\nThe result of the area operation is the input polygon if the area condition is met.\n\nIn the same fashion, \"perimeter\" applies to the perimeter of the polygon. \"bbox_min\" etc. will evaluate a particular dimensions of the polygon's bounding box and use the respective dimension for filtering the polygon.\n\nNote that it's basically possible to use the polygon filters on any input - computed and secondaries. In fact, plain \"area\" for example is a shortcut for \"primary.area\" indicating that the area of primary shapes are supposed to be computed. However, any input other than the primary is not necessarily complete or it may consist of multiple polygons. Hence the computed values may be too big or too small. It's recommended therefore to use the measurement functions on primary polygons unless you know what you're doing.\n\nFilter predicates\n\nThe \"drc\" feature also supports some predicates. \"predicates\" are boolean values indicating a certain condition. A predicate filter works in a way that it only passes the polygons if the condition is met.\n\nThe predicates available currently are:\n\n\"DRC#rectangles\": Filters rectangles\n\n\"DRC#squares\": Filters squares\n\n\"DRC#rectilinear\": Filters rectilinear (\"Manhattan\") polygons\n\nFor the same reason as explained above, it's recommended to use these predicates standalone, so they act on primary shapes. It's possible to use the predicates on computed shapes or secondaries, but that may not render the desired results.\n\nLogical NOT operator\n\nThe \"!\" operator will evaluate the expression behind it and return the current primary shape if the input is empty and return an empty polygon set if not. Hence the following filter will deliver all polygons which are not rectangles:\n\nout = in.drc(! rectangles)\n\nLogical combination operators\n\nThe logical \"if_any\" or \"if_all\" functions allow connecting multiple conditions and evaluate to \"true\" (means: a non-empty shape set) if either one input is a non-empty shape set (\"if_any\") or if all inputs are non-empty (\"if_all\").\n\nFor example, this will select all polygons which are rectangles and whose area is larger than 20 square micrometers:\n\nout = in.drc(if_all(rectangles, area > 20.0))\n\n\"if_all\" delivers the primary shape if all of the input expressions render a non-empty result.\n\nIn contrast to this, the \"if_any\" operation will deliver the primary shape if one of the input expressions renders a non-empty result.\n\nThe \"switch\" function allows selecting one input based on the results of an expression. In the two-input form it's equivalent to \"if\". The first expression is the condition. If it evaluates to a non-empty shape set, the result of the second expression is taken. Otherwise, the result is empty.\n\nHence the following code delivers all rectangles sized by 100 nm. All other shapes are skipped:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm)))\n\nA third expression will be considered the \"else\" branch: the result of this expression will be taken if the first one is not taken. So this example will size all rectangles and leave other shapes untouched:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm), primary))\n\nIf more expressions are given, they are considered as a sequence of condition/result chain (c1, e1, c2, e2, ...) in the sense of \"if(c1) return(e1) else if(c2) return(e2) ...\". So the e1 is taken if c1 is met, e2 is taken when c1 is not met, but c2 is and so forth. If there is an odd number of expressions, the last one will be the default expression which is taken if none of the conditions is met.\n\nPolygon manipulations", "source": "klayout"}
{"script_name": "DRC#angle", "definition_description": "This script selects edges based on their orientation or angle.", "parameters": {"angle": "The orientation or angle of the edges to be selected"}, "values": "angle: <numeric_value>", "script_paradigm": "out = in.drc(angle == <angle>)", "examples": [{"query": "How to select edges with an angle of 90 degrees?", "answer": "out = in.drc(angle == 90)"}], "reference": "\"DRC#length\": selects edges based on their length\n\n\"DRC#angle\": selects edges based on their orientation\n\nFor example, to select polygons with an area larger than one square micrometer, use:\n\nout = in.drc(area > 1.0)\n\nFor the condition, use the usual numerical bounds like:\n\nout = in.drc(area == 1.0)\nout = in.drc(area <= 1.0)\nout = in.drc(0.2 < area < 1.0)\n\nThe result of the area operation is the input polygon if the area condition is met.\n\nIn the same fashion, \"perimeter\" applies to the perimeter of the polygon. \"bbox_min\" etc. will evaluate a particular dimensions of the polygon's bounding box and use the respective dimension for filtering the polygon.\n\nNote that it's basically possible to use the polygon filters on any input - computed and secondaries. In fact, plain \"area\" for example is a shortcut for \"primary.area\" indicating that the area of primary shapes are supposed to be computed. However, any input other than the primary is not necessarily complete or it may consist of multiple polygons. Hence the computed values may be too big or too small. It's recommended therefore to use the measurement functions on primary polygons unless you know what you're doing.\n\nFilter predicates\n\nThe \"drc\" feature also supports some predicates. \"predicates\" are boolean values indicating a certain condition. A predicate filter works in a way that it only passes the polygons if the condition is met.\n\nThe predicates available currently are:\n\n\"DRC#rectangles\": Filters rectangles\n\n\"DRC#squares\": Filters squares\n\n\"DRC#rectilinear\": Filters rectilinear (\"Manhattan\") polygons\n\nFor the same reason as explained above, it's recommended to use these predicates standalone, so they act on primary shapes. It's possible to use the predicates on computed shapes or secondaries, but that may not render the desired results.\n\nLogical NOT operator\n\nThe \"!\" operator will evaluate the expression behind it and return the current primary shape if the input is empty and return an empty polygon set if not. Hence the following filter will deliver all polygons which are not rectangles:\n\nout = in.drc(! rectangles)\n\nLogical combination operators\n\nThe logical \"if_any\" or \"if_all\" functions allow connecting multiple conditions and evaluate to \"true\" (means: a non-empty shape set) if either one input is a non-empty shape set (\"if_any\") or if all inputs are non-empty (\"if_all\").\n\nFor example, this will select all polygons which are rectangles and whose area is larger than 20 square micrometers:\n\nout = in.drc(if_all(rectangles, area > 20.0))\n\n\"if_all\" delivers the primary shape if all of the input expressions render a non-empty result.\n\nIn contrast to this, the \"if_any\" operation will deliver the primary shape if one of the input expressions renders a non-empty result.\n\nThe \"switch\" function allows selecting one input based on the results of an expression. In the two-input form it's equivalent to \"if\". The first expression is the condition. If it evaluates to a non-empty shape set, the result of the second expression is taken. Otherwise, the result is empty.\n\nHence the following code delivers all rectangles sized by 100 nm. All other shapes are skipped:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm)))\n\nA third expression will be considered the \"else\" branch: the result of this expression will be taken if the first one is not taken. So this example will size all rectangles and leave other shapes untouched:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm), primary))\n\nIf more expressions are given, they are considered as a sequence of condition/result chain (c1, e1, c2, e2, ...) in the sense of \"if(c1) return(e1) else if(c2) return(e2) ...\". So the e1 is taken if c1 is met, e2 is taken when c1 is not met, but c2 is and so forth. If there is an odd number of expressions, the last one will be the default expression which is taken if none of the conditions is met.\n\nPolygon manipulations", "source": "klayout"}
{"script_name": "DRC#area", "definition_description": "This script filters polygons based on their area.", "parameters": {"area": "The area condition for the polygons, can be set with different comparison operators"}, "values": "area: <numeric_value>", "script_paradigm": "out = in.drc(area > <area>)", "examples": [{"query": "How to select polygons with an area greater than 1 square micrometer?", "answer": "out = in.drc(area > 1.0)"}, {"query": "How to select polygons with an area between 0.2 and 1 square micrometer?", "answer": "out = in.drc(0.2 < area < 1.0)"}], "reference": "\"DRC#length\": selects edges based on their length\n\n\"DRC#angle\": selects edges based on their orientation\n\nFor example, to select polygons with an area larger than one square micrometer, use:\n\nout = in.drc(area > 1.0)\n\nFor the condition, use the usual numerical bounds like:\n\nout = in.drc(area == 1.0)\nout = in.drc(area <= 1.0)\nout = in.drc(0.2 < area < 1.0)\n\nThe result of the area operation is the input polygon if the area condition is met.\n\nIn the same fashion, \"perimeter\" applies to the perimeter of the polygon. \"bbox_min\" etc. will evaluate a particular dimensions of the polygon's bounding box and use the respective dimension for filtering the polygon.\n\nNote that it's basically possible to use the polygon filters on any input - computed and secondaries. In fact, plain \"area\" for example is a shortcut for \"primary.area\" indicating that the area of primary shapes are supposed to be computed. However, any input other than the primary is not necessarily complete or it may consist of multiple polygons. Hence the computed values may be too big or too small. It's recommended therefore to use the measurement functions on primary polygons unless you know what you're doing.\n\nFilter predicates\n\nThe \"drc\" feature also supports some predicates. \"predicates\" are boolean values indicating a certain condition. A predicate filter works in a way that it only passes the polygons if the condition is met.\n\nThe predicates available currently are:\n\n\"DRC#rectangles\": Filters rectangles\n\n\"DRC#squares\": Filters squares\n\n\"DRC#rectilinear\": Filters rectilinear (\"Manhattan\") polygons\n\nFor the same reason as explained above, it's recommended to use these predicates standalone, so they act on primary shapes. It's possible to use the predicates on computed shapes or secondaries, but that may not render the desired results.\n\nLogical NOT operator\n\nThe \"!\" operator will evaluate the expression behind it and return the current primary shape if the input is empty and return an empty polygon set if not. Hence the following filter will deliver all polygons which are not rectangles:\n\nout = in.drc(! rectangles)\n\nLogical combination operators\n\nThe logical \"if_any\" or \"if_all\" functions allow connecting multiple conditions and evaluate to \"true\" (means: a non-empty shape set) if either one input is a non-empty shape set (\"if_any\") or if all inputs are non-empty (\"if_all\").\n\nFor example, this will select all polygons which are rectangles and whose area is larger than 20 square micrometers:\n\nout = in.drc(if_all(rectangles, area > 20.0))\n\n\"if_all\" delivers the primary shape if all of the input expressions render a non-empty result.\n\nIn contrast to this, the \"if_any\" operation will deliver the primary shape if one of the input expressions renders a non-empty result.\n\nThe \"switch\" function allows selecting one input based on the results of an expression. In the two-input form it's equivalent to \"if\". The first expression is the condition. If it evaluates to a non-empty shape set, the result of the second expression is taken. Otherwise, the result is empty.\n\nHence the following code delivers all rectangles sized by 100 nm. All other shapes are skipped:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm)))\n\nA third expression will be considered the \"else\" branch: the result of this expression will be taken if the first one is not taken. So this example will size all rectangles and leave other shapes untouched:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm), primary))\n\nIf more expressions are given, they are considered as a sequence of condition/result chain (c1, e1, c2, e2, ...) in the sense of \"if(c1) return(e1) else if(c2) return(e2) ...\". So the e1 is taken if c1 is met, e2 is taken when c1 is not met, but c2 is and so forth. If there is an odd number of expressions, the last one will be the default expression which is taken if none of the conditions is met.\n\nPolygon manipulations", "source": "klayout"}
{"script_name": "DRC#perimeter", "definition_description": "This script filters polygons based on their perimeter.", "parameters": {"perimeter": "The perimeter condition for the polygons"}, "values": "perimeter: <numeric_value>", "script_paradigm": "out = in.drc(perimeter > <perimeter>)", "examples": [{"query": "How to select polygons with a perimeter larger than 5 micrometers?", "answer": "out = in.drc(perimeter > 5.0)"}], "reference": "\"DRC#length\": selects edges based on their length\n\n\"DRC#angle\": selects edges based on their orientation\n\nFor example, to select polygons with an area larger than one square micrometer, use:\n\nout = in.drc(area > 1.0)\n\nFor the condition, use the usual numerical bounds like:\n\nout = in.drc(area == 1.0)\nout = in.drc(area <= 1.0)\nout = in.drc(0.2 < area < 1.0)\n\nThe result of the area operation is the input polygon if the area condition is met.\n\nIn the same fashion, \"perimeter\" applies to the perimeter of the polygon. \"bbox_min\" etc. will evaluate a particular dimensions of the polygon's bounding box and use the respective dimension for filtering the polygon.\n\nNote that it's basically possible to use the polygon filters on any input - computed and secondaries. In fact, plain \"area\" for example is a shortcut for \"primary.area\" indicating that the area of primary shapes are supposed to be computed. However, any input other than the primary is not necessarily complete or it may consist of multiple polygons. Hence the computed values may be too big or too small. It's recommended therefore to use the measurement functions on primary polygons unless you know what you're doing.\n\nFilter predicates\n\nThe \"drc\" feature also supports some predicates. \"predicates\" are boolean values indicating a certain condition. A predicate filter works in a way that it only passes the polygons if the condition is met.\n\nThe predicates available currently are:\n\n\"DRC#rectangles\": Filters rectangles\n\n\"DRC#squares\": Filters squares\n\n\"DRC#rectilinear\": Filters rectilinear (\"Manhattan\") polygons\n\nFor the same reason as explained above, it's recommended to use these predicates standalone, so they act on primary shapes. It's possible to use the predicates on computed shapes or secondaries, but that may not render the desired results.\n\nLogical NOT operator\n\nThe \"!\" operator will evaluate the expression behind it and return the current primary shape if the input is empty and return an empty polygon set if not. Hence the following filter will deliver all polygons which are not rectangles:\n\nout = in.drc(! rectangles)\n\nLogical combination operators\n\nThe logical \"if_any\" or \"if_all\" functions allow connecting multiple conditions and evaluate to \"true\" (means: a non-empty shape set) if either one input is a non-empty shape set (\"if_any\") or if all inputs are non-empty (\"if_all\").\n\nFor example, this will select all polygons which are rectangles and whose area is larger than 20 square micrometers:\n\nout = in.drc(if_all(rectangles, area > 20.0))\n\n\"if_all\" delivers the primary shape if all of the input expressions render a non-empty result.\n\nIn contrast to this, the \"if_any\" operation will deliver the primary shape if one of the input expressions renders a non-empty result.\n\nThe \"switch\" function allows selecting one input based on the results of an expression. In the two-input form it's equivalent to \"if\". The first expression is the condition. If it evaluates to a non-empty shape set, the result of the second expression is taken. Otherwise, the result is empty.\n\nHence the following code delivers all rectangles sized by 100 nm. All other shapes are skipped:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm)))\n\nA third expression will be considered the \"else\" branch: the result of this expression will be taken if the first one is not taken. So this example will size all rectangles and leave other shapes untouched:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm), primary))\n\nIf more expressions are given, they are considered as a sequence of condition/result chain (c1, e1, c2, e2, ...) in the sense of \"if(c1) return(e1) else if(c2) return(e2) ...\". So the e1 is taken if c1 is met, e2 is taken when c1 is not met, but c2 is and so forth. If there is an odd number of expressions, the last one will be the default expression which is taken if none of the conditions is met.\n\nPolygon manipulations", "source": "klayout"}
{"script_name": "DRC#bbox_min", "definition_description": "This script filters polygons based on a specific dimension of their bounding box.", "parameters": {"bbox_min": "The minimum dimension of the polygon's bounding box to filter"}, "values": "bbox_min: <numeric_value>", "script_paradigm": "out = in.drc(bbox_min > <bbox_min>)", "examples": [{"query": "How to select polygons with a minimum bounding box dimension greater than 1 micrometer?", "answer": "out = in.drc(bbox_min > 1.0)"}], "reference": "\"DRC#length\": selects edges based on their length\n\n\"DRC#angle\": selects edges based on their orientation\n\nFor example, to select polygons with an area larger than one square micrometer, use:\n\nout = in.drc(area > 1.0)\n\nFor the condition, use the usual numerical bounds like:\n\nout = in.drc(area == 1.0)\nout = in.drc(area <= 1.0)\nout = in.drc(0.2 < area < 1.0)\n\nThe result of the area operation is the input polygon if the area condition is met.\n\nIn the same fashion, \"perimeter\" applies to the perimeter of the polygon. \"bbox_min\" etc. will evaluate a particular dimensions of the polygon's bounding box and use the respective dimension for filtering the polygon.\n\nNote that it's basically possible to use the polygon filters on any input - computed and secondaries. In fact, plain \"area\" for example is a shortcut for \"primary.area\" indicating that the area of primary shapes are supposed to be computed. However, any input other than the primary is not necessarily complete or it may consist of multiple polygons. Hence the computed values may be too big or too small. It's recommended therefore to use the measurement functions on primary polygons unless you know what you're doing.\n\nFilter predicates\n\nThe \"drc\" feature also supports some predicates. \"predicates\" are boolean values indicating a certain condition. A predicate filter works in a way that it only passes the polygons if the condition is met.\n\nThe predicates available currently are:\n\n\"DRC#rectangles\": Filters rectangles\n\n\"DRC#squares\": Filters squares\n\n\"DRC#rectilinear\": Filters rectilinear (\"Manhattan\") polygons\n\nFor the same reason as explained above, it's recommended to use these predicates standalone, so they act on primary shapes. It's possible to use the predicates on computed shapes or secondaries, but that may not render the desired results.\n\nLogical NOT operator\n\nThe \"!\" operator will evaluate the expression behind it and return the current primary shape if the input is empty and return an empty polygon set if not. Hence the following filter will deliver all polygons which are not rectangles:\n\nout = in.drc(! rectangles)\n\nLogical combination operators\n\nThe logical \"if_any\" or \"if_all\" functions allow connecting multiple conditions and evaluate to \"true\" (means: a non-empty shape set) if either one input is a non-empty shape set (\"if_any\") or if all inputs are non-empty (\"if_all\").\n\nFor example, this will select all polygons which are rectangles and whose area is larger than 20 square micrometers:\n\nout = in.drc(if_all(rectangles, area > 20.0))\n\n\"if_all\" delivers the primary shape if all of the input expressions render a non-empty result.\n\nIn contrast to this, the \"if_any\" operation will deliver the primary shape if one of the input expressions renders a non-empty result.\n\nThe \"switch\" function allows selecting one input based on the results of an expression. In the two-input form it's equivalent to \"if\". The first expression is the condition. If it evaluates to a non-empty shape set, the result of the second expression is taken. Otherwise, the result is empty.\n\nHence the following code delivers all rectangles sized by 100 nm. All other shapes are skipped:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm)))\n\nA third expression will be considered the \"else\" branch: the result of this expression will be taken if the first one is not taken. So this example will size all rectangles and leave other shapes untouched:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm), primary))\n\nIf more expressions are given, they are considered as a sequence of condition/result chain (c1, e1, c2, e2, ...) in the sense of \"if(c1) return(e1) else if(c2) return(e2) ...\". So the e1 is taken if c1 is met, e2 is taken when c1 is not met, but c2 is and so forth. If there is an odd number of expressions, the last one will be the default expression which is taken if none of the conditions is met.\n\nPolygon manipulations", "source": "klayout"}
{"script_name": "DRC#predicates", "definition_description": "This script applies boolean predicates to filter polygons based on certain geometric properties.", "parameters": {"rectangles": "Filter condition for rectangles", "squares": "Filter condition for squares", "rectilinear": "Filter condition for rectilinear polygons"}, "values": "rectangles: <boolean>, squares: <boolean>, rectilinear: <boolean>", "script_paradigm": "out = in.drc(<predicate>)", "examples": [{"query": "How to filter for rectangles?", "answer": "out = in.drc(rectangles)"}, {"query": "How to filter for squares?", "answer": "out = in.drc(squares)"}], "reference": "\"DRC#length\": selects edges based on their length\n\n\"DRC#angle\": selects edges based on their orientation\n\nFor example, to select polygons with an area larger than one square micrometer, use:\n\nout = in.drc(area > 1.0)\n\nFor the condition, use the usual numerical bounds like:\n\nout = in.drc(area == 1.0)\nout = in.drc(area <= 1.0)\nout = in.drc(0.2 < area < 1.0)\n\nThe result of the area operation is the input polygon if the area condition is met.\n\nIn the same fashion, \"perimeter\" applies to the perimeter of the polygon. \"bbox_min\" etc. will evaluate a particular dimensions of the polygon's bounding box and use the respective dimension for filtering the polygon.\n\nNote that it's basically possible to use the polygon filters on any input - computed and secondaries. In fact, plain \"area\" for example is a shortcut for \"primary.area\" indicating that the area of primary shapes are supposed to be computed. However, any input other than the primary is not necessarily complete or it may consist of multiple polygons. Hence the computed values may be too big or too small. It's recommended therefore to use the measurement functions on primary polygons unless you know what you're doing.\n\nFilter predicates\n\nThe \"drc\" feature also supports some predicates. \"predicates\" are boolean values indicating a certain condition. A predicate filter works in a way that it only passes the polygons if the condition is met.\n\nThe predicates available currently are:\n\n\"DRC#rectangles\": Filters rectangles\n\n\"DRC#squares\": Filters squares\n\n\"DRC#rectilinear\": Filters rectilinear (\"Manhattan\") polygons\n\nFor the same reason as explained above, it's recommended to use these predicates standalone, so they act on primary shapes. It's possible to use the predicates on computed shapes or secondaries, but that may not render the desired results.\n\nLogical NOT operator\n\nThe \"!\" operator will evaluate the expression behind it and return the current primary shape if the input is empty and return an empty polygon set if not. Hence the following filter will deliver all polygons which are not rectangles:\n\nout = in.drc(! rectangles)\n\nLogical combination operators\n\nThe logical \"if_any\" or \"if_all\" functions allow connecting multiple conditions and evaluate to \"true\" (means: a non-empty shape set) if either one input is a non-empty shape set (\"if_any\") or if all inputs are non-empty (\"if_all\").\n\nFor example, this will select all polygons which are rectangles and whose area is larger than 20 square micrometers:\n\nout = in.drc(if_all(rectangles, area > 20.0))\n\n\"if_all\" delivers the primary shape if all of the input expressions render a non-empty result.\n\nIn contrast to this, the \"if_any\" operation will deliver the primary shape if one of the input expressions renders a non-empty result.\n\nThe \"switch\" function allows selecting one input based on the results of an expression. In the two-input form it's equivalent to \"if\". The first expression is the condition. If it evaluates to a non-empty shape set, the result of the second expression is taken. Otherwise, the result is empty.\n\nHence the following code delivers all rectangles sized by 100 nm. All other shapes are skipped:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm)))\n\nA third expression will be considered the \"else\" branch: the result of this expression will be taken if the first one is not taken. So this example will size all rectangles and leave other shapes untouched:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm), primary))\n\nIf more expressions are given, they are considered as a sequence of condition/result chain (c1, e1, c2, e2, ...) in the sense of \"if(c1) return(e1) else if(c2) return(e2) ...\". So the e1 is taken if c1 is met, e2 is taken when c1 is not met, but c2 is and so forth. If there is an odd number of expressions, the last one will be the default expression which is taken if none of the conditions is met.\n\nPolygon manipulations", "source": "klayout"}
{"script_name": "DRC#logical_NOT", "definition_description": "This script applies the logical NOT operator to filter out shapes that match a condition.", "parameters": {"condition": "The condition to apply the NOT operator to"}, "values": "condition: <boolean_expression>", "script_paradigm": "out = in.drc(!<condition>)", "examples": [{"query": "How to filter out rectangles?", "answer": "out = in.drc(!rectangles)"}], "reference": "\"DRC#length\": selects edges based on their length\n\n\"DRC#angle\": selects edges based on their orientation\n\nFor example, to select polygons with an area larger than one square micrometer, use:\n\nout = in.drc(area > 1.0)\n\nFor the condition, use the usual numerical bounds like:\n\nout = in.drc(area == 1.0)\nout = in.drc(area <= 1.0)\nout = in.drc(0.2 < area < 1.0)\n\nThe result of the area operation is the input polygon if the area condition is met.\n\nIn the same fashion, \"perimeter\" applies to the perimeter of the polygon. \"bbox_min\" etc. will evaluate a particular dimensions of the polygon's bounding box and use the respective dimension for filtering the polygon.\n\nNote that it's basically possible to use the polygon filters on any input - computed and secondaries. In fact, plain \"area\" for example is a shortcut for \"primary.area\" indicating that the area of primary shapes are supposed to be computed. However, any input other than the primary is not necessarily complete or it may consist of multiple polygons. Hence the computed values may be too big or too small. It's recommended therefore to use the measurement functions on primary polygons unless you know what you're doing.\n\nFilter predicates\n\nThe \"drc\" feature also supports some predicates. \"predicates\" are boolean values indicating a certain condition. A predicate filter works in a way that it only passes the polygons if the condition is met.\n\nThe predicates available currently are:\n\n\"DRC#rectangles\": Filters rectangles\n\n\"DRC#squares\": Filters squares\n\n\"DRC#rectilinear\": Filters rectilinear (\"Manhattan\") polygons\n\nFor the same reason as explained above, it's recommended to use these predicates standalone, so they act on primary shapes. It's possible to use the predicates on computed shapes or secondaries, but that may not render the desired results.\n\nLogical NOT operator\n\nThe \"!\" operator will evaluate the expression behind it and return the current primary shape if the input is empty and return an empty polygon set if not. Hence the following filter will deliver all polygons which are not rectangles:\n\nout = in.drc(! rectangles)\n\nLogical combination operators\n\nThe logical \"if_any\" or \"if_all\" functions allow connecting multiple conditions and evaluate to \"true\" (means: a non-empty shape set) if either one input is a non-empty shape set (\"if_any\") or if all inputs are non-empty (\"if_all\").\n\nFor example, this will select all polygons which are rectangles and whose area is larger than 20 square micrometers:\n\nout = in.drc(if_all(rectangles, area > 20.0))\n\n\"if_all\" delivers the primary shape if all of the input expressions render a non-empty result.\n\nIn contrast to this, the \"if_any\" operation will deliver the primary shape if one of the input expressions renders a non-empty result.\n\nThe \"switch\" function allows selecting one input based on the results of an expression. In the two-input form it's equivalent to \"if\". The first expression is the condition. If it evaluates to a non-empty shape set, the result of the second expression is taken. Otherwise, the result is empty.\n\nHence the following code delivers all rectangles sized by 100 nm. All other shapes are skipped:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm)))\n\nA third expression will be considered the \"else\" branch: the result of this expression will be taken if the first one is not taken. So this example will size all rectangles and leave other shapes untouched:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm), primary))\n\nIf more expressions are given, they are considered as a sequence of condition/result chain (c1, e1, c2, e2, ...) in the sense of \"if(c1) return(e1) else if(c2) return(e2) ...\". So the e1 is taken if c1 is met, e2 is taken when c1 is not met, but c2 is and so forth. If there is an odd number of expressions, the last one will be the default expression which is taken if none of the conditions is met.\n\nPolygon manipulations", "source": "klayout"}
{"script_name": "DRC#if_any", "definition_description": "This script connects multiple conditions and selects polygons if any of the conditions is met.", "parameters": {"condition1": "First condition to be evaluated", "condition2": "Second condition to be evaluated"}, "values": "condition1: <boolean_expression>, condition2: <boolean_expression>", "script_paradigm": "out = in.drc(if_any(<condition1>, <condition2>))", "examples": [{"query": "How to select polygons which are either rectangles or have an area greater than 20 micrometers?", "answer": "out = in.drc(if_any(rectangles, area > 20.0))"}], "reference": "\"DRC#length\": selects edges based on their length\n\n\"DRC#angle\": selects edges based on their orientation\n\nFor example, to select polygons with an area larger than one square micrometer, use:\n\nout = in.drc(area > 1.0)\n\nFor the condition, use the usual numerical bounds like:\n\nout = in.drc(area == 1.0)\nout = in.drc(area <= 1.0)\nout = in.drc(0.2 < area < 1.0)\n\nThe result of the area operation is the input polygon if the area condition is met.\n\nIn the same fashion, \"perimeter\" applies to the perimeter of the polygon. \"bbox_min\" etc. will evaluate a particular dimensions of the polygon's bounding box and use the respective dimension for filtering the polygon.\n\nNote that it's basically possible to use the polygon filters on any input - computed and secondaries. In fact, plain \"area\" for example is a shortcut for \"primary.area\" indicating that the area of primary shapes are supposed to be computed. However, any input other than the primary is not necessarily complete or it may consist of multiple polygons. Hence the computed values may be too big or too small. It's recommended therefore to use the measurement functions on primary polygons unless you know what you're doing.\n\nFilter predicates\n\nThe \"drc\" feature also supports some predicates. \"predicates\" are boolean values indicating a certain condition. A predicate filter works in a way that it only passes the polygons if the condition is met.\n\nThe predicates available currently are:\n\n\"DRC#rectangles\": Filters rectangles\n\n\"DRC#squares\": Filters squares\n\n\"DRC#rectilinear\": Filters rectilinear (\"Manhattan\") polygons\n\nFor the same reason as explained above, it's recommended to use these predicates standalone, so they act on primary shapes. It's possible to use the predicates on computed shapes or secondaries, but that may not render the desired results.\n\nLogical NOT operator\n\nThe \"!\" operator will evaluate the expression behind it and return the current primary shape if the input is empty and return an empty polygon set if not. Hence the following filter will deliver all polygons which are not rectangles:\n\nout = in.drc(! rectangles)\n\nLogical combination operators\n\nThe logical \"if_any\" or \"if_all\" functions allow connecting multiple conditions and evaluate to \"true\" (means: a non-empty shape set) if either one input is a non-empty shape set (\"if_any\") or if all inputs are non-empty (\"if_all\").\n\nFor example, this will select all polygons which are rectangles and whose area is larger than 20 square micrometers:\n\nout = in.drc(if_all(rectangles, area > 20.0))\n\n\"if_all\" delivers the primary shape if all of the input expressions render a non-empty result.\n\nIn contrast to this, the \"if_any\" operation will deliver the primary shape if one of the input expressions renders a non-empty result.\n\nThe \"switch\" function allows selecting one input based on the results of an expression. In the two-input form it's equivalent to \"if\". The first expression is the condition. If it evaluates to a non-empty shape set, the result of the second expression is taken. Otherwise, the result is empty.\n\nHence the following code delivers all rectangles sized by 100 nm. All other shapes are skipped:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm)))\n\nA third expression will be considered the \"else\" branch: the result of this expression will be taken if the first one is not taken. So this example will size all rectangles and leave other shapes untouched:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm), primary))\n\nIf more expressions are given, they are considered as a sequence of condition/result chain (c1, e1, c2, e2, ...) in the sense of \"if(c1) return(e1) else if(c2) return(e2) ...\". So the e1 is taken if c1 is met, e2 is taken when c1 is not met, but c2 is and so forth. If there is an odd number of expressions, the last one will be the default expression which is taken if none of the conditions is met.\n\nPolygon manipulations", "source": "klayout"}
{"script_name": "DRC#if_all", "definition_description": "This script connects multiple conditions and selects polygons if all conditions are met.", "parameters": {"condition1": "First condition to be evaluated", "condition2": "Second condition to be evaluated"}, "values": "condition1: <boolean_expression>, condition2: <boolean_expression>", "script_paradigm": "out = in.drc(if_all(<condition1>, <condition2>))", "examples": [{"query": "How to select polygons which are rectangles and have an area larger than 20 micrometers?", "answer": "out = in.drc(if_all(rectangles, area > 20.0))"}], "reference": "\"DRC#length\": selects edges based on their length\n\n\"DRC#angle\": selects edges based on their orientation\n\nFor example, to select polygons with an area larger than one square micrometer, use:\n\nout = in.drc(area > 1.0)\n\nFor the condition, use the usual numerical bounds like:\n\nout = in.drc(area == 1.0)\nout = in.drc(area <= 1.0)\nout = in.drc(0.2 < area < 1.0)\n\nThe result of the area operation is the input polygon if the area condition is met.\n\nIn the same fashion, \"perimeter\" applies to the perimeter of the polygon. \"bbox_min\" etc. will evaluate a particular dimensions of the polygon's bounding box and use the respective dimension for filtering the polygon.\n\nNote that it's basically possible to use the polygon filters on any input - computed and secondaries. In fact, plain \"area\" for example is a shortcut for \"primary.area\" indicating that the area of primary shapes are supposed to be computed. However, any input other than the primary is not necessarily complete or it may consist of multiple polygons. Hence the computed values may be too big or too small. It's recommended therefore to use the measurement functions on primary polygons unless you know what you're doing.\n\nFilter predicates\n\nThe \"drc\" feature also supports some predicates. \"predicates\" are boolean values indicating a certain condition. A predicate filter works in a way that it only passes the polygons if the condition is met.\n\nThe predicates available currently are:\n\n\"DRC#rectangles\": Filters rectangles\n\n\"DRC#squares\": Filters squares\n\n\"DRC#rectilinear\": Filters rectilinear (\"Manhattan\") polygons\n\nFor the same reason as explained above, it's recommended to use these predicates standalone, so they act on primary shapes. It's possible to use the predicates on computed shapes or secondaries, but that may not render the desired results.\n\nLogical NOT operator\n\nThe \"!\" operator will evaluate the expression behind it and return the current primary shape if the input is empty and return an empty polygon set if not. Hence the following filter will deliver all polygons which are not rectangles:\n\nout = in.drc(! rectangles)\n\nLogical combination operators\n\nThe logical \"if_any\" or \"if_all\" functions allow connecting multiple conditions and evaluate to \"true\" (means: a non-empty shape set) if either one input is a non-empty shape set (\"if_any\") or if all inputs are non-empty (\"if_all\").\n\nFor example, this will select all polygons which are rectangles and whose area is larger than 20 square micrometers:\n\nout = in.drc(if_all(rectangles, area > 20.0))\n\n\"if_all\" delivers the primary shape if all of the input expressions render a non-empty result.\n\nIn contrast to this, the \"if_any\" operation will deliver the primary shape if one of the input expressions renders a non-empty result.\n\nThe \"switch\" function allows selecting one input based on the results of an expression. In the two-input form it's equivalent to \"if\". The first expression is the condition. If it evaluates to a non-empty shape set, the result of the second expression is taken. Otherwise, the result is empty.\n\nHence the following code delivers all rectangles sized by 100 nm. All other shapes are skipped:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm)))\n\nA third expression will be considered the \"else\" branch: the result of this expression will be taken if the first one is not taken. So this example will size all rectangles and leave other shapes untouched:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm), primary))\n\nIf more expressions are given, they are considered as a sequence of condition/result chain (c1, e1, c2, e2, ...) in the sense of \"if(c1) return(e1) else if(c2) return(e2) ...\". So the e1 is taken if c1 is met, e2 is taken when c1 is not met, but c2 is and so forth. If there is an odd number of expressions, the last one will be the default expression which is taken if none of the conditions is met.\n\nPolygon manipulations", "source": "klayout"}
{"script_name": "DRC#switch", "definition_description": "This script selects one input based on the results of a condition.", "parameters": {"condition": "The condition to evaluate", "true_result": "The result if the condition is met", "false_result": "The result if the condition is not met"}, "values": "condition: <boolean_expression>, true_result: <result>, false_result: <result>", "script_paradigm": "out = in.drc(switch(<condition>, <true_result>, <false_result>))", "examples": [{"query": "How to select rectangles sized by 100 nm?", "answer": "out = in.drc(switch(rectangles, primary.sized(100.nm)))"}], "reference": "\"DRC#length\": selects edges based on their length\n\n\"DRC#angle\": selects edges based on their orientation\n\nFor example, to select polygons with an area larger than one square micrometer, use:\n\nout = in.drc(area > 1.0)\n\nFor the condition, use the usual numerical bounds like:\n\nout = in.drc(area == 1.0)\nout = in.drc(area <= 1.0)\nout = in.drc(0.2 < area < 1.0)\n\nThe result of the area operation is the input polygon if the area condition is met.\n\nIn the same fashion, \"perimeter\" applies to the perimeter of the polygon. \"bbox_min\" etc. will evaluate a particular dimensions of the polygon's bounding box and use the respective dimension for filtering the polygon.\n\nNote that it's basically possible to use the polygon filters on any input - computed and secondaries. In fact, plain \"area\" for example is a shortcut for \"primary.area\" indicating that the area of primary shapes are supposed to be computed. However, any input other than the primary is not necessarily complete or it may consist of multiple polygons. Hence the computed values may be too big or too small. It's recommended therefore to use the measurement functions on primary polygons unless you know what you're doing.\n\nFilter predicates\n\nThe \"drc\" feature also supports some predicates. \"predicates\" are boolean values indicating a certain condition. A predicate filter works in a way that it only passes the polygons if the condition is met.\n\nThe predicates available currently are:\n\n\"DRC#rectangles\": Filters rectangles\n\n\"DRC#squares\": Filters squares\n\n\"DRC#rectilinear\": Filters rectilinear (\"Manhattan\") polygons\n\nFor the same reason as explained above, it's recommended to use these predicates standalone, so they act on primary shapes. It's possible to use the predicates on computed shapes or secondaries, but that may not render the desired results.\n\nLogical NOT operator\n\nThe \"!\" operator will evaluate the expression behind it and return the current primary shape if the input is empty and return an empty polygon set if not. Hence the following filter will deliver all polygons which are not rectangles:\n\nout = in.drc(! rectangles)\n\nLogical combination operators\n\nThe logical \"if_any\" or \"if_all\" functions allow connecting multiple conditions and evaluate to \"true\" (means: a non-empty shape set) if either one input is a non-empty shape set (\"if_any\") or if all inputs are non-empty (\"if_all\").\n\nFor example, this will select all polygons which are rectangles and whose area is larger than 20 square micrometers:\n\nout = in.drc(if_all(rectangles, area > 20.0))\n\n\"if_all\" delivers the primary shape if all of the input expressions render a non-empty result.\n\nIn contrast to this, the \"if_any\" operation will deliver the primary shape if one of the input expressions renders a non-empty result.\n\nThe \"switch\" function allows selecting one input based on the results of an expression. In the two-input form it's equivalent to \"if\". The first expression is the condition. If it evaluates to a non-empty shape set, the result of the second expression is taken. Otherwise, the result is empty.\n\nHence the following code delivers all rectangles sized by 100 nm. All other shapes are skipped:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm)))\n\nA third expression will be considered the \"else\" branch: the result of this expression will be taken if the first one is not taken. So this example will size all rectangles and leave other shapes untouched:\n\nout = in.drc(switch(rectangles, primary.sized(100.nm), primary))\n\nIf more expressions are given, they are considered as a sequence of condition/result chain (c1, e1, c2, e2, ...) in the sense of \"if(c1) return(e1) else if(c2) return(e2) ...\". So the e1 is taken if c1 is met, e2 is taken when c1 is not met, but c2 is and so forth. If there is an odd number of expressions, the last one will be the default expression which is taken if none of the conditions is met.\n\nPolygon manipulations", "source": "klayout"}
{"script_name": "eval", "definition_description": "This script evaluates the value of a signal based on the value of all required inputs.", "parameters": {"selection": "The selection of the signal whose value needs to be evaluated", "options": "Various options to modify the evaluation process, including setting signal values or showing values"}, "values": "selection: <signal>, options: [-set <signal> <value>, -set-undef, -table <signal>, -show <signal>]", "script_paradigm": "eval [options] [selection]", "examples": [{"query": "How to evaluate the value of the signal 'clk'?", "answer": "eval clk"}, {"query": "Set the signal 'clk' to 1 and evaluate its value.", "answer": "eval -set clk 1"}, {"query": "Show the value of the signal 'reset' during evaluation.", "answer": "eval -show reset"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n-maxiter <N>\nmaximum number of iterations to run before aborting\n10.68 eval - evaluate the circuit given an input\nyosys> help eval\neval [options] [selection]\nThis command evaluates the value of a signal given the value of all required\ninputs.\n-set <signal> <value>\nset the specified signal to the specified value.\n-set-undef\nset all unspecified source signals to undef (x)\n-table <signal>\ncreate a truth table using the specified input signals\n-show <signal>\nshow the value for the specified signal. if no -show option is passed\nthen all output ports of the current module are used.\n10.69 example_dt - drivertools example\nyosys> help example_dt\nTODO: add help message\n10.70 exec - execute commands in the operating system shell\nyosys> help exec\nexec [options] -- [command]\nExecute a command in the operating system shell.\nAll supplied arguments are\nconcatenated and passed as a command to popen(3).\nWhitespace is not guaranteed\nto be preserved, even if quoted.\nstdin and stderr are not connected, while\nstdout is logged unless the \"-q\" option is specified.\n-q\nSuppress stdout and stderr from subprocess\n-expect-return <int>\n(continues on next page)\n10.68.\neval - evaluate the circuit given an input\n399", "source": "yosys_hq"}
{"script_name": "exec", "definition_description": "This script executes commands in the operating system shell from within Yosys.", "parameters": {"command": "The command to execute in the operating system shell", "options": "Various options to control the execution, such as suppressing output or specifying an expected return value"}, "values": "command: <command>, options: [-q, -expect-return <int>]", "script_paradigm": "exec [options] -- [command]", "examples": [{"query": "How to execute the shell command 'ls' and suppress the output?", "answer": "exec -q -- ls"}, {"query": "Execute the command 'make' and expect a return value of 0.", "answer": "exec -expect-return 0 -- make"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n-maxiter <N>\nmaximum number of iterations to run before aborting\n10.68 eval - evaluate the circuit given an input\nyosys> help eval\neval [options] [selection]\nThis command evaluates the value of a signal given the value of all required\ninputs.\n-set <signal> <value>\nset the specified signal to the specified value.\n-set-undef\nset all unspecified source signals to undef (x)\n-table <signal>\ncreate a truth table using the specified input signals\n-show <signal>\nshow the value for the specified signal. if no -show option is passed\nthen all output ports of the current module are used.\n10.69 example_dt - drivertools example\nyosys> help example_dt\nTODO: add help message\n10.70 exec - execute commands in the operating system shell\nyosys> help exec\nexec [options] -- [command]\nExecute a command in the operating system shell.\nAll supplied arguments are\nconcatenated and passed as a command to popen(3).\nWhitespace is not guaranteed\nto be preserved, even if quoted.\nstdin and stderr are not connected, while\nstdout is logged unless the \"-q\" option is specified.\n-q\nSuppress stdout and stderr from subprocess\n-expect-return <int>\n(continues on next page)\n10.68.\neval - evaluate the circuit given an input\n399", "source": "yosys_hq"}
{"script_name": "show", "definition_description": "This script generates a graphical representation of the current circuit design in a specified format.", "parameters": {"format": "The format in which the circuit diagram will be output (e.g., 'dot')", "prefix": "The prefix to be added to the output files' names"}, "values": "format: dot, prefix: cmos_00", "script_paradigm": "show -format <format> -prefix <prefix>", "examples": [{"query": "How to generate a circuit diagram in dot format with prefix cmos_00?", "answer": "show -format dot -prefix cmos_00"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nexample\na\nA\nB\n$2\n$add\nY\nb\nc\nCLK\nD\nEN\n$7\n$dffe\nQ\nclk\ny\nFig. 3.26: Output of the third show command in example_show.ys\n(continued from previous page)\n{a, b, -{c, d}, ~{e, f}};\nendmodule\nNotice how the output for this circuit from the show command (Fig. 3.27) appears quite complex. This is\nan unfortunate side effect of the way Yosys handles signal vectors (aka. multi-bit wires or buses) as native\nobjects. While this provides great advantages when analyzing circuits that operate on wide integers, it also\nintroduces some additional complexity when the individual bits of of a signal vector are accessed.\nThe key elements in understanding this circuit diagram are of course the boxes with round corners and rows\nlabeled <MSB_LEFT>:<LSB_LEFT> - <MSB_RIGHT>:<LSB_RIGHT>. Each of these boxes have one signal per\nrow on one side and a common signal for all rows on the other side. The <MSB>:<LSB> tuples specify which\nbits of the signals are broken out and connected. So the top row of the box connecting the signals a and x\nindicates that the bit 0 (i.e. the range 0:0) from signal a is connected to bit 1 (i.e. the range 1:1) of signal x.\nLines connecting such boxes together and lines connecting such boxes to cell ports have a slightly different\nlook to emphasise that they are not actual signal wires but a necessity of the graphical representation. This\ndistinction seems like a technicality, until one wants to debug a problem related to the way Yosys internally\nrepresents signal vectors, for example when writing custom Yosys commands.\nGate level netlists\nFig. 3.28 shows two common pitfalls when working with designs mapped to a cell library:\nListing 3.51: Generating Fig. 3.28\nread_verilog cmos.v\nprep -top cmos_demo\ntechmap\nabc -liberty . . /intro/mycells.lib;;\nshow -format dot -prefix cmos_00\n108\nChapter 3.\nUsing Yosys (advanced)", "source": "yosys_hq"}
{"script_name": "techmap", "definition_description": "This script performs technology mapping for the design to target a specific library of standard cells.", "parameters": {}, "values": "None", "script_paradigm": "techmap", "examples": [{"query": "How to perform technology mapping for the design?", "answer": "techmap"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nexample\na\nA\nB\n$2\n$add\nY\nb\nc\nCLK\nD\nEN\n$7\n$dffe\nQ\nclk\ny\nFig. 3.26: Output of the third show command in example_show.ys\n(continued from previous page)\n{a, b, -{c, d}, ~{e, f}};\nendmodule\nNotice how the output for this circuit from the show command (Fig. 3.27) appears quite complex. This is\nan unfortunate side effect of the way Yosys handles signal vectors (aka. multi-bit wires or buses) as native\nobjects. While this provides great advantages when analyzing circuits that operate on wide integers, it also\nintroduces some additional complexity when the individual bits of of a signal vector are accessed.\nThe key elements in understanding this circuit diagram are of course the boxes with round corners and rows\nlabeled <MSB_LEFT>:<LSB_LEFT> - <MSB_RIGHT>:<LSB_RIGHT>. Each of these boxes have one signal per\nrow on one side and a common signal for all rows on the other side. The <MSB>:<LSB> tuples specify which\nbits of the signals are broken out and connected. So the top row of the box connecting the signals a and x\nindicates that the bit 0 (i.e. the range 0:0) from signal a is connected to bit 1 (i.e. the range 1:1) of signal x.\nLines connecting such boxes together and lines connecting such boxes to cell ports have a slightly different\nlook to emphasise that they are not actual signal wires but a necessity of the graphical representation. This\ndistinction seems like a technicality, until one wants to debug a problem related to the way Yosys internally\nrepresents signal vectors, for example when writing custom Yosys commands.\nGate level netlists\nFig. 3.28 shows two common pitfalls when working with designs mapped to a cell library:\nListing 3.51: Generating Fig. 3.28\nread_verilog cmos.v\nprep -top cmos_demo\ntechmap\nabc -liberty . . /intro/mycells.lib;;\nshow -format dot -prefix cmos_00\n108\nChapter 3.\nUsing Yosys (advanced)", "source": "yosys_hq"}
{"script_name": "abc", "definition_description": "This script performs logic synthesis using the ABC tool and targets a specific standard cell library.", "parameters": {"liberty_file": "The path to the Liberty file that describes the standard cells"}, "values": "liberty_file: /intro/mycells.lib", "script_paradigm": "abc -liberty <liberty_file>", "examples": [{"query": "How to perform logic synthesis using the abc tool with a specific liberty file?", "answer": "abc -liberty /intro/mycells.lib"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nexample\na\nA\nB\n$2\n$add\nY\nb\nc\nCLK\nD\nEN\n$7\n$dffe\nQ\nclk\ny\nFig. 3.26: Output of the third show command in example_show.ys\n(continued from previous page)\n{a, b, -{c, d}, ~{e, f}};\nendmodule\nNotice how the output for this circuit from the show command (Fig. 3.27) appears quite complex. This is\nan unfortunate side effect of the way Yosys handles signal vectors (aka. multi-bit wires or buses) as native\nobjects. While this provides great advantages when analyzing circuits that operate on wide integers, it also\nintroduces some additional complexity when the individual bits of of a signal vector are accessed.\nThe key elements in understanding this circuit diagram are of course the boxes with round corners and rows\nlabeled <MSB_LEFT>:<LSB_LEFT> - <MSB_RIGHT>:<LSB_RIGHT>. Each of these boxes have one signal per\nrow on one side and a common signal for all rows on the other side. The <MSB>:<LSB> tuples specify which\nbits of the signals are broken out and connected. So the top row of the box connecting the signals a and x\nindicates that the bit 0 (i.e. the range 0:0) from signal a is connected to bit 1 (i.e. the range 1:1) of signal x.\nLines connecting such boxes together and lines connecting such boxes to cell ports have a slightly different\nlook to emphasise that they are not actual signal wires but a necessity of the graphical representation. This\ndistinction seems like a technicality, until one wants to debug a problem related to the way Yosys internally\nrepresents signal vectors, for example when writing custom Yosys commands.\nGate level netlists\nFig. 3.28 shows two common pitfalls when working with designs mapped to a cell library:\nListing 3.51: Generating Fig. 3.28\nread_verilog cmos.v\nprep -top cmos_demo\ntechmap\nabc -liberty . . /intro/mycells.lib;;\nshow -format dot -prefix cmos_00\n108\nChapter 3.\nUsing Yosys (advanced)", "source": "yosys_hq"}
{"script_name": "prep", "definition_description": "This script prepares the design for further operations, such as mapping, synthesis, or verification.", "parameters": {"top_module": "The name of the top module to be used in the design"}, "values": "top_module: cmos_demo", "script_paradigm": "prep -top <top_module>", "examples": [{"query": "How to prepare the design for the top module cmos_demo?", "answer": "prep -top cmos_demo"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nexample\na\nA\nB\n$2\n$add\nY\nb\nc\nCLK\nD\nEN\n$7\n$dffe\nQ\nclk\ny\nFig. 3.26: Output of the third show command in example_show.ys\n(continued from previous page)\n{a, b, -{c, d}, ~{e, f}};\nendmodule\nNotice how the output for this circuit from the show command (Fig. 3.27) appears quite complex. This is\nan unfortunate side effect of the way Yosys handles signal vectors (aka. multi-bit wires or buses) as native\nobjects. While this provides great advantages when analyzing circuits that operate on wide integers, it also\nintroduces some additional complexity when the individual bits of of a signal vector are accessed.\nThe key elements in understanding this circuit diagram are of course the boxes with round corners and rows\nlabeled <MSB_LEFT>:<LSB_LEFT> - <MSB_RIGHT>:<LSB_RIGHT>. Each of these boxes have one signal per\nrow on one side and a common signal for all rows on the other side. The <MSB>:<LSB> tuples specify which\nbits of the signals are broken out and connected. So the top row of the box connecting the signals a and x\nindicates that the bit 0 (i.e. the range 0:0) from signal a is connected to bit 1 (i.e. the range 1:1) of signal x.\nLines connecting such boxes together and lines connecting such boxes to cell ports have a slightly different\nlook to emphasise that they are not actual signal wires but a necessity of the graphical representation. This\ndistinction seems like a technicality, until one wants to debug a problem related to the way Yosys internally\nrepresents signal vectors, for example when writing custom Yosys commands.\nGate level netlists\nFig. 3.28 shows two common pitfalls when working with designs mapped to a cell library:\nListing 3.51: Generating Fig. 3.28\nread_verilog cmos.v\nprep -top cmos_demo\ntechmap\nabc -liberty . . /intro/mycells.lib;;\nshow -format dot -prefix cmos_00\n108\nChapter 3.\nUsing Yosys (advanced)", "source": "yosys_hq"}
{"script_name": "ContributeToOpenROAD", "definition_description": "This script provides guidelines on how to contribute to the OpenROAD project, including contributions related to PDK, designs, scripts, and following licensing rules.", "parameters": {"contribution_type": "Defines the type of contribution being made (e.g., PDK, Design, Script, etc.)", "license_type": "Specifies the license under which the contribution is made (e.g., BSD3, MIT, Apache2.0)", "add_tests": "Indicates whether new tests should be added for the contributed code"}, "values": "contribution_type: <type>, license_type: <license>, add_tests: <true/false>", "script_paradigm": "contribute -type <contribution_type> -license <license_type> -tests <add_tests>", "examples": [{"query": "How to contribute a new PDK with a BSD3 license and add tests?", "answer": "contribute -type PDK -license BSD3 -tests true"}, {"query": "How to contribute a new design with MIT license without tests?", "answer": "contribute -type Design -license MIT -tests false"}, {"query": "How to contribute a script under the Apache2.0 license with tests?", "answer": "contribute -type Script -license Apache2.0 -tests true"}], "reference": "Getting Involved\nThank you for taking the time to read this document and to contribute.\nThe OpenROAD project will not reach all of its objectives without help!\nPossible ways to contribute in the scope of OpenROAD Flow:\n\nOpen-source PDK information\nOpen-source Designs\nUseful scripts\nStar our project and repos so we can see the number of people\n    who are interested\n\nLicensing Contributions\nAs much as possible, all contributions should be licensed using the BSD3\nlicense. You can propose another license if you must, but contributions\nmade with BSD3 fit best with the spirit of OpenROAD's permissive open-source\nphilosophy. We do have exceptions in the project, but over time we hope\nthat all contributions will be BSD3, or some other permissive license such as MIT\nor Apache2.0.\nContributing Open Source PDK information and Designs\nIf you have new design or PDK information to contribute, please add this\nto the repo\nOpenROAD-flow-scripts.\nIn the\nflow directory\nyou will see a directory for\ndesigns\nwith Makefiles to run them, and one for PDK\nplatforms\nused by the designs. If you add a new PDK platform, be sure to add at\nleast one design that uses it.\nContributing Scripts and Code\nWe follow the Google C++ style guide.\nIf you find code in our project that does not follow this guide, then within each file that\nyou edit, follow the style in that file.\nPlease pay careful attention to the\ntool checklist for all code. If you want\nto add or improve functionality in OpenROAD, please start with the\ntop-level app repo. You\ncan see in the src directory that submodules exist pointing to tested\nversions of the other relevant repos in the project. Please look at the\ntool workflow in the developer guide document\nto work with the app and its submodule repos in an efficient way.\nPlease run clang-format on all the C++ source files that you change, before\ncommitting. In the root directory of the OpenROAD repository there is the\nfile .clang-format that defines all coding formatting rules.\nPlease pay attention to the\ntest directory\nand be sure to add tests for any code changes that you make, using open-source\nPDK and design information. We provide the nangate45 PDK in\nthe OpenROAD-flow-scripts repo to help with this. Pull requests with\ncode changes are unlikely to be accepted without accompanying test\ncases. There are many\nexamples\ntests. Each repo has a test directory as well with tests you should run\nand add to if you modify something in one of the submodules.\nFor changes that claim to improve QoR or PPA, please run many tests and\nensure that the improvement is not design-specific. There are designs in\nthe\nOpenROAD-flow-scripts\nrepo which can be used unless the improvement is technology-specific.\nDo not add runtime or build dependencies without serious thought. For a\nproject like OpenROAD with many application subcomponents, the software\narchitecture can quickly get out of control. Changes with lots of new\ndependencies which are not necessary are less likely to be integrated.\nIf you want to add Tcl code to define a new tool command, look at pdngen\nas an example of how to do so. Take a look at the\nCMakeLists file\nwhich automatically sources the Tcl code and the\nTcl file\nitself.\nTo accept contributions, we require each commit to be made with a DCO (Developer\nCertificate of Origin) attached.\nWhen you commit you add the -s flag to your commit. For example:\nshell\ngit commit -s -m \"test dco with -s\"\nThis will append a statement to your commit comment that attests to the DCO. GitHub\nhas built in the -s option to its command line since use of this is so\npervasive. The promise is very basic, certifying that you know that you\nhave the right to commit the code. Please read the  full statement\nhere.\nQuestions\nPlease refer to our FAQs.", "source": "OpenROAD_flow_script"}
{"script_name": "UpCounter", "definition_description": "This script defines a 16-bit up counter with enable input and overflow output. The counter overflows when it reaches a fixed limit.", "parameters": {"limit": "The value at which the counter overflows. This is a fixed value set at design time."}, "values": "limit: <int>", "script_paradigm": "from amaranth import *\nfrom amaranth.lib import wiring\nfrom amaranth.lib.wiring import In, Out\n\nclass UpCounter(wiring.Component):\n    def __init__(self, limit):\n        self.limit = limit\n        self.count = Signal(16)\n        super().__init__()\n    def elaborate(self, platform):\n        m = Module()\n        m.d.comb += self.ovf.eq(self.count == self.limit)\n        with m.If(self.en):\n            with m.If(self.ovf):\n                m.d.sync += self.count.eq(0)\n            with m.Else():\n                m.d.sync += self.count.eq(self.count + 1)\n        return m", "examples": [{"query": "How to implement a 16-bit up counter with a limit of 25?", "answer": "from amaranth import *\nfrom amaranth.lib import wiring\nfrom amaranth.lib.wiring import In, Out\n\nclass UpCounter(wiring.Component):\n    def __init__(self, limit):\n        self.limit = limit\n        self.count = Signal(16)\n        super().__init__()\n    def elaborate(self, platform):\n        m = Module()\n        m.d.comb += self.ovf.eq(self.count == self.limit)\n        with m.If(self.en):\n            with m.If(self.ovf):\n                m.d.sync += self.count.eq(0)\n            with m.Else():\n                m.d.sync += self.count.eq(self.count + 1)\n        return m"}], "reference": "Language & toolchain\n\nGetting started\n\nView page source\n\nGetting started\n\nThis section demonstrates the basic Amaranth workflow to provide a cursory overview of the language and the toolchain. See the tutorial for a step-by-step introduction to the language, and the language guide for a detailed explanation of every language construct.\n\nA counter\n\nAs a first example, consider a counter with a fixed limit, enable, and overflow. The code for this example is shown below. Download and run it:\n\n$ python3 up_counter.py\r\n\nImplementing a counter\n\nA 16-bit up counter with enable input, overflow output, and a limit fixed at design time can be implemented in Amaranth as follows:\n\n 1from amaranth import *\r\n 2from amaranth.lib import wiring\r\n 3from amaranth.lib.wiring import In, Out\r\n 4\r\n 5\r\n 6class UpCounter(wiring.Component):\r\n 7    \"\"\"\r\n 8    A 16-bit up counter with a fixed limit.\r\n 9\r\n10    Parameters\r\n11    ----------\r\n12    limit : int\r\n13        The value at which the counter overflows.\r\n14\r\n15    Attributes\r\n16    ----------\r\n17    en : Signal, in\r\n18        The counter is incremented if ``en`` is asserted, and retains\r\n19        its value otherwise.\r\n20    ovf : Signal, out\r\n21        ``ovf`` is asserted when the counter reaches its limit.\r\n22    \"\"\"\r\n23\r\n24    en: In(1)\r\n25    ovf: Out(1)\r\n26\r\n27    def __init__(self, limit):\r\n28        self.limit = limit\r\n29        self.count = Signal(16)\r\n30\r\n31        super().__init__()\r\n32\r\n33    def elaborate(self, platform):\r\n34        m = Module()\r\n35\r\n36        m.d.comb += self.ovf.eq(self.count == self.limit)\r\n37\r\n38        with m.If(self.en):\r\n39            with m.If(self.ovf):\r\n40                m.d.sync += self.count.eq(0)\r\n41            with m.Else():\r\n42                m.d.sync += self.count.eq(self.count + 1)\r\n43\r\n44        return m\r\n\nThe reusable building block of Amaranth designs is a Component: a Python class declares its interface (en and ovf, in this case) and implements the elaborate method that defines its behavior.\n\nMost elaborate implementations use a Module helper to describe combinational (m.d.comb) and synchronous (m.d.sync) logic controlled with conditional syntax (m.If, m.Elif, m.Else) similar to Python’s. They can also instantiate vendor-defined black boxes or modules written in other HDLs.\n\nTesting a counter\n\nTo verify its functionality, the counter can be simulated for a small amount of time, with a test bench driving it and checking a few simple conditions:\n\n46from amaranth.sim import Simulator, Period\r\n47\r\n48\r\n49dut = UpCounter(25)\r\n50async def bench(ctx):\r\n51    # Disabled counter should not overflow.\r\n52    ctx.set(dut.en, 0)\r\n53    for _ in range(30):\r\n54        await ctx.tick()\r\n55        assert not ctx.get(dut.ovf)\r\n56\r\n57    # Once enabled, the counter should overflow in 25 cycles.\r\n58    ctx.set(dut.en, 1)\r\n59    for _ in range(24):\r\n60        await ctx.tick()\r\n61        assert not ctx.get(dut.ovf)\r\n62    await ctx.tick()\r\n63    assert ctx.get(dut.ovf)\r\n64\r\n65    # The overflow should clear in one cycle.\r\n66    await ctx.tick()\r\n67    assert not ctx.get(dut.ovf)\r\n68\r\n69\r\n70sim = Simulator(dut)\r\n71sim.add_clock(Period(MHz=1))\r\n72sim.add_testbench(bench)\r\n73with sim.write_vcd(\"up_counter.vcd\"):\r\n74    sim.run()\r\n\nThe testbench is implemented as a Python async function that is simulated concurrently with the counter itself. The testbench can inspect the simulated signals using ctx.get(sig), update them using ctx.set(sig, val), and advance the simulation by one clock cycle with await ctx.tick(). See the simulator documentation for details.\n\nWhen run, the testbench finishes successfully, since all of the assertions hold, and produces a VCD file with waveforms recorded for every Signal as well as the clock of the sync domain:\n\nConverting a counter\n\nAlthough some Amaranth workflows do not include Verilog at all, it is still the de facto standard for HDL interoperability. Any Amaranth design can be converted to synthesizable Verilog using the corresponding backend:", "source": "amaranth"}
{"script_name": "CounterTestbench", "definition_description": "This script defines a testbench for the UpCounter, simulating its behavior and checking its overflow condition.", "parameters": {}, "values": "N/A", "script_paradigm": "from amaranth.sim import Simulator, Period\n\ndut = UpCounter(25)\nasync def bench(ctx):\n    ctx.set(dut.en, 0)\n    for _ in range(30):\n        await ctx.tick()\n        assert not ctx.get(dut.ovf)\n    ctx.set(dut.en, 1)\n    for _ in range(24):\n        await ctx.tick()\n        assert not ctx.get(dut.ovf)\n    await ctx.tick()\n    assert ctx.get(dut.ovf)\n    await ctx.tick()\n    assert not ctx.get(dut.ovf)\n\nsim = Simulator(dut)\nsim.add_clock(Period(MHz=1))\nsim.add_testbench(bench)\nwith sim.write_vcd('up_counter.vcd'):\n    sim.run()", "examples": [{"query": "How to test the functionality of the UpCounter with a limit of 25?", "answer": "from amaranth.sim import Simulator, Period\n\ndut = UpCounter(25)\nasync def bench(ctx):\n    ctx.set(dut.en, 0)\n    for _ in range(30):\n        await ctx.tick()\n        assert not ctx.get(dut.ovf)\n    ctx.set(dut.en, 1)\n    for _ in range(24):\n        await ctx.tick()\n        assert not ctx.get(dut.ovf)\n    await ctx.tick()\n    assert ctx.get(dut.ovf)\n    await ctx.tick()\n    assert not ctx.get(dut.ovf)\n\nsim = Simulator(dut)\nsim.add_clock(Period(MHz=1))\nsim.add_testbench(bench)\nwith sim.write_vcd('up_counter.vcd'):\n    sim.run()"}], "reference": "Language & toolchain\n\nGetting started\n\nView page source\n\nGetting started\n\nThis section demonstrates the basic Amaranth workflow to provide a cursory overview of the language and the toolchain. See the tutorial for a step-by-step introduction to the language, and the language guide for a detailed explanation of every language construct.\n\nA counter\n\nAs a first example, consider a counter with a fixed limit, enable, and overflow. The code for this example is shown below. Download and run it:\n\n$ python3 up_counter.py\r\n\nImplementing a counter\n\nA 16-bit up counter with enable input, overflow output, and a limit fixed at design time can be implemented in Amaranth as follows:\n\n 1from amaranth import *\r\n 2from amaranth.lib import wiring\r\n 3from amaranth.lib.wiring import In, Out\r\n 4\r\n 5\r\n 6class UpCounter(wiring.Component):\r\n 7    \"\"\"\r\n 8    A 16-bit up counter with a fixed limit.\r\n 9\r\n10    Parameters\r\n11    ----------\r\n12    limit : int\r\n13        The value at which the counter overflows.\r\n14\r\n15    Attributes\r\n16    ----------\r\n17    en : Signal, in\r\n18        The counter is incremented if ``en`` is asserted, and retains\r\n19        its value otherwise.\r\n20    ovf : Signal, out\r\n21        ``ovf`` is asserted when the counter reaches its limit.\r\n22    \"\"\"\r\n23\r\n24    en: In(1)\r\n25    ovf: Out(1)\r\n26\r\n27    def __init__(self, limit):\r\n28        self.limit = limit\r\n29        self.count = Signal(16)\r\n30\r\n31        super().__init__()\r\n32\r\n33    def elaborate(self, platform):\r\n34        m = Module()\r\n35\r\n36        m.d.comb += self.ovf.eq(self.count == self.limit)\r\n37\r\n38        with m.If(self.en):\r\n39            with m.If(self.ovf):\r\n40                m.d.sync += self.count.eq(0)\r\n41            with m.Else():\r\n42                m.d.sync += self.count.eq(self.count + 1)\r\n43\r\n44        return m\r\n\nThe reusable building block of Amaranth designs is a Component: a Python class declares its interface (en and ovf, in this case) and implements the elaborate method that defines its behavior.\n\nMost elaborate implementations use a Module helper to describe combinational (m.d.comb) and synchronous (m.d.sync) logic controlled with conditional syntax (m.If, m.Elif, m.Else) similar to Python’s. They can also instantiate vendor-defined black boxes or modules written in other HDLs.\n\nTesting a counter\n\nTo verify its functionality, the counter can be simulated for a small amount of time, with a test bench driving it and checking a few simple conditions:\n\n46from amaranth.sim import Simulator, Period\r\n47\r\n48\r\n49dut = UpCounter(25)\r\n50async def bench(ctx):\r\n51    # Disabled counter should not overflow.\r\n52    ctx.set(dut.en, 0)\r\n53    for _ in range(30):\r\n54        await ctx.tick()\r\n55        assert not ctx.get(dut.ovf)\r\n56\r\n57    # Once enabled, the counter should overflow in 25 cycles.\r\n58    ctx.set(dut.en, 1)\r\n59    for _ in range(24):\r\n60        await ctx.tick()\r\n61        assert not ctx.get(dut.ovf)\r\n62    await ctx.tick()\r\n63    assert ctx.get(dut.ovf)\r\n64\r\n65    # The overflow should clear in one cycle.\r\n66    await ctx.tick()\r\n67    assert not ctx.get(dut.ovf)\r\n68\r\n69\r\n70sim = Simulator(dut)\r\n71sim.add_clock(Period(MHz=1))\r\n72sim.add_testbench(bench)\r\n73with sim.write_vcd(\"up_counter.vcd\"):\r\n74    sim.run()\r\n\nThe testbench is implemented as a Python async function that is simulated concurrently with the counter itself. The testbench can inspect the simulated signals using ctx.get(sig), update them using ctx.set(sig, val), and advance the simulation by one clock cycle with await ctx.tick(). See the simulator documentation for details.\n\nWhen run, the testbench finishes successfully, since all of the assertions hold, and produces a VCD file with waveforms recorded for every Signal as well as the clock of the sync domain:\n\nConverting a counter\n\nAlthough some Amaranth workflows do not include Verilog at all, it is still the de facto standard for HDL interoperability. Any Amaranth design can be converted to synthesizable Verilog using the corresponding backend:", "source": "amaranth"}
{"script_name": "$_DFFSR_PPP_", "definition_description": "This script represents a positive edge-triggered D flip-flop with a positive polarity set (S) and reset (R). It captures the D input on the rising edge of the clock (C), or when the set (S) or reset (R) signals are asserted.", "parameters": {"C": "Clock input, triggering the flip-flop on the rising edge.", "S": "Set input, forces the output Q to 1 when asserted.", "R": "Reset input, forces the output Q to 0 when asserted.", "D": "Data input, which is stored in Q when neither S nor R is asserted."}, "values": "C: <clock>, S: <set>, R: <reset>, D: <data>", "script_paradigm": "module $_DFFSR_PPP_ (C, S, R, D, Q); input C, S, R, D; output reg Q; always @(posedge C, posedge S, posedge R) begin if (R == 1) Q <= 0; else if (S == 1) Q <= 1; else Q <= D; end endmodule", "examples": [{"query": "How to implement a D flip-flop with positive edge clock, positive polarity set and reset?", "answer": "module $_DFFSR_PPP_ (C, S, R, D, Q); input C, S, R, D; output reg Q; always @(posedge C, posedge S, posedge R) begin if (R == 1) Q <= 0; else if (S == 1) Q <= 1; else Q <= D; end endmodule"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nTruth table:\nC S R D | Q\n---------+---\n- - 1 - | 0\n- 1 - - | 1\n/ - - d | d\n- - - - | q\nSimulation model (verilog)\nListing 9.176: simcells.v\n1817\nmodule \\$_DFFSR_PPP_ (C, S, R, D, Q);\n1818\ninput C, S, R, D;\n1819\noutput reg Q;\n1820\nalways @(posedge C, posedge S, posedge R) begin\n1821\nif (R == 1)\n1822\nQ <= 0;\n1823\nelse if (S == 1)\n1824\nQ <= 1;\n1825\nelse\n1826\nQ <= D;\n1827\nend\n1828\nendmodule\nyosys> help $_DFF_NN0_\nA negative edge D-type flip-flop with negative polarity reset.\nTruth table:\nD C R | Q\n-------+---\n- - 0 | 0\nd \\ - | d\n- - - | q\nSimulation model (verilog)\nListing 9.177: simcells.v\n731\nmodule \\$_DFF_NN0_ (D, C, R, Q);\n732\ninput D, C, R;\n733\noutput reg Q;\n734\nalways @(negedge C or negedge R) begin\n735\nif (R == 0)\n736\nQ <= 0;\n737\nelse\n738\nQ <= D;\n739\nend\n740\nendmodule\nyosys> help $_DFF_NN1_\nA negative edge D-type flip-flop with negative polarity set.\nTruth table:\nD C R | Q\n-------+---\n(continues on next page)\n9.2.\nGate-level cells\n319", "source": "yosys_hq"}
{"script_name": "$_DFF_NN0_", "definition_description": "This script represents a negative edge-triggered D flip-flop with a negative polarity reset. It captures the D input on the falling edge of the clock (C) and resets the output Q to 0 when the reset (R) is asserted.", "parameters": {"D": "Data input, which is stored in Q when reset is not asserted.", "C": "Clock input, triggering the flip-flop on the falling edge.", "R": "Reset input, forces the output Q to 0 when asserted."}, "values": "D: <data>, C: <clock>, R: <reset>", "script_paradigm": "module $_DFF_NN0_ (D, C, R, Q); input D, C, R; output reg Q; always @(negedge C or negedge R) begin if (R == 0) Q <= 0; else Q <= D; end endmodule", "examples": [{"query": "How to implement a D flip-flop with negative edge clock and negative polarity reset?", "answer": "module $_DFF_NN0_ (D, C, R, Q); input D, C, R; output reg Q; always @(negedge C or negedge R) begin if (R == 0) Q <= 0; else Q <= D; end endmodule"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nTruth table:\nC S R D | Q\n---------+---\n- - 1 - | 0\n- 1 - - | 1\n/ - - d | d\n- - - - | q\nSimulation model (verilog)\nListing 9.176: simcells.v\n1817\nmodule \\$_DFFSR_PPP_ (C, S, R, D, Q);\n1818\ninput C, S, R, D;\n1819\noutput reg Q;\n1820\nalways @(posedge C, posedge S, posedge R) begin\n1821\nif (R == 1)\n1822\nQ <= 0;\n1823\nelse if (S == 1)\n1824\nQ <= 1;\n1825\nelse\n1826\nQ <= D;\n1827\nend\n1828\nendmodule\nyosys> help $_DFF_NN0_\nA negative edge D-type flip-flop with negative polarity reset.\nTruth table:\nD C R | Q\n-------+---\n- - 0 | 0\nd \\ - | d\n- - - | q\nSimulation model (verilog)\nListing 9.177: simcells.v\n731\nmodule \\$_DFF_NN0_ (D, C, R, Q);\n732\ninput D, C, R;\n733\noutput reg Q;\n734\nalways @(negedge C or negedge R) begin\n735\nif (R == 0)\n736\nQ <= 0;\n737\nelse\n738\nQ <= D;\n739\nend\n740\nendmodule\nyosys> help $_DFF_NN1_\nA negative edge D-type flip-flop with negative polarity set.\nTruth table:\nD C R | Q\n-------+---\n(continues on next page)\n9.2.\nGate-level cells\n319", "source": "yosys_hq"}
{"script_name": "repair_antennas", "definition_description": "This script is used to repair antenna violations by inserting diodes into the design.", "parameters": {"diode_cell": "The diode cell used to fix antenna violations.", "iterations": "The number of iterations to perform. Default is 1.", "ratio_margin": "The margin added to the antenna ratios. Default is 0."}, "values": "diode_cell: <diode_cell>, iterations: <iterations>, ratio_margin: <ratio_margin>", "script_paradigm": "repair_antennas <diode_cell> -iterations <iterations> -ratio_margin <ratio_margin>", "examples": [{"query": "How to repair antennas using diode_cell 'diode' with 5 iterations and a ratio margin of 10?", "answer": "repair_antennas diode -iterations 5 -ratio_margin 10"}], "reference": "If any repairs are made the filler instances are remove and must be\nplaced with the filler_placement command.\nIf the LEF technology layer ANTENNADIFFSIDEAREARATIO properties are constant\ninstead of PWL, inserting diodes will not improve the antenna ratios, \nand thus, no\ndiodes are inserted. The following warning message will be reported:\n[WARNING GRT-0243] Unable to repair antennas on net with diodes.\ntcl\nrepair_antennas \n    [diode_cell]\n    [-iterations iterations]\n    [-ratio_margin margin]\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| diode_cell | Diode cell to fix antenna violations. |\n| -iterations | Number of iterations. The default value is 1, and the allowed values are integers [0, MAX_INT]. |\n| -ratio_margin | Add a margin to the antenna ratios. The default value is 0, and the allowed values are integers [0, 100]. |\nPlot Global Routing Guides\nThe draw_route_guides command plots the route guides for a set of nets.\nTo erase the route guides from the GUI, pass an empty list to this command:\ndraw_route_guides {}.\ntcl\ndraw_route_guides \n    net_names \n    [-show_pin_locations]\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| net_names | Tcl list of set of nets (e.g. {net1, net2}). |\n| -show_pin_locations | Draw circles for the pin positions on the routing grid. |\nReport Wirelength\nThe report_wire_length command reports the wire length of the nets. Use the -global_route\nand the -detailed_route flags to report the wire length from global and detailed routing,\nrespectively. If none of these flags are used, the tool will identify the state of the design\nand report the wire length accordingly.\nExample: report_wire_length -net {clk net60} -global_route -detailed_route -verbose -file out.csv\ntcl\nreport_wire_length \n    [-net net_list]\n    [-file file]\n    [-global_route]\n    [-detailed_route]\n    [-verbose]\nOptions\n| Switch Name | Description | \n| ----- | ----- |\n| -net | List of nets to report the wirelength. Use * to report the wire length for all nets of the design. |\n| -file | The name of the file for the wirelength report. |\n| -global_route | Report the wire length of the global routing. |\n| -detailed_route | Report the wire length of the detailed routing. |\n| -verbose | This flag enables the full reporting of the layer-wise wirelength information. |\nGlobal Route Debug Mode\nThe global_route_debug command allows you to start a debug mode to view the status of the Steiner Trees.\nIt also allows you to dump the input positions for the Steiner tree creation of a net.\nThis must be used before calling the global_route command. \nSet the name of the net and the trees that you want to visualize.\ntcl\nglobal_route_debug \n    [-st]\n    [-rst]\n    [-tree2D]\n    [-tree3D]\n    [-saveSttInput file_name]\n    [-net net_name]\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| -st | Show the Steiner Tree generated by stt. |\n| -rst | Show the Rectilinear Steiner Tree generated by grt. |\n| -tree2D | Show the Rectilinear Steiner Tree generated by grt after the overflow iterations. |\n| -tree3D | Show the 3D Rectilinear Steiner Tree post-layer assignment. |\n| -saveSttInput | File name to save stt input of a net. |\n| -net | The name of the net name to be displayed. |\nRead Global Routing Guides\nThis command reads global routing guides. \ntcl\nread_guides file_name\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| file_name | Path to global routing guide. | \nExample scripts\nExamples scripts demonstrating how to run FastRoute on a sample design of gcd as follows:\nshell\n./test/gcd.tcl\nUseful Developer Commands\nIf you are a developer, you might find these useful. More details can be found in the source file or the swig file.\n| Command Name | Description |\n| ----- | ----- |\n| check_routing_layer | Check if the layer is within the min/max routing layer specified. |\n| parse_layer_name | Get routing layer number from layer name |\n| parse_layer_range | Parses a range from layer_range argument of format (%s-%s). cmd argument is not used. |\n| check_region | Checks the defined region if its within the die area. |", "source": "OpenROAD"}
{"script_name": "draw_route_guides", "definition_description": "This script plots the route guides for a set of nets.", "parameters": {"net_names": "A list of nets for which the route guides are to be plotted.", "show_pin_locations": "Option to display circles for pin positions on the routing grid."}, "values": "net_names: <net_names>, show_pin_locations: <show_pin_locations>", "script_paradigm": "draw_route_guides <net_names> -show_pin_locations <show_pin_locations>", "examples": [{"query": "How to plot route guides for nets 'net1' and 'net2' and show pin locations?", "answer": "draw_route_guides {net1 net2} -show_pin_locations"}], "reference": "If any repairs are made the filler instances are remove and must be\nplaced with the filler_placement command.\nIf the LEF technology layer ANTENNADIFFSIDEAREARATIO properties are constant\ninstead of PWL, inserting diodes will not improve the antenna ratios, \nand thus, no\ndiodes are inserted. The following warning message will be reported:\n[WARNING GRT-0243] Unable to repair antennas on net with diodes.\ntcl\nrepair_antennas \n    [diode_cell]\n    [-iterations iterations]\n    [-ratio_margin margin]\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| diode_cell | Diode cell to fix antenna violations. |\n| -iterations | Number of iterations. The default value is 1, and the allowed values are integers [0, MAX_INT]. |\n| -ratio_margin | Add a margin to the antenna ratios. The default value is 0, and the allowed values are integers [0, 100]. |\nPlot Global Routing Guides\nThe draw_route_guides command plots the route guides for a set of nets.\nTo erase the route guides from the GUI, pass an empty list to this command:\ndraw_route_guides {}.\ntcl\ndraw_route_guides \n    net_names \n    [-show_pin_locations]\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| net_names | Tcl list of set of nets (e.g. {net1, net2}). |\n| -show_pin_locations | Draw circles for the pin positions on the routing grid. |\nReport Wirelength\nThe report_wire_length command reports the wire length of the nets. Use the -global_route\nand the -detailed_route flags to report the wire length from global and detailed routing,\nrespectively. If none of these flags are used, the tool will identify the state of the design\nand report the wire length accordingly.\nExample: report_wire_length -net {clk net60} -global_route -detailed_route -verbose -file out.csv\ntcl\nreport_wire_length \n    [-net net_list]\n    [-file file]\n    [-global_route]\n    [-detailed_route]\n    [-verbose]\nOptions\n| Switch Name | Description | \n| ----- | ----- |\n| -net | List of nets to report the wirelength. Use * to report the wire length for all nets of the design. |\n| -file | The name of the file for the wirelength report. |\n| -global_route | Report the wire length of the global routing. |\n| -detailed_route | Report the wire length of the detailed routing. |\n| -verbose | This flag enables the full reporting of the layer-wise wirelength information. |\nGlobal Route Debug Mode\nThe global_route_debug command allows you to start a debug mode to view the status of the Steiner Trees.\nIt also allows you to dump the input positions for the Steiner tree creation of a net.\nThis must be used before calling the global_route command. \nSet the name of the net and the trees that you want to visualize.\ntcl\nglobal_route_debug \n    [-st]\n    [-rst]\n    [-tree2D]\n    [-tree3D]\n    [-saveSttInput file_name]\n    [-net net_name]\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| -st | Show the Steiner Tree generated by stt. |\n| -rst | Show the Rectilinear Steiner Tree generated by grt. |\n| -tree2D | Show the Rectilinear Steiner Tree generated by grt after the overflow iterations. |\n| -tree3D | Show the 3D Rectilinear Steiner Tree post-layer assignment. |\n| -saveSttInput | File name to save stt input of a net. |\n| -net | The name of the net name to be displayed. |\nRead Global Routing Guides\nThis command reads global routing guides. \ntcl\nread_guides file_name\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| file_name | Path to global routing guide. | \nExample scripts\nExamples scripts demonstrating how to run FastRoute on a sample design of gcd as follows:\nshell\n./test/gcd.tcl\nUseful Developer Commands\nIf you are a developer, you might find these useful. More details can be found in the source file or the swig file.\n| Command Name | Description |\n| ----- | ----- |\n| check_routing_layer | Check if the layer is within the min/max routing layer specified. |\n| parse_layer_name | Get routing layer number from layer name |\n| parse_layer_range | Parses a range from layer_range argument of format (%s-%s). cmd argument is not used. |\n| check_region | Checks the defined region if its within the die area. |", "source": "OpenROAD"}
{"script_name": "report_wire_length", "definition_description": "This script reports the wire length of nets, either from global or detailed routing, and can output the data to a file.", "parameters": {"net": "A list of nets for which the wire length is reported.", "file": "The output file to save the wire length report.", "global_route": "Flag to report wire length for global routing.", "detailed_route": "Flag to report wire length for detailed routing.", "verbose": "Flag to enable full reporting of layer-wise wire length information."}, "values": "net: <net>, file: <file>, global_route: <global_route>, detailed_route: <detailed_route>, verbose: <verbose>", "script_paradigm": "report_wire_length -net <net> -file <file> -global_route -detailed_route -verbose", "examples": [{"query": "How to report wire length for nets 'clk' and 'net60' and output to 'out.csv' with global and detailed routing?", "answer": "report_wire_length -net {clk net60} -global_route -detailed_route -verbose -file out.csv"}], "reference": "If any repairs are made the filler instances are remove and must be\nplaced with the filler_placement command.\nIf the LEF technology layer ANTENNADIFFSIDEAREARATIO properties are constant\ninstead of PWL, inserting diodes will not improve the antenna ratios, \nand thus, no\ndiodes are inserted. The following warning message will be reported:\n[WARNING GRT-0243] Unable to repair antennas on net with diodes.\ntcl\nrepair_antennas \n    [diode_cell]\n    [-iterations iterations]\n    [-ratio_margin margin]\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| diode_cell | Diode cell to fix antenna violations. |\n| -iterations | Number of iterations. The default value is 1, and the allowed values are integers [0, MAX_INT]. |\n| -ratio_margin | Add a margin to the antenna ratios. The default value is 0, and the allowed values are integers [0, 100]. |\nPlot Global Routing Guides\nThe draw_route_guides command plots the route guides for a set of nets.\nTo erase the route guides from the GUI, pass an empty list to this command:\ndraw_route_guides {}.\ntcl\ndraw_route_guides \n    net_names \n    [-show_pin_locations]\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| net_names | Tcl list of set of nets (e.g. {net1, net2}). |\n| -show_pin_locations | Draw circles for the pin positions on the routing grid. |\nReport Wirelength\nThe report_wire_length command reports the wire length of the nets. Use the -global_route\nand the -detailed_route flags to report the wire length from global and detailed routing,\nrespectively. If none of these flags are used, the tool will identify the state of the design\nand report the wire length accordingly.\nExample: report_wire_length -net {clk net60} -global_route -detailed_route -verbose -file out.csv\ntcl\nreport_wire_length \n    [-net net_list]\n    [-file file]\n    [-global_route]\n    [-detailed_route]\n    [-verbose]\nOptions\n| Switch Name | Description | \n| ----- | ----- |\n| -net | List of nets to report the wirelength. Use * to report the wire length for all nets of the design. |\n| -file | The name of the file for the wirelength report. |\n| -global_route | Report the wire length of the global routing. |\n| -detailed_route | Report the wire length of the detailed routing. |\n| -verbose | This flag enables the full reporting of the layer-wise wirelength information. |\nGlobal Route Debug Mode\nThe global_route_debug command allows you to start a debug mode to view the status of the Steiner Trees.\nIt also allows you to dump the input positions for the Steiner tree creation of a net.\nThis must be used before calling the global_route command. \nSet the name of the net and the trees that you want to visualize.\ntcl\nglobal_route_debug \n    [-st]\n    [-rst]\n    [-tree2D]\n    [-tree3D]\n    [-saveSttInput file_name]\n    [-net net_name]\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| -st | Show the Steiner Tree generated by stt. |\n| -rst | Show the Rectilinear Steiner Tree generated by grt. |\n| -tree2D | Show the Rectilinear Steiner Tree generated by grt after the overflow iterations. |\n| -tree3D | Show the 3D Rectilinear Steiner Tree post-layer assignment. |\n| -saveSttInput | File name to save stt input of a net. |\n| -net | The name of the net name to be displayed. |\nRead Global Routing Guides\nThis command reads global routing guides. \ntcl\nread_guides file_name\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| file_name | Path to global routing guide. | \nExample scripts\nExamples scripts demonstrating how to run FastRoute on a sample design of gcd as follows:\nshell\n./test/gcd.tcl\nUseful Developer Commands\nIf you are a developer, you might find these useful. More details can be found in the source file or the swig file.\n| Command Name | Description |\n| ----- | ----- |\n| check_routing_layer | Check if the layer is within the min/max routing layer specified. |\n| parse_layer_name | Get routing layer number from layer name |\n| parse_layer_range | Parses a range from layer_range argument of format (%s-%s). cmd argument is not used. |\n| check_region | Checks the defined region if its within the die area. |", "source": "OpenROAD"}
{"script_name": "global_route_debug", "definition_description": "This script starts a debug mode to view the status of Steiner Trees and allows the visualization of the trees for specific nets.", "parameters": {"st": "Option to show the Steiner Tree generated by STT.", "rst": "Option to show the Rectilinear Steiner Tree generated by GRT.", "tree2D": "Option to show the Rectilinear Steiner Tree after overflow iterations in 2D.", "tree3D": "Option to show the 3D Rectilinear Steiner Tree post-layer assignment.", "saveSttInput": "The file name to save the STT input for a net.", "net": "The net name whose tree status will be displayed."}, "values": "st: <st>, rst: <rst>, tree2D: <tree2D>, tree3D: <tree3D>, saveSttInput: <saveSttInput>, net: <net>", "script_paradigm": "global_route_debug -st -rst -tree2D -tree3D -saveSttInput <saveSttInput> -net <net>", "examples": [{"query": "How to enable debug for net 'clk' and save the STT input to 'clk_input.txt'?", "answer": "global_route_debug -saveSttInput clk_input.txt -net clk"}], "reference": "If any repairs are made the filler instances are remove and must be\nplaced with the filler_placement command.\nIf the LEF technology layer ANTENNADIFFSIDEAREARATIO properties are constant\ninstead of PWL, inserting diodes will not improve the antenna ratios, \nand thus, no\ndiodes are inserted. The following warning message will be reported:\n[WARNING GRT-0243] Unable to repair antennas on net with diodes.\ntcl\nrepair_antennas \n    [diode_cell]\n    [-iterations iterations]\n    [-ratio_margin margin]\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| diode_cell | Diode cell to fix antenna violations. |\n| -iterations | Number of iterations. The default value is 1, and the allowed values are integers [0, MAX_INT]. |\n| -ratio_margin | Add a margin to the antenna ratios. The default value is 0, and the allowed values are integers [0, 100]. |\nPlot Global Routing Guides\nThe draw_route_guides command plots the route guides for a set of nets.\nTo erase the route guides from the GUI, pass an empty list to this command:\ndraw_route_guides {}.\ntcl\ndraw_route_guides \n    net_names \n    [-show_pin_locations]\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| net_names | Tcl list of set of nets (e.g. {net1, net2}). |\n| -show_pin_locations | Draw circles for the pin positions on the routing grid. |\nReport Wirelength\nThe report_wire_length command reports the wire length of the nets. Use the -global_route\nand the -detailed_route flags to report the wire length from global and detailed routing,\nrespectively. If none of these flags are used, the tool will identify the state of the design\nand report the wire length accordingly.\nExample: report_wire_length -net {clk net60} -global_route -detailed_route -verbose -file out.csv\ntcl\nreport_wire_length \n    [-net net_list]\n    [-file file]\n    [-global_route]\n    [-detailed_route]\n    [-verbose]\nOptions\n| Switch Name | Description | \n| ----- | ----- |\n| -net | List of nets to report the wirelength. Use * to report the wire length for all nets of the design. |\n| -file | The name of the file for the wirelength report. |\n| -global_route | Report the wire length of the global routing. |\n| -detailed_route | Report the wire length of the detailed routing. |\n| -verbose | This flag enables the full reporting of the layer-wise wirelength information. |\nGlobal Route Debug Mode\nThe global_route_debug command allows you to start a debug mode to view the status of the Steiner Trees.\nIt also allows you to dump the input positions for the Steiner tree creation of a net.\nThis must be used before calling the global_route command. \nSet the name of the net and the trees that you want to visualize.\ntcl\nglobal_route_debug \n    [-st]\n    [-rst]\n    [-tree2D]\n    [-tree3D]\n    [-saveSttInput file_name]\n    [-net net_name]\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| -st | Show the Steiner Tree generated by stt. |\n| -rst | Show the Rectilinear Steiner Tree generated by grt. |\n| -tree2D | Show the Rectilinear Steiner Tree generated by grt after the overflow iterations. |\n| -tree3D | Show the 3D Rectilinear Steiner Tree post-layer assignment. |\n| -saveSttInput | File name to save stt input of a net. |\n| -net | The name of the net name to be displayed. |\nRead Global Routing Guides\nThis command reads global routing guides. \ntcl\nread_guides file_name\nOptions\n| Switch Name | Description |\n| ----- | ----- |\n| file_name | Path to global routing guide. | \nExample scripts\nExamples scripts demonstrating how to run FastRoute on a sample design of gcd as follows:\nshell\n./test/gcd.tcl\nUseful Developer Commands\nIf you are a developer, you might find these useful. More details can be found in the source file or the swig file.\n| Command Name | Description |\n| ----- | ----- |\n| check_routing_layer | Check if the layer is within the min/max routing layer specified. |\n| parse_layer_name | Get routing layer number from layer name |\n| parse_layer_range | Parses a range from layer_range argument of format (%s-%s). cmd argument is not used. |\n| check_region | Checks the defined region if its within the die area. |", "source": "OpenROAD"}
{"script_name": "CellView", "definition_description": "This class describes what is shown inside a layout view, pointing to a specific cell within a layout and its hierarchical context.", "parameters": {"layout_pointer": "A pointer to the layout containing the cell view, which can be nil if the cell view is invalid.", "cell_index": "The index or reference of the cell within the layout.", "ctx_cell_index": "The index of the context cell in the hierarchical path.", "ctx_cell": "The actual context cell object, representing the parent in the hierarchy.", "InstElement": "A set of objects used to identify a specific instance of a subcell in the context of the parent cell."}, "values": "layout_pointer: <layout>, cell_index: <index>, ctx_cell_index: <index>, ctx_cell: <cell>, InstElement: <element>", "script_paradigm": "cv = RBA::CellView::active\ncv.cell_name = <cell_name>", "examples": [{"query": "How to set the active cell view to 'TOP2'?", "answer": "cv = RBA::CellView::active\ncv.cell_name = 'TOP2'"}], "reference": "KLayout Documentation (Qt 5): Main Index » Class Index » API reference - Class CellView\n\nAPI reference - Class CellView\n\nNotation used in Ruby API documentation\n\nModule: lay\n\nDescription: A class describing what is shown inside a layout view\n\nPublic constructors\n\nPublic methods\n\nPublic static methods and constants\n\nDeprecated methods (protected, public, static, non-static and constructors)\n\nDetailed description\n\nThe cell view points to a specific cell within a certain layout and a hierarchical context. For that, first of all a layout pointer is provided. The cell itself is addressed by an cell_index or a cell object reference. The layout pointer can be nil, indicating that the cell view is invalid.\n\nThe cell is not only identified by its index or object but also by the path leading to that cell. This path indicates how to find the cell in the hierarchical context of its parent cells.\n\nThe path is in fact composed of two parts: first in an unspecific fashion, just describing which parent cells are used. The target of this path is called the \"context cell\". It is accessible by the ctx_cell_index or ctx_cell methods. In the viewer, the unspecific part of the path is the location of the cell in the cell tree.\n\nAdditionally the path's second part may further identify a specific instance of a certain subcell in the context cell. This is done through a set of InstElement objects. The target of this specific path is the actual cell addressed by the cellview. This target cell is accessible by the cell_index or cell methods. In the viewer, the target cell is shown in the context of the context cell. The hierarchy levels are counted from the context cell, which is on level 0. If the context path is empty, the context cell is identical with the target cell.\n\nStarting with version 0.25, the cellview can be modified directly. This will have an immediate effect on the display. For example, the following code will select a different cell:\n\ncv = RBA::CellView::active\ncv.cell_name = \"TOP2\"\n\nSee The Application API for more details about the cellview objects.\n\nPublic constructors\n\nnew CellView ptr new Creates a new object of this class\n\nPublic methods", "source": "klayout"}
{"script_name": "global_placement", "definition_description": "This script performs global placement of cells in the design, which can be driven either by timing or routability constraints. It can also skip initial placement, perform incremental placement, and adjust various placement-related parameters to optimize the design.", "parameters": {"timing_driven": "Enables timing-driven placement, optimizing for timing constraints by adjusting net weights based on slack.", "routability_driven": "Enables routability-driven placement, focusing on minimizing routing congestion by adjusting the area of congested tiles.", "skip_initial_place": "Skips the initial placement phase, which is typically used to improve the HPWL for large designs.", "incremental": "Enables incremental placement, which adjusts the placement based on a pre-placed solution.", "bin_grid_count": "Sets the grid count for binning during placement to control the resolution of the placement grid.", "density": "Sets the target density for the placement to control how tightly the cells are packed.", "init_density_penalty": "Defines the penalty for initial density, used when performing incremental placement with pre-placed solutions.", "init_wirelength_coef": "Sets the coefficient for the wirelength optimization during initial placement.", "min_phi_coef": "Sets the minimum coefficient for the phi function used in placement optimization.", "max_phi_coef": "Sets the maximum coefficient for the phi function used in placement optimization.", "reference_hpwl": "Defines the reference HPWL (Half Perimeter Wire Length) for placement optimization.", "overflow": "Specifies the overflow threshold for recalculating weights during placement to optimize timing or routability.", "initial_place_max_iter": "Sets the maximum number of iterations for the initial placement phase.", "initial_place_max_fanout": "Defines the maximum allowed fanout during the initial placement.", "pad_left": "Sets the padding on the left side of the placement grid.", "pad_right": "Sets the padding on the right side of the placement grid.", "skip_io": "Skips the placement of IO cells during global placement.", "skip_nesterov_place": "Skips the Nesterov placement optimization step.", "routability_use_grt": "Enables the use of GRT (Global Routing Tool) to estimate routing congestion during routability-driven placement.", "routability_target_rc_metric": "Defines the target RC (routing congestion) metric for the routability-driven placement optimization.", "routability_check_overflow": "Checks for overflow during routability-driven placement, ensuring that no tiles exceed the specified congestion thresholds.", "routability_max_density": "Defines the maximum allowed tile density during routability-driven placement.", "routability_max_bloat_iter": "Sets the maximum number of iterations for the inflation of cell area during routability-driven placement.", "routability_max_inflation_iter": "Defines the maximum number of iterations for adjusting the area inflation during routability-driven placement.", "routability_inflation_ratio_coef": "Sets the coefficient for the inflation ratio during routability-driven placement.", "routability_max_inflation_ratio": "Defines the maximum allowed inflation ratio during routability-driven placement.", "routability_rc_coefficients": "Specifies the coefficients used in the routing congestion calculation for routability-driven placement.", "timing_driven_net_reweight_overflow": "Defines the overflow threshold for recalculating net weights in timing-driven placement.", "timing_driven_net_weight_max": "Sets the maximum weight for nets in timing-driven placement.", "timing_driven_nets_percentage": "Defines the percentage of nets with the worst slack to be adjusted in timing-driven placement."}, "values": "timing_driven: <true/false>, routability_driven: <true/false>, skip_initial_place: <true/false>, incremental: <true/false>, bin_grid_count: <integer>, density: <float>, init_density_penalty: <float>, init_wirelength_coef: <float>, min_phi_coef: <float>, max_phi_coef: <float>, reference_hpwl: <float>, overflow: <float>, initial_place_max_iter: <integer>, initial_place_max_fanout: <integer>, pad_left: <integer>, pad_right: <integer>, skip_io: <true/false>, skip_nesterov_place: <true/false>, routability_use_grt: <true/false>, routability_target_rc_metric: <float>, routability_check_overflow: <true/false>, routability_max_density: <float>, routability_max_bloat_iter: <integer>, routability_max_inflation_iter: <integer>, routability_inflation_ratio_coef: <float>, routability_max_inflation_ratio: <float>, routability_rc_coefficients: <list of floats>, timing_driven_net_reweight_overflow: <float>, timing_driven_net_weight_max: <float>, timing_driven_nets_percentage: <float>", "script_paradigm": "global_placement -timing_driven <timing_driven> -routability_driven <routability_driven> -skip_initial_place <skip_initial_place> -incremental <incremental> -bin_grid_count <bin_grid_count> -density <density> -init_density_penalty <init_density_penalty> -init_wirelength_coef <init_wirelength_coef> -min_phi_coef <min_phi_coef> -max_phi_coef <max_phi_coef> -reference_hpwl <reference_hpwl> -overflow <overflow> -initial_place_max_iter <initial_place_max_iter> -initial_place_max_fanout <initial_place_max_fanout> -pad_left <pad_left> -pad_right <pad_right> -skip_io <skip_io> -skip_nesterov_place <skip_nesterov_place> -routability_use_grt <routability_use_grt> -routability_target_rc_metric <routability_target_rc_metric> -routability_check_overflow <routability_check_overflow> -routability_max_density <routability_max_density> -routability_max_bloat_iter <routability_max_bloat_iter> -routability_max_inflation_iter <routability_max_inflation_iter> -routability_inflation_ratio_coef <routability_inflation_ratio_coef> -routability_max_inflation_ratio <routability_max_inflation_ratio> -routability_rc_coefficients <routability_rc_coefficients> -timing_driven_net_reweight_overflow <timing_driven_net_reweight_overflow> -timing_driven_net_weight_max <timing_driven_net_weight_max> -timing_driven_nets_percentage <timing_driven_nets_percentage>", "examples": [{"query": "How to perform global placement with timing-driven optimization?", "answer": "global_placement -timing_driven true -routability_driven false"}, {"query": "How to perform global placement with routability-driven optimization and skip initial placement?", "answer": "global_placement -timing_driven false -routability_driven true -skip_initial_place true"}, {"query": "How to use incremental global placement with a target density of 0.75?", "answer": "global_placement -incremental true -density 0.75"}], "reference": "NAME\nglobal_placement - global placement\nSYNOPSIS\nglobal_placement\n    [-timing_driven]\n    [-routability_driven]\n    [-disable_timing_driven]\n    [-disable_routability_driven]\n    [-skip_initial_place]\n    [-incremental]\n    [-bin_grid_count grid_count]\n    [-density target_density]\n    [-init_density_penalty init_density_penalty]\n    [-init_wirelength_coef init_wirelength_coef]\n    [-min_phi_coef min_phi_conef]\n    [-max_phi_coef max_phi_coef]\n    [-reference_hpwl reference_hpwl]\n    [-overflow overflow]\n    [-initial_place_max_iter initial_place_max_iter]\n    [-initial_place_max_fanout initial_place_max_fanout]\n    [-pad_left pad_left]\n    [-pad_right pad_right]\n    [-skip_io]\n    [-skip_nesterov_place]\n    [-routability_use_grt]\n    [-routability_target_rc_metric routability_target_rc_metric]\n    [-routability_check_overflow routability_check_overflow]\n    [-routability_max_density routability_max_density]\n    [-routability_max_bloat_iter routability_max_bloat_iter]\n    [-routability_max_inflation_iter routability_max_inflation_iter]  \n    [-routability_inflation_ratio_coef routability_inflation_ratio_coef]\n    [-routability_max_inflation_ratio routability_max_inflation_ratio]\n    [-routability_rc_coefficients routability_rc_coefficients]\n    [-timing_driven_net_reweight_overflow]\n    [-timing_driven_net_weight_max]\n    [-timing_driven_nets_percentage]\nDESCRIPTION\nWhen using the -timing_driven flag, gpl does a virtual repair_design \nto find slacks and\nweight nets with low slack. It adjusts the worst slacks (modified with \n-timing_driven_nets_percentage) using a multiplier (modified with \n-timing_driven_net_weight_max). The multiplier\nis scaled from the full value for the worst slack, to 1.0 at the\ntiming_driven_nets_percentage point. Use the set_wire_rc command to set\nresistance and capacitance of estimated wires used for timing. \nTiming-driven iterations are triggered based on a list of overflow threshold \nvalues. Each time the placer execution reaches these overflow values, the \nresizer is executed. This process can be costly in terms of runtime. The \noverflow values for recalculating weights can be modified with \n-timing_driven_net_reweight_overflow, you may use less overflow threshold \nvalues to decrease runtime, for example.\nWhen the routability-driven option is enabled, each of its iterations will \nexecute RUDY to provide an estimation of routing congestion. Congested tiles \nwill have the area of their logic cells inflated to reduce routing congestion. \nThe iterations will attempt to achieve the target RC (routing congestion) \nby comparing it to the final RC at each iteration. If the algorithm takes too \nlong during routability-driven execution, consider raising the target RC value \n(-routability_target_rc_metric) to alleviate the constraints. The final RC \nvalue is calculated based on the weight coefficients. The algorithm will stop \nif the RC is not decreasing for three consecutive iterations.\nRoutability-driven arguments\n- They begin with -routability.\n- -routability_target_rc_metric, -routability_check_overflow, -routability_max_density, -routability_max_bloat_iter, -routability_max_inflation_iter, -routability_inflation_ratio_coef, -routability_max_inflation_ratio, -routability_rc_coefficients\nTiming-driven arguments\n- They begin with -timing_driven.\n- -timing_driven_net_reweight_overflow, -timing_driven_net_weight_max, -timing_driven_nets_percentage\nOPTIONS\n-timing_driven:  Enable timing-driven mode. See link for timing-specific arguments.\n-routability_driven:  Enable routability-driven mode. See link for routability-specific arguments.\n-skip_initial_place:  Skip the initial placement (Biconjugate gradient stabilized, or BiCGSTAB solving) before Nesterov placement. Initial placement improves HPWL by ~5% on large designs. Equivalent to -initial_place_max_iter 0.\n-incremental:  Enable the incremental global placement. Users would need to tune other parameters (e.g., init_density_penalty) with pre-placed solutions.", "source": "OpenROAD"}
{"script_name": "AsynchronousResetCounter", "definition_description": "This script models a counter with an asynchronous reset using Verilog.", "parameters": {"clk": "The clock signal that triggers the counter increment", "reset": "The reset signal that resets the counter to zero", "y": "The counter register that holds the current count"}, "values": "clk: <clk>, reset: <reset>, y: <y>", "script_paradigm": "always @(posedge <clk>, posedge <reset>) begin\n  if (<reset>)\n    <y> <= 0;\n  else\n    <y> <= <y> + 1;\nend", "examples": [{"query": "How to implement a counter with asynchronous reset using clk and reset signals?", "answer": "always @(posedge clk, posedge reset) begin\n  if (reset)\n    y <= 0;\n  else\n    y <= y + 1;\nend"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n1\n// counter with asynchronous reset\n2\nalways @(posedge clk, posedge reset) begin\n3\nif (reset)\n4\ny <= 0;\n5\nelse\n6\ny <= y + 1;\n7\nend\nMany synthesis tools support a wider subset of flip-flops that can be modelled using always-statements\n(including Yosys). But only the ones listed above are covered by the Verilog synthesis standard and when\nwriting new designs one should limit herself or himself to these cases.\nIn behavioural modelling, blocking assignments (=) and non-blocking assignments (<=) can be used. The\nconcept of blocking vs. non-blocking assignment is one of the most misunderstood constructs in Verilog\n[CI00].\nThe blocking assignment behaves exactly like an assignment in any imperative programming language, while\nwith the non-blocking assignment the right hand side of the assignment is evaluated immediately but the\nactual update of the left hand side register is delayed until the end of the time-step. For example the Verilog\ncode a <= b; b <= a; exchanges the values of the two registers.\n5.2.4 Functions and tasks\nVerilog supports Functions and Tasks to bundle statements that are used in multiple places (similar to\nProcedures in imperative programming). Both constructs can be implemented easily by substituting the\nfunction/task-call with the body of the function or task.\n5.2.5 Conditionals, loops and generate-statements\nVerilog supports if-else-statements and for-loops inside always-statements.\nIt also supports both features in generate-statements on the module level. This can be used to selectively\nenable or disable parts of the module based on the module parameters (if-else) or to generate a set of\nsimilar subcircuits (for).\nWhile the if-else-statement inside an always-block is part of behavioural modelling, the three other cases\nare (at least for a synthesis tool) part of a built-in macro processor.\nTherefore it must be possible for\nthe synthesis tool to completely unroll all loops and evaluate the condition in all if-else-statement in\ngenerate-statements using const-folding..\n5.2.6 Arrays and memories\nVerilog supports arrays. This is in general a synthesizable language feature. In most cases arrays can be\nsynthesized by generating addressable memories. However, when complex or asynchronous access patterns\nare used, it is not possible to model an array as memory. In these cases the array must be modelled using\nindividual signals for each word and all accesses to the array must be implemented using large multiplexers.\nIn some cases it would be possible to model an array using memories, but it is not desired. Consider the\nfollowing delay circuit:\n1\nmodule (clk, in_data, out_data);\n2\n3\nparameter BITS = 8;\n4\nparameter STAGES = 4;\n5\n6\ninput clk;\n(continues on next page)\n180\nChapter 5.\nA primer on digital circuit synthesis", "source": "yosys_hq"}
{"script_name": "VerilogConditionalAndLoop", "definition_description": "This script demonstrates the use of if-else-statements and for-loops inside always-statements in Verilog.", "parameters": {"condition": "The condition for if-else decision-making", "loop_count": "The number of iterations for the for-loop"}, "values": "condition: <condition>, loop_count: <loop_count>", "script_paradigm": "always @(posedge clk) begin\n  if (<condition>)\n    // statements for true\n  else\n    // statements for false\nend\n\n// for-loop example\nfor (int i = 0; i < <loop_count>; i = i + 1) begin\n  // loop body\nend", "examples": [{"query": "How to use an if-else statement inside an always block?", "answer": "always @(posedge clk) begin\n  if (condition)\n    // statements for true\n  else\n    // statements for false\nend"}, {"query": "How to write a for-loop inside an always block?", "answer": "for (int i = 0; i < loop_count; i = i + 1) begin\n  // loop body\nend"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n1\n// counter with asynchronous reset\n2\nalways @(posedge clk, posedge reset) begin\n3\nif (reset)\n4\ny <= 0;\n5\nelse\n6\ny <= y + 1;\n7\nend\nMany synthesis tools support a wider subset of flip-flops that can be modelled using always-statements\n(including Yosys). But only the ones listed above are covered by the Verilog synthesis standard and when\nwriting new designs one should limit herself or himself to these cases.\nIn behavioural modelling, blocking assignments (=) and non-blocking assignments (<=) can be used. The\nconcept of blocking vs. non-blocking assignment is one of the most misunderstood constructs in Verilog\n[CI00].\nThe blocking assignment behaves exactly like an assignment in any imperative programming language, while\nwith the non-blocking assignment the right hand side of the assignment is evaluated immediately but the\nactual update of the left hand side register is delayed until the end of the time-step. For example the Verilog\ncode a <= b; b <= a; exchanges the values of the two registers.\n5.2.4 Functions and tasks\nVerilog supports Functions and Tasks to bundle statements that are used in multiple places (similar to\nProcedures in imperative programming). Both constructs can be implemented easily by substituting the\nfunction/task-call with the body of the function or task.\n5.2.5 Conditionals, loops and generate-statements\nVerilog supports if-else-statements and for-loops inside always-statements.\nIt also supports both features in generate-statements on the module level. This can be used to selectively\nenable or disable parts of the module based on the module parameters (if-else) or to generate a set of\nsimilar subcircuits (for).\nWhile the if-else-statement inside an always-block is part of behavioural modelling, the three other cases\nare (at least for a synthesis tool) part of a built-in macro processor.\nTherefore it must be possible for\nthe synthesis tool to completely unroll all loops and evaluate the condition in all if-else-statement in\ngenerate-statements using const-folding..\n5.2.6 Arrays and memories\nVerilog supports arrays. This is in general a synthesizable language feature. In most cases arrays can be\nsynthesized by generating addressable memories. However, when complex or asynchronous access patterns\nare used, it is not possible to model an array as memory. In these cases the array must be modelled using\nindividual signals for each word and all accesses to the array must be implemented using large multiplexers.\nIn some cases it would be possible to model an array using memories, but it is not desired. Consider the\nfollowing delay circuit:\n1\nmodule (clk, in_data, out_data);\n2\n3\nparameter BITS = 8;\n4\nparameter STAGES = 4;\n5\n6\ninput clk;\n(continues on next page)\n180\nChapter 5.\nA primer on digital circuit synthesis", "source": "yosys_hq"}
{"script_name": "VerilogArrayAndMemoryModeling", "definition_description": "This script demonstrates how to model arrays and memories in Verilog, including addressing complex access patterns.", "parameters": {"array_name": "The name of the array being modeled", "access_pattern": "The access pattern for the array (synchronous or asynchronous)"}, "values": "array_name: <array_name>, access_pattern: <access_pattern>", "script_paradigm": "// Array modeled as memory\n<array_name> [<index>];\n\n// Complex access pattern modeling using individual signals\n<array_name>_0, <array_name>_1, ..., <array_name>_N;", "examples": [{"query": "How to model an array using memory in Verilog?", "answer": "<array_name> [<index>];"}, {"query": "How to model an array with complex access pattern in Verilog?", "answer": "<array_name>_0, <array_name>_1, ..., <array_name>_N;"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n1\n// counter with asynchronous reset\n2\nalways @(posedge clk, posedge reset) begin\n3\nif (reset)\n4\ny <= 0;\n5\nelse\n6\ny <= y + 1;\n7\nend\nMany synthesis tools support a wider subset of flip-flops that can be modelled using always-statements\n(including Yosys). But only the ones listed above are covered by the Verilog synthesis standard and when\nwriting new designs one should limit herself or himself to these cases.\nIn behavioural modelling, blocking assignments (=) and non-blocking assignments (<=) can be used. The\nconcept of blocking vs. non-blocking assignment is one of the most misunderstood constructs in Verilog\n[CI00].\nThe blocking assignment behaves exactly like an assignment in any imperative programming language, while\nwith the non-blocking assignment the right hand side of the assignment is evaluated immediately but the\nactual update of the left hand side register is delayed until the end of the time-step. For example the Verilog\ncode a <= b; b <= a; exchanges the values of the two registers.\n5.2.4 Functions and tasks\nVerilog supports Functions and Tasks to bundle statements that are used in multiple places (similar to\nProcedures in imperative programming). Both constructs can be implemented easily by substituting the\nfunction/task-call with the body of the function or task.\n5.2.5 Conditionals, loops and generate-statements\nVerilog supports if-else-statements and for-loops inside always-statements.\nIt also supports both features in generate-statements on the module level. This can be used to selectively\nenable or disable parts of the module based on the module parameters (if-else) or to generate a set of\nsimilar subcircuits (for).\nWhile the if-else-statement inside an always-block is part of behavioural modelling, the three other cases\nare (at least for a synthesis tool) part of a built-in macro processor.\nTherefore it must be possible for\nthe synthesis tool to completely unroll all loops and evaluate the condition in all if-else-statement in\ngenerate-statements using const-folding..\n5.2.6 Arrays and memories\nVerilog supports arrays. This is in general a synthesizable language feature. In most cases arrays can be\nsynthesized by generating addressable memories. However, when complex or asynchronous access patterns\nare used, it is not possible to model an array as memory. In these cases the array must be modelled using\nindividual signals for each word and all accesses to the array must be implemented using large multiplexers.\nIn some cases it would be possible to model an array using memories, but it is not desired. Consider the\nfollowing delay circuit:\n1\nmodule (clk, in_data, out_data);\n2\n3\nparameter BITS = 8;\n4\nparameter STAGES = 4;\n5\n6\ninput clk;\n(continues on next page)\n180\nChapter 5.\nA primer on digital circuit synthesis", "source": "yosys_hq"}
{"script_name": "Circle PCell", "definition_description": "This script creates a parameterized PCell that draws a circle in the layout, demonstrating basic PCell implementation techniques and the use of guiding shapes for dynamic parameter updates.", "parameters": {"l": "The layer for the circle, defined by LayerInfo.", "s": "The shape, which determines the position of the circle's radius handle.", "r": "The radius of the circle.", "n": "The number of points used to approximate the circle's shape.", "ru": "A hidden parameter used to determine if the radius or the handle has been moved, ensuring the correct update of circle parameters."}, "values": "l: LayerInfo::new(1, 0), s: DPoint::new(0, 0), r: 0.1, n: 64, ru: 0.0", "script_paradigm": "module MyLib\n\n  include RBA\n\n  class Circle < PCellDeclarationHelper\n    def initialize\n      super\n      param(:l, TypeLayer, 'Layer', :default => LayerInfo::new(1, 0))\n      param(:s, TypeShape, '', :default => DPoint::new(0, 0))\n      param(:r, TypeDouble, 'Radius', :default => 0.1)\n      param(:n, TypeInt, 'Number of points', :default => 64)\n      param(:ru, TypeDouble, 'Radius', :default => 0.0, :hidden => true)\n    end\n\n    def display_text_impl\n      'Circle(L=#{l.to_s},R=#{'%.3f' % r.to_f})'\n    end\n\n    def coerce_parameters_impl\n      rs = nil\n      if s.is_a?(DPoint)\n        rs = s.distance(DPoint::new(0, 0))\n      end\n      if rs && (r-ru).abs < 1e-6\n        set_ru rs\n        set_r rs\n      else\n        set_ru r\n        set_s DPoint::new(-r, 0)\n      end\n      n > 4 || (set_n 4)\n    end\n\n    def can_create_from_shape_impl\n      shape.is_box? || shape.is_polygon? || shape.is_path?\n    end\n\n    def parameters_from_shape_impl\n      set_r shape.bbox.width * layout.dbu / 2\n      set_l layout.get_info(layer)\n    end\n\n    def transformation_from_shape_impl\n      Trans.new(shape.bbox.center)\n    end\n\n    def produce_impl\n      # create the layout\n    end\n  end\nend", "examples": [{"query": "How do you create a circle with a radius of 0.1 on layer 1?", "answer": "module MyLib\n\n  include RBA\n\n  class Circle < PCellDeclarationHelper\n    def initialize\n      super\n      param(:l, TypeLayer, 'Layer', :default => LayerInfo::new(1, 0))\n      param(:s, TypeShape, '', :default => DPoint::new(0, 0))\n      param(:r, TypeDouble, 'Radius', :default => 0.1)\n      param(:n, TypeInt, 'Number of points', :default => 64)\n      param(:ru, TypeDouble, 'Radius', :default => 0.0, :hidden => true)\n    end\n\n    def display_text_impl\n      'Circle(L=#{l.to_s},R=#{'%.3f' % r.to_f})'\n    end\n  end\nend"}, {"query": "How do you ensure the number of points for the circle is at least 4?", "answer": "def coerce_parameters_impl\n  n > 4 || (set_n 4)\nend"}], "reference": "KLayout Documentation (Qt 5): Main Index » Programming scripts » Coding PCells In Ruby\n\nCoding PCells In Ruby\n\nThe Sample\n\nPreamble\n\nThe PCell Class\n\nThe Library\n\nDebugging The Code\n\nA good starting point for Ruby PCells is the PCell sample. Create a macro in the macro development IDE (use the \"+\" button) and choose \"PCell sample\" from the templates.\n\nThe Sample\n\nWe'll do a code walk through that sample here and explain the concepts while doing so. Here is the complete sample:\n\n# Sample PCell\n#\n# This sample PCell implements a library called \"MyLib\" with a single PCell that\n# draws a circle. It demonstrates the basic implementation techniques for a PCell \n# and how to use the \"guiding shape\" feature to implement a handle for the circle\n# radius.\n# \n# NOTE: after changing the code, the macro needs to be rerun to install the new\n# implementation. The macro is also set to \"auto run\" to install the PCell \n# when KLayout is run.\n\nmodule MyLib\n\n  include RBA\n\n  # Remove any definition of our classes (this helps when \n  # reexecuting this code after a change has been applied)\n  MyLib.constants.member?(:Circle) && remove_const(:Circle)\n  MyLib.constants.member?(:MyLib) && remove_const(:MyLib)\n  \n  # The PCell declaration for the circle\n  class Circle < PCellDeclarationHelper\n  \n    include RBA\n\n    def initialize\n\n      # Important: initialize the super class\n      super\n\n      # declare the parameters\n      param(:l, TypeLayer, \"Layer\", :default => LayerInfo::new(1, 0))\n      param(:s, TypeShape, \"\", :default => DPoint::new(0, 0))\n      param(:r, TypeDouble, \"Radius\", :default => 0.1)\n      param(:n, TypeInt, \"Number of points\", :default => 64)     \n      # this hidden parameter is used to determine whether the radius has changed\n      # or the \"s\" handle has been moved\n      param(:ru, TypeDouble, \"Radius\", :default => 0.0, :hidden => true)\n\n    end\n  \n    def display_text_impl\n      # Provide a descriptive text for the cell\n      \"Circle(L=#{l.to_s},R=#{'%.3f' % r.to_f})\"\n    end\n    \n    def coerce_parameters_impl\n    \n      # We employ coerce_parameters_impl to decide whether the handle or the \n      # numeric parameter has changed (by comparing against the effective \n      # radius ru) and set ru to the effective radius. We also update the \n      # numerical value or the shape, depending on which on has not changed.\n      rs = nil\n      if s.is_a?(DPoint) \n        # compute distance in micron\n        rs = s.distance(DPoint::new(0, 0))\n      end \n      if rs && (r-ru).abs < 1e-6\n        set_ru rs\n        set_r rs \n      else\n        set_ru r \n        set_s DPoint::new(-r, 0)\n      end\n      \n      # n must be larger or equal than 4\n      n > 4 || (set_n 4)\n       \n    end\n    \n    def can_create_from_shape_impl\n      # Implement the \"Create PCell from shape\" protocol: we can use any shape which \n      # has a finite bounding box\n      shape.is_box? || shape.is_polygon? || shape.is_path?\n    end\n    \n    def parameters_from_shape_impl\n      # Implement the \"Create PCell from shape\" protocol: we set r and l from the shape's \n      # bounding box width and layer\n      set_r shape.bbox.width * layout.dbu / 2\n      set_l layout.get_info(layer)\n    end\n    \n    def transformation_from_shape_impl\n      # Implement the \"Create PCell from shape\" protocol: we use the center of the shape's\n      # bounding box to determine the transformation\n      Trans.new(shape.bbox.center)\n    end\n    \n    def produce_impl\n    \n      # This is the main part of the implementation: create the layout", "source": "klayout"}
{"script_name": "ODB Error Handling", "definition_description": "This script manages and logs errors and warnings within the OpenROAD toolset, particularly related to database issues and connectivity.", "parameters": {"error_code": "A specific error code generated by the OpenROAD tool", "file": "The file from which the error was logged", "line_number": "The line number in the source file where the error occurred"}, "values": "error_code: <0352 to 2000>, file: <odb.tcl, dbInst.cpp, etc.>, line_number: <436 to 660>", "script_paradigm": "log_error -code <error_code> -file <file> -line <line_number>", "examples": [{"query": "How to log an error for error code 0352 in odb.tcl?", "answer": "log_error -code 0352 -file odb.tcl -line 436"}, {"query": "Log a warning from dbInst.cpp at line 513", "answer": "log_warning -code 0359 -file dbInst.cpp -line 513"}], "reference": "| ODB | 0352 | odb.tcl:436 | ERROR |- |\n| ODB | 0353 | odb.tcl:449 | ERROR |- |\n| ODB | 0354 | odb.tcl:468 | ERROR |- |\n| ODB | 0355 | odb.tcl:533 | ERROR |- |\n| ODB | 0356 | lefin.cpp:2212 | WARN |- |\n| ODB | 0357 | cdl.cpp:221 | WARN |- |\n| ODB | 0358 | cdl.cpp:195 | ERROR |- |\n| ODB | 0359 | dbInst.cpp:513 | ERROR |- |\n| ODB | 0360 | dbInst.cpp:610 | ERROR |- |\n| ODB | 0361 | lefin.cpp:2226 | WARN |- |\n| ODB | 0362 | dbInst.cpp:1542 | ERROR |- |\n| ODB | 0364 | dbNet.cpp:3111 | ERROR |- |\n| ODB | 0367 | dbModule.cpp:250 | ERROR |- |\n| ODB | 0368 | dbInst.cpp:1217 | ERROR |- |\n| ODB | 0369 | dbITerm.cpp:400 | ERROR |- |\n| ODB | 0370 | dbITerm.cpp:521 | ERROR |- |\n| ODB | 0371 | dbModule.cpp:287 | ERROR |- |\n| ODB | 0372 | dbITerm.cpp:531 | ERROR |- |\n| ODB | 0373 | dbITerm.cpp:408 | ERROR |- |\n| ODB | 0374 | dbBTerm.cpp:812 | ERROR |- |\n| ODB | 0375 | dbBTerm.cpp:527 | ERROR |- |\n| ODB | 0376 | dbBTerm.cpp:709 | ERROR |- |\n| ODB | 0377 | dbBTerm.cpp:492 | ERROR |- |\n| ODB | 0378 | dbBlock.cpp:4082 | WARN |- |\n| ODB | 0379 | dbGlobalConnect.cpp:307 | WARN |- |\n| ODB | 0380 | dbGlobalConnect.cpp:336 | WARN |- |\n| ODB | 0381 | dbBlock.cpp:4056 | ERROR |- |\n| ODB | 0382 | dbBlock.cpp:4060 | WARN |- |\n| ODB | 0383 | dbBlock.cpp:4128 | WARN |- |\n| ODB | 0384 | dbGlobalConnect.cpp:267 | ERROR |- |\n| ODB | 0385 | dbInst.cpp:1403 | ERROR |- |\n| ODB | 0386 | util.cpp:228 | WARN |- |\n| ODB | 0387 | definNonDefaultRule.cpp:238 | WARN |- |\n| ODB | 0388 | lefin.cpp:775 | INFO |- |\n| ODB | 0390 | tmg_conn.cpp:1205 | ERROR |- |\n| ODB | 0391 | tmg_conn.cpp:1235 | ERROR |- |\n| ODB | 0392 | tmg_conn.cpp:1271 | ERROR |- |\n| ODB | 0393 | tmg_conn.cpp:1742 | ERROR |- |\n| ODB | 0394 | lefin.cpp:1690 | INFO |- |\n| ODB | 0395 | tmg_conn.cpp:1557 | WARN |- |\n| ODB | 0396 | tmg_conn.cpp:1639 | WARN |- |\n| ODB | 0397 | dbITerm.cpp:492 | ERROR |- |\n| ODB | 0400 | dbUtil.cpp:303 | WARN |- |\n| ODB | 0401 | dbUtil.cpp:306 | WARN |- |\n| ODB | 0402 | dbUtil.cpp:356 | WARN |- |\n| ODB | 0403 | dbUtil.cpp:383 | WARN |- |\n| ODB | 0404 | dbUtil.cpp:539 | WARN |- |\n| ODB | 0405 | dbUtil.cpp:542 | WARN |- |\n| ODB | 0406 | dbUtil.cpp:618 | WARN |- |\n| ODB | 0407 | dbUtil.cpp:632 | WARN |- |\n| ODB | 0414 | dbTrackGrid.cpp:276 | ERROR |- |\n| ODB | 0415 | dbTrackGrid.cpp:289 | ERROR |- |\n| ODB | 0416 | dbTrackGrid.cpp:295 | ERROR |- |\n| ODB | 0418 | dbTrackGrid.cpp:265 | ERROR |- |\n| ODB | 0420 | tmg_conn.cpp:602 | ERROR |- |\n| ODB | 0421 | definReader.cpp:1933 | ERROR |- |\n| ODB | 0422 | definReader.cpp:1969 | ERROR |- |\n| ODB | 0423 | lefin.cpp:631 | WARN |- |\n| ODB | 0424 | parse.cpp:65 | ERROR |- |\n| ODB | 0425 | definComponentMaskShift.cpp:55 | WARN |- |\n| ODB | 0428 | parse.cpp:50 | ERROR |- |\n| ODB | 0429 | parse.cpp:412 | ERROR |- |\n| ODB | 0430 | dbBox.cpp:826 | ERROR |- |\n| ODB | 0431 | dbMaster.cpp:790 | ERROR |- |\n| ODB | 0432 | dbDatabase.cpp:501 | ERROR |- |\n| ODB | 0433 | dbITerm.cpp:415 | ERROR |- |\n| ODB | 0434 | dbBox.cpp:499 | ERROR |- |\n| ODB | 0435 | dbBox.cpp:804 | ERROR |- |\n| ODB | 0436 | dbInst.cpp:1500 | ERROR |- |\n| ODB | 0437 | definReader.cpp:999 | WARN |- |\n| ODB | 0438 | dbDatabase.cpp:162 | CRITICAL |- |\n| ODB | 0439 | odb.tcl:548 | ERROR |- |\n| ODB | 0440 | dbITerm.cpp:390 | ERROR |- |\n| ODB | 1000 | odb.tcl:72 | WARN |- |\n| ODB | 1001 | odb.tcl:143 | WARN |- |\n| ODB | 1002 | odb.tcl:146 | WARN |- |\n| ODB | 1004 | odb.tcl:161 | ERROR |- |\n| ODB | 1005 | odb.tcl:168 | ERROR |- |\n| ODB | 1006 | odb.tcl:173 | ERROR |- |\n| ODB | 1007 | odb.tcl:180 | ERROR |- |\n| ODB | 1008 | odb.tcl:188 | ERROR |- |\n| ODB | 1009 | odb.tcl:92 | WARN |- |\n| ODB | 1100 | dbAccessPoint.cpp:318 | ERROR |- |\n| ODB | 1101 | dbAccessPoint.cpp:338 | ERROR |- |\n| ODB | 1102 | dbWireCodec.cpp:636 | ERROR |- |\n| ODB | 1103 | dbWireCodec.cpp:660 | ERROR |- |\n| ODB | 2000 | lefin.cpp:1214 | WARN |- |\n| ORD | 0001 | OpenRoad.tcl:45 | ERROR |- |\n| ORD | 0002 | OpenRoad.tcl:48 | ERROR |- |\n| ORD | 0003 | OpenRoad.tcl:85 | ERROR |- |\n| ORD | 0004 | OpenRoad.tcl:88 | ERROR |- |\n| ORD | 0005 | OpenRoad.tcl:94 | ERROR |- |\n| ORD | 0006 | OpenRoad.tcl:125 | ERROR |- |", "source": "OpenROAD"}
{"script_name": "group_path", "definition_description": "This script is used to group paths reported by the report_checks command. It allows the user to define various groupings of paths based on different conditions like clock edges or instances.", "parameters": {"group_name": "The name of the path group to be created", "weight": "Not supported", "critical_range": "Not supported", "from_list": "A list of clocks, instances, ports, register clock pins, or latch data pins that the paths should be grouped from", "rise_from": "A list of clocks, instances, ports, register clock pins, or latch data pins for paths starting at the rising edge", "fall_from": "A list of clocks, instances, ports, register clock pins, or latch data pins for paths starting at the falling edge", "through_list": "A list of instances, pins, or nets that the paths should go through", "rise_through": "A list of instances, pins, or nets for paths through the rising edge", "fall_through": "A list of instances, pins, or nets for paths through the falling edge", "to_list": "A list of clocks, instances, ports, or pins that the paths should go to", "rise_to": "A list of clocks, instances, ports, or pins for paths ending at the rising edge", "fall_to": "A list of clocks, instances, ports, or pins for paths ending at the falling edge"}, "values": "group_name: <group_name>, weight: <weight>, critical_range: <range>, from_list: <from_list>, rise_from: <rise_from>, fall_from: <fall_from>, through_list: <through_list>, rise_through: <rise_through>, fall_through: <fall_through>, to_list: <to_list>, rise_to: <rise_to>, fall_to: <fall_to>", "script_paradigm": "group_path -name <group_name> [-weight <weight>] [-critical_range <range>] [-from <from_list>] [-rise_from <rise_from>] [-fall_from <fall_from>] [-through <through_list>] [-rise_through <rise_through>] [-fall_through <fall_through>] [-to <to_list>] [-rise_to <rise_to>] [-fall_to <fall_to>]", "examples": [{"query": "How to group paths from 'clk1' and 'clk2'?", "answer": "group_path -name path_group -from {clk1 clk2}"}, {"query": "How to group rising paths through a list of instances?", "answer": "group_path -name rising_paths -rise_through {inst1 inst2}"}, {"query": "How to group paths to 'port1' and 'port2'?", "answer": "group_path -name to_ports -to {port1 port2}"}], "reference": "group_path\n-name group_name\n[-weight weight]\n[-critical_range range]\n[-from from_list\n |-rise_from from_list\n |-fall_from from_list]\n[-through through_list]\n[-rise_through through_list]\n[-fall_through through_list]\n[-to to_list\n |-rise_to to_list\n |-fall_to to_list]\n-name group_name\nThe name of the path group.\n-weight weight\nNot supported.\n-critical_range range\nNot supported.\n-from from_list\nGroup paths from a list of clocks, instances, ports, register clock pins, or latch \ndata pins.\n-rise_from from_list\nGroup  paths from the rising edge of clocks, instances, ports, register clock \npins, or latch data pins.\n-fall_from from_list\nGroup paths from the falling edge of clocks, instances, ports, register clock \npins, or latch data pins.\n-through through_list\nGroup paths through a list of instances, pins or nets.\n-rise_through \nthrough_list\nGroup rising paths through a list of instances, pins or nets.\n-fall_through \nthrough_list\nGroup falling paths through a list of instances, pins or nets.\n-to to_list\nGroup paths to a list of clocks, instances, ports or pins.\n-rise_to to_list\nGroup rising paths to a list of clocks, instances, ports or pins.\n-fall_to to_list\nGroup falling paths to a list of clocks, instances, ports or pins.\nThe group_path command is used to group paths reported by the report_checks command. See \nset_false_path for a description of allowed from_list, through_list and to_list objects.", "source": "OpenSTA"}
{"script_name": "param", "definition_description": "This script declares a parameter with a specified name, type, description, and optional attributes. It automatically creates accessor methods for getting and setting the parameter value.", "parameters": {"name": "The name of the parameter, must be a simple word", "type": "The type of the parameter, selected from predefined constants like TypeLayer", "description": "A text description of the parameter's role", "hidden": "Optional, boolean; if true, the parameter will not appear in the dialog", "readonly": "Optional, boolean; if true, the parameter cannot be edited", "unit": "Optional, a string indicating the unit of the parameter", "tooltip": "Optional, a tooltip displayed on the edit field and label", "min_value": "Optional, the minimum valid value for numerical types", "max_value": "Optional, the maximum valid value for numerical types", "default": "Optional, the default value of the parameter", "choices": "Optional, a list of choices for the parameter, represented as an array of two-element arrays (description, value)"}, "values": "name: <param_name>, type: <Type>, description: <param_description>, hidden: <boolean>, readonly: <boolean>, unit: <unit>, tooltip: <tooltip_text>, min_value: <min_value>, max_value: <max_value>, default: <default_value>, choices: <choices_array>", "script_paradigm": "param(<name>, <type>, <description>, [<hidden>, <readonly>, <unit>, <tooltip>, <min_value>, <max_value>, <default>, <choices>])", "examples": [{"query": "How to declare a parameter 'width' of type 'TypeInt' with a range between 1 and 100?", "answer": "param(width, TypeInt, 'Width of the element', min_value=1, max_value=100)"}, {"query": "Declare a parameter 'layer' of type 'TypeLayer' with choices 'Metal' and 'Poly'.", "answer": "param(layer, TypeLayer, 'Layer type', choices=[['Metal', 'metal'], ['Poly', 'poly']])"}], "reference": "choice each for parameters with a choice of values. Such parameters are represented by a drop-down box. This declaration will create accessor methods \"x\" and \"set_x\", where \"x\" is the name of the parameter.\nIf the type is TypeLayer, an accessor \"x_layer\" delivering the layer index inside produce_impl is\ncreated as well. (2) Signature : param (name, type, description, ...) Description : Declares a parameter with the given name, type and description and optional attributes. name : The name of the parameter. Must be a simple word. type : The type. One of the Type... constants, that this class borrowed from PCellParameterDeclaration . description : The description text for this parameter Optional, named parameters are :hidden : (boolean) true, if the parameter is not shown in the dialog :readonly : (boolean) true, if the parameter cannot be edited :unit : the unit string tooltip : the tool tip text displayed on the edit fields and labels :min_value : the minimum value (effective for numerical types and if no choices are present) :max_value : the maximum value (effective for numerical types and if no choices are present) :default : the default value :choices : ([ [ d, v ], ... ]) choice descriptions/value for choice type \":choices\" must be an array of two-element arrays (description text, value) which specify one\nchoice each for parameters with a choice of values. Such parameters are represented by a drop-down box. This declaration will create accessor methods \"x\" and \"set_x\", where \"x\" is the name of the parameter.\nIf the type is TypeLayer, an accessor \"x_layer\" delivering the layer index inside produce_impl is\ncreated as well. parameters_from_shape_impl (1) Signature : parameters_from_shape_impl Description : Sets the parameters from a shape This method can be reimplemented in a PCell class.\nIf can_create_from_shape_impl returns true, this method is called to set the parameters from the \ngiven shape (see shape , layout and layer ). Note, that for setting a layer parameter you need\nto create the LayerInfo object, i.e. like this: set_l layout.get_info(layer) The default implementation does nothing. All parameters not set in this method will receive their default value. If you use a parameter called \"layer\" for example, the parameter getter will hide the\n\"layer\" argument. Use \"_layer\" for the argument in this case (same for \"layout\", \"shape\" or \"cell): set_layer layout.get_info(_layer) (2) Signature : parameters_from_shape_impl Description : Sets the parameters from a shape This method can be reimplemented in a PCell class.\nIf can_create_from_shape_impl returns true, this method is called to set the parameters from the \ngiven shape (see shape , layout and layer ). Note, that for setting a layer parameter you need\nto create the LayerInfo object, i.e. like this: set_l layout.get_info(layer) The default implementation does nothing. All parameters not set in this method will receive their default value. If you use a parameter called \"layer\" for example, the parameter getter will hide the\n\"layer\" argument. Use \"_layer\" for the argument in this case (same for \"layout\", \"shape\" or \"cell): set_layer layout.get_info(_layer) produce_impl (1) Signature : produce_impl Description : Produces the layout This method must be reimplemented in a PCell class.\nUsing the parameter values provided by the parameter accessor methods and the layout and cell through layout and cell ,\nthis method is supposed to produce the final layout inside the given cell. (2) Signature : produce_impl Description : Produces the layout This method must be reimplemented in a PCell class.\nUsing the parameter values provided by the parameter accessor methods and the layout and cell through layout and cell ,", "source": "klayout"}
{"script_name": "parameters_from_shape_impl", "definition_description": "This script method is used to set the parameters of a PCell from a given shape. It can be reimplemented to customize how parameters are assigned based on the shape. It is invoked when 'can_create_from_shape_impl' returns true.", "parameters": {"shape": "The shape object from which parameters are derived", "layout": "The layout object containing the shape", "layer": "The layer object, typically set using the LayerInfo", "cell": "The cell object in the layout"}, "values": "shape: <shape_object>, layout: <layout_object>, layer: <layer_object>, cell: <cell_object>", "script_paradigm": "parameters_from_shape_impl(<shape>, <layout>, <layer>, <cell>)", "examples": [{"query": "How to implement setting parameters from a shape with layer information?", "answer": "parameters_from_shape_impl(shape, layout, set_layer(layout.get_info(layer)), cell)"}], "reference": "choice each for parameters with a choice of values. Such parameters are represented by a drop-down box. This declaration will create accessor methods \"x\" and \"set_x\", where \"x\" is the name of the parameter.\nIf the type is TypeLayer, an accessor \"x_layer\" delivering the layer index inside produce_impl is\ncreated as well. (2) Signature : param (name, type, description, ...) Description : Declares a parameter with the given name, type and description and optional attributes. name : The name of the parameter. Must be a simple word. type : The type. One of the Type... constants, that this class borrowed from PCellParameterDeclaration . description : The description text for this parameter Optional, named parameters are :hidden : (boolean) true, if the parameter is not shown in the dialog :readonly : (boolean) true, if the parameter cannot be edited :unit : the unit string tooltip : the tool tip text displayed on the edit fields and labels :min_value : the minimum value (effective for numerical types and if no choices are present) :max_value : the maximum value (effective for numerical types and if no choices are present) :default : the default value :choices : ([ [ d, v ], ... ]) choice descriptions/value for choice type \":choices\" must be an array of two-element arrays (description text, value) which specify one\nchoice each for parameters with a choice of values. Such parameters are represented by a drop-down box. This declaration will create accessor methods \"x\" and \"set_x\", where \"x\" is the name of the parameter.\nIf the type is TypeLayer, an accessor \"x_layer\" delivering the layer index inside produce_impl is\ncreated as well. parameters_from_shape_impl (1) Signature : parameters_from_shape_impl Description : Sets the parameters from a shape This method can be reimplemented in a PCell class.\nIf can_create_from_shape_impl returns true, this method is called to set the parameters from the \ngiven shape (see shape , layout and layer ). Note, that for setting a layer parameter you need\nto create the LayerInfo object, i.e. like this: set_l layout.get_info(layer) The default implementation does nothing. All parameters not set in this method will receive their default value. If you use a parameter called \"layer\" for example, the parameter getter will hide the\n\"layer\" argument. Use \"_layer\" for the argument in this case (same for \"layout\", \"shape\" or \"cell): set_layer layout.get_info(_layer) (2) Signature : parameters_from_shape_impl Description : Sets the parameters from a shape This method can be reimplemented in a PCell class.\nIf can_create_from_shape_impl returns true, this method is called to set the parameters from the \ngiven shape (see shape , layout and layer ). Note, that for setting a layer parameter you need\nto create the LayerInfo object, i.e. like this: set_l layout.get_info(layer) The default implementation does nothing. All parameters not set in this method will receive their default value. If you use a parameter called \"layer\" for example, the parameter getter will hide the\n\"layer\" argument. Use \"_layer\" for the argument in this case (same for \"layout\", \"shape\" or \"cell): set_layer layout.get_info(_layer) produce_impl (1) Signature : produce_impl Description : Produces the layout This method must be reimplemented in a PCell class.\nUsing the parameter values provided by the parameter accessor methods and the layout and cell through layout and cell ,\nthis method is supposed to produce the final layout inside the given cell. (2) Signature : produce_impl Description : Produces the layout This method must be reimplemented in a PCell class.\nUsing the parameter values provided by the parameter accessor methods and the layout and cell through layout and cell ,", "source": "klayout"}
{"script_name": "$allseq", "definition_description": "This script simulates a sequence generation model that outputs an undefined value ('bx).", "parameters": {"WIDTH": "The width of the output signal Y."}, "values": "WIDTH: <0>", "script_paradigm": "module $allseq (Y); output [WIDTH-1:0] Y; assign Y = 'bx; endmodule", "examples": [{"query": "How to use the $allseq module with a width of 8?", "answer": "module $allseq (Y); output [7:0] Y; assign Y = 'bx; endmodule"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n2066\n2067\nassign Y = 'bx;\n2068\n2069\nendmodule\nyosys> help $allseq\nProperties\nis_evaluable\nSimulation model (verilog)\nListing 9.80: simlib.v\n2074\nmodule \\$allseq (Y);\n2075\n2076\nparameter WIDTH = 0;\n2077\n2078\noutput [WIDTH-1:0] Y;\n2079\n2080\nassign Y = 'bx;\n2081\n2082\nendmodule\nyosys> help $anyconst\nProperties\nis_evaluable\nSimulation model (verilog)\nListing 9.81: simlib.v\n2014\nmodule \\$anyconst (Y);\n2015\n2016\nparameter WIDTH = 0;\n2017\n2018\noutput [WIDTH-1:0] Y;\n2019\n2020\nassign Y = 'bx;\n2021\n2022\nendmodule\nyosys> help $anyinit\nSimulation model (verilog)\nListing 9.82: simlib.v\n2043\nmodule \\$anyinit (D, Q);\n2044\n2045\nparameter WIDTH = 0;\n2046\n2047\ninput [WIDTH-1:0] D;\n(continues on next page)\n268\nChapter 9.\nInternal cell library", "source": "yosys_hq"}
{"script_name": "$anyconst", "definition_description": "This script simulates a constant value model that outputs an undefined value ('bx).", "parameters": {"WIDTH": "The width of the output signal Y."}, "values": "WIDTH: <0>", "script_paradigm": "module $anyconst (Y); output [WIDTH-1:0] Y; assign Y = 'bx; endmodule", "examples": [{"query": "How to use the $anyconst module with a width of 16?", "answer": "module $anyconst (Y); output [15:0] Y; assign Y = 'bx; endmodule"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n2066\n2067\nassign Y = 'bx;\n2068\n2069\nendmodule\nyosys> help $allseq\nProperties\nis_evaluable\nSimulation model (verilog)\nListing 9.80: simlib.v\n2074\nmodule \\$allseq (Y);\n2075\n2076\nparameter WIDTH = 0;\n2077\n2078\noutput [WIDTH-1:0] Y;\n2079\n2080\nassign Y = 'bx;\n2081\n2082\nendmodule\nyosys> help $anyconst\nProperties\nis_evaluable\nSimulation model (verilog)\nListing 9.81: simlib.v\n2014\nmodule \\$anyconst (Y);\n2015\n2016\nparameter WIDTH = 0;\n2017\n2018\noutput [WIDTH-1:0] Y;\n2019\n2020\nassign Y = 'bx;\n2021\n2022\nendmodule\nyosys> help $anyinit\nSimulation model (verilog)\nListing 9.82: simlib.v\n2043\nmodule \\$anyinit (D, Q);\n2044\n2045\nparameter WIDTH = 0;\n2046\n2047\ninput [WIDTH-1:0] D;\n(continues on next page)\n268\nChapter 9.\nInternal cell library", "source": "yosys_hq"}
{"script_name": "$anyinit", "definition_description": "This script simulates an initialization model that assigns an undefined value ('bx) to the output Q based on the input D.", "parameters": {"WIDTH": "The width of the input and output signals."}, "values": "WIDTH: <0>", "script_paradigm": "module $anyinit (D, Q); input [WIDTH-1:0] D; output [WIDTH-1:0] Q; assign Q = 'bx; endmodule", "examples": [{"query": "How to use the $anyinit module with a width of 8?", "answer": "module $anyinit (D, Q); input [7:0] D; output [7:0] Q; assign Q = 'bx; endmodule"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n2066\n2067\nassign Y = 'bx;\n2068\n2069\nendmodule\nyosys> help $allseq\nProperties\nis_evaluable\nSimulation model (verilog)\nListing 9.80: simlib.v\n2074\nmodule \\$allseq (Y);\n2075\n2076\nparameter WIDTH = 0;\n2077\n2078\noutput [WIDTH-1:0] Y;\n2079\n2080\nassign Y = 'bx;\n2081\n2082\nendmodule\nyosys> help $anyconst\nProperties\nis_evaluable\nSimulation model (verilog)\nListing 9.81: simlib.v\n2014\nmodule \\$anyconst (Y);\n2015\n2016\nparameter WIDTH = 0;\n2017\n2018\noutput [WIDTH-1:0] Y;\n2019\n2020\nassign Y = 'bx;\n2021\n2022\nendmodule\nyosys> help $anyinit\nSimulation model (verilog)\nListing 9.82: simlib.v\n2043\nmodule \\$anyinit (D, Q);\n2044\n2045\nparameter WIDTH = 0;\n2046\n2047\ninput [WIDTH-1:0] D;\n(continues on next page)\n268\nChapter 9.\nInternal cell library", "source": "yosys_hq"}
{"script_name": "synth_intel_alm", "definition_description": "This script runs synthesis for ALM-based Intel (Altera) FPGAs, specifically targeting the Cyclone V family by default.", "parameters": {"top": "The name of the module to be used as the top module in the synthesis process.", "family": "The target FPGA family for synthesis, default is 'cyclonev'.", "noflatten": "Flag to prevent flattening of the design before synthesis, useful for per-module area statistics.", "dff": "Flag to pass DFFs to ABC for sequential logic optimizations (EXPERIMENTAL).", "run": "Specify the range of synthesis commands to run, defined by from_label and to_label.", "nolutram": "Flag to prevent the usage of LUT RAM cells in the output netlist.", "nobram": "Flag to prevent the usage of block RAM cells in the output netlist.", "nodsp": "Flag to prevent the mapping of multipliers to MISTRAL_MUL cells."}, "values": "top: <module>, family: <family>, noflatten: <true/false>, dff: <true/false>, run: <from_label>:<to_label>, nolutram: <true/false>, nobram: <true/false>, nodsp: <true/false>", "script_paradigm": "synth_intel_alm -top <top> -family <family> -noflatten <noflatten> -dff <dff> -run <from_label>:<to_label> -nolutram <nolutram> -nobram <nobram> -nodsp <nodsp>", "examples": [{"query": "How to run synthesis for a top module 'design_top' targeting the Cyclone V family without flattening the design?", "answer": "synth_intel_alm -top design_top -family cyclonev -noflatten"}, {"query": "Run synthesis for 'design_top' with sequential logic optimizations and no use of LUT RAM cells.", "answer": "synth_intel_alm -top design_top -family cyclonev -dff -nolutram"}, {"query": "How to run synthesis for 'design_top' with a specific command range?", "answer": "synth_intel_alm -top design_top -family cyclonev -run start_label:end_label"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nvqm:\nwrite_verilog -attr2comment -defparam -nohex -decimal -renameprefix syn_ <file-\n˓→name>\nvpr:\nopt_clean -purge\nwrite_blif <file-name>\nWARNING: THE 'synth_intel' COMMAND IS EXPERIMENTAL.\n10.229 synth_intel_alm - synthesis for ALM-based Intel (Altera) FP-\nGAs.\nyosys> help synth_intel_alm\nsynth_intel_alm [options]\nThis command runs synthesis for ALM-based Intel FPGAs.\n-top <module>\nuse the specified module as top module\n-family <family>\ntarget one of:\n\"cyclonev\"\n- Cyclone V (default)\n-noflatten\ndo not flatten design before synthesis; useful for per-module area\nstatistics\n-dff\npass DFFs to ABC to perform sequential logic optimisations\n(EXPERIMENTAL)\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-nolutram\ndo not use LUT RAM cells in output netlist\n-nobram\ndo not use block RAM cells in output netlist\n-nodsp\ndo not map multipliers to MISTRAL_MUL cells\n(continues on next page)\n10.229.\nsynth_intel_alm - synthesis for ALM-based Intel (Altera) FPGAs.\n511", "source": "yosys_hq"}
{"script_name": "VerifyInstallation", "definition_description": "This script verifies the installation of OpenROAD and Yosys by checking if their executable paths are set correctly.", "parameters": {"OPENROAD_EXE": "The path to the OpenROAD executable", "YOSYS_CMD": "The path to the Yosys executable", "LD_LIBRARY_PATH": "The library path for the installed OpenROAD binaries if built from source"}, "values": "OPENROAD_EXE: <path_to_openroad>, YOSYS_CMD: <path_to_yosys>, LD_LIBRARY_PATH: <path_to_binaries>", "script_paradigm": "export OPENROAD_EXE=$(command -v openroad)\nexport YOSYS_CMD=$(command -v yosys)\nonly if KLayout is built from source\nexport LD_LIBRARY_PATH=\"/bin:$PATH\"\nyosys -help\nopenroad -help\ncd flow\nmake\nmake gui_final", "examples": [{"query": "How to verify the installation of OpenROAD and Yosys?", "answer": "export OPENROAD_EXE=$(command -v openroad)\nexport YOSYS_CMD=$(command -v yosys)\nexport LD_LIBRARY_PATH=\"/bin:$PATH\"\nyosys -help\nopenroad -help\ncd flow\nmake\nmake gui_final"}], "reference": "Using Pre-built Binaries\nInstall Klayout and Yosys\nPlease ensure the Klayout version (denoted with klayoutVersion variable) is consistent with the one used in DependencyInstaller script. \nInstructions for installing:\n- Klayout>=0.28.8\n- Yosys>=0.39\n{tip} Unfortunately KLayout maintainers do not provide Debian 10/11 compatible packages. You can follow the build-from-sources instruction (Version >=0.25) and Ubuntu 22 instructions [here](https://www.klayout.de/build.html#:~:text=Building%20KLayout%20on%20Linux%20(Version%20%3E%3D%200.25)).\nInstall OpenROAD\nDownload pre-built binaries with self-contained dependencies\nincluded from the Precision Innovations' GitHub releases\nhere.\nThanks to Precision Innovations for hosting and maintaining these binaries.\nThe following platforms are supported currently:\n- Ubuntu 20.04/22.04\n- Debian 10/11\nUse the following steps to download:\nStep 1: Click on the Precision Innovations Github releases link.\nStep 2: Download the artifacts for your distribution.\nStep 3: Run the install command based on platform use package installer.\n        For example Ubuntu 20.04 use:\nshell\nsudo apt install ./openroad_2.0_amd64-ubuntu20.04.deb\nInstall Klayout and Yosys\nPlease ensure the Klayout version (denoted with klayoutVersion variable) is consistent with the one used in DependencyInstaller script. \nInstructions for installing:\n- Klayout>=0.28.8\n- Yosys>=0.39\n{tip} Unfortunately KLayout maintainers do not provide Debian 10/11 compatible packages. You can follow the build-from-sources instruction (Version >=0.25) and Ubuntu 22 instructions [here](https://www.klayout.de/build.html#:~:text=Building%20KLayout%20on%20Linux%20(Version%20%3E%3D%200.25)).\nVerify Installation\nYou may clone the OpenROAD-flow-scripts repository non-recursively. \ngit clone https://github.com/The-OpenROAD-Project/OpenROAD-flow-scripts.git\nExport path variables accordingly.\n```\nthese variables are used in flow/Makefile. Do make sure the yosys path is sourced.\nexport OPENROAD_EXE=$(command -v openroad)\nexport YOSYS_CMD=$(command -v yosys)\nonly if KLayout is built from source\nexport LD_LIBRARY_PATH=\"/bin:$PATH\" \nyosys -help\nopenroad -help\ncd flow\nmake\nmake gui_final\n```", "source": "OpenROAD_flow_script"}
{"script_name": "$xnor", "definition_description": "This script performs a bit-wise XNOR operation, corresponding to the Verilog '~^' operator.", "parameters": {"A_SIGNED": "A parameter indicating whether input A is signed (default: 0)", "B_SIGNED": "A parameter indicating whether input B is signed (default: 0)", "A_WIDTH": "The width of input A (default: 0)", "B_WIDTH": "The width of input B (default: 0)", "Y_WIDTH": "The width of output Y (default: 0)"}, "values": "A_SIGNED: <0 or 1>, B_SIGNED: <0 or 1>, A_WIDTH: <positive integer>, B_WIDTH: <positive integer>, Y_WIDTH: <positive integer>", "script_paradigm": "module $xnor (A, B, Y); \nparameter A_SIGNED = <A_SIGNED>; \nparameter B_SIGNED = <B_SIGNED>; \nparameter A_WIDTH = <A_WIDTH>; \nparameter B_WIDTH = <B_WIDTH>; \nparameter Y_WIDTH = <Y_WIDTH>; \ninput [A_WIDTH-1:0] A; \ninput [B_WIDTH-1:0] B; \noutput [Y_WIDTH-1:0] Y; \ngenerate \nif (A_SIGNED && B_SIGNED) begin:BLOCK1 \nassign Y = $signed(A) ~^ $signed(B); \nend else begin:BLOCK2 \nassign Y = A ~^ B; \nend \nendgenerate \nendmodule", "examples": [{"query": "How to create an XNOR operation for unsigned 8-bit inputs A and B, resulting in an 8-bit output Y?", "answer": "module $xnor (A, B, Y); \nparameter A_SIGNED = 0; \nparameter B_SIGNED = 0; \nparameter A_WIDTH = 8; \nparameter B_WIDTH = 8; \nparameter Y_WIDTH = 8; \ninput [A_WIDTH-1:0] A; \ninput [B_WIDTH-1:0] B; \noutput [Y_WIDTH-1:0] Y; \ngenerate \nassign Y = A ~^ B; \nendgenerate \nendmodule"}, {"query": "How to create an XNOR operation for signed 16-bit inputs A and B, resulting in a 16-bit output Y?", "answer": "module $xnor (A, B, Y); \nparameter A_SIGNED = 1; \nparameter B_SIGNED = 1; \nparameter A_WIDTH = 16; \nparameter B_WIDTH = 16; \nparameter Y_WIDTH = 16; \ninput [A_WIDTH-1:0] A; \ninput [B_WIDTH-1:0] B; \noutput [Y_WIDTH-1:0] Y; \ngenerate \nassign Y = $signed(A) ~^ $signed(B); \nendgenerate \nendmodule"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n1025\nendmodule\nyosys> help $xnor\nA bit-wise XNOR. This corresponds to the Verilog ‘~^’ operator.\nProperties\nis_evaluable\nSimulation model (verilog)\nListing 9.38: simlib.v\n239\nmodule \\$xnor (A, B, Y);\n240\n241\nparameter A_SIGNED = 0;\n242\nparameter B_SIGNED = 0;\n243\nparameter A_WIDTH = 0;\n244\nparameter B_WIDTH = 0;\n245\nparameter Y_WIDTH = 0;\n246\n247\ninput [A_WIDTH-1:0] A;\n248\ninput [B_WIDTH-1:0] B;\n249\noutput [Y_WIDTH-1:0] Y;\n250\n251\ngenerate\n252\nif (A_SIGNED && B_SIGNED) begin:BLOCK1\n253\nassign Y = $signed(A) ~^ $signed(B);\n254\nend else begin:BLOCK2\n255\nassign Y = A ~^ B;\n256\nend\n257\nendgenerate\n258\n259\nendmodule\nyosys> help $xor\nA bit-wise XOR. This corresponds to the Verilog ‘^’ operator.\nProperties\nis_evaluable\nSimulation model (verilog)\nListing 9.39: simlib.v\n208\nmodule \\$xor (A, B, Y);\n209\n210\nparameter A_SIGNED = 0;\n211\nparameter B_SIGNED = 0;\n212\nparameter A_WIDTH = 0;\n213\nparameter B_WIDTH = 0;\n214\nparameter Y_WIDTH = 0;\n215\n216\ninput [A_WIDTH-1:0] A;\n217\ninput [B_WIDTH-1:0] B;\n(continues on next page)\n226\nChapter 9.\nInternal cell library", "source": "yosys_hq"}
{"script_name": "$xor", "definition_description": "This script performs a bit-wise XOR operation, corresponding to the Verilog '^' operator.", "parameters": {"A_SIGNED": "A parameter indicating whether input A is signed (default: 0)", "B_SIGNED": "A parameter indicating whether input B is signed (default: 0)", "A_WIDTH": "The width of input A (default: 0)", "B_WIDTH": "The width of input B (default: 0)", "Y_WIDTH": "The width of output Y (default: 0)"}, "values": "A_SIGNED: <0 or 1>, B_SIGNED: <0 or 1>, A_WIDTH: <positive integer>, B_WIDTH: <positive integer>, Y_WIDTH: <positive integer>", "script_paradigm": "module $xor (A, B, Y); \nparameter A_SIGNED = <A_SIGNED>; \nparameter B_SIGNED = <B_SIGNED>; \nparameter A_WIDTH = <A_WIDTH>; \nparameter B_WIDTH = <B_WIDTH>; \nparameter Y_WIDTH = <Y_WIDTH>; \ninput [A_WIDTH-1:0] A; \ninput [B_WIDTH-1:0] B; \noutput [Y_WIDTH-1:0] Y; \ngenerate \nif (A_SIGNED && B_SIGNED) begin:BLOCK1 \nassign Y = $signed(A) ^ $signed(B); \nend else begin:BLOCK2 \nassign Y = A ^ B; \nend \nendgenerate \nendmodule", "examples": [{"query": "How to create an XOR operation for unsigned 8-bit inputs A and B, resulting in an 8-bit output Y?", "answer": "module $xor (A, B, Y); \nparameter A_SIGNED = 0; \nparameter B_SIGNED = 0; \nparameter A_WIDTH = 8; \nparameter B_WIDTH = 8; \nparameter Y_WIDTH = 8; \ninput [A_WIDTH-1:0] A; \ninput [B_WIDTH-1:0] B; \noutput [Y_WIDTH-1:0] Y; \ngenerate \nassign Y = A ^ B; \nendgenerate \nendmodule"}, {"query": "How to create an XOR operation for signed 16-bit inputs A and B, resulting in a 16-bit output Y?", "answer": "module $xor (A, B, Y); \nparameter A_SIGNED = 1; \nparameter B_SIGNED = 1; \nparameter A_WIDTH = 16; \nparameter B_WIDTH = 16; \nparameter Y_WIDTH = 16; \ninput [A_WIDTH-1:0] A; \ninput [B_WIDTH-1:0] B; \noutput [Y_WIDTH-1:0] Y; \ngenerate \nassign Y = $signed(A) ^ $signed(B); \nendgenerate \nendmodule"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n1025\nendmodule\nyosys> help $xnor\nA bit-wise XNOR. This corresponds to the Verilog ‘~^’ operator.\nProperties\nis_evaluable\nSimulation model (verilog)\nListing 9.38: simlib.v\n239\nmodule \\$xnor (A, B, Y);\n240\n241\nparameter A_SIGNED = 0;\n242\nparameter B_SIGNED = 0;\n243\nparameter A_WIDTH = 0;\n244\nparameter B_WIDTH = 0;\n245\nparameter Y_WIDTH = 0;\n246\n247\ninput [A_WIDTH-1:0] A;\n248\ninput [B_WIDTH-1:0] B;\n249\noutput [Y_WIDTH-1:0] Y;\n250\n251\ngenerate\n252\nif (A_SIGNED && B_SIGNED) begin:BLOCK1\n253\nassign Y = $signed(A) ~^ $signed(B);\n254\nend else begin:BLOCK2\n255\nassign Y = A ~^ B;\n256\nend\n257\nendgenerate\n258\n259\nendmodule\nyosys> help $xor\nA bit-wise XOR. This corresponds to the Verilog ‘^’ operator.\nProperties\nis_evaluable\nSimulation model (verilog)\nListing 9.39: simlib.v\n208\nmodule \\$xor (A, B, Y);\n209\n210\nparameter A_SIGNED = 0;\n211\nparameter B_SIGNED = 0;\n212\nparameter A_WIDTH = 0;\n213\nparameter B_WIDTH = 0;\n214\nparameter Y_WIDTH = 0;\n215\n216\ninput [A_WIDTH-1:0] A;\n217\ninput [B_WIDTH-1:0] B;\n(continues on next page)\n226\nChapter 9.\nInternal cell library", "source": "yosys_hq"}
{"script_name": "abc9_ops", "definition_description": "This script optimizes logic designs by calling ABC internally for logic snippet optimization. It provides various options for handling DFF cells and managing temporary files.", "parameters": {"dff": "Specifies whether to pass DFF cells through to ABC for clock domain partitioning (optional).", "nocleanup": "When enabled, prevents the removal of temporary files for debugging purposes.", "showtmp": "Prints the temporary directory name for debugging.", "box": "Passes a box library file to ABC for optimization. This option is for logic optimization within Yosys, not external ABC processing."}, "values": "dff: <True/False>, nocleanup: <True/False>, showtmp: <True/False>, box: <file>", "script_paradigm": "abc9_ops -check [-dff] \nabc9_ops -prep_hier [-dff] \nscc -specify -set_attr abc9_scc_id {}\nabc9_ops -prep_bypass [-prep_dff]", "examples": [{"query": "How to use abc9_ops to check the design with DFF cells passed to ABC?", "answer": "abc9_ops -check -dff"}, {"query": "How to run abc9_ops with temporary files not cleaned up?", "answer": "abc9_ops -nocleanup"}, {"query": "How to pass a box library file to ABC in abc9_ops?", "answer": "abc9_ops -box box_file.lib"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\ngreater than this size (applicable when neither -lut nor -luts is\nspecified).\n-dff\nalso pass $_DFF_[NP]_ cells through to ABC. modules with many clock\ndomains are supported and automatically partitioned by ABC.\n-nocleanup\nwhen this option is used, the temporary files created by this pass\nare not removed. this is useful for debugging.\n-showtmp\nprint the temp dir name in log. usually this is suppressed so that the\ncommand output is identical across runs.\n-box <file>\npass this file with box library to ABC.\nNote that this is a logic optimization pass within Yosys that is calling ABC\ninternally. This is not going to \"run ABC on your design\". It will instead run\nABC on logic snippets extracted from your design. You will not get any useful\noutput when passing an ABC script that writes a file. Instead write your full\ndesign as an XAIGER file with `write_xaiger' and then load that into ABC\nexternally if you want to use ABC to convert your design into another format.\n[1] http://www.eecs.berkeley.edu/~alanmi/abc/\ncheck:\nabc9_ops -check [-dff]\n(option if -dff)\nmap:\nabc9_ops -prep_hier [-dff]\n(option if -dff)\nscc -specify -set_attr abc9_scc_id {}\nabc9_ops -prep_bypass [-prep_dff]\n(option if -dff)\ndesign -stash $abc9\ndesign -load $abc9_map\nproc\nwbflip\ntechmap -wb -map %$abc9 -map +/techmap.v A:abc9_flop\nopt -nodffe -nosdff\nabc9_ops -prep_dff_submod\n␣\n˓→(only if -dff)\nsetattr -set submod \"$abc9_flop\" t:$_DFF_?_ %ci* %co* t:$_DFF_?_ %d\n␣\n˓→(only if -dff)\nsubmod\n␣\n˓→(only if -dff)\nsetattr -mod -set whitebox 1 -set abc9_flop 1 -set abc9_box 1 *_$abc9_flop\n␣\n˓→(only if -dff)\nforeach module in design\nrename <module-name>_$abc9_flop _TECHMAP_REPLACE_\n␣\n˓→(only if -dff)\n(continues on next page)\n364\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "SetInstallPrefix", "definition_description": "This script configures the installation directory for Verilator, including the version number in the path.", "parameters": {"VERILATOR_ROOT": "The root directory of the Verilator Git repository", "INSTALL_PREFIX": "The destination directory where Verilator will be installed"}, "values": "VERILATOR_ROOT: unset, INSTALL_PREFIX: /CAD_DISK/verilator/<version_number>", "script_paradigm": "unset VERILATOR_ROOT # if your shell is bash\nunsetenv VERILATOR_ROOT # if your shell is csh\n./configure --prefix <INSTALL_PREFIX>", "examples": [{"query": "How to set the installation prefix for Verilator?", "answer": "unset VERILATOR_ROOT # if your shell is bash\nunsetenv VERILATOR_ROOT # if your shell is csh\n./configure --prefix /CAD_DISK/verilator/`git describe | sed \"s/verilator_//\"`"}], "reference": "Verilator, Release Devel 5.031\n3.4.4 Auto Conﬁgure\nCreate the conﬁguration script:\nautoconf\n# Create ./configure script\n3.4.5 Eventual Installation Options\nBefore conﬁguring the build, you must decide how you’re going to eventually install Verilator onto your system. Ver-\nilator will be compiling the current value of the environment variables VERILATOR_ROOT, VERILATOR_SOLVER,\nSYSTEMC_INCLUDE, and SYSTEMC_LIBDIR as defaults into the executable, so they must be correct before con-\nﬁguring.\nThese are the installation options:\n1. Run-in-Place from VERILATOR_ROOT\nOur personal favorite is to always run Verilator in-place from its Git directory (don’t run make install). This\nallows the easiest experimentation and upgrading, and allows many versions of Verilator to co-exist on a system.\nexport VERILATOR_ROOT=`pwd`\n# if your shell is bash\nsetenv VERILATOR_ROOT `pwd`\n# if your shell is csh\n./configure\n# Running will use files from $VERILATOR_ROOT, so no install needed\nNote after installing (see Installation),\na calling program or shell must set the environment variable\nVERILATOR_ROOT to point to this Git directory, then execute $VERILATOR_ROOT/bin/verilator, which\nwill ﬁnd the path to all needed ﬁles.\n2. Install into a Speciﬁc Preﬁx\nYou may be an OS package maintainer building a Verilator package, or you may eventually be installing onto a\nproject/company-wide “CAD” tools disk that may support multiple versions of every tool. Tell conﬁgure the eventual\ndestination directory name. We recommend that the destination location include the Verilator version name:\nunset VERILATOR_ROOT\n# if your shell is bash\nunsetenv VERILATOR_ROOT\n# if your shell is csh\n# For the tarball, use the version number instead of git describe\n./configure --prefix /CAD_DISK/verilator/`git describe | sed \"s/verilator_//\"`\nNote after installing (see Installation), you need to add the path to the bin directory to your PATH. Or, if you use\nmodulecmd, you’ll want a module ﬁle like the following:\nset install_root /CAD_DISK/verilator/{version-number-used-above}\nunsetenv VERILATOR_ROOT\nprepend-path PATH $install_root/bin\nprepend-path MANPATH $install_root/man\nprepend-path PKG_CONFIG_PATH $install_root/share/pkgconfig\n3.4. Detailed Build Instructions\n10", "source": "verilator"}
{"script_name": "ConfigurePathForInstalledVerilator", "definition_description": "This script adjusts environment variables to include the installed Verilator binary and other resources into the system paths.", "parameters": {"install_root": "The root directory where Verilator is installed"}, "values": "install_root: <path_to_installation>", "script_paradigm": "set install_root <path_to_installation>\nunsetenv VERILATOR_ROOT\nprepend-path PATH $install_root/bin\nprepend-path MANPATH $install_root/man\nprepend-path PKG_CONFIG_PATH $install_root/share/pkgconfig", "examples": [{"query": "How to adjust the system path for an installed Verilator?", "answer": "set install_root <path_to_installation>\nunsetenv VERILATOR_ROOT\nprepend-path PATH $install_root/bin\nprepend-path MANPATH $install_root/man\nprepend-path PKG_CONFIG_PATH $install_root/share/pkgconfig"}], "reference": "Verilator, Release Devel 5.031\n3.4.4 Auto Conﬁgure\nCreate the conﬁguration script:\nautoconf\n# Create ./configure script\n3.4.5 Eventual Installation Options\nBefore conﬁguring the build, you must decide how you’re going to eventually install Verilator onto your system. Ver-\nilator will be compiling the current value of the environment variables VERILATOR_ROOT, VERILATOR_SOLVER,\nSYSTEMC_INCLUDE, and SYSTEMC_LIBDIR as defaults into the executable, so they must be correct before con-\nﬁguring.\nThese are the installation options:\n1. Run-in-Place from VERILATOR_ROOT\nOur personal favorite is to always run Verilator in-place from its Git directory (don’t run make install). This\nallows the easiest experimentation and upgrading, and allows many versions of Verilator to co-exist on a system.\nexport VERILATOR_ROOT=`pwd`\n# if your shell is bash\nsetenv VERILATOR_ROOT `pwd`\n# if your shell is csh\n./configure\n# Running will use files from $VERILATOR_ROOT, so no install needed\nNote after installing (see Installation),\na calling program or shell must set the environment variable\nVERILATOR_ROOT to point to this Git directory, then execute $VERILATOR_ROOT/bin/verilator, which\nwill ﬁnd the path to all needed ﬁles.\n2. Install into a Speciﬁc Preﬁx\nYou may be an OS package maintainer building a Verilator package, or you may eventually be installing onto a\nproject/company-wide “CAD” tools disk that may support multiple versions of every tool. Tell conﬁgure the eventual\ndestination directory name. We recommend that the destination location include the Verilator version name:\nunset VERILATOR_ROOT\n# if your shell is bash\nunsetenv VERILATOR_ROOT\n# if your shell is csh\n# For the tarball, use the version number instead of git describe\n./configure --prefix /CAD_DISK/verilator/`git describe | sed \"s/verilator_//\"`\nNote after installing (see Installation), you need to add the path to the bin directory to your PATH. Or, if you use\nmodulecmd, you’ll want a module ﬁle like the following:\nset install_root /CAD_DISK/verilator/{version-number-used-above}\nunsetenv VERILATOR_ROOT\nprepend-path PATH $install_root/bin\nprepend-path MANPATH $install_root/man\nprepend-path PKG_CONFIG_PATH $install_root/share/pkgconfig\n3.4. Detailed Build Instructions\n10", "source": "verilator"}
{"script_name": "specparam_delay", "definition_description": "This script specifies the delay parameters for different signal transitions in the timing analysis.", "parameters": {"tpllh_B_Y": "Delay value for the transition from B to Y in the positive direction", "tplhl_B_Y": "Delay value for the transition from B to Y in the negative direction", "tpllh_A_Y": "Delay value for the transition from A to Y in the positive direction", "tplhl_A_Y": "Delay value for the transition from A to Y in the negative direction"}, "values": "tpllh_B_Y: 0.14, tplhl_B_Y: 0.15, tpllh_A_Y: 0.12, tplhl_A_Y: 0.12", "script_paradigm": "specparam tpllh$B$Y = <tpllh_B_Y>:<tpllh_B_Y>:<tpllh_B_Y>, tplhl$B$Y = <tplhl_B_Y>:<tplhl_B_Y>:<tplhl_B_Y>, tpllh$A$Y = <tpllh_A_Y>:<tpllh_A_Y>:<tpllh_A_Y>, tplhl$A$Y = <tplhl_A_Y>:<tplhl_A_Y>:<tplhl_A_Y>", "examples": [{"query": "How to specify path delays for A and B to Y?", "answer": "specparam tpllh$B$Y = 0.14:0.14:0.14, tplhl$B$Y = 0.15:0.15:0.15, tpllh$A$Y = 0.12:0.12:0.12, tplhl$A$Y = 0.12:0.12:0.12"}], "reference": "B); specify // delay parameters specparam tpllh$B$Y = 0.14:0.14:0.14, tplhl$B$Y = 0.15:0.15:0.15, tpllh$A$Y = 0.12:0.12:0.12, tplhl$A$Y = 0.12:0.12:0.12; // path delays (A *> Y) = (tpllh$A$Y, tplhl$A$Y); (B *> Y) = (tpllh$B$Y, tplhl$B$Y); endspecify endmodule `endcelldefine primitive udp_dff (out, in, clk, clr, set, NOTIFIER); output out; input in, clk, clr, set, NOTIFIER; reg out; table // in clk clr set NOT : Qt : Qt+1 // 0 r ? 0 ? : ? : 0 ; // clock in 0 1 r 0 ? ? : ? : 1 ; // clock in 1 1 * 0 ? ? : 1 : 1 ; // reduce pessimism 0 * ? 0 ? : 0 : 0 ; // reduce pessimism ? f ? ? ? : ? : - ; // no changes on negedge clk * b ? ? ? : ? : - ; // no changes when in switches ? ? ? 1 ? : ? : 1 ; // set output ? b 0 * ? : 1 : 1 ; // cover all transistions on set 1 x 0 * ? : 1 : 1 ; // cover all transistions on set ? ? 1 0 ? : ? : 0 ; // reset output ? b * 0 ? : 0 : 0 ; // cover all transistions on clr 0 x * 0 ? : 0 : 0 ; // cover all transistions on clr ? ? ? ? * : ? : x ; // any notifier changed endtable endprimitive // udp_dff primitive udp_tlat (out, in, enable, clr, set, NOTIFIER); output out; input in, enable, clr, set, NOTIFIER; reg out; table // in enable clr set NOT : Qt : Qt+1 // 1 1 0 ? ? : ? : 1 ; // 0 1 ? 0 ? : ? : 0 ; // 1 * 0 ? ? : 1 : 1 ; // reduce pessimism 0 * ? 0 ? : 0 : 0 ; // reduce pessimism * 0 ? ? ? : ? : - ; // no changes when in switches ? ? ? 1 ? : ? : 1 ; // set output ? 0 0 * ? : 1 : 1 ; // cover all transistions on set 1 ? 0 * ? : 1 : 1 ; // cover all transistions on set ? ? 1 0 ? : ? : 0 ; // reset output ? 0 * 0 ? : 0 : 0 ; // cover all transistions on clr 0 ? * 0 ? : 0 : 0 ; // cover all transistions on clr ? ? ? ? * : ? : x ; // any notifier changed endtable endprimitive // udp_tlat primitive udp_rslat (out, clr, set, NOTIFIER); output out; input clr, set, NOTIFIER; reg out; table // clr set NOT : Qt : Qt+1 // ? 1 ? : ? : 1 ; // set output 0 * ? : 1 : 1 ; // cover all transistions on set 1 0 ? : ? : 0 ; // reset output * 0 ? : 0 : 0 ; // cover all transistions on clr ? ? * : ? : x ; // any notifier changed endtable endprimitive // udp_tlat primitive udp_mux2 (out, in0, in1, sel); output out; input in0, in1, sel; table // in0 in1 sel : out // 1 ? 0 : 1 ; 0 ? 0 : 0 ; ? 1 1 : 1 ; ? 0 1 : 0 ; 0 0 x : 0 ; 1 1 x : 1 ; endtable endprimitive // udp_mux2 module PADNC(); endmodule module PADFC(); endmodule module PADGND(); endmodule module PADVDD(); endmodule", "source": "qflow"}
{"script_name": "udp_dff", "definition_description": "This script defines a D flip-flop with asynchronous clear and set inputs, typically used in sequential logic.", "parameters": {"out": "The output of the D flip-flop", "in": "The input to the D flip-flop", "clk": "Clock signal for triggering the flip-flop", "clr": "Asynchronous clear input", "set": "Asynchronous set input", "NOTIFIER": "Notifier for detecting changes"}, "values": "out: <out>, in: <in>, clk: <clk>, clr: <clr>, set: <set>, NOTIFIER: <NOTIFIER>", "script_paradigm": "primitive udp_dff (out, in, clk, clr, set, NOTIFIER); output out; input in, clk, clr, set, NOTIFIER; reg out; table // ... endtable endprimitive", "examples": [{"query": "How to define a D flip-flop in the script?", "answer": "primitive udp_dff (out, in, clk, clr, set, NOTIFIER); output out; input in, clk, clr, set, NOTIFIER; reg out; table // ... endtable endprimitive"}], "reference": "B); specify // delay parameters specparam tpllh$B$Y = 0.14:0.14:0.14, tplhl$B$Y = 0.15:0.15:0.15, tpllh$A$Y = 0.12:0.12:0.12, tplhl$A$Y = 0.12:0.12:0.12; // path delays (A *> Y) = (tpllh$A$Y, tplhl$A$Y); (B *> Y) = (tpllh$B$Y, tplhl$B$Y); endspecify endmodule `endcelldefine primitive udp_dff (out, in, clk, clr, set, NOTIFIER); output out; input in, clk, clr, set, NOTIFIER; reg out; table // in clk clr set NOT : Qt : Qt+1 // 0 r ? 0 ? : ? : 0 ; // clock in 0 1 r 0 ? ? : ? : 1 ; // clock in 1 1 * 0 ? ? : 1 : 1 ; // reduce pessimism 0 * ? 0 ? : 0 : 0 ; // reduce pessimism ? f ? ? ? : ? : - ; // no changes on negedge clk * b ? ? ? : ? : - ; // no changes when in switches ? ? ? 1 ? : ? : 1 ; // set output ? b 0 * ? : 1 : 1 ; // cover all transistions on set 1 x 0 * ? : 1 : 1 ; // cover all transistions on set ? ? 1 0 ? : ? : 0 ; // reset output ? b * 0 ? : 0 : 0 ; // cover all transistions on clr 0 x * 0 ? : 0 : 0 ; // cover all transistions on clr ? ? ? ? * : ? : x ; // any notifier changed endtable endprimitive // udp_dff primitive udp_tlat (out, in, enable, clr, set, NOTIFIER); output out; input in, enable, clr, set, NOTIFIER; reg out; table // in enable clr set NOT : Qt : Qt+1 // 1 1 0 ? ? : ? : 1 ; // 0 1 ? 0 ? : ? : 0 ; // 1 * 0 ? ? : 1 : 1 ; // reduce pessimism 0 * ? 0 ? : 0 : 0 ; // reduce pessimism * 0 ? ? ? : ? : - ; // no changes when in switches ? ? ? 1 ? : ? : 1 ; // set output ? 0 0 * ? : 1 : 1 ; // cover all transistions on set 1 ? 0 * ? : 1 : 1 ; // cover all transistions on set ? ? 1 0 ? : ? : 0 ; // reset output ? 0 * 0 ? : 0 : 0 ; // cover all transistions on clr 0 ? * 0 ? : 0 : 0 ; // cover all transistions on clr ? ? ? ? * : ? : x ; // any notifier changed endtable endprimitive // udp_tlat primitive udp_rslat (out, clr, set, NOTIFIER); output out; input clr, set, NOTIFIER; reg out; table // clr set NOT : Qt : Qt+1 // ? 1 ? : ? : 1 ; // set output 0 * ? : 1 : 1 ; // cover all transistions on set 1 0 ? : ? : 0 ; // reset output * 0 ? : 0 : 0 ; // cover all transistions on clr ? ? * : ? : x ; // any notifier changed endtable endprimitive // udp_tlat primitive udp_mux2 (out, in0, in1, sel); output out; input in0, in1, sel; table // in0 in1 sel : out // 1 ? 0 : 1 ; 0 ? 0 : 0 ; ? 1 1 : 1 ; ? 0 1 : 0 ; 0 0 x : 0 ; 1 1 x : 1 ; endtable endprimitive // udp_mux2 module PADNC(); endmodule module PADFC(); endmodule module PADGND(); endmodule module PADVDD(); endmodule", "source": "qflow"}
{"script_name": "udp_tlat", "definition_description": "This script defines a transparent latch with enable, asynchronous clear, and set inputs.", "parameters": {"out": "The output of the latch", "in": "The input to the latch", "enable": "Enable signal for the latch", "clr": "Asynchronous clear input", "set": "Asynchronous set input", "NOTIFIER": "Notifier for detecting changes"}, "values": "out: <out>, in: <in>, enable: <enable>, clr: <clr>, set: <set>, NOTIFIER: <NOTIFIER>", "script_paradigm": "primitive udp_tlat (out, in, enable, clr, set, NOTIFIER); output out; input in, enable, clr, set, NOTIFIER; reg out; table // ... endtable endprimitive", "examples": [{"query": "How to define a transparent latch with enable?", "answer": "primitive udp_tlat (out, in, enable, clr, set, NOTIFIER); output out; input in, enable, clr, set, NOTIFIER; reg out; table // ... endtable endprimitive"}], "reference": "B); specify // delay parameters specparam tpllh$B$Y = 0.14:0.14:0.14, tplhl$B$Y = 0.15:0.15:0.15, tpllh$A$Y = 0.12:0.12:0.12, tplhl$A$Y = 0.12:0.12:0.12; // path delays (A *> Y) = (tpllh$A$Y, tplhl$A$Y); (B *> Y) = (tpllh$B$Y, tplhl$B$Y); endspecify endmodule `endcelldefine primitive udp_dff (out, in, clk, clr, set, NOTIFIER); output out; input in, clk, clr, set, NOTIFIER; reg out; table // in clk clr set NOT : Qt : Qt+1 // 0 r ? 0 ? : ? : 0 ; // clock in 0 1 r 0 ? ? : ? : 1 ; // clock in 1 1 * 0 ? ? : 1 : 1 ; // reduce pessimism 0 * ? 0 ? : 0 : 0 ; // reduce pessimism ? f ? ? ? : ? : - ; // no changes on negedge clk * b ? ? ? : ? : - ; // no changes when in switches ? ? ? 1 ? : ? : 1 ; // set output ? b 0 * ? : 1 : 1 ; // cover all transistions on set 1 x 0 * ? : 1 : 1 ; // cover all transistions on set ? ? 1 0 ? : ? : 0 ; // reset output ? b * 0 ? : 0 : 0 ; // cover all transistions on clr 0 x * 0 ? : 0 : 0 ; // cover all transistions on clr ? ? ? ? * : ? : x ; // any notifier changed endtable endprimitive // udp_dff primitive udp_tlat (out, in, enable, clr, set, NOTIFIER); output out; input in, enable, clr, set, NOTIFIER; reg out; table // in enable clr set NOT : Qt : Qt+1 // 1 1 0 ? ? : ? : 1 ; // 0 1 ? 0 ? : ? : 0 ; // 1 * 0 ? ? : 1 : 1 ; // reduce pessimism 0 * ? 0 ? : 0 : 0 ; // reduce pessimism * 0 ? ? ? : ? : - ; // no changes when in switches ? ? ? 1 ? : ? : 1 ; // set output ? 0 0 * ? : 1 : 1 ; // cover all transistions on set 1 ? 0 * ? : 1 : 1 ; // cover all transistions on set ? ? 1 0 ? : ? : 0 ; // reset output ? 0 * 0 ? : 0 : 0 ; // cover all transistions on clr 0 ? * 0 ? : 0 : 0 ; // cover all transistions on clr ? ? ? ? * : ? : x ; // any notifier changed endtable endprimitive // udp_tlat primitive udp_rslat (out, clr, set, NOTIFIER); output out; input clr, set, NOTIFIER; reg out; table // clr set NOT : Qt : Qt+1 // ? 1 ? : ? : 1 ; // set output 0 * ? : 1 : 1 ; // cover all transistions on set 1 0 ? : ? : 0 ; // reset output * 0 ? : 0 : 0 ; // cover all transistions on clr ? ? * : ? : x ; // any notifier changed endtable endprimitive // udp_tlat primitive udp_mux2 (out, in0, in1, sel); output out; input in0, in1, sel; table // in0 in1 sel : out // 1 ? 0 : 1 ; 0 ? 0 : 0 ; ? 1 1 : 1 ; ? 0 1 : 0 ; 0 0 x : 0 ; 1 1 x : 1 ; endtable endprimitive // udp_mux2 module PADNC(); endmodule module PADFC(); endmodule module PADGND(); endmodule module PADVDD(); endmodule", "source": "qflow"}
{"script_name": "udp_rslat", "definition_description": "This script defines a reset-set latch with asynchronous clear and set inputs.", "parameters": {"out": "The output of the latch", "clr": "Asynchronous clear input", "set": "Asynchronous set input", "NOTIFIER": "Notifier for detecting changes"}, "values": "out: <out>, clr: <clr>, set: <set>, NOTIFIER: <NOTIFIER>", "script_paradigm": "primitive udp_rslat (out, clr, set, NOTIFIER); output out; input clr, set, NOTIFIER; reg out; table // ... endtable endprimitive", "examples": [{"query": "How to define a reset-set latch in the script?", "answer": "primitive udp_rslat (out, clr, set, NOTIFIER); output out; input clr, set, NOTIFIER; reg out; table // ... endtable endprimitive"}], "reference": "B); specify // delay parameters specparam tpllh$B$Y = 0.14:0.14:0.14, tplhl$B$Y = 0.15:0.15:0.15, tpllh$A$Y = 0.12:0.12:0.12, tplhl$A$Y = 0.12:0.12:0.12; // path delays (A *> Y) = (tpllh$A$Y, tplhl$A$Y); (B *> Y) = (tpllh$B$Y, tplhl$B$Y); endspecify endmodule `endcelldefine primitive udp_dff (out, in, clk, clr, set, NOTIFIER); output out; input in, clk, clr, set, NOTIFIER; reg out; table // in clk clr set NOT : Qt : Qt+1 // 0 r ? 0 ? : ? : 0 ; // clock in 0 1 r 0 ? ? : ? : 1 ; // clock in 1 1 * 0 ? ? : 1 : 1 ; // reduce pessimism 0 * ? 0 ? : 0 : 0 ; // reduce pessimism ? f ? ? ? : ? : - ; // no changes on negedge clk * b ? ? ? : ? : - ; // no changes when in switches ? ? ? 1 ? : ? : 1 ; // set output ? b 0 * ? : 1 : 1 ; // cover all transistions on set 1 x 0 * ? : 1 : 1 ; // cover all transistions on set ? ? 1 0 ? : ? : 0 ; // reset output ? b * 0 ? : 0 : 0 ; // cover all transistions on clr 0 x * 0 ? : 0 : 0 ; // cover all transistions on clr ? ? ? ? * : ? : x ; // any notifier changed endtable endprimitive // udp_dff primitive udp_tlat (out, in, enable, clr, set, NOTIFIER); output out; input in, enable, clr, set, NOTIFIER; reg out; table // in enable clr set NOT : Qt : Qt+1 // 1 1 0 ? ? : ? : 1 ; // 0 1 ? 0 ? : ? : 0 ; // 1 * 0 ? ? : 1 : 1 ; // reduce pessimism 0 * ? 0 ? : 0 : 0 ; // reduce pessimism * 0 ? ? ? : ? : - ; // no changes when in switches ? ? ? 1 ? : ? : 1 ; // set output ? 0 0 * ? : 1 : 1 ; // cover all transistions on set 1 ? 0 * ? : 1 : 1 ; // cover all transistions on set ? ? 1 0 ? : ? : 0 ; // reset output ? 0 * 0 ? : 0 : 0 ; // cover all transistions on clr 0 ? * 0 ? : 0 : 0 ; // cover all transistions on clr ? ? ? ? * : ? : x ; // any notifier changed endtable endprimitive // udp_tlat primitive udp_rslat (out, clr, set, NOTIFIER); output out; input clr, set, NOTIFIER; reg out; table // clr set NOT : Qt : Qt+1 // ? 1 ? : ? : 1 ; // set output 0 * ? : 1 : 1 ; // cover all transistions on set 1 0 ? : ? : 0 ; // reset output * 0 ? : 0 : 0 ; // cover all transistions on clr ? ? * : ? : x ; // any notifier changed endtable endprimitive // udp_tlat primitive udp_mux2 (out, in0, in1, sel); output out; input in0, in1, sel; table // in0 in1 sel : out // 1 ? 0 : 1 ; 0 ? 0 : 0 ; ? 1 1 : 1 ; ? 0 1 : 0 ; 0 0 x : 0 ; 1 1 x : 1 ; endtable endprimitive // udp_mux2 module PADNC(); endmodule module PADFC(); endmodule module PADGND(); endmodule module PADVDD(); endmodule", "source": "qflow"}
{"script_name": "udp_mux2", "definition_description": "This script defines a 2-input multiplexer.", "parameters": {"out": "The output of the multiplexer", "in0": "The first input to the multiplexer", "in1": "The second input to the multiplexer", "sel": "The selector signal to choose between in0 and in1"}, "values": "out: <out>, in0: <in0>, in1: <in1>, sel: <sel>", "script_paradigm": "primitive udp_mux2 (out, in0, in1, sel); output out; input in0, in1, sel; table // ... endtable endprimitive", "examples": [{"query": "How to define a 2-input multiplexer?", "answer": "primitive udp_mux2 (out, in0, in1, sel); output out; input in0, in1, sel; table // ... endtable endprimitive"}], "reference": "B); specify // delay parameters specparam tpllh$B$Y = 0.14:0.14:0.14, tplhl$B$Y = 0.15:0.15:0.15, tpllh$A$Y = 0.12:0.12:0.12, tplhl$A$Y = 0.12:0.12:0.12; // path delays (A *> Y) = (tpllh$A$Y, tplhl$A$Y); (B *> Y) = (tpllh$B$Y, tplhl$B$Y); endspecify endmodule `endcelldefine primitive udp_dff (out, in, clk, clr, set, NOTIFIER); output out; input in, clk, clr, set, NOTIFIER; reg out; table // in clk clr set NOT : Qt : Qt+1 // 0 r ? 0 ? : ? : 0 ; // clock in 0 1 r 0 ? ? : ? : 1 ; // clock in 1 1 * 0 ? ? : 1 : 1 ; // reduce pessimism 0 * ? 0 ? : 0 : 0 ; // reduce pessimism ? f ? ? ? : ? : - ; // no changes on negedge clk * b ? ? ? : ? : - ; // no changes when in switches ? ? ? 1 ? : ? : 1 ; // set output ? b 0 * ? : 1 : 1 ; // cover all transistions on set 1 x 0 * ? : 1 : 1 ; // cover all transistions on set ? ? 1 0 ? : ? : 0 ; // reset output ? b * 0 ? : 0 : 0 ; // cover all transistions on clr 0 x * 0 ? : 0 : 0 ; // cover all transistions on clr ? ? ? ? * : ? : x ; // any notifier changed endtable endprimitive // udp_dff primitive udp_tlat (out, in, enable, clr, set, NOTIFIER); output out; input in, enable, clr, set, NOTIFIER; reg out; table // in enable clr set NOT : Qt : Qt+1 // 1 1 0 ? ? : ? : 1 ; // 0 1 ? 0 ? : ? : 0 ; // 1 * 0 ? ? : 1 : 1 ; // reduce pessimism 0 * ? 0 ? : 0 : 0 ; // reduce pessimism * 0 ? ? ? : ? : - ; // no changes when in switches ? ? ? 1 ? : ? : 1 ; // set output ? 0 0 * ? : 1 : 1 ; // cover all transistions on set 1 ? 0 * ? : 1 : 1 ; // cover all transistions on set ? ? 1 0 ? : ? : 0 ; // reset output ? 0 * 0 ? : 0 : 0 ; // cover all transistions on clr 0 ? * 0 ? : 0 : 0 ; // cover all transistions on clr ? ? ? ? * : ? : x ; // any notifier changed endtable endprimitive // udp_tlat primitive udp_rslat (out, clr, set, NOTIFIER); output out; input clr, set, NOTIFIER; reg out; table // clr set NOT : Qt : Qt+1 // ? 1 ? : ? : 1 ; // set output 0 * ? : 1 : 1 ; // cover all transistions on set 1 0 ? : ? : 0 ; // reset output * 0 ? : 0 : 0 ; // cover all transistions on clr ? ? * : ? : x ; // any notifier changed endtable endprimitive // udp_tlat primitive udp_mux2 (out, in0, in1, sel); output out; input in0, in1, sel; table // in0 in1 sel : out // 1 ? 0 : 1 ; 0 ? 0 : 0 ; ? 1 1 : 1 ; ? 0 1 : 0 ; 0 0 x : 0 ; 1 1 x : 1 ; endtable endprimitive // udp_mux2 module PADNC(); endmodule module PADFC(); endmodule module PADGND(); endmodule module PADVDD(); endmodule", "source": "qflow"}
{"script_name": "set_false_path", "definition_description": "This script is used to disable timing analysis along specific paths in the design, applying false path constraints to setup, hold, or edge-specific paths.", "parameters": {"setup": "Applies the false path constraint to setup checks.", "hold": "Applies the false path constraint to hold checks.", "rise": "Applies the false path constraint to rising path edges.", "fall": "Applies the false path constraint to falling path edges.", "from": "A list of clocks, instances, ports, or pins from which the false path constraint originates.", "rise_from": "A list of clocks, instances, ports, or pins from which the false path constraint originates on the rising edge.", "fall_from": "A list of clocks, instances, ports, or pins from which the false path constraint originates on the falling edge.", "through": "A list of instances, pins, or nets that the false path constraint passes through.", "rise_through": "A list of instances, pins, or nets that the false path constraint passes through on the rising edge.", "fall_through": "A list of instances, pins, or nets that the false path constraint passes through on the falling edge.", "to": "A list of clocks, instances, ports, or pins where the false path constraint ends.", "rise_to": "A list of clocks, instances, ports, or pins where the false path constraint ends on the rising edge.", "fall_to": "A list of clocks, instances, ports, or pins where the false path constraint ends on the falling edge.", "reset_path": "Removes any matching set_false_path, set_multicycle_path, set_max_delay, set_min_delay exceptions before applying the new constraint."}, "values": "setup: <apply setup check>, hold: <apply hold check>, rise: <apply rising edge>, fall: <apply falling edge>, from: <from_list>, rise_from: <rise_from_list>, fall_from: <fall_from_list>, through: <through_list>, rise_through: <rise_through_list>, fall_through: <fall_through_list>, to: <to_list>, rise_to: <rise_to_list>, fall_to: <fall_to_list>, reset_path: <remove exceptions>", "script_paradigm": "set_false_path [-setup] [-hold] [-rise] [-fall] [-from <from_list>] [-rise_from <rise_from_list>] [-fall_from <fall_from_list>] [-through <through_list>] [-rise_through <rise_through_list>] [-fall_through <fall_through_list>] [-to <to_list>] [-rise_to <rise_to_list>] [-fall_to <fall_to_list>] [-reset_path]", "examples": [{"query": "How to disable false paths for setup checks from clock clk to instance reg1?", "answer": "set_false_path -setup -from clk -to reg1"}, {"query": "Disable false path for hold checks between net net1 and instance reg2 on the falling edge.", "answer": "set_false_path -hold -fall -from net1 -to reg2"}, {"query": "Remove previous false path exceptions and apply a false path from clock clk to instance reg3.", "answer": "set_false_path -reset_path -from clk -to reg3"}], "reference": "set_false_path\n[-setup]\n[-hold]\n[-rise]\n[-fall]\n[-from from_list]\n[-rise_from from_list]\n[-fall_from from_list]\n[-through through_list]\n[-rise_through through_list]\n[-fall_through through_list]\n[-to to_list]\n[-rise_to to_list]\n[-fall_to to_list]\n[-reset_path]\n-setup\nApply to setup checks.\n-hold\nApply to hold checks.\n-rise\nApply to rising path edges.\n-fall\nApply to falling path edges.\n-reset_path\nRemove any matching set_false_path, set_multicycle_path, \nset_max_delay, set_min_delay exceptions first.\n-from from_list\nA list of clocks, instances, ports or pins.\n-through through_list\nA list of instances, pins or nets.\n-to to_list\nA list of clocks, instances, ports or pins.\nThe set_false_path command disables timing along a path from, through and to a group of design objects.\nObjects in from_list can be clocks, register/latch instances, or register/latch clock pins. The -rise_from \nand -fall_from keywords restrict the false paths to a specific clock edge.\nObjects in through_list can be nets, instances, instance pins, or hierarchical pins,. The -rise_through \nand -fall_through keywords restrict the false paths to a specific path edge that traverses through the \nobject.\nObjects in to_list can be clocks, register/latch instances, or register/latch clock pins. The -rise_to and -\nfall_to keywords restrict the false paths to a specific transition at the path end.", "source": "OpenSTA"}
{"script_name": "VerilatorDockerRun", "definition_description": "This script demonstrates how to run Verilator in a Docker container for Verilating a given Verilog file.", "parameters": {"verilog_file": "The Verilog source file to be processed by Verilator", "docker_image": "The Docker image to use for Verilator (e.g., verilator/verilator:latest)", "volume": "The path to the local directory to mount as a volume in the Docker container", "user": "The user id and group id for proper file permissions"}, "values": "verilog_file: test.v, docker_image: verilator/verilator:latest, volume: ${PWD}:/work, user: $(id -u):$(id -g)", "script_paradigm": "docker run -ti -v <volume> --user <user> <docker_image> --cc <verilog_file>", "examples": [{"query": "How to run Verilator with test.v using Docker?", "answer": "docker run -ti -v ${PWD}:/work --user $(id -u):$(id -g) verilator/verilator:latest --cc test.v"}, {"query": "How to run Verilator with test.v in a container using a custom volume path?", "answer": "docker run -ti -v /path/to/dir:/work --user $(id -u):$(id -g) verilator/verilator:latest --cc test.v"}], "reference": "Verilator, Release Devel 5.031\n./verilator-docker 4.030 --cc test.v\nIf you prefer not to use verilator-docker you must give the container access to your ﬁles as a volume with\nappropriate user rights. For example to Verilate test.v:\ndocker run -ti -v ${PWD}:/work --user $(id -u):$(id -g) verilator/verilator:latest --\n˓→cc test.v\nThis method can only access ﬁles below the current directory. An alternative is setup the volume -workdir.\nYou can also work in the container by setting the entrypoint (don’t forget to mount a volume if you want your work\npersistent):\ndocker run -ti --entrypoint /bin/bash verilator/verilator:latest\nYou can also use the container to build Verilator at a speciﬁc commit:\ndocker build --build-arg SOURCE_COMMIT=<commit> .\n3.6.1 Internals\nThe Dockerﬁle builds Verilator and removes the tree when completed to reduce the image size. The entrypoint is a\nwrapper script (verilator-wrap.sh). That script 1. calls Verilator, and 2. copies the Verilated runtime ﬁles to\nthe obj_dir or the -Mdir respectively. This allows the user to have the ﬁles to they may later build the C++ output\nwith the matching runtime ﬁles. The wrapper also patches the Verilated Makeﬁle accordingly.\nA hook is also deﬁned and run by Docker Hub via automated builds.\n3.6. Verilator Executable Docker Container\n13", "source": "verilator"}
{"script_name": "VerilatorDockerBuild", "definition_description": "This script shows how to build the Verilator Docker image at a specific commit.", "parameters": {"commit": "The commit hash or tag to use for building Verilator in the Docker container"}, "values": "commit: <commit>", "script_paradigm": "docker build --build-arg SOURCE_COMMIT=<commit> .", "examples": [{"query": "How to build Verilator from a specific commit using Docker?", "answer": "docker build --build-arg SOURCE_COMMIT=abc123 ."}], "reference": "Verilator, Release Devel 5.031\n./verilator-docker 4.030 --cc test.v\nIf you prefer not to use verilator-docker you must give the container access to your ﬁles as a volume with\nappropriate user rights. For example to Verilate test.v:\ndocker run -ti -v ${PWD}:/work --user $(id -u):$(id -g) verilator/verilator:latest --\n˓→cc test.v\nThis method can only access ﬁles below the current directory. An alternative is setup the volume -workdir.\nYou can also work in the container by setting the entrypoint (don’t forget to mount a volume if you want your work\npersistent):\ndocker run -ti --entrypoint /bin/bash verilator/verilator:latest\nYou can also use the container to build Verilator at a speciﬁc commit:\ndocker build --build-arg SOURCE_COMMIT=<commit> .\n3.6.1 Internals\nThe Dockerﬁle builds Verilator and removes the tree when completed to reduce the image size. The entrypoint is a\nwrapper script (verilator-wrap.sh). That script 1. calls Verilator, and 2. copies the Verilated runtime ﬁles to\nthe obj_dir or the -Mdir respectively. This allows the user to have the ﬁles to they may later build the C++ output\nwith the matching runtime ﬁles. The wrapper also patches the Verilated Makeﬁle accordingly.\nA hook is also deﬁned and run by Docker Hub via automated builds.\n3.6. Verilator Executable Docker Container\n13", "source": "verilator"}
{"script_name": "VerilatorDockerEntrypoint", "definition_description": "This script allows you to start a Verilator Docker container with an entrypoint set to bash for interactive work.", "parameters": {"docker_image": "The Docker image to use for the Verilator container", "volume": "The path to the local directory to mount as a volume in the Docker container"}, "values": "docker_image: verilator/verilator:latest, volume: ${PWD}:/work", "script_paradigm": "docker run -ti --entrypoint /bin/bash -v <volume> <docker_image>", "examples": [{"query": "How to start a Verilator Docker container with bash as entrypoint?", "answer": "docker run -ti --entrypoint /bin/bash -v ${PWD}:/work verilator/verilator:latest"}], "reference": "Verilator, Release Devel 5.031\n./verilator-docker 4.030 --cc test.v\nIf you prefer not to use verilator-docker you must give the container access to your ﬁles as a volume with\nappropriate user rights. For example to Verilate test.v:\ndocker run -ti -v ${PWD}:/work --user $(id -u):$(id -g) verilator/verilator:latest --\n˓→cc test.v\nThis method can only access ﬁles below the current directory. An alternative is setup the volume -workdir.\nYou can also work in the container by setting the entrypoint (don’t forget to mount a volume if you want your work\npersistent):\ndocker run -ti --entrypoint /bin/bash verilator/verilator:latest\nYou can also use the container to build Verilator at a speciﬁc commit:\ndocker build --build-arg SOURCE_COMMIT=<commit> .\n3.6.1 Internals\nThe Dockerﬁle builds Verilator and removes the tree when completed to reduce the image size. The entrypoint is a\nwrapper script (verilator-wrap.sh). That script 1. calls Verilator, and 2. copies the Verilated runtime ﬁles to\nthe obj_dir or the -Mdir respectively. This allows the user to have the ﬁles to they may later build the C++ output\nwith the matching runtime ﬁles. The wrapper also patches the Verilated Makeﬁle accordingly.\nA hook is also deﬁned and run by Docker Hub via automated builds.\n3.6. Verilator Executable Docker Container\n13", "source": "verilator"}
{"script_name": "ignore_param", "definition_description": "This script prevents the use of a specific parameter when matching cells during the pass.", "parameters": {"cell_type": "The type of the cell that the parameter belongs to", "parameter_name": "The name of the parameter to be ignored"}, "values": "cell_type: <type>, parameter_name: <name>", "script_paradigm": "ignore_param <cell_type> <parameter_name>", "examples": [{"query": "How to ignore the 'width' parameter when matching cells of type 'mux'?", "answer": "ignore_param mux width"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n-ignore_param <cell_type> <parameter_name>\nDo not use this parameter when matching cells.\nThis pass does not operate on modules with unprocessed processes in it.\n(I.e. the 'proc' pass should be used first to convert processes to netlists.)\nThis pass can also be used for mining for frequent subcircuits. In this mode\nthe following options are to be used instead of the -map option.\n-mine <out_file>\nmine for frequent subcircuits and write them to the given RTLIL file\n-mine_cells_span <min> <max>\nonly mine for subcircuits with the specified number of cells\ndefault value: 3 5\n-mine_min_freq <num>\nonly mine for subcircuits with at least the specified number of matches\ndefault value: 10\n-mine_limit_matches_per_module <num>\nwhen calculating the number of matches for a subcircuit, don't count\nmore than the specified number of matches per module\n-mine_max_fanout <num>\ndon't consider internal signals with more than <num> connections\nThe modules in the map file may have the attribute 'extract_order' set to an\ninteger value. Then this value is used to determine the order in which the pass\ntries to map the modules to the design (ascending, default value is 0).\nSee 'help techmap' for a pass that does the opposite thing.\n10.73 extract_counter - Extract GreenPak4 counter cells\nyosys> help extract_counter\nextract_counter [options] [selection]\nThis pass converts non-resettable or async resettable counters to counter cells.\nUse a target-specific 'techmap' map file to convert those cells to the actual\ntarget cells.\n-maxwidth N\nOnly extract counters up to N bits wide (default 64)\n-minwidth N\nOnly extract counters at least N bits wide (default 2)\n-allow_arst yes|no\n(continues on next page)\n402\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "mine", "definition_description": "This script mines for frequent subcircuits and writes them to a specified RTLIL file.", "parameters": {"out_file": "The file where the mined subcircuits will be written"}, "values": "out_file: <file>", "script_paradigm": "mine -mine <out_file>", "examples": [{"query": "How to mine for frequent subcircuits and save them to 'subcircuits.rlil'?", "answer": "mine -mine subcircuits.rlil"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n-ignore_param <cell_type> <parameter_name>\nDo not use this parameter when matching cells.\nThis pass does not operate on modules with unprocessed processes in it.\n(I.e. the 'proc' pass should be used first to convert processes to netlists.)\nThis pass can also be used for mining for frequent subcircuits. In this mode\nthe following options are to be used instead of the -map option.\n-mine <out_file>\nmine for frequent subcircuits and write them to the given RTLIL file\n-mine_cells_span <min> <max>\nonly mine for subcircuits with the specified number of cells\ndefault value: 3 5\n-mine_min_freq <num>\nonly mine for subcircuits with at least the specified number of matches\ndefault value: 10\n-mine_limit_matches_per_module <num>\nwhen calculating the number of matches for a subcircuit, don't count\nmore than the specified number of matches per module\n-mine_max_fanout <num>\ndon't consider internal signals with more than <num> connections\nThe modules in the map file may have the attribute 'extract_order' set to an\ninteger value. Then this value is used to determine the order in which the pass\ntries to map the modules to the design (ascending, default value is 0).\nSee 'help techmap' for a pass that does the opposite thing.\n10.73 extract_counter - Extract GreenPak4 counter cells\nyosys> help extract_counter\nextract_counter [options] [selection]\nThis pass converts non-resettable or async resettable counters to counter cells.\nUse a target-specific 'techmap' map file to convert those cells to the actual\ntarget cells.\n-maxwidth N\nOnly extract counters up to N bits wide (default 64)\n-minwidth N\nOnly extract counters at least N bits wide (default 2)\n-allow_arst yes|no\n(continues on next page)\n402\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "mine_cells_span", "definition_description": "This script restricts the mining of subcircuits to those that have a specified number of cells.", "parameters": {"min": "The minimum number of cells in the subcircuit", "max": "The maximum number of cells in the subcircuit"}, "values": "min: <min>, max: <max>", "script_paradigm": "mine_cells_span <min> <max>", "examples": [{"query": "How to mine subcircuits with between 4 and 6 cells?", "answer": "mine_cells_span 4 6"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n-ignore_param <cell_type> <parameter_name>\nDo not use this parameter when matching cells.\nThis pass does not operate on modules with unprocessed processes in it.\n(I.e. the 'proc' pass should be used first to convert processes to netlists.)\nThis pass can also be used for mining for frequent subcircuits. In this mode\nthe following options are to be used instead of the -map option.\n-mine <out_file>\nmine for frequent subcircuits and write them to the given RTLIL file\n-mine_cells_span <min> <max>\nonly mine for subcircuits with the specified number of cells\ndefault value: 3 5\n-mine_min_freq <num>\nonly mine for subcircuits with at least the specified number of matches\ndefault value: 10\n-mine_limit_matches_per_module <num>\nwhen calculating the number of matches for a subcircuit, don't count\nmore than the specified number of matches per module\n-mine_max_fanout <num>\ndon't consider internal signals with more than <num> connections\nThe modules in the map file may have the attribute 'extract_order' set to an\ninteger value. Then this value is used to determine the order in which the pass\ntries to map the modules to the design (ascending, default value is 0).\nSee 'help techmap' for a pass that does the opposite thing.\n10.73 extract_counter - Extract GreenPak4 counter cells\nyosys> help extract_counter\nextract_counter [options] [selection]\nThis pass converts non-resettable or async resettable counters to counter cells.\nUse a target-specific 'techmap' map file to convert those cells to the actual\ntarget cells.\n-maxwidth N\nOnly extract counters up to N bits wide (default 64)\n-minwidth N\nOnly extract counters at least N bits wide (default 2)\n-allow_arst yes|no\n(continues on next page)\n402\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "mine_min_freq", "definition_description": "This script ensures that only subcircuits with at least a specified number of matches are mined.", "parameters": {"num": "The minimum number of matches for a subcircuit to be considered"}, "values": "num: <num>", "script_paradigm": "mine_min_freq <num>", "examples": [{"query": "How to mine subcircuits with at least 15 matches?", "answer": "mine_min_freq 15"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n-ignore_param <cell_type> <parameter_name>\nDo not use this parameter when matching cells.\nThis pass does not operate on modules with unprocessed processes in it.\n(I.e. the 'proc' pass should be used first to convert processes to netlists.)\nThis pass can also be used for mining for frequent subcircuits. In this mode\nthe following options are to be used instead of the -map option.\n-mine <out_file>\nmine for frequent subcircuits and write them to the given RTLIL file\n-mine_cells_span <min> <max>\nonly mine for subcircuits with the specified number of cells\ndefault value: 3 5\n-mine_min_freq <num>\nonly mine for subcircuits with at least the specified number of matches\ndefault value: 10\n-mine_limit_matches_per_module <num>\nwhen calculating the number of matches for a subcircuit, don't count\nmore than the specified number of matches per module\n-mine_max_fanout <num>\ndon't consider internal signals with more than <num> connections\nThe modules in the map file may have the attribute 'extract_order' set to an\ninteger value. Then this value is used to determine the order in which the pass\ntries to map the modules to the design (ascending, default value is 0).\nSee 'help techmap' for a pass that does the opposite thing.\n10.73 extract_counter - Extract GreenPak4 counter cells\nyosys> help extract_counter\nextract_counter [options] [selection]\nThis pass converts non-resettable or async resettable counters to counter cells.\nUse a target-specific 'techmap' map file to convert those cells to the actual\ntarget cells.\n-maxwidth N\nOnly extract counters up to N bits wide (default 64)\n-minwidth N\nOnly extract counters at least N bits wide (default 2)\n-allow_arst yes|no\n(continues on next page)\n402\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "mine_limit_matches_per_module", "definition_description": "This script limits the number of matches counted for a subcircuit in each module during mining.", "parameters": {"num": "The maximum number of matches to be counted per module"}, "values": "num: <num>", "script_paradigm": "mine_limit_matches_per_module <num>", "examples": [{"query": "How to limit the number of matches counted per module to 5?", "answer": "mine_limit_matches_per_module 5"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n-ignore_param <cell_type> <parameter_name>\nDo not use this parameter when matching cells.\nThis pass does not operate on modules with unprocessed processes in it.\n(I.e. the 'proc' pass should be used first to convert processes to netlists.)\nThis pass can also be used for mining for frequent subcircuits. In this mode\nthe following options are to be used instead of the -map option.\n-mine <out_file>\nmine for frequent subcircuits and write them to the given RTLIL file\n-mine_cells_span <min> <max>\nonly mine for subcircuits with the specified number of cells\ndefault value: 3 5\n-mine_min_freq <num>\nonly mine for subcircuits with at least the specified number of matches\ndefault value: 10\n-mine_limit_matches_per_module <num>\nwhen calculating the number of matches for a subcircuit, don't count\nmore than the specified number of matches per module\n-mine_max_fanout <num>\ndon't consider internal signals with more than <num> connections\nThe modules in the map file may have the attribute 'extract_order' set to an\ninteger value. Then this value is used to determine the order in which the pass\ntries to map the modules to the design (ascending, default value is 0).\nSee 'help techmap' for a pass that does the opposite thing.\n10.73 extract_counter - Extract GreenPak4 counter cells\nyosys> help extract_counter\nextract_counter [options] [selection]\nThis pass converts non-resettable or async resettable counters to counter cells.\nUse a target-specific 'techmap' map file to convert those cells to the actual\ntarget cells.\n-maxwidth N\nOnly extract counters up to N bits wide (default 64)\n-minwidth N\nOnly extract counters at least N bits wide (default 2)\n-allow_arst yes|no\n(continues on next page)\n402\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "mine_max_fanout", "definition_description": "This script excludes internal signals with more than a specified number of connections from being considered during mining.", "parameters": {"num": "The maximum allowed number of connections for internal signals"}, "values": "num: <num>", "script_paradigm": "mine_max_fanout <num>", "examples": [{"query": "How to exclude internal signals with more than 10 connections during mining?", "answer": "mine_max_fanout 10"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n-ignore_param <cell_type> <parameter_name>\nDo not use this parameter when matching cells.\nThis pass does not operate on modules with unprocessed processes in it.\n(I.e. the 'proc' pass should be used first to convert processes to netlists.)\nThis pass can also be used for mining for frequent subcircuits. In this mode\nthe following options are to be used instead of the -map option.\n-mine <out_file>\nmine for frequent subcircuits and write them to the given RTLIL file\n-mine_cells_span <min> <max>\nonly mine for subcircuits with the specified number of cells\ndefault value: 3 5\n-mine_min_freq <num>\nonly mine for subcircuits with at least the specified number of matches\ndefault value: 10\n-mine_limit_matches_per_module <num>\nwhen calculating the number of matches for a subcircuit, don't count\nmore than the specified number of matches per module\n-mine_max_fanout <num>\ndon't consider internal signals with more than <num> connections\nThe modules in the map file may have the attribute 'extract_order' set to an\ninteger value. Then this value is used to determine the order in which the pass\ntries to map the modules to the design (ascending, default value is 0).\nSee 'help techmap' for a pass that does the opposite thing.\n10.73 extract_counter - Extract GreenPak4 counter cells\nyosys> help extract_counter\nextract_counter [options] [selection]\nThis pass converts non-resettable or async resettable counters to counter cells.\nUse a target-specific 'techmap' map file to convert those cells to the actual\ntarget cells.\n-maxwidth N\nOnly extract counters up to N bits wide (default 64)\n-minwidth N\nOnly extract counters at least N bits wide (default 2)\n-allow_arst yes|no\n(continues on next page)\n402\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "extract_counter", "definition_description": "This script extracts GreenPak4 counter cells by converting non-resettable or async resettable counters to counter cells.", "parameters": {"maxwidth": "The maximum width of counters to be extracted (default is 64)", "minwidth": "The minimum width of counters to be extracted (default is 2)", "allow_arst": "Allows the extraction of async resettable counters (yes|no)"}, "values": "maxwidth: <N>, minwidth: <N>, allow_arst: <yes/no>", "script_paradigm": "extract_counter -maxwidth <N> -minwidth <N> -allow_arst <yes/no>", "examples": [{"query": "How to extract counters with widths between 4 and 32 bits and allow async resettable counters?", "answer": "extract_counter -maxwidth 32 -minwidth 4 -allow_arst yes"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\n-ignore_param <cell_type> <parameter_name>\nDo not use this parameter when matching cells.\nThis pass does not operate on modules with unprocessed processes in it.\n(I.e. the 'proc' pass should be used first to convert processes to netlists.)\nThis pass can also be used for mining for frequent subcircuits. In this mode\nthe following options are to be used instead of the -map option.\n-mine <out_file>\nmine for frequent subcircuits and write them to the given RTLIL file\n-mine_cells_span <min> <max>\nonly mine for subcircuits with the specified number of cells\ndefault value: 3 5\n-mine_min_freq <num>\nonly mine for subcircuits with at least the specified number of matches\ndefault value: 10\n-mine_limit_matches_per_module <num>\nwhen calculating the number of matches for a subcircuit, don't count\nmore than the specified number of matches per module\n-mine_max_fanout <num>\ndon't consider internal signals with more than <num> connections\nThe modules in the map file may have the attribute 'extract_order' set to an\ninteger value. Then this value is used to determine the order in which the pass\ntries to map the modules to the design (ascending, default value is 0).\nSee 'help techmap' for a pass that does the opposite thing.\n10.73 extract_counter - Extract GreenPak4 counter cells\nyosys> help extract_counter\nextract_counter [options] [selection]\nThis pass converts non-resettable or async resettable counters to counter cells.\nUse a target-specific 'techmap' map file to convert those cells to the actual\ntarget cells.\n-maxwidth N\nOnly extract counters up to N bits wide (default 64)\n-minwidth N\nOnly extract counters at least N bits wide (default 2)\n-allow_arst yes|no\n(continues on next page)\n402\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "$_DFF_NP1_", "definition_description": "This script models a negative edge D-type flip-flop with a positive polarity reset.", "parameters": {"D": "The data input to the flip-flop", "C": "The clock input, which triggers on the negative edge", "R": "The reset input, which triggers on the positive edge", "Q": "The output of the flip-flop, which stores the value of D or the reset state"}, "values": "D: <data>, C: <clock>, R: <reset>, Q: <output>", "script_paradigm": "always @(negedge C or posedge R) begin\n  if (R == 1)\n    Q <= 1;\n  else\n    Q <= D;\nend", "examples": [{"query": "How to model a negative edge D-type flip-flop with positive polarity reset?", "answer": "always @(negedge C or posedge R) begin\n  if (R == 1)\n    Q <= 1;\n  else\n    Q <= D;\nend"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nListing 9.180: simcells.v\n803\nmodule \\$_DFF_NP1_ (D, C, R, Q);\n804\ninput D, C, R;\n805\noutput reg Q;\n806\nalways @(negedge C or posedge R) begin\n807\nif (R == 1)\n808\nQ <= 1;\n809\nelse\n810\nQ <= D;\n811\nend\n812\nendmodule\nyosys> help $_DFF_N_\nA negative edge D-type flip-flop.\nTruth table:\nD C | Q\n-----+---\nd \\ | d\n- - | q\nSimulation model (verilog)\nListing 9.181: simcells.v\n610\nmodule \\$_DFF_N_ (D, C, Q);\n611\ninput D, C;\n612\noutput reg Q;\n613\nalways @(negedge C) begin\n614\nQ <= D;\n615\nend\n616\nendmodule\nyosys> help $_DFF_PN0_\nA positive edge D-type flip-flop with negative polarity reset.\nTruth table:\nD C R | Q\n-------+---\n- - 0 | 0\nd / - | d\n- - - | q\nSimulation model (verilog)\nListing 9.182: simcells.v\n827\nmodule \\$_DFF_PN0_ (D, C, R, Q);\n828\ninput D, C, R;\n829\noutput reg Q;\n830\nalways @(posedge C or negedge R) begin\n831\nif (R == 0)\n832\nQ <= 0;\n833\nelse\n(continues on next page)\n9.2.\nGate-level cells\n321", "source": "yosys_hq"}
{"script_name": "$_DFF_N_", "definition_description": "This script models a negative edge D-type flip-flop without reset.", "parameters": {"D": "The data input to the flip-flop", "C": "The clock input, which triggers on the negative edge", "Q": "The output of the flip-flop, which stores the value of D"}, "values": "D: <data>, C: <clock>, Q: <output>", "script_paradigm": "always @(negedge C) begin\n  Q <= D;\nend", "examples": [{"query": "How to model a negative edge D-type flip-flop?", "answer": "always @(negedge C) begin\n  Q <= D;\nend"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nListing 9.180: simcells.v\n803\nmodule \\$_DFF_NP1_ (D, C, R, Q);\n804\ninput D, C, R;\n805\noutput reg Q;\n806\nalways @(negedge C or posedge R) begin\n807\nif (R == 1)\n808\nQ <= 1;\n809\nelse\n810\nQ <= D;\n811\nend\n812\nendmodule\nyosys> help $_DFF_N_\nA negative edge D-type flip-flop.\nTruth table:\nD C | Q\n-----+---\nd \\ | d\n- - | q\nSimulation model (verilog)\nListing 9.181: simcells.v\n610\nmodule \\$_DFF_N_ (D, C, Q);\n611\ninput D, C;\n612\noutput reg Q;\n613\nalways @(negedge C) begin\n614\nQ <= D;\n615\nend\n616\nendmodule\nyosys> help $_DFF_PN0_\nA positive edge D-type flip-flop with negative polarity reset.\nTruth table:\nD C R | Q\n-------+---\n- - 0 | 0\nd / - | d\n- - - | q\nSimulation model (verilog)\nListing 9.182: simcells.v\n827\nmodule \\$_DFF_PN0_ (D, C, R, Q);\n828\ninput D, C, R;\n829\noutput reg Q;\n830\nalways @(posedge C or negedge R) begin\n831\nif (R == 0)\n832\nQ <= 0;\n833\nelse\n(continues on next page)\n9.2.\nGate-level cells\n321", "source": "yosys_hq"}
{"script_name": "$_DFF_PN0_", "definition_description": "This script models a positive edge D-type flip-flop with a negative polarity reset.", "parameters": {"D": "The data input to the flip-flop", "C": "The clock input, which triggers on the positive edge", "R": "The reset input, which triggers on the negative edge", "Q": "The output of the flip-flop, which stores the value of D or the reset state"}, "values": "D: <data>, C: <clock>, R: <reset>, Q: <output>", "script_paradigm": "always @(posedge C or negedge R) begin\n  if (R == 0)\n    Q <= 0;\n  else\n    Q <= D;\nend", "examples": [{"query": "How to model a positive edge D-type flip-flop with negative polarity reset?", "answer": "always @(posedge C or negedge R) begin\n  if (R == 0)\n    Q <= 0;\n  else\n    Q <= D;\nend"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nListing 9.180: simcells.v\n803\nmodule \\$_DFF_NP1_ (D, C, R, Q);\n804\ninput D, C, R;\n805\noutput reg Q;\n806\nalways @(negedge C or posedge R) begin\n807\nif (R == 1)\n808\nQ <= 1;\n809\nelse\n810\nQ <= D;\n811\nend\n812\nendmodule\nyosys> help $_DFF_N_\nA negative edge D-type flip-flop.\nTruth table:\nD C | Q\n-----+---\nd \\ | d\n- - | q\nSimulation model (verilog)\nListing 9.181: simcells.v\n610\nmodule \\$_DFF_N_ (D, C, Q);\n611\ninput D, C;\n612\noutput reg Q;\n613\nalways @(negedge C) begin\n614\nQ <= D;\n615\nend\n616\nendmodule\nyosys> help $_DFF_PN0_\nA positive edge D-type flip-flop with negative polarity reset.\nTruth table:\nD C R | Q\n-------+---\n- - 0 | 0\nd / - | d\n- - - | q\nSimulation model (verilog)\nListing 9.182: simcells.v\n827\nmodule \\$_DFF_PN0_ (D, C, R, Q);\n828\ninput D, C, R;\n829\noutput reg Q;\n830\nalways @(posedge C or negedge R) begin\n831\nif (R == 0)\n832\nQ <= 0;\n833\nelse\n(continues on next page)\n9.2.\nGate-level cells\n321", "source": "yosys_hq"}
{"script_name": "set_units", "definition_description": "This script sets the units used by the STA command interpreter for various parameters like time, voltage, current, power, and capacitance.", "parameters": {"time": "The time scale factor followed by a unit (e.g., ns, ps)", "voltage": "The voltage scale factor followed by a unit (e.g., V, mV)", "current": "The current scale factor followed by a unit (e.g., A, mA)", "power": "The power scale factor followed by a unit (e.g., W, mW)", "capacitance": "The capacitance scale factor followed by a unit (e.g., pF, nF)", "resistance": "The resistance scale factor followed by a unit (e.g., Ohm, kOhm)"}, "values": "time: <ns>, voltage: <V>, current: <mA>, power: <W>, capacitance: <pF>, resistance: <kOhm>", "script_paradigm": "set_units -time <time> -voltage <voltage> -current <current> -power <power> -capacitance <capacitance> -resistance <resistance>", "examples": [{"query": "How to set the units for time as ns, voltage as V, current as mA, power as W, capacitance as pF, and resistance as kOhm?", "answer": "set_units -time ns -voltage V -current mA -power W -capacitance pF -resistance kOhm"}], "reference": "-time time_unit\nThe time scale factor followed by 's'.\n-voltage voltage_unit\nThe voltage scale factor followed by 'v'.\n-current current_unit\nThe current scale factor followed by 'A'.\n-power power_unit\nThe power scale factor followed by 'w'.\nThe set_units command is used to check the units used by the STA command interpreter when parsing \ncommands and reporting results. If the current units differ from the set_unit value a warning is printed. Use \nthe set_cmd_units command to change the command units.\nUnits are specified as a scale factor followed by a unit name. The scale factors are as follows.\nM 1E+6\nk 1E+3\nm 1E-3\nu 1E-6\nn 1E-9\np 1E-12\nf 1E-15\nAn example of the set_units command is shown below.\nset_units -time ns -capacitance pF -current mA -voltage V -resistance kOhm\nset_wire_load_min_block_size size\nThe set_wire_load_min_block_size command is not supported.\nset_wire_load_mode\ntop|enclosed|segmented\ntop\nenclosed\nsegmented\nThe set_wire_load_mode command is ignored during timing but is included in SDC files that are written.", "source": "OpenSTA"}
{"script_name": "set_cmd_units", "definition_description": "This script is used to change the command units used by the STA tool when parsing commands and reporting results.", "parameters": {"time": "The time scale factor followed by a unit (e.g., ns, ps)", "voltage": "The voltage scale factor followed by a unit (e.g., V, mV)", "current": "The current scale factor followed by a unit (e.g., A, mA)", "power": "The power scale factor followed by a unit (e.g., W, mW)", "capacitance": "The capacitance scale factor followed by a unit (e.g., pF, nF)", "resistance": "The resistance scale factor followed by a unit (e.g., Ohm, kOhm)"}, "values": "time: <ns>, voltage: <V>, current: <mA>, power: <W>, capacitance: <pF>, resistance: <kOhm>", "script_paradigm": "set_cmd_units -time <time> -voltage <voltage> -current <current> -power <power> -capacitance <capacitance> -resistance <resistance>", "examples": [{"query": "How to change the command units to time in ns, voltage in V, current in mA, power in W, capacitance in pF, and resistance in kOhm?", "answer": "set_cmd_units -time ns -voltage V -current mA -power W -capacitance pF -resistance kOhm"}], "reference": "-time time_unit\nThe time scale factor followed by 's'.\n-voltage voltage_unit\nThe voltage scale factor followed by 'v'.\n-current current_unit\nThe current scale factor followed by 'A'.\n-power power_unit\nThe power scale factor followed by 'w'.\nThe set_units command is used to check the units used by the STA command interpreter when parsing \ncommands and reporting results. If the current units differ from the set_unit value a warning is printed. Use \nthe set_cmd_units command to change the command units.\nUnits are specified as a scale factor followed by a unit name. The scale factors are as follows.\nM 1E+6\nk 1E+3\nm 1E-3\nu 1E-6\nn 1E-9\np 1E-12\nf 1E-15\nAn example of the set_units command is shown below.\nset_units -time ns -capacitance pF -current mA -voltage V -resistance kOhm\nset_wire_load_min_block_size size\nThe set_wire_load_min_block_size command is not supported.\nset_wire_load_mode\ntop|enclosed|segmented\ntop\nenclosed\nsegmented\nThe set_wire_load_mode command is ignored during timing but is included in SDC files that are written.", "source": "OpenSTA"}
{"script_name": "set_wire_load_mode", "definition_description": "This script sets the wire load mode for the design, which can affect the load models used during timing analysis.", "parameters": {"mode": "The wire load mode to be set, which can be one of top, enclosed, or segmented."}, "values": "mode: <top|enclosed|segmented>", "script_paradigm": "set_wire_load_mode <mode>", "examples": [{"query": "How to set the wire load mode to 'top'?", "answer": "set_wire_load_mode top"}, {"query": "Set the wire load mode to 'segmented'.", "answer": "set_wire_load_mode segmented"}], "reference": "-time time_unit\nThe time scale factor followed by 's'.\n-voltage voltage_unit\nThe voltage scale factor followed by 'v'.\n-current current_unit\nThe current scale factor followed by 'A'.\n-power power_unit\nThe power scale factor followed by 'w'.\nThe set_units command is used to check the units used by the STA command interpreter when parsing \ncommands and reporting results. If the current units differ from the set_unit value a warning is printed. Use \nthe set_cmd_units command to change the command units.\nUnits are specified as a scale factor followed by a unit name. The scale factors are as follows.\nM 1E+6\nk 1E+3\nm 1E-3\nu 1E-6\nn 1E-9\np 1E-12\nf 1E-15\nAn example of the set_units command is shown below.\nset_units -time ns -capacitance pF -current mA -voltage V -resistance kOhm\nset_wire_load_min_block_size size\nThe set_wire_load_min_block_size command is not supported.\nset_wire_load_mode\ntop|enclosed|segmented\ntop\nenclosed\nsegmented\nThe set_wire_load_mode command is ignored during timing but is included in SDC files that are written.", "source": "OpenSTA"}
{"script_name": "repair_timing -setup", "definition_description": "This script is used to repair setup violations in the design by inserting buffers and resizing instances.", "parameters": {"timing_type": "Specifies the type of timing violation to repair, in this case, setup violations"}, "values": "timing_type: setup", "script_paradigm": "repair_timing -setup", "examples": [{"query": "How to repair setup violations in the design?", "answer": "repair_timing -setup"}], "reference": "0.145   data required time\n       -1.809   data arrival time\n\n\n       -1.664   slack (VIOLATED)\n\n```\nFix setup violation using:\ntcl\nrepair_timing -setup\nThe log is as follows:\n[INFO RSZ-0040] Inserted 4 buffers.\n[INFO RSZ-0041] Resized 16 instances.\n[WARNING RSZ-0062] Unable to repair all setup violations.\nReduce the clock frequency by increasing the clock period to 0.9 and re-run\nrepair_timing to fix the setup violation warnings. Such timing violations\nare automatically fixed by the resizer post CTS and global routing.\nyvl\ncreate_clock -period 0.9 clk\nrepair_timing -setup\nTo view timing logs post-repair timing, type:\ntcl\nreport_checks -fields input -digits 3\nThe log is as follows:\n```\nStartpoint: r1 (rising edge-triggered flip-flop clocked by clk)\nEndpoint: r2 (rising edge-triggered flip-flop clocked by clk)\nPath Group: clk\nPath Type: max\nCorner: slow\nDelay     Time   Description\n0.000    0.000   clock clk (rise edge)\n   0.000    0.000   clock network delay (ideal)\n   0.000    0.000 ^ r1/CK (DFF_X1)\n   0.264    0.264 v r1/Q (DFF_X1)\n   0.002    0.266 v u1/A (BUF_X4)\n   0.090    0.356 v u1/Z (BUF_X4)\n   0.003    0.359 v u2/A (BUF_X8)\n   0.076    0.435 v u2/Z (BUF_X8)\n   0.003    0.438 v u3/A (BUF_X8)\n   0.074    0.512 v u3/Z (BUF_X8)\n   0.003    0.515 v u4/A (BUF_X8)\n   0.077    0.592 v u4/Z (BUF_X8)\n   0.005    0.597 v u5/A (BUF_X16)\n   0.077    0.674 v u5/Z (BUF_X16)\n   0.036    0.710 v r2/D (DFF_X1)\n            0.710   data arrival time\n0.900    0.900   clock clk (rise edge)\n   0.000    0.900   clock network delay (ideal)\n   0.000    0.900   clock reconvergence pessimism\n            0.900 ^ r2/CK (DFF_X1)\n  -0.172    0.728   library setup time\n            0.728   data required time\n\n        0.728   data required time\n       -0.710   data arrival time\n\n\n        0.019   slack (MET)\n\n```\nFixing Hold Violations\nTo fix hold violation for the design, command to use repair_timing\n-hold\nRefer to the example here\nto learn more about fixing hold violations.\nCheck hold violation post-global routing using the following Tcl\ncommands. Run below steps in terminal in OpenROAD tool root directory:\nshell\ncd ../tools/OpenROAD/src/rsz/test/\nopenroad -gui\nCopy and paste the below commands in the Tcl Commands section of GUI.\ntcl\nsource helpers.tcl\nread_liberty sky130hd/sky130hd_tt.lib\nread_lef sky130hd/sky130hd.tlef\nread_lef sky130hd/sky130hd_std_cell.lef\nread_def repair_hold10.def\ncreate_clock -period 2 clk\nset_propagated_clock clk\nset_wire_rc -resistance 0.0001 -capacitance 0.00001\nset_routing_layers -signal met1-met5\nglobal_route\nestimate_parasitics -global_routing\nreport_worst_slack -min\nRead the resulting worst slack as:\nworst slack -1.95\nThe above worst slack was fixed with:\ntcl\nrepair_timing -hold\nThe log is as follows:\n[INFO RSZ-0046] Found 2 endpoints with hold violations.\n[INFO RSZ-0032] Inserted 5 hold buffers.\nRe-check the slack value after repair_timing. Type:\ntcl\nreport_worst_slack -min\nThe result worst slack value is as follows:\nworst slack 0.16\nNote that the worst slack is now met and the hold violation was fixed by\nthe resizer.\nClock Tree Synthesis\nTo perform clock tree synthesis clock_tree_synthesis flow command used.\nThe OpenROAD-flow-scripts automatically generates a well-balanced clock tree post-placement.\nIn this section, you will learn details about the building and visualize the\nclock tree.\nRefer to the built-in example here.\nLaunch OpenROAD GUI by running the following command(s) in the terminal in OpenROAD tool root directory:\nshell\ncd ../tools/OpenROAD/src/cts/test/\nopenroad -gui\nTo build the clock tree, run the following commands in Tcl Commands of\nGUI:\ntcl\nread_lef Nangate45/Nangate45.lef\nread_liberty Nangate45/Nangate45_typ.lib\nread_def \"16sinks.def\"\ncreate_clock -period 5 clk\nset_wire_rc -clock -layer metal3\nclock_tree_synthesis -root_buf CLKBUF_X3 \\\n                     -buf_list CLKBUF_X3 \\\n                     -wire_unit 20\nLayout view before CTS as follows:\n\nLayout view after CTS can be viewed with Update option.", "source": "OpenROAD_flow_script"}
{"script_name": "create_clock -period", "definition_description": "This script is used to create a clock with a specified period.", "parameters": {"clock_period": "The period of the clock to be set, in this case, the new clock period to fix timing violations"}, "values": "clock_period: 0.9", "script_paradigm": "create_clock -period <clock_period> clk", "examples": [{"query": "How to set a clock period of 0.9ns to fix setup violations?", "answer": "create_clock -period 0.9 clk"}], "reference": "0.145   data required time\n       -1.809   data arrival time\n\n\n       -1.664   slack (VIOLATED)\n\n```\nFix setup violation using:\ntcl\nrepair_timing -setup\nThe log is as follows:\n[INFO RSZ-0040] Inserted 4 buffers.\n[INFO RSZ-0041] Resized 16 instances.\n[WARNING RSZ-0062] Unable to repair all setup violations.\nReduce the clock frequency by increasing the clock period to 0.9 and re-run\nrepair_timing to fix the setup violation warnings. Such timing violations\nare automatically fixed by the resizer post CTS and global routing.\nyvl\ncreate_clock -period 0.9 clk\nrepair_timing -setup\nTo view timing logs post-repair timing, type:\ntcl\nreport_checks -fields input -digits 3\nThe log is as follows:\n```\nStartpoint: r1 (rising edge-triggered flip-flop clocked by clk)\nEndpoint: r2 (rising edge-triggered flip-flop clocked by clk)\nPath Group: clk\nPath Type: max\nCorner: slow\nDelay     Time   Description\n0.000    0.000   clock clk (rise edge)\n   0.000    0.000   clock network delay (ideal)\n   0.000    0.000 ^ r1/CK (DFF_X1)\n   0.264    0.264 v r1/Q (DFF_X1)\n   0.002    0.266 v u1/A (BUF_X4)\n   0.090    0.356 v u1/Z (BUF_X4)\n   0.003    0.359 v u2/A (BUF_X8)\n   0.076    0.435 v u2/Z (BUF_X8)\n   0.003    0.438 v u3/A (BUF_X8)\n   0.074    0.512 v u3/Z (BUF_X8)\n   0.003    0.515 v u4/A (BUF_X8)\n   0.077    0.592 v u4/Z (BUF_X8)\n   0.005    0.597 v u5/A (BUF_X16)\n   0.077    0.674 v u5/Z (BUF_X16)\n   0.036    0.710 v r2/D (DFF_X1)\n            0.710   data arrival time\n0.900    0.900   clock clk (rise edge)\n   0.000    0.900   clock network delay (ideal)\n   0.000    0.900   clock reconvergence pessimism\n            0.900 ^ r2/CK (DFF_X1)\n  -0.172    0.728   library setup time\n            0.728   data required time\n\n        0.728   data required time\n       -0.710   data arrival time\n\n\n        0.019   slack (MET)\n\n```\nFixing Hold Violations\nTo fix hold violation for the design, command to use repair_timing\n-hold\nRefer to the example here\nto learn more about fixing hold violations.\nCheck hold violation post-global routing using the following Tcl\ncommands. Run below steps in terminal in OpenROAD tool root directory:\nshell\ncd ../tools/OpenROAD/src/rsz/test/\nopenroad -gui\nCopy and paste the below commands in the Tcl Commands section of GUI.\ntcl\nsource helpers.tcl\nread_liberty sky130hd/sky130hd_tt.lib\nread_lef sky130hd/sky130hd.tlef\nread_lef sky130hd/sky130hd_std_cell.lef\nread_def repair_hold10.def\ncreate_clock -period 2 clk\nset_propagated_clock clk\nset_wire_rc -resistance 0.0001 -capacitance 0.00001\nset_routing_layers -signal met1-met5\nglobal_route\nestimate_parasitics -global_routing\nreport_worst_slack -min\nRead the resulting worst slack as:\nworst slack -1.95\nThe above worst slack was fixed with:\ntcl\nrepair_timing -hold\nThe log is as follows:\n[INFO RSZ-0046] Found 2 endpoints with hold violations.\n[INFO RSZ-0032] Inserted 5 hold buffers.\nRe-check the slack value after repair_timing. Type:\ntcl\nreport_worst_slack -min\nThe result worst slack value is as follows:\nworst slack 0.16\nNote that the worst slack is now met and the hold violation was fixed by\nthe resizer.\nClock Tree Synthesis\nTo perform clock tree synthesis clock_tree_synthesis flow command used.\nThe OpenROAD-flow-scripts automatically generates a well-balanced clock tree post-placement.\nIn this section, you will learn details about the building and visualize the\nclock tree.\nRefer to the built-in example here.\nLaunch OpenROAD GUI by running the following command(s) in the terminal in OpenROAD tool root directory:\nshell\ncd ../tools/OpenROAD/src/cts/test/\nopenroad -gui\nTo build the clock tree, run the following commands in Tcl Commands of\nGUI:\ntcl\nread_lef Nangate45/Nangate45.lef\nread_liberty Nangate45/Nangate45_typ.lib\nread_def \"16sinks.def\"\ncreate_clock -period 5 clk\nset_wire_rc -clock -layer metal3\nclock_tree_synthesis -root_buf CLKBUF_X3 \\\n                     -buf_list CLKBUF_X3 \\\n                     -wire_unit 20\nLayout view before CTS as follows:\n\nLayout view after CTS can be viewed with Update option.", "source": "OpenROAD_flow_script"}
{"script_name": "repair_timing -hold", "definition_description": "This script is used to repair hold violations in the design by inserting buffers and adjusting timing constraints.", "parameters": {"timing_type": "Specifies the type of timing violation to repair, in this case, hold violations"}, "values": "timing_type: hold", "script_paradigm": "repair_timing -hold", "examples": [{"query": "How to fix hold violations in the design?", "answer": "repair_timing -hold"}], "reference": "0.145   data required time\n       -1.809   data arrival time\n\n\n       -1.664   slack (VIOLATED)\n\n```\nFix setup violation using:\ntcl\nrepair_timing -setup\nThe log is as follows:\n[INFO RSZ-0040] Inserted 4 buffers.\n[INFO RSZ-0041] Resized 16 instances.\n[WARNING RSZ-0062] Unable to repair all setup violations.\nReduce the clock frequency by increasing the clock period to 0.9 and re-run\nrepair_timing to fix the setup violation warnings. Such timing violations\nare automatically fixed by the resizer post CTS and global routing.\nyvl\ncreate_clock -period 0.9 clk\nrepair_timing -setup\nTo view timing logs post-repair timing, type:\ntcl\nreport_checks -fields input -digits 3\nThe log is as follows:\n```\nStartpoint: r1 (rising edge-triggered flip-flop clocked by clk)\nEndpoint: r2 (rising edge-triggered flip-flop clocked by clk)\nPath Group: clk\nPath Type: max\nCorner: slow\nDelay     Time   Description\n0.000    0.000   clock clk (rise edge)\n   0.000    0.000   clock network delay (ideal)\n   0.000    0.000 ^ r1/CK (DFF_X1)\n   0.264    0.264 v r1/Q (DFF_X1)\n   0.002    0.266 v u1/A (BUF_X4)\n   0.090    0.356 v u1/Z (BUF_X4)\n   0.003    0.359 v u2/A (BUF_X8)\n   0.076    0.435 v u2/Z (BUF_X8)\n   0.003    0.438 v u3/A (BUF_X8)\n   0.074    0.512 v u3/Z (BUF_X8)\n   0.003    0.515 v u4/A (BUF_X8)\n   0.077    0.592 v u4/Z (BUF_X8)\n   0.005    0.597 v u5/A (BUF_X16)\n   0.077    0.674 v u5/Z (BUF_X16)\n   0.036    0.710 v r2/D (DFF_X1)\n            0.710   data arrival time\n0.900    0.900   clock clk (rise edge)\n   0.000    0.900   clock network delay (ideal)\n   0.000    0.900   clock reconvergence pessimism\n            0.900 ^ r2/CK (DFF_X1)\n  -0.172    0.728   library setup time\n            0.728   data required time\n\n        0.728   data required time\n       -0.710   data arrival time\n\n\n        0.019   slack (MET)\n\n```\nFixing Hold Violations\nTo fix hold violation for the design, command to use repair_timing\n-hold\nRefer to the example here\nto learn more about fixing hold violations.\nCheck hold violation post-global routing using the following Tcl\ncommands. Run below steps in terminal in OpenROAD tool root directory:\nshell\ncd ../tools/OpenROAD/src/rsz/test/\nopenroad -gui\nCopy and paste the below commands in the Tcl Commands section of GUI.\ntcl\nsource helpers.tcl\nread_liberty sky130hd/sky130hd_tt.lib\nread_lef sky130hd/sky130hd.tlef\nread_lef sky130hd/sky130hd_std_cell.lef\nread_def repair_hold10.def\ncreate_clock -period 2 clk\nset_propagated_clock clk\nset_wire_rc -resistance 0.0001 -capacitance 0.00001\nset_routing_layers -signal met1-met5\nglobal_route\nestimate_parasitics -global_routing\nreport_worst_slack -min\nRead the resulting worst slack as:\nworst slack -1.95\nThe above worst slack was fixed with:\ntcl\nrepair_timing -hold\nThe log is as follows:\n[INFO RSZ-0046] Found 2 endpoints with hold violations.\n[INFO RSZ-0032] Inserted 5 hold buffers.\nRe-check the slack value after repair_timing. Type:\ntcl\nreport_worst_slack -min\nThe result worst slack value is as follows:\nworst slack 0.16\nNote that the worst slack is now met and the hold violation was fixed by\nthe resizer.\nClock Tree Synthesis\nTo perform clock tree synthesis clock_tree_synthesis flow command used.\nThe OpenROAD-flow-scripts automatically generates a well-balanced clock tree post-placement.\nIn this section, you will learn details about the building and visualize the\nclock tree.\nRefer to the built-in example here.\nLaunch OpenROAD GUI by running the following command(s) in the terminal in OpenROAD tool root directory:\nshell\ncd ../tools/OpenROAD/src/cts/test/\nopenroad -gui\nTo build the clock tree, run the following commands in Tcl Commands of\nGUI:\ntcl\nread_lef Nangate45/Nangate45.lef\nread_liberty Nangate45/Nangate45_typ.lib\nread_def \"16sinks.def\"\ncreate_clock -period 5 clk\nset_wire_rc -clock -layer metal3\nclock_tree_synthesis -root_buf CLKBUF_X3 \\\n                     -buf_list CLKBUF_X3 \\\n                     -wire_unit 20\nLayout view before CTS as follows:\n\nLayout view after CTS can be viewed with Update option.", "source": "OpenROAD_flow_script"}
{"script_name": "clock_tree_synthesis", "definition_description": "This script is used to perform Clock Tree Synthesis (CTS) and create a balanced clock tree in the design.", "parameters": {"root_buffer": "The root buffer to be used for clock tree synthesis", "buffer_list": "A list of buffers used in the clock tree", "wire_unit": "The wire unit size used during the synthesis process"}, "values": "root_buffer: CLKBUF_X3, buffer_list: CLKBUF_X3, wire_unit: 20", "script_paradigm": "clock_tree_synthesis -root_buf <root_buffer> -buf_list <buffer_list> -wire_unit <wire_unit>", "examples": [{"query": "How to perform clock tree synthesis using CLKBUF_X3 as the root buffer and buffer list?", "answer": "clock_tree_synthesis -root_buf CLKBUF_X3 -buf_list CLKBUF_X3 -wire_unit 20"}], "reference": "0.145   data required time\n       -1.809   data arrival time\n\n\n       -1.664   slack (VIOLATED)\n\n```\nFix setup violation using:\ntcl\nrepair_timing -setup\nThe log is as follows:\n[INFO RSZ-0040] Inserted 4 buffers.\n[INFO RSZ-0041] Resized 16 instances.\n[WARNING RSZ-0062] Unable to repair all setup violations.\nReduce the clock frequency by increasing the clock period to 0.9 and re-run\nrepair_timing to fix the setup violation warnings. Such timing violations\nare automatically fixed by the resizer post CTS and global routing.\nyvl\ncreate_clock -period 0.9 clk\nrepair_timing -setup\nTo view timing logs post-repair timing, type:\ntcl\nreport_checks -fields input -digits 3\nThe log is as follows:\n```\nStartpoint: r1 (rising edge-triggered flip-flop clocked by clk)\nEndpoint: r2 (rising edge-triggered flip-flop clocked by clk)\nPath Group: clk\nPath Type: max\nCorner: slow\nDelay     Time   Description\n0.000    0.000   clock clk (rise edge)\n   0.000    0.000   clock network delay (ideal)\n   0.000    0.000 ^ r1/CK (DFF_X1)\n   0.264    0.264 v r1/Q (DFF_X1)\n   0.002    0.266 v u1/A (BUF_X4)\n   0.090    0.356 v u1/Z (BUF_X4)\n   0.003    0.359 v u2/A (BUF_X8)\n   0.076    0.435 v u2/Z (BUF_X8)\n   0.003    0.438 v u3/A (BUF_X8)\n   0.074    0.512 v u3/Z (BUF_X8)\n   0.003    0.515 v u4/A (BUF_X8)\n   0.077    0.592 v u4/Z (BUF_X8)\n   0.005    0.597 v u5/A (BUF_X16)\n   0.077    0.674 v u5/Z (BUF_X16)\n   0.036    0.710 v r2/D (DFF_X1)\n            0.710   data arrival time\n0.900    0.900   clock clk (rise edge)\n   0.000    0.900   clock network delay (ideal)\n   0.000    0.900   clock reconvergence pessimism\n            0.900 ^ r2/CK (DFF_X1)\n  -0.172    0.728   library setup time\n            0.728   data required time\n\n        0.728   data required time\n       -0.710   data arrival time\n\n\n        0.019   slack (MET)\n\n```\nFixing Hold Violations\nTo fix hold violation for the design, command to use repair_timing\n-hold\nRefer to the example here\nto learn more about fixing hold violations.\nCheck hold violation post-global routing using the following Tcl\ncommands. Run below steps in terminal in OpenROAD tool root directory:\nshell\ncd ../tools/OpenROAD/src/rsz/test/\nopenroad -gui\nCopy and paste the below commands in the Tcl Commands section of GUI.\ntcl\nsource helpers.tcl\nread_liberty sky130hd/sky130hd_tt.lib\nread_lef sky130hd/sky130hd.tlef\nread_lef sky130hd/sky130hd_std_cell.lef\nread_def repair_hold10.def\ncreate_clock -period 2 clk\nset_propagated_clock clk\nset_wire_rc -resistance 0.0001 -capacitance 0.00001\nset_routing_layers -signal met1-met5\nglobal_route\nestimate_parasitics -global_routing\nreport_worst_slack -min\nRead the resulting worst slack as:\nworst slack -1.95\nThe above worst slack was fixed with:\ntcl\nrepair_timing -hold\nThe log is as follows:\n[INFO RSZ-0046] Found 2 endpoints with hold violations.\n[INFO RSZ-0032] Inserted 5 hold buffers.\nRe-check the slack value after repair_timing. Type:\ntcl\nreport_worst_slack -min\nThe result worst slack value is as follows:\nworst slack 0.16\nNote that the worst slack is now met and the hold violation was fixed by\nthe resizer.\nClock Tree Synthesis\nTo perform clock tree synthesis clock_tree_synthesis flow command used.\nThe OpenROAD-flow-scripts automatically generates a well-balanced clock tree post-placement.\nIn this section, you will learn details about the building and visualize the\nclock tree.\nRefer to the built-in example here.\nLaunch OpenROAD GUI by running the following command(s) in the terminal in OpenROAD tool root directory:\nshell\ncd ../tools/OpenROAD/src/cts/test/\nopenroad -gui\nTo build the clock tree, run the following commands in Tcl Commands of\nGUI:\ntcl\nread_lef Nangate45/Nangate45.lef\nread_liberty Nangate45/Nangate45_typ.lib\nread_def \"16sinks.def\"\ncreate_clock -period 5 clk\nset_wire_rc -clock -layer metal3\nclock_tree_synthesis -root_buf CLKBUF_X3 \\\n                     -buf_list CLKBUF_X3 \\\n                     -wire_unit 20\nLayout view before CTS as follows:\n\nLayout view after CTS can be viewed with Update option.", "source": "OpenROAD_flow_script"}
{"script_name": "CheckMetrics", "definition_description": "This script checks if the new execution metrics degrade compared to the 'golden' metrics stored in the metadata-base-ok.json and rules.json files.", "parameters": {"clean_metadata": "Flag to clean the metadata before running the check (optional). If you need to re-run the check, use this flag."}, "values": "clean_metadata: <yes/no>", "script_paradigm": "cd OpenROAD-flow-scripts/flow\nmake [clean_metadata] metadata", "examples": [{"query": "How to check metrics after a bug fix?", "answer": "cd OpenROAD-flow-scripts/flow\nmake metadata"}, {"query": "How to clean metadata and check metrics?", "answer": "cd OpenROAD-flow-scripts/flow\nmake clean_metadata metadata"}], "reference": "Metrics\nThe OpenROAD-flow-scripts\nrepository contains source files (e.g., LEF/DEF, Verilog, SDC, Liberty,\nRC extraction) and configuration files (e.g. config.mk) that enable the user to run\na small set of example designs through our complete RTL-to-GDS flow.\nTo keep track of the quality of the results, we maintain inside each\ndesign folder two files:\n\n\nmetadata-base-ok.json which contains all the relevant\ninformation extracted from the \"golden\" execution of the flow (i.e.,\nlast known good result).\n\n\nrules.json which holds a set of rules that we use to\nevaluate new executions when a change is made.\n\n\nChecking against golden\nThe evaluation checks for key metrics (e.g., worst slack, number of\nDRCs) to ensure that changes do not degrade too much with respect to the\n\"golden\" values.\nAfter you make a significant change, e.g., fixing a bug in a piece of\ncode, or changing some configuration variable\n(PLACE_DENSITY), you should review the results and compare\nthem with the \"golden\". To perform the check, you will need to run the\nfollowing command:\n``` shell\ncd OpenROAD-flow-scripts/flow\nthe clean_metadata is only required if you need to re-run\nmake [clean_metadata] metadata\n```\nIf the command above yields any error message, please review to\nmake sure the change in metrics is expected and justifiable. If so,\nproceed to the next section to update the \"golden\" reference.\nUpdate process\nUpdate of the reference files is mandatory if any metrics became worse\nthan the values limited by the rules.json (see previous\nsection on how to perform the check). Also, it is a good idea to update\nthe \"golden\" files if your changes have improved a metric, to ensure that\nthe improvement will not be lost in the future.\nTo update all the reference files:\nshell\ncd OpenROAD-flow-scripts/flow\nmake update_ok\nIn case you have a special reason to only update one of the files, you\ncan do so with the following commands:\n``` shell\nupdate metadata-base-ok.json file for the design\nmake update_metadata\nupdate rules.json file for the design\nthis will use the current (+ a padding) metadata-base-ok.json\nthe padding ensures that small changes do not break the flow\nmake update_rules\n```", "source": "OpenROAD_flow_script"}
{"script_name": "UpdateGoldenReference", "definition_description": "This script updates the reference files (metadata-base-ok.json and rules.json) after checking metrics to ensure that future executions are compared to the latest valid results.", "parameters": {"update_metadata": "Flag to update the metadata-base-ok.json file.", "update_rules": "Flag to update the rules.json file."}, "values": "update_metadata: <yes/no>, update_rules: <yes/no>", "script_paradigm": "cd OpenROAD-flow-scripts/flow\nmake update_ok\nmake update_metadata\nmake update_rules", "examples": [{"query": "How to update the golden reference files after a successful change?", "answer": "cd OpenROAD-flow-scripts/flow\nmake update_ok"}, {"query": "How to update only the metadata file?", "answer": "cd OpenROAD-flow-scripts/flow\nmake update_metadata"}, {"query": "How to update only the rules file?", "answer": "cd OpenROAD-flow-scripts/flow\nmake update_rules"}], "reference": "Metrics\nThe OpenROAD-flow-scripts\nrepository contains source files (e.g., LEF/DEF, Verilog, SDC, Liberty,\nRC extraction) and configuration files (e.g. config.mk) that enable the user to run\na small set of example designs through our complete RTL-to-GDS flow.\nTo keep track of the quality of the results, we maintain inside each\ndesign folder two files:\n\n\nmetadata-base-ok.json which contains all the relevant\ninformation extracted from the \"golden\" execution of the flow (i.e.,\nlast known good result).\n\n\nrules.json which holds a set of rules that we use to\nevaluate new executions when a change is made.\n\n\nChecking against golden\nThe evaluation checks for key metrics (e.g., worst slack, number of\nDRCs) to ensure that changes do not degrade too much with respect to the\n\"golden\" values.\nAfter you make a significant change, e.g., fixing a bug in a piece of\ncode, or changing some configuration variable\n(PLACE_DENSITY), you should review the results and compare\nthem with the \"golden\". To perform the check, you will need to run the\nfollowing command:\n``` shell\ncd OpenROAD-flow-scripts/flow\nthe clean_metadata is only required if you need to re-run\nmake [clean_metadata] metadata\n```\nIf the command above yields any error message, please review to\nmake sure the change in metrics is expected and justifiable. If so,\nproceed to the next section to update the \"golden\" reference.\nUpdate process\nUpdate of the reference files is mandatory if any metrics became worse\nthan the values limited by the rules.json (see previous\nsection on how to perform the check). Also, it is a good idea to update\nthe \"golden\" files if your changes have improved a metric, to ensure that\nthe improvement will not be lost in the future.\nTo update all the reference files:\nshell\ncd OpenROAD-flow-scripts/flow\nmake update_ok\nIn case you have a special reason to only update one of the files, you\ncan do so with the following commands:\n``` shell\nupdate metadata-base-ok.json file for the design\nmake update_metadata\nupdate rules.json file for the design\nthis will use the current (+ a padding) metadata-base-ok.json\nthe padding ensures that small changes do not break the flow\nmake update_rules\n```", "source": "OpenROAD_flow_script"}
{"script_name": "ResetInserter", "definition_description": "This script inserts reset logic into a given elaboratable, ensuring that signals are held at their initial value when any reset input is asserted for the specified clock domain.", "parameters": {"domains": "A dictionary mapping clock domain names to reset signals for that domain."}, "values": "domains: {sync: rst}", "script_paradigm": "ResetInserter(<domains>)(<elaboratable>)", "examples": [{"query": "How to insert a reset for the sync domain using the rst signal?", "answer": "m = ResetInserter({'sync': rst})(m)"}], "reference": "A control flow modifier affects all logic within a given elaboratable and clock domain, which includes the submodules of that elaboratable.\n\nNote\n\nApplying a control flow modifier to an elaboratable does not mutate it; a new proxy object is returned that forwards attribute accesses and method calls to the original elaboratable. Whenever this proxy object is elaborated, it manipulates the circuit defined by the original elaboratable to include the requested control inputs.\n\nNote\n\nIt is possible to apply several control flow modifiers to the same elaboratable, even if the same domain is used. For ResetInserter, the signals in a domain are held at their initial value whenever any of the reset inputs for that domain are asserted (logical OR), and for EnableInserter, the signals in a domain are allowed to update whenever all of the enable signals for that domain are asserted (logical AND).\n\nConsider the following code:\n\nm = Module()\r\nm.d.sync += n.eq(n + 1)\r\nm.d.comb += z.eq(n == 0)\r\n\r\nm = ResetInserter({\"sync\": rst})(m)\r\nm = EnableInserter({\"sync\": en})(m)\r\n\nThe application of control flow modifiers in it causes the behavior of the final m to be identical to that of this module:\n\nm = Module()\r\nwith m.If(en):\r\n    m.d.sync += n.eq(n + 1)\r\nwith m.If(rst):\r\n    m.d.sync += n.eq(n.init)\r\nm.d.comb += z.eq(n == 0)\r\n\nTip\n\nThe control input provided to ResetInserter must be synchronous to the domain that is being reset by it. If you need to reset another domain, use amaranth.lib.cdc.ResetSynchronizer instead.\n\nRenaming domains\n\nA reusable elaboratable usually specifies the use of one or more clock domains while leaving the details of clocking and initialization to a later phase in the design process. DomainRenamer can be used to alter a reusable elaboratable for integration in a specific design. Most elaboratables use a single clock domain named sync, and DomainRenamer makes it easy to place such elaboratables in any clock domain of a design.\n\nClock domains can be renamed using the syntax DomainRenamer(domains)(elaboratable), where domains is a mapping from clock domain names to clock domain names and elaboratable is any elaboratable object. The keys of domains correspond to existing clock domain names specified by elaboratable, and the values of domains correspond to the clock domain names from the containing elaboratable that will be used instead. When only the sync domain is being renamed, instead of writing DomainRenamer({\"sync\": name})(elaboratable), the equivalent but shorter DomainRenamer(name)(elaboratable) syntax can be used.\n\nThe result of renaming clock domains in an elaboratable is, itself, an elaboratable object. A common way to rename domains is to apply DomainRenamer to another elaboratable while adding it as a submodule:\n\nm.submodules.counter = counter = DomainRenamer(\"video\")(counter)\r\n\nRenaming a clock domain affects all logic within a given elaboratable and clock domain, which includes the submodules of that elaboratable. It does not affect any logic outside of that elaboratable.\n\nNote\n\nRenaming domains in an elaboratable does not mutate it; a new proxy object is returned that forwards attribute accesses and method calls to the original elaboratable. Whenever this proxy object is elaborated, it manipulates the circuit defined by the original elaboratable to use the requested clock domain.\n\nNote\n\nIt is possible to rename domains in an elaboratable and also apply control flow modifiers.\n\nConsider the following code:\n\nm = Module()\r\nm.d.sync += count.eq(count + 1)\r\nm.d.comb += zero.eq(count == 0)\r\n\r\nm = DomainRenamer({\"sync\": \"video\"})(m)\r\n\nThe renaming of the sync clock domain in it causes the behavior of the final m to be identical to that of this module:\n\nm = Module()\r\nm.d.video += count.eq(count + 1)\r\nm.d.comb += zero.eq(count == 0)\r\n\nWarning", "source": "amaranth"}
{"script_name": "EnableInserter", "definition_description": "This script inserts enable logic into a given elaboratable, ensuring that signals in the domain are updated when all enable signals are asserted for the specified domain.", "parameters": {"domains": "A dictionary mapping clock domain names to enable signals for that domain."}, "values": "domains: {sync: en}", "script_paradigm": "EnableInserter(<domains>)(<elaboratable>)", "examples": [{"query": "How to insert enable logic for the sync domain using the en signal?", "answer": "m = EnableInserter({'sync': en})(m)"}], "reference": "A control flow modifier affects all logic within a given elaboratable and clock domain, which includes the submodules of that elaboratable.\n\nNote\n\nApplying a control flow modifier to an elaboratable does not mutate it; a new proxy object is returned that forwards attribute accesses and method calls to the original elaboratable. Whenever this proxy object is elaborated, it manipulates the circuit defined by the original elaboratable to include the requested control inputs.\n\nNote\n\nIt is possible to apply several control flow modifiers to the same elaboratable, even if the same domain is used. For ResetInserter, the signals in a domain are held at their initial value whenever any of the reset inputs for that domain are asserted (logical OR), and for EnableInserter, the signals in a domain are allowed to update whenever all of the enable signals for that domain are asserted (logical AND).\n\nConsider the following code:\n\nm = Module()\r\nm.d.sync += n.eq(n + 1)\r\nm.d.comb += z.eq(n == 0)\r\n\r\nm = ResetInserter({\"sync\": rst})(m)\r\nm = EnableInserter({\"sync\": en})(m)\r\n\nThe application of control flow modifiers in it causes the behavior of the final m to be identical to that of this module:\n\nm = Module()\r\nwith m.If(en):\r\n    m.d.sync += n.eq(n + 1)\r\nwith m.If(rst):\r\n    m.d.sync += n.eq(n.init)\r\nm.d.comb += z.eq(n == 0)\r\n\nTip\n\nThe control input provided to ResetInserter must be synchronous to the domain that is being reset by it. If you need to reset another domain, use amaranth.lib.cdc.ResetSynchronizer instead.\n\nRenaming domains\n\nA reusable elaboratable usually specifies the use of one or more clock domains while leaving the details of clocking and initialization to a later phase in the design process. DomainRenamer can be used to alter a reusable elaboratable for integration in a specific design. Most elaboratables use a single clock domain named sync, and DomainRenamer makes it easy to place such elaboratables in any clock domain of a design.\n\nClock domains can be renamed using the syntax DomainRenamer(domains)(elaboratable), where domains is a mapping from clock domain names to clock domain names and elaboratable is any elaboratable object. The keys of domains correspond to existing clock domain names specified by elaboratable, and the values of domains correspond to the clock domain names from the containing elaboratable that will be used instead. When only the sync domain is being renamed, instead of writing DomainRenamer({\"sync\": name})(elaboratable), the equivalent but shorter DomainRenamer(name)(elaboratable) syntax can be used.\n\nThe result of renaming clock domains in an elaboratable is, itself, an elaboratable object. A common way to rename domains is to apply DomainRenamer to another elaboratable while adding it as a submodule:\n\nm.submodules.counter = counter = DomainRenamer(\"video\")(counter)\r\n\nRenaming a clock domain affects all logic within a given elaboratable and clock domain, which includes the submodules of that elaboratable. It does not affect any logic outside of that elaboratable.\n\nNote\n\nRenaming domains in an elaboratable does not mutate it; a new proxy object is returned that forwards attribute accesses and method calls to the original elaboratable. Whenever this proxy object is elaborated, it manipulates the circuit defined by the original elaboratable to use the requested clock domain.\n\nNote\n\nIt is possible to rename domains in an elaboratable and also apply control flow modifiers.\n\nConsider the following code:\n\nm = Module()\r\nm.d.sync += count.eq(count + 1)\r\nm.d.comb += zero.eq(count == 0)\r\n\r\nm = DomainRenamer({\"sync\": \"video\"})(m)\r\n\nThe renaming of the sync clock domain in it causes the behavior of the final m to be identical to that of this module:\n\nm = Module()\r\nm.d.video += count.eq(count + 1)\r\nm.d.comb += zero.eq(count == 0)\r\n\nWarning", "source": "amaranth"}
{"script_name": "DomainRenamer", "definition_description": "This script renames clock domains in a given elaboratable, allowing it to integrate into a specific design by remapping domain names.", "parameters": {"domains": "A dictionary mapping existing clock domain names to the new clock domain names.", "elaboratable": "The elaboratable object whose clock domains are being renamed."}, "values": "domains: {'sync': 'video'}", "script_paradigm": "DomainRenamer(<domains>)(<elaboratable>)", "examples": [{"query": "How to rename the sync clock domain to video in the elaboratable?", "answer": "m = DomainRenamer({'sync': 'video'})(m)"}], "reference": "A control flow modifier affects all logic within a given elaboratable and clock domain, which includes the submodules of that elaboratable.\n\nNote\n\nApplying a control flow modifier to an elaboratable does not mutate it; a new proxy object is returned that forwards attribute accesses and method calls to the original elaboratable. Whenever this proxy object is elaborated, it manipulates the circuit defined by the original elaboratable to include the requested control inputs.\n\nNote\n\nIt is possible to apply several control flow modifiers to the same elaboratable, even if the same domain is used. For ResetInserter, the signals in a domain are held at their initial value whenever any of the reset inputs for that domain are asserted (logical OR), and for EnableInserter, the signals in a domain are allowed to update whenever all of the enable signals for that domain are asserted (logical AND).\n\nConsider the following code:\n\nm = Module()\r\nm.d.sync += n.eq(n + 1)\r\nm.d.comb += z.eq(n == 0)\r\n\r\nm = ResetInserter({\"sync\": rst})(m)\r\nm = EnableInserter({\"sync\": en})(m)\r\n\nThe application of control flow modifiers in it causes the behavior of the final m to be identical to that of this module:\n\nm = Module()\r\nwith m.If(en):\r\n    m.d.sync += n.eq(n + 1)\r\nwith m.If(rst):\r\n    m.d.sync += n.eq(n.init)\r\nm.d.comb += z.eq(n == 0)\r\n\nTip\n\nThe control input provided to ResetInserter must be synchronous to the domain that is being reset by it. If you need to reset another domain, use amaranth.lib.cdc.ResetSynchronizer instead.\n\nRenaming domains\n\nA reusable elaboratable usually specifies the use of one or more clock domains while leaving the details of clocking and initialization to a later phase in the design process. DomainRenamer can be used to alter a reusable elaboratable for integration in a specific design. Most elaboratables use a single clock domain named sync, and DomainRenamer makes it easy to place such elaboratables in any clock domain of a design.\n\nClock domains can be renamed using the syntax DomainRenamer(domains)(elaboratable), where domains is a mapping from clock domain names to clock domain names and elaboratable is any elaboratable object. The keys of domains correspond to existing clock domain names specified by elaboratable, and the values of domains correspond to the clock domain names from the containing elaboratable that will be used instead. When only the sync domain is being renamed, instead of writing DomainRenamer({\"sync\": name})(elaboratable), the equivalent but shorter DomainRenamer(name)(elaboratable) syntax can be used.\n\nThe result of renaming clock domains in an elaboratable is, itself, an elaboratable object. A common way to rename domains is to apply DomainRenamer to another elaboratable while adding it as a submodule:\n\nm.submodules.counter = counter = DomainRenamer(\"video\")(counter)\r\n\nRenaming a clock domain affects all logic within a given elaboratable and clock domain, which includes the submodules of that elaboratable. It does not affect any logic outside of that elaboratable.\n\nNote\n\nRenaming domains in an elaboratable does not mutate it; a new proxy object is returned that forwards attribute accesses and method calls to the original elaboratable. Whenever this proxy object is elaborated, it manipulates the circuit defined by the original elaboratable to use the requested clock domain.\n\nNote\n\nIt is possible to rename domains in an elaboratable and also apply control flow modifiers.\n\nConsider the following code:\n\nm = Module()\r\nm.d.sync += count.eq(count + 1)\r\nm.d.comb += zero.eq(count == 0)\r\n\r\nm = DomainRenamer({\"sync\": \"video\"})(m)\r\n\nThe renaming of the sync clock domain in it causes the behavior of the final m to be identical to that of this module:\n\nm = Module()\r\nm.d.video += count.eq(count + 1)\r\nm.d.comb += zero.eq(count == 0)\r\n\nWarning", "source": "amaranth"}
{"script_name": "CombinationalSignalUpdate", "definition_description": "This script updates the value of a combinational signal based on conditions such as changes in other signals or control conditions.", "parameters": {"signal": "The signal being updated", "control_signal": "A control signal (e.g. en) that determines if the update occurs", "expression": "The expression that computes the new value of the signal if the control signal is active"}, "values": "signal: <a>, control_signal: <en>, expression: <b + 1>", "script_paradigm": "m.d.comb += <signal>.eq(<expression>)", "examples": [{"query": "How to update signal a when en is true to b + 1?", "answer": "m.d.comb += a.eq(b + 1)"}, {"query": "What happens if en is false?", "answer": "The value of a will remain its initial value, 1."}], "reference": "Combinational evaluation\n\nSignals in the combinational control domain change whenever any value used to compute them changes. The final value of a combinational signal is equal to its initial value updated by the active assignments in the assignment order. Combinational signals cannot hold any state.\n\nConsider the following code:\n\na = Signal(8, init=1)\r\nwith m.If(en):\r\n    m.d.comb += a.eq(b + 1)\r\n\nWhenever the signals en or b change, the signal a changes as well. If en is false, the final value of a is its initial value, 1. If en is true, the final value of a is equal to b + 1.\n\nA combinational signal that is computed directly or indirectly based on its own value is a part of a combinational feedback loop, sometimes shortened to just feedback loop. Combinational feedback loops can be stable (e.g. implement a constant driver or a transparent latch), or unstable (e.g. implement a ring oscillator). Amaranth prohibits using assignments to describe any kind of a combinational feedback loop, including transparent latches.\n\nNote\n\nIn the exceedingly rare case when a combinational feedback loop is desirable, it is possible to implement it by directly instantiating technology primitives (e.g. device-specific LUTs or latches). This is also the only way to introduce a combinational feedback loop with well-defined behavior in simulation and synthesis, regardless of the HDL being used.\n\nSynchronous evaluation\n\nSignals in synchronous control domains change whenever the active edge (a 0-to-1 or 1-to-0 transition, configured when creating the domain) occurs on the clock of the synchronous domain. In addition, the signals in clock domains with an asynchronous reset change when such a reset is asserted. The final value of a synchronous signal is equal to its initial value if the reset (of any type) is asserted, or to its current value updated by the active assignments in the assignment order otherwise. Synchronous signals always hold state.\n\nConsider the following code:\n\ntimer = Signal(8)\r\n\r\nwith m.If(up):\r\n    m.d.sync += timer.eq(timer + 1)\r\nwith m.Elif(down):\r\n    m.d.sync += timer.eq(timer - 1)\r\n\nWhenever there is a transition on the clock of the sync domain, the timer signal is incremented by one if up is true, decremented by one if down is true, and retains its value otherwise.\n\nAssertions\n\nSome properties are so important that if they are violated, the computations described by the design become meaningless. These properties should be guarded with an Assert statement that immediately terminates the simulation if its condition is false. Assertions should generally be added to a synchronous domain, and may have an optional message printed when it is violated:\n\nip = Signal(16)\r\nm.d.sync += Assert(ip < 128, \"instruction pointer past the end of program code!\")\r\n\nAssertions may be nested within a control block:\n\nwith m.If(~booting):\r\n    m.d.sync += Assert(ip < 128)\r\n\nWarning\n\nWhile is is also possible to add assertions to the combinational domain, simulations of combinational circuits may have glitches: instantaneous, transient changes in the values of expressions that are being computed which do not affect the result of the computation (and are not visible in most waveform viewers for that reason). Depending on the tools used for simulation, a glitch in the condition of an assertion or of a control block that contains it may cause the simulation to be terminated, even if the glitch would have been instantaneously resolved afterwards.\n\nIf the condition of an assertion is assigned in a synchronous domain, then it is safe to add that assertion in the combinational domain. For example, neither of the assertions in the example below will be violated due to glitches, regardless of which domain the ip and booting signals are driven by:\n\nip_sync = Signal.like(ip)\r\nm.d.sync += ip_sync.eq(ip)\r\n\r\nm.d.comb += Assert(ip_sync < 128)\r\nwith m.If(booting):\r\n    m.d.comb += Assert(ip_sync < 128)", "source": "amaranth"}
{"script_name": "SynchronousSignalUpdate", "definition_description": "This script updates the value of a synchronous signal based on clock transitions and control signals in a synchronous domain.", "parameters": {"signal": "The signal being updated", "increment_condition": "A condition (e.g. up) to increment the signal", "decrement_condition": "A condition (e.g. down) to decrement the signal"}, "values": "signal: <timer>, increment_condition: <up>, decrement_condition: <down>", "script_paradigm": "m.d.sync += <signal>.eq(<signal> + 1) if <increment_condition> else <signal>.eq(<signal> - 1)", "examples": [{"query": "How to increment a timer signal by 1 when up is true?", "answer": "m.d.sync += timer.eq(timer + 1)"}, {"query": "How to decrement a timer signal by 1 when down is true?", "answer": "m.d.sync += timer.eq(timer - 1)"}], "reference": "Combinational evaluation\n\nSignals in the combinational control domain change whenever any value used to compute them changes. The final value of a combinational signal is equal to its initial value updated by the active assignments in the assignment order. Combinational signals cannot hold any state.\n\nConsider the following code:\n\na = Signal(8, init=1)\r\nwith m.If(en):\r\n    m.d.comb += a.eq(b + 1)\r\n\nWhenever the signals en or b change, the signal a changes as well. If en is false, the final value of a is its initial value, 1. If en is true, the final value of a is equal to b + 1.\n\nA combinational signal that is computed directly or indirectly based on its own value is a part of a combinational feedback loop, sometimes shortened to just feedback loop. Combinational feedback loops can be stable (e.g. implement a constant driver or a transparent latch), or unstable (e.g. implement a ring oscillator). Amaranth prohibits using assignments to describe any kind of a combinational feedback loop, including transparent latches.\n\nNote\n\nIn the exceedingly rare case when a combinational feedback loop is desirable, it is possible to implement it by directly instantiating technology primitives (e.g. device-specific LUTs or latches). This is also the only way to introduce a combinational feedback loop with well-defined behavior in simulation and synthesis, regardless of the HDL being used.\n\nSynchronous evaluation\n\nSignals in synchronous control domains change whenever the active edge (a 0-to-1 or 1-to-0 transition, configured when creating the domain) occurs on the clock of the synchronous domain. In addition, the signals in clock domains with an asynchronous reset change when such a reset is asserted. The final value of a synchronous signal is equal to its initial value if the reset (of any type) is asserted, or to its current value updated by the active assignments in the assignment order otherwise. Synchronous signals always hold state.\n\nConsider the following code:\n\ntimer = Signal(8)\r\n\r\nwith m.If(up):\r\n    m.d.sync += timer.eq(timer + 1)\r\nwith m.Elif(down):\r\n    m.d.sync += timer.eq(timer - 1)\r\n\nWhenever there is a transition on the clock of the sync domain, the timer signal is incremented by one if up is true, decremented by one if down is true, and retains its value otherwise.\n\nAssertions\n\nSome properties are so important that if they are violated, the computations described by the design become meaningless. These properties should be guarded with an Assert statement that immediately terminates the simulation if its condition is false. Assertions should generally be added to a synchronous domain, and may have an optional message printed when it is violated:\n\nip = Signal(16)\r\nm.d.sync += Assert(ip < 128, \"instruction pointer past the end of program code!\")\r\n\nAssertions may be nested within a control block:\n\nwith m.If(~booting):\r\n    m.d.sync += Assert(ip < 128)\r\n\nWarning\n\nWhile is is also possible to add assertions to the combinational domain, simulations of combinational circuits may have glitches: instantaneous, transient changes in the values of expressions that are being computed which do not affect the result of the computation (and are not visible in most waveform viewers for that reason). Depending on the tools used for simulation, a glitch in the condition of an assertion or of a control block that contains it may cause the simulation to be terminated, even if the glitch would have been instantaneously resolved afterwards.\n\nIf the condition of an assertion is assigned in a synchronous domain, then it is safe to add that assertion in the combinational domain. For example, neither of the assertions in the example below will be violated due to glitches, regardless of which domain the ip and booting signals are driven by:\n\nip_sync = Signal.like(ip)\r\nm.d.sync += ip_sync.eq(ip)\r\n\r\nm.d.comb += Assert(ip_sync < 128)\r\nwith m.If(booting):\r\n    m.d.comb += Assert(ip_sync < 128)", "source": "amaranth"}
{"script_name": "AssertionStatement", "definition_description": "This script adds an assertion to guard critical properties in the design and terminates the simulation if the condition is violated.", "parameters": {"condition": "The condition that should hold true", "message": "An optional message that will be printed if the assertion fails"}, "values": "condition: <ip < 128>, message: <instruction pointer past the end of program code!>", "script_paradigm": "m.d.sync += Assert(<condition>, <message>)", "examples": [{"query": "How to add an assertion to ensure ip is less than 128?", "answer": "m.d.sync += Assert(ip < 128, 'instruction pointer past the end of program code!')"}, {"query": "How to add an assertion in a control block when booting is false?", "answer": "with m.If(~booting):\n    m.d.sync += Assert(ip < 128)"}], "reference": "Combinational evaluation\n\nSignals in the combinational control domain change whenever any value used to compute them changes. The final value of a combinational signal is equal to its initial value updated by the active assignments in the assignment order. Combinational signals cannot hold any state.\n\nConsider the following code:\n\na = Signal(8, init=1)\r\nwith m.If(en):\r\n    m.d.comb += a.eq(b + 1)\r\n\nWhenever the signals en or b change, the signal a changes as well. If en is false, the final value of a is its initial value, 1. If en is true, the final value of a is equal to b + 1.\n\nA combinational signal that is computed directly or indirectly based on its own value is a part of a combinational feedback loop, sometimes shortened to just feedback loop. Combinational feedback loops can be stable (e.g. implement a constant driver or a transparent latch), or unstable (e.g. implement a ring oscillator). Amaranth prohibits using assignments to describe any kind of a combinational feedback loop, including transparent latches.\n\nNote\n\nIn the exceedingly rare case when a combinational feedback loop is desirable, it is possible to implement it by directly instantiating technology primitives (e.g. device-specific LUTs or latches). This is also the only way to introduce a combinational feedback loop with well-defined behavior in simulation and synthesis, regardless of the HDL being used.\n\nSynchronous evaluation\n\nSignals in synchronous control domains change whenever the active edge (a 0-to-1 or 1-to-0 transition, configured when creating the domain) occurs on the clock of the synchronous domain. In addition, the signals in clock domains with an asynchronous reset change when such a reset is asserted. The final value of a synchronous signal is equal to its initial value if the reset (of any type) is asserted, or to its current value updated by the active assignments in the assignment order otherwise. Synchronous signals always hold state.\n\nConsider the following code:\n\ntimer = Signal(8)\r\n\r\nwith m.If(up):\r\n    m.d.sync += timer.eq(timer + 1)\r\nwith m.Elif(down):\r\n    m.d.sync += timer.eq(timer - 1)\r\n\nWhenever there is a transition on the clock of the sync domain, the timer signal is incremented by one if up is true, decremented by one if down is true, and retains its value otherwise.\n\nAssertions\n\nSome properties are so important that if they are violated, the computations described by the design become meaningless. These properties should be guarded with an Assert statement that immediately terminates the simulation if its condition is false. Assertions should generally be added to a synchronous domain, and may have an optional message printed when it is violated:\n\nip = Signal(16)\r\nm.d.sync += Assert(ip < 128, \"instruction pointer past the end of program code!\")\r\n\nAssertions may be nested within a control block:\n\nwith m.If(~booting):\r\n    m.d.sync += Assert(ip < 128)\r\n\nWarning\n\nWhile is is also possible to add assertions to the combinational domain, simulations of combinational circuits may have glitches: instantaneous, transient changes in the values of expressions that are being computed which do not affect the result of the computation (and are not visible in most waveform viewers for that reason). Depending on the tools used for simulation, a glitch in the condition of an assertion or of a control block that contains it may cause the simulation to be terminated, even if the glitch would have been instantaneously resolved afterwards.\n\nIf the condition of an assertion is assigned in a synchronous domain, then it is safe to add that assertion in the combinational domain. For example, neither of the assertions in the example below will be violated due to glitches, regardless of which domain the ip and booting signals are driven by:\n\nip_sync = Signal.like(ip)\r\nm.d.sync += ip_sync.eq(ip)\r\n\r\nm.d.comb += Assert(ip_sync < 128)\r\nwith m.If(booting):\r\n    m.d.comb += Assert(ip_sync < 128)", "source": "amaranth"}
{"script_name": "RunCommandsBetweenLabels", "definition_description": "This script runs the commands between the specified labels in the design.", "parameters": {"from_label": "The label from which the commands should start (empty means begin)", "to_label": "The label where the commands should stop (empty means end of command list)"}, "values": "from_label: <from_label>, to_label: <to_label>", "script_paradigm": "run <from_label>:<to_label>", "examples": [{"query": "How to run commands from label start to label end?", "answer": "run start:end"}, {"query": "How to run all commands from the beginning?", "answer": "run :end"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "DisableFlatten", "definition_description": "This script prevents flattening the design before synthesis.", "parameters": {}, "values": "", "script_paradigm": "noflatten", "examples": [{"query": "How to disable flattening before synthesis?", "answer": "noflatten"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "RunABCWithDFF", "definition_description": "This script runs the 'abc' or 'abc9' tool with the '-dff' option.", "parameters": {}, "values": "", "script_paradigm": "dff", "examples": [{"query": "How to run 'abc' with the '-dff' option?", "answer": "dff"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "RetimeABC", "definition_description": "This script runs the 'abc' tool with '-dff -D 1' options for retiming.", "parameters": {}, "values": "", "script_paradigm": "retime", "examples": [{"query": "How to run 'abc' with '-dff -D 1' options?", "answer": "retime"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "DisableSBCarryCells", "definition_description": "This script prevents the use of SB_CARRY cells in the output netlist.", "parameters": {}, "values": "", "script_paradigm": "nocarry", "examples": [{"query": "How to avoid using SB_CARRY cells in the netlist?", "answer": "nocarry"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "DisableSBDFECCells", "definition_description": "This script prevents the use of SB_DFFE* cells in the output netlist.", "parameters": {}, "values": "", "script_paradigm": "nodffe", "examples": [{"query": "How to disable the use of SB_DFFE* cells in the netlist?", "answer": "nodffe"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "MinCEUseForSBDFECCells", "definition_description": "This script prevents the use of SB_DFFE* cells if the resulting CE line goes to less than a specified minimum number of SB_DFFE* cells.", "parameters": {"min_ce_use": "The minimum number of SB_DFFE* cells the CE line should go to"}, "values": "min_ce_use: <min_ce_use>", "script_paradigm": "dffe_min_ce_use <min_ce_use>", "examples": [{"query": "How to prevent using SB_DFFE* cells if the CE line goes to fewer than 3 cells?", "answer": "dffe_min_ce_use 3"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "DisableSBRAMCells", "definition_description": "This script prevents the use of SB_RAM40_4K* cells in the output netlist.", "parameters": {}, "values": "", "script_paradigm": "nobram", "examples": [{"query": "How to avoid using SB_RAM40_4K* cells in the netlist?", "answer": "nobram"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "EnableSBSPRAMInference", "definition_description": "This script enables automatic inference of SB_SPRAM256KA cells.", "parameters": {}, "values": "", "script_paradigm": "spram", "examples": [{"query": "How to enable automatic inference of SB_SPRAM256KA cells?", "answer": "spram"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "UseiCE40UltraPlusDSP", "definition_description": "This script forces the use of iCE40 UltraPlus DSP cells for large arithmetic operations.", "parameters": {}, "values": "", "script_paradigm": "dsp", "examples": [{"query": "How to use iCE40 UltraPlus DSP cells for large arithmetic?", "answer": "dsp"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "DisableABCFlow", "definition_description": "This script uses the built-in Yosys LUT techmapping instead of the abc flow.", "parameters": {}, "values": "", "script_paradigm": "noabc", "examples": [{"query": "How to disable the use of ABC flow for LUT techmapping?", "answer": "noabc"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "RunABCWithTwoPasses", "definition_description": "This script runs two passes of the 'abc' tool for slightly improved logic density.", "parameters": {}, "values": "", "script_paradigm": "abc2", "examples": [{"query": "How to run 'abc' with two passes for better logic density?", "answer": "abc2"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "GenerateVPRNetlist", "definition_description": "This script generates an output netlist (and BLIF file) suitable for VPR.", "parameters": {}, "values": "", "script_paradigm": "vpr", "examples": [{"query": "How to generate a VPR-compatible netlist?", "answer": "vpr"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "DisableABC9Flow", "definition_description": "This script disables the use of the new ABC9 flow for logic synthesis.", "parameters": {}, "values": "", "script_paradigm": "noabc9", "examples": [{"query": "How to disable the use of ABC9 flow?", "answer": "noabc9"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "UseFlowMapLUTTechMapping", "definition_description": "This experimental script uses the FlowMap LUT techmapping instead of abc.", "parameters": {}, "values": "", "script_paradigm": "flowmap", "examples": [{"query": "How to use FlowMap for LUT techmapping?", "answer": "flowmap"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "DisableRWCheck", "definition_description": "This script disables the read-write check during synthesis.", "parameters": {}, "values": "", "script_paradigm": "no-rw-check", "examples": [{"query": "How to disable the read-write check during synthesis?", "answer": "no-rw-check"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nis omitted if this parameter is not specified.\n-run <from_label>:<to_label>\nonly run the commands between the labels (see below). an empty\nfrom label is synonymous to 'begin', and empty to label is\nsynonymous to the end of the command list.\n-noflatten\ndo not flatten design before synthesis\n-dff\nrun 'abc'/'abc9' with -dff option\n-retime\nrun 'abc' with '-dff -D 1' options\n-nocarry\ndo not use SB_CARRY cells in output netlist\n-nodffe\ndo not use SB_DFFE* cells in output netlist\n-dffe_min_ce_use <min_ce_use>\ndo not use SB_DFFE* cells if the resulting CE line would go to less\nthan min_ce_use SB_DFFE* in output netlist\n-nobram\ndo not use SB_RAM40_4K* cells in output netlist\n-spram\nenable automatic inference of SB_SPRAM256KA\n-dsp\nuse iCE40 UltraPlus DSP cells for large arithmetic\n-noabc\nuse built-in Yosys LUT techmapping instead of abc\n-abc2\nrun two passes of 'abc' for slightly improved logic density\n-vpr\ngenerate an output netlist (and BLIF file) suitable for VPR\n(this feature is experimental and incomplete)\n-noabc9\ndisable use of new ABC9 flow\n-flowmap\nuse FlowMap LUT techmapping instead of abc (EXPERIMENTAL)\n-no-rw-check\n(continues on next page)\n506\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "Flatten", "definition_description": "This script flattens the design by removing hierarchy levels, unless the -noflatten option is specified.", "parameters": {"noflatten": "Optional parameter to prevent flattening of the design hierarchy"}, "values": "noflatten: true or false", "script_paradigm": "flatten [-noflatten]", "examples": [{"query": "How to flatten the design without hierarchy?", "answer": "flatten"}, {"query": "How to flatten the design but keep the hierarchy?", "answer": "flatten -noflatten"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "Synthesize Coarse", "definition_description": "This script runs the coarse synthesis pass, which performs optimizations suitable for coarse-grain synthesis.", "parameters": {}, "values": "", "script_paradigm": "synth -run coarse", "examples": [{"query": "How to run coarse synthesis?", "answer": "synth -run coarse"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "Map RAM", "definition_description": "This script maps RAM cells in the design, using a memory library mapping file and optionally avoiding automatic block creation.", "parameters": {"memory_libmap": "The path to the RAM library mapping file", "no_auto_block": "Optional parameter to prevent automatic block creation if -nobram is specified"}, "values": "memory_libmap: +/efinix/brams.txt, no_auto_block: true or false", "script_paradigm": "memory_libmap -lib <memory_libmap> [-no-auto-block]", "examples": [{"query": "How to map RAM using efinix/brams.txt?", "answer": "memory_libmap -lib +/efinix/brams.txt"}, {"query": "How to map RAM with no automatic block creation?", "answer": "memory_libmap -lib +/efinix/brams.txt -no-auto-block"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "Map FF RAM", "definition_description": "This script performs optimizations on flip-flop based RAMs by applying fine-grained optimizations.", "parameters": {}, "values": "", "script_paradigm": "opt -fast -mux_undef -undriven -fine", "examples": [{"query": "How to optimize FF RAM with fine-grained settings?", "answer": "opt -fast -mux_undef -undriven -fine"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "Map Gates", "definition_description": "This script applies a gate-level mapping, using provided mapping files for arithmetic and general gates.", "parameters": {"arith_map": "Path to the arithmetic gate mapping file", "tech_map": "Path to the general technology mapping file"}, "values": "arith_map: +/efinix/arith_map.v, tech_map: +/techmap.v", "script_paradigm": "techmap -map <tech_map> -map <arith_map>", "examples": [{"query": "How to map gates using efinix/arith_map.v and techmap.v?", "answer": "techmap -map +/efinix/arith_map.v -map +/techmap.v"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "Map FFS", "definition_description": "This script applies flip-flop legalizations and optimizations for specific cell types, along with additional technology mapping.", "parameters": {"dffe_cell": "The DFFE flip-flop cell type to be legalized", "sdffe_cell": "The SDFFE flip-flop cell type to be legalized", "tech_map": "Path to the technology mapping file"}, "values": "dffe_cell: $_DFFE_????_, sdffe_cell: $_SDFFE_????_, tech_map: +/efinix/cells_map.v", "script_paradigm": "dfflegalize -cell <dffe_cell> 0 -cell <sdffe_cell> 0 -cell <sdffe_cell> 0 -cell $_DLATCH_?_ x; techmap -D NO_LUT -map <tech_map>", "examples": [{"query": "How to apply flip-flop legalization and map cells?", "answer": "dfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_DLATCH_?_ x; techmap -D NO_LUT -map +/efinix/cells_map.v"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "Map LUTs", "definition_description": "This script applies logic optimization using LUT mapping with a specified LUT size.", "parameters": {"lut_size": "The size of the LUT to be used in the mapping"}, "values": "lut_size: 4", "script_paradigm": "abc -lut <lut_size>", "examples": [{"query": "How to map using 4-input LUTs?", "answer": "abc -lut 4"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "Clean", "definition_description": "This script performs design clean-up, removing unused cells or signals.", "parameters": {}, "values": "", "script_paradigm": "clean", "examples": [{"query": "How to clean the design?", "answer": "clean"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "Map Cells", "definition_description": "This script applies technology mapping using a specified cells mapping file.", "parameters": {"cells_map": "The path to the cell mapping file"}, "values": "cells_map: +/efinix/cells_map.v", "script_paradigm": "techmap -map <cells_map>", "examples": [{"query": "How to map cells using efinix/cells_map.v?", "answer": "techmap -map +/efinix/cells_map.v"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "Map GBUF", "definition_description": "This script maps global buffers to the design, ensuring proper clock buffering.", "parameters": {"clkbufmap": "The buffer type for global buffers"}, "values": "clkbufmap: $__EFX_GBUF O:I", "script_paradigm": "clkbufmap -buf <clkbufmap>; techmap -map +/efinix/gbuf_map.v", "examples": [{"query": "How to map global buffers for a clock signal?", "answer": "clkbufmap -buf $__EFX_GBUF O:I; techmap -map +/efinix/gbuf_map.v"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "EFINIX Fix Carry", "definition_description": "This script applies specific fixes for carry chains in the Efinix FPGA design flow.", "parameters": {}, "values": "", "script_paradigm": "efinix_fixcarry", "examples": [{"query": "How to fix carry chains in Efinix?", "answer": "efinix_fixcarry"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "Check", "definition_description": "This script performs design checks, such as hierarchy verification and initialization.", "parameters": {"noinit": "Optional parameter to check without initializing", "blackbox": "Optional parameter to set a blackbox to a specific whitebox"}, "values": "noinit: true or false, blackbox: A:whitebox", "script_paradigm": "hierarchy -check; stat; check -noinit; blackbox =<blackbox>", "examples": [{"query": "How to check the hierarchy and initialization status?", "answer": "hierarchy -check; stat; check -noinit"}, {"query": "How to check and set A as a whitebox?", "answer": "hierarchy -check; stat; check -noinit; blackbox =A:whitebox"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_ram:\nmemory_libmap -lib +/efinix/brams.txt [-no-auto-block]\n(-no-auto-block if -\n˓→nobram)\ntechmap -map +/efinix/brams_map.v\nmap_ffram:\nopt -fast -mux_undef -undriven -fine\nmemory_map\nopt -undriven -fine\nmap_gates:\ntechmap -map +/techmap.v -map +/efinix/arith_map.v\nopt -fast\nabc -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_????_ 0 -cell $_SDFFE_????_ 0 -cell $_SDFFCE_????_ 0 -\n˓→cell $_DLATCH_?_ x\ntechmap -D NO_LUT -map +/efinix/cells_map.v\nopt_expr -mux_undef\nsimplemap\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\ntechmap -map +/efinix/cells_map.v\nclean\nmap_gbuf:\nclkbufmap -buf $__EFX_GBUF O:I\ntechmap -map +/efinix/gbuf_map.v\nefinix_fixcarry\nclean\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n494\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "MyPass", "definition_description": "This script defines a simple pass in Yosys that prints the arguments passed to it and lists the modules in the current design.", "parameters": {"args": "A vector of strings representing the arguments passed to the command.", "design": "A pointer to the RTLIL::Design object representing the current design."}, "values": "args: <vector_of_strings>, design: <RTLIL_Design>", "script_paradigm": "# include \"kernel/yosys.h\"\nUSING_YOSYS_NAMESPACE\nstruct MyPass : public Pass {\nMyPass() : Pass(\"my_cmd\", \"just a simple test\") { }\nvoid execute(std::vector<std::string> args, RTLIL::Design *design) override {\nlog(\"Arguments to my_cmd:\\n\");\nfor (auto &arg : args)\nlog(\"\\n%s\\n\", arg.c_str());\nlog(\"Modules in current design:\\n\");\nfor (auto mod : design->modules())\nlog(\"\\n%s (%d wires, %d cells)\\n\", log_id(mod), GetSize(mod->wires()), GetSize(mod->cells()));\n}\n} MyPass;", "examples": [{"query": "How to create a simple pass that prints arguments and lists design modules?", "answer": "# include \"kernel/yosys.h\"\nUSING_YOSYS_NAMESPACE\nstruct MyPass : public Pass {\nMyPass() : Pass(\"my_cmd\", \"just a simple test\") { }\nvoid execute(std::vector<std::string> args, RTLIL::Design *design) override {\nlog(\"Arguments to my_cmd:\\n\");\nfor (auto &arg : args)\nlog(\"\\n%s\\n\", arg.c_str());\nlog(\"Modules in current design:\\n\");\nfor (auto mod : design->modules())\nlog(\"\\n%s (%d wires, %d cells)\\n\", log_id(mod), GetSize(mod->wires()), GetSize(mod->cells()));\n}\n} MyPass;"}, {"query": "How to compile the MyPass command to a Yosys plugin?", "answer": "yosys-config --build my_cmd.so my_cmd.cc"}], "reference": "YosysHQ Yosys, Version 0.48-dev\nfor (RTLIL::Module *module : design->selected_modules() {\nif (module->has_memories_warn() || module->has_processes_warn())\ncontinue;\n....\n}\nWhen trying to understand what a command does, creating a small test case to look at the output of dump\nand show before and after the command has been executed can be helpful. Selections has more information\non using these commands.\nCreating a command\nLet’s create a very simple test command which prints the arguments we called it with, and lists off the\ncurrent design’s modules.\nListing 4.1: Example command my_cmd from my_cmd.cc\n# include \"kernel/yosys.h\"\nUSING_YOSYS_NAMESPACE\nstruct MyPass : public Pass {\nMyPass() : Pass(\"my_cmd\", \"just a simple test\") { }\nvoid execute(std::vector<std::string> args, RTLIL::Design *design) override\n{\nlog(\"Arguments to my_cmd:\\n\");\nfor (auto &arg : args)\nlog(\"\n%s\\n\", arg.c_str());\nlog(\"Modules in current design:\\n\");\nfor (auto mod : design->modules())\nlog(\"\n%s (%d wires, %d cells)\\n\", log_id(mod),\nGetSize(mod->wires()), GetSize(mod->cells()));\n}\n} MyPass;\nNote that we are making a global instance of a class derived from Yosys::Pass, which we get by including\nkernel/yosys.h.\nCompiling to a plugin\nYosys can be extended by adding additional C++ code to the Yosys code base, or by loading plugins into\nYosys. For maintainability it is generally recommended to create plugins.\nThe following command compiles our example my_cmd to a Yosys plugin:\nyosys-config --exec --cxx --cxxflags --ldflags \\\n-o my_cmd.so -shared my_cmd.cc --ldlibs\nOr shorter:\nyosys-config --build my_cmd.so my_cmd.cc\nRunning Yosys with the -m option allows the plugin to be used. Here’s a quick example that also uses the\n-p option to run my_cmd foo bar.\n146\nChapter 4.\nYosys internals", "source": "yosys_hq"}
{"script_name": "CompareFileDiff", "definition_description": "This script compares two versions of a file to detect differences, typically used for version control or change tracking.", "parameters": {"old_file_path": "The file path of the old version to compare.", "new_file_path": "The file path of the new version to compare."}, "values": "old_file_path: <path_to_old_version>, new_file_path: <path_to_new_version>", "script_paradigm": "diff -Naur <old_file_path> <new_file_path>", "examples": [{"query": "How to compare the files graywolf/src/twsc/gateswap.c and graywolf_new/src/twsc/gateswap.c?", "answer": "diff -Naur graywolf/src/twsc/gateswap.c graywolf_new/src/twsc/gateswap.c"}], "reference": "diff -Naur graywolf/src/twsc/gateswap.c graywolf_new/src/twsc/gateswap.c --- graywolf/src/twsc/gateswap.c 2015-05-15 22:22:22.406535822 -0400 +++ graywolf_new/src/twsc/gateswap.c 2015-05-15 21:42:44.542599522 -0400 @@ -20,8 +20,9 @@ #include", "source": "qflow"}
{"script_name": "no_inline", "definition_description": "This script specifies that a module, task, or function should not be inlined into any modules or locations that use it.", "parameters": {"module_name": "The name of the module that should not be inlined.", "task_name": "The name of the task that should not be inlined.", "func_name": "The name of the function that should not be inlined."}, "values": "module_name: <modulename>, task_name: <taskname>, func_name: <funcname>", "script_paradigm": "no_inline [-module <module_name>] -task <task_name>", "examples": [{"query": "How to specify that the module my_module should not be inlined?", "answer": "no_inline -module my_module"}, {"query": "Prevent the task my_task from being inlined?", "answer": "no_inline -task my_task"}, {"query": "Prevent the function my_function from being inlined?", "answer": "no_inline -function my_function"}], "reference": "Verilator, Release Devel 5.031\nno_inline -module \"<modulename>\"\nSpeciﬁes the module should not be inlined into any modules that use this module.\nSame as /\n*verilator&32;no_inline_module*/ metacomment.\nno_inline [-module \"<modulename>\"] -task \"<taskname>\"\nno_inline [-module \"<modulename>\"] -function \"<funcname>\"\nSpecify the function or task should not be inlined into where it is used. This may reduce the size of the ﬁnal\nexecutable when a task is used a very large number of times. For this ﬂag to work, the task and tasks below it\nmust be pure; they cannot reference any variables outside the task itself.\nSame as /*verilator&32;no_inline_task*/ metacomment.\nlint_on\n[-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\"] [-contents \"<wildcard>\"] [-match \"<wildcard\nEnable/disables the speciﬁed lint warning, in the speciﬁed ﬁlename (or wildcard with ‘*’ or ‘?’, or all ﬁles if\nomitted) and range of line numbers (or all lines if omitted).\nWith lint_off using “*” will override any lint_on directives in the source, i.e. the warning will still not be printed.\nIf the -rule is omitted, all lint warnings (see list in -Wno-lint) are enabled/disabled. This will override all\nlater lint warning enables for the speciﬁed region.\nIf -contents is provided, the input ﬁles must contain the given wildcard (with ‘*’ or ‘?’), and are waived in\ncase they match, provided the -rule, -file, and -contents also match. The wildcard should be designed\nto match a single line; it is unspeciﬁed if the wildcard is allowed to match across multiple lines. The input\ncontents does not include --std standard ﬁles, nor conﬁguration ﬁles (with verilator_config). Typical\nuse for this is to match a version number present in the Verilog sources, so that the waiver will only apply to that\nversion of the sources.\nIf -match is provided, the linter warnings are matched against the given wildcard (with ‘*’ or ‘?’), and are\nwaived in case they match, provided the -rule, -file, and -contents also match. The wildcard is com-\npared across the entire multi-line message; see --waiver-multiline.\nBefore version 4.026, -rule was named -msg, and -msg remained a deprecated alias until Version 5.000.\npublic [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rd [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rw [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\" \"@\nSets the variable to be public.\nSame as /*verilator&32;public*/ or /*verilator&32;\npublic_flat*/, etc., metacomments. See also VPI Example.\nprofile_data -mtask \"<mtask_hash>\" -cost <cost_value>\nFeeds proﬁle-guided optimization data into the Verilator algorithms in order to improve model runtime perfor-\nmance. This option is not expected to be used by users directly. See Thread Proﬁle-Guided Optimization.\nsc_bv -module \"<modulename>\" [-task \"<taskname>\"] -var \"<signame>\"\nsc_bv -module \"<modulename>\" [-function \"<funcname>\"] -var \"<signame>\"\nSets the port to be of sc_bv<{width}> type, instead of bool, uint32_t, or uint64_t.\nSame as /\n*verilator&32;sc_bv*/ metacomment.\nsformat [-module \"<modulename>\"] [-task \"<taskname>\"] -var \"<signame>\"\nsformat [-module \"<modulename>\"] [-function \"<funcname>\"] -var \"<signame>\"\nMust be applied to the ﬁnal argument of type input string of a function or task to indicate that the function\n12.2. Conﬁguration Files\n95", "source": "verilator"}
{"script_name": "lint_on", "definition_description": "This script enables specified lint warnings for particular files and line ranges.", "parameters": {"rule": "The specific lint warning rule to enable.", "file": "The filename where the lint warning should be enabled.", "line_range": "The range of line numbers where the lint warning should be enabled."}, "values": "rule: <message>, file: <filename>, line_range: <line>, <line>", "script_paradigm": "lint_on [-rule <rule>] [-file <file>] [-lines <line_range>]", "examples": [{"query": "How to enable lint warning for rule my_rule in file my_file?", "answer": "lint_on -rule my_rule -file my_file"}, {"query": "Enable lint warning on lines 20 to 30 in my_source_file?", "answer": "lint_on -file my_source_file -lines 20-30"}], "reference": "Verilator, Release Devel 5.031\nno_inline -module \"<modulename>\"\nSpeciﬁes the module should not be inlined into any modules that use this module.\nSame as /\n*verilator&32;no_inline_module*/ metacomment.\nno_inline [-module \"<modulename>\"] -task \"<taskname>\"\nno_inline [-module \"<modulename>\"] -function \"<funcname>\"\nSpecify the function or task should not be inlined into where it is used. This may reduce the size of the ﬁnal\nexecutable when a task is used a very large number of times. For this ﬂag to work, the task and tasks below it\nmust be pure; they cannot reference any variables outside the task itself.\nSame as /*verilator&32;no_inline_task*/ metacomment.\nlint_on\n[-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\"] [-contents \"<wildcard>\"] [-match \"<wildcard\nEnable/disables the speciﬁed lint warning, in the speciﬁed ﬁlename (or wildcard with ‘*’ or ‘?’, or all ﬁles if\nomitted) and range of line numbers (or all lines if omitted).\nWith lint_off using “*” will override any lint_on directives in the source, i.e. the warning will still not be printed.\nIf the -rule is omitted, all lint warnings (see list in -Wno-lint) are enabled/disabled. This will override all\nlater lint warning enables for the speciﬁed region.\nIf -contents is provided, the input ﬁles must contain the given wildcard (with ‘*’ or ‘?’), and are waived in\ncase they match, provided the -rule, -file, and -contents also match. The wildcard should be designed\nto match a single line; it is unspeciﬁed if the wildcard is allowed to match across multiple lines. The input\ncontents does not include --std standard ﬁles, nor conﬁguration ﬁles (with verilator_config). Typical\nuse for this is to match a version number present in the Verilog sources, so that the waiver will only apply to that\nversion of the sources.\nIf -match is provided, the linter warnings are matched against the given wildcard (with ‘*’ or ‘?’), and are\nwaived in case they match, provided the -rule, -file, and -contents also match. The wildcard is com-\npared across the entire multi-line message; see --waiver-multiline.\nBefore version 4.026, -rule was named -msg, and -msg remained a deprecated alias until Version 5.000.\npublic [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rd [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rw [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\" \"@\nSets the variable to be public.\nSame as /*verilator&32;public*/ or /*verilator&32;\npublic_flat*/, etc., metacomments. See also VPI Example.\nprofile_data -mtask \"<mtask_hash>\" -cost <cost_value>\nFeeds proﬁle-guided optimization data into the Verilator algorithms in order to improve model runtime perfor-\nmance. This option is not expected to be used by users directly. See Thread Proﬁle-Guided Optimization.\nsc_bv -module \"<modulename>\" [-task \"<taskname>\"] -var \"<signame>\"\nsc_bv -module \"<modulename>\" [-function \"<funcname>\"] -var \"<signame>\"\nSets the port to be of sc_bv<{width}> type, instead of bool, uint32_t, or uint64_t.\nSame as /\n*verilator&32;sc_bv*/ metacomment.\nsformat [-module \"<modulename>\"] [-task \"<taskname>\"] -var \"<signame>\"\nsformat [-module \"<modulename>\"] [-function \"<funcname>\"] -var \"<signame>\"\nMust be applied to the ﬁnal argument of type input string of a function or task to indicate that the function\n12.2. Conﬁguration Files\n95", "source": "verilator"}
{"script_name": "lint_off", "definition_description": "This script disables specified lint warnings for particular files, line ranges, or contents.", "parameters": {"rule": "The specific lint warning rule to disable.", "file": "The filename where the lint warning should be disabled.", "line_range": "The range of line numbers where the lint warning should be disabled.", "contents": "A wildcard for the contents to match when disabling the lint warning.", "match": "A wildcard for matching the warning message."}, "values": "rule: <message>, file: <filename>, line_range: <line>, <line>, contents: <wildcard>, match: <wildcard>", "script_paradigm": "lint_off [-rule <rule>] [-file <file>] [-lines <line_range>] [-contents <wildcard>] [-match <wildcard>]", "examples": [{"query": "How to disable lint warning for rule my_rule in my_file?", "answer": "lint_off -rule my_rule -file my_file"}, {"query": "Disable lint warnings for lines 10 to 20 in my_code_file?", "answer": "lint_off -file my_code_file -lines 10-20"}], "reference": "Verilator, Release Devel 5.031\nno_inline -module \"<modulename>\"\nSpeciﬁes the module should not be inlined into any modules that use this module.\nSame as /\n*verilator&32;no_inline_module*/ metacomment.\nno_inline [-module \"<modulename>\"] -task \"<taskname>\"\nno_inline [-module \"<modulename>\"] -function \"<funcname>\"\nSpecify the function or task should not be inlined into where it is used. This may reduce the size of the ﬁnal\nexecutable when a task is used a very large number of times. For this ﬂag to work, the task and tasks below it\nmust be pure; they cannot reference any variables outside the task itself.\nSame as /*verilator&32;no_inline_task*/ metacomment.\nlint_on\n[-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\"] [-contents \"<wildcard>\"] [-match \"<wildcard\nEnable/disables the speciﬁed lint warning, in the speciﬁed ﬁlename (or wildcard with ‘*’ or ‘?’, or all ﬁles if\nomitted) and range of line numbers (or all lines if omitted).\nWith lint_off using “*” will override any lint_on directives in the source, i.e. the warning will still not be printed.\nIf the -rule is omitted, all lint warnings (see list in -Wno-lint) are enabled/disabled. This will override all\nlater lint warning enables for the speciﬁed region.\nIf -contents is provided, the input ﬁles must contain the given wildcard (with ‘*’ or ‘?’), and are waived in\ncase they match, provided the -rule, -file, and -contents also match. The wildcard should be designed\nto match a single line; it is unspeciﬁed if the wildcard is allowed to match across multiple lines. The input\ncontents does not include --std standard ﬁles, nor conﬁguration ﬁles (with verilator_config). Typical\nuse for this is to match a version number present in the Verilog sources, so that the waiver will only apply to that\nversion of the sources.\nIf -match is provided, the linter warnings are matched against the given wildcard (with ‘*’ or ‘?’), and are\nwaived in case they match, provided the -rule, -file, and -contents also match. The wildcard is com-\npared across the entire multi-line message; see --waiver-multiline.\nBefore version 4.026, -rule was named -msg, and -msg remained a deprecated alias until Version 5.000.\npublic [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rd [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rw [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\" \"@\nSets the variable to be public.\nSame as /*verilator&32;public*/ or /*verilator&32;\npublic_flat*/, etc., metacomments. See also VPI Example.\nprofile_data -mtask \"<mtask_hash>\" -cost <cost_value>\nFeeds proﬁle-guided optimization data into the Verilator algorithms in order to improve model runtime perfor-\nmance. This option is not expected to be used by users directly. See Thread Proﬁle-Guided Optimization.\nsc_bv -module \"<modulename>\" [-task \"<taskname>\"] -var \"<signame>\"\nsc_bv -module \"<modulename>\" [-function \"<funcname>\"] -var \"<signame>\"\nSets the port to be of sc_bv<{width}> type, instead of bool, uint32_t, or uint64_t.\nSame as /\n*verilator&32;sc_bv*/ metacomment.\nsformat [-module \"<modulename>\"] [-task \"<taskname>\"] -var \"<signame>\"\nsformat [-module \"<modulename>\"] [-function \"<funcname>\"] -var \"<signame>\"\nMust be applied to the ﬁnal argument of type input string of a function or task to indicate that the function\n12.2. Conﬁguration Files\n95", "source": "verilator"}
{"script_name": "public", "definition_description": "This script sets a variable, task, or function to be public, making it accessible externally.", "parameters": {"module_name": "The name of the module for which to set the public variable.", "task_name": "The name of the task for which to set the public variable.", "func_name": "The name of the function for which to set the public variable.", "signame": "The signal name that should be set as public."}, "values": "module_name: <modulename>, task_name: <taskname>, func_name: <funcname>, signame: <signame>", "script_paradigm": "public [-module <module_name>] [-task/-function <task_name>] -var <signame>", "examples": [{"query": "How to set the variable my_signal as public in module my_module?", "answer": "public -module my_module -var my_signal"}, {"query": "Make the variable my_task_signal public in my_task?", "answer": "public -task my_task -var my_task_signal"}], "reference": "Verilator, Release Devel 5.031\nno_inline -module \"<modulename>\"\nSpeciﬁes the module should not be inlined into any modules that use this module.\nSame as /\n*verilator&32;no_inline_module*/ metacomment.\nno_inline [-module \"<modulename>\"] -task \"<taskname>\"\nno_inline [-module \"<modulename>\"] -function \"<funcname>\"\nSpecify the function or task should not be inlined into where it is used. This may reduce the size of the ﬁnal\nexecutable when a task is used a very large number of times. For this ﬂag to work, the task and tasks below it\nmust be pure; they cannot reference any variables outside the task itself.\nSame as /*verilator&32;no_inline_task*/ metacomment.\nlint_on\n[-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\"] [-contents \"<wildcard>\"] [-match \"<wildcard\nEnable/disables the speciﬁed lint warning, in the speciﬁed ﬁlename (or wildcard with ‘*’ or ‘?’, or all ﬁles if\nomitted) and range of line numbers (or all lines if omitted).\nWith lint_off using “*” will override any lint_on directives in the source, i.e. the warning will still not be printed.\nIf the -rule is omitted, all lint warnings (see list in -Wno-lint) are enabled/disabled. This will override all\nlater lint warning enables for the speciﬁed region.\nIf -contents is provided, the input ﬁles must contain the given wildcard (with ‘*’ or ‘?’), and are waived in\ncase they match, provided the -rule, -file, and -contents also match. The wildcard should be designed\nto match a single line; it is unspeciﬁed if the wildcard is allowed to match across multiple lines. The input\ncontents does not include --std standard ﬁles, nor conﬁguration ﬁles (with verilator_config). Typical\nuse for this is to match a version number present in the Verilog sources, so that the waiver will only apply to that\nversion of the sources.\nIf -match is provided, the linter warnings are matched against the given wildcard (with ‘*’ or ‘?’), and are\nwaived in case they match, provided the -rule, -file, and -contents also match. The wildcard is com-\npared across the entire multi-line message; see --waiver-multiline.\nBefore version 4.026, -rule was named -msg, and -msg remained a deprecated alias until Version 5.000.\npublic [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rd [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rw [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\" \"@\nSets the variable to be public.\nSame as /*verilator&32;public*/ or /*verilator&32;\npublic_flat*/, etc., metacomments. See also VPI Example.\nprofile_data -mtask \"<mtask_hash>\" -cost <cost_value>\nFeeds proﬁle-guided optimization data into the Verilator algorithms in order to improve model runtime perfor-\nmance. This option is not expected to be used by users directly. See Thread Proﬁle-Guided Optimization.\nsc_bv -module \"<modulename>\" [-task \"<taskname>\"] -var \"<signame>\"\nsc_bv -module \"<modulename>\" [-function \"<funcname>\"] -var \"<signame>\"\nSets the port to be of sc_bv<{width}> type, instead of bool, uint32_t, or uint64_t.\nSame as /\n*verilator&32;sc_bv*/ metacomment.\nsformat [-module \"<modulename>\"] [-task \"<taskname>\"] -var \"<signame>\"\nsformat [-module \"<modulename>\"] [-function \"<funcname>\"] -var \"<signame>\"\nMust be applied to the ﬁnal argument of type input string of a function or task to indicate that the function\n12.2. Conﬁguration Files\n95", "source": "verilator"}
{"script_name": "sformat", "definition_description": "This script applies to the final input string argument of a function or task to indicate its formatting.", "parameters": {"module_name": "The name of the module where the formatting should be applied.", "task_name": "The name of the task where the formatting should be applied.", "func_name": "The name of the function where the formatting should be applied.", "signame": "The signal name that should be formatted."}, "values": "module_name: <modulename>, task_name: <taskname>, func_name: <funcname>, signame: <signame>", "script_paradigm": "sformat [-module <module_name>] [-task <task_name>] -var <signame>", "examples": [{"query": "How to format the string my_string in task my_task?", "answer": "sformat -task my_task -var my_string"}, {"query": "Apply formatting to the string my_func_string in function my_function?", "answer": "sformat -function my_function -var my_func_string"}], "reference": "Verilator, Release Devel 5.031\nno_inline -module \"<modulename>\"\nSpeciﬁes the module should not be inlined into any modules that use this module.\nSame as /\n*verilator&32;no_inline_module*/ metacomment.\nno_inline [-module \"<modulename>\"] -task \"<taskname>\"\nno_inline [-module \"<modulename>\"] -function \"<funcname>\"\nSpecify the function or task should not be inlined into where it is used. This may reduce the size of the ﬁnal\nexecutable when a task is used a very large number of times. For this ﬂag to work, the task and tasks below it\nmust be pure; they cannot reference any variables outside the task itself.\nSame as /*verilator&32;no_inline_task*/ metacomment.\nlint_on\n[-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\" [-lines <line> [ - <line>]]]\nlint_off [-rule <message>] [-file \"<filename>\"] [-contents \"<wildcard>\"] [-match \"<wildcard\nEnable/disables the speciﬁed lint warning, in the speciﬁed ﬁlename (or wildcard with ‘*’ or ‘?’, or all ﬁles if\nomitted) and range of line numbers (or all lines if omitted).\nWith lint_off using “*” will override any lint_on directives in the source, i.e. the warning will still not be printed.\nIf the -rule is omitted, all lint warnings (see list in -Wno-lint) are enabled/disabled. This will override all\nlater lint warning enables for the speciﬁed region.\nIf -contents is provided, the input ﬁles must contain the given wildcard (with ‘*’ or ‘?’), and are waived in\ncase they match, provided the -rule, -file, and -contents also match. The wildcard should be designed\nto match a single line; it is unspeciﬁed if the wildcard is allowed to match across multiple lines. The input\ncontents does not include --std standard ﬁles, nor conﬁguration ﬁles (with verilator_config). Typical\nuse for this is to match a version number present in the Verilog sources, so that the waiver will only apply to that\nversion of the sources.\nIf -match is provided, the linter warnings are matched against the given wildcard (with ‘*’ or ‘?’), and are\nwaived in case they match, provided the -rule, -file, and -contents also match. The wildcard is com-\npared across the entire multi-line message; see --waiver-multiline.\nBefore version 4.026, -rule was named -msg, and -msg remained a deprecated alias until Version 5.000.\npublic [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rd [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\"\npublic_flat_rw [-module \"<modulename>\"] [-task/-function \"<taskname>\"]\n-var \"<signame>\" \"@\nSets the variable to be public.\nSame as /*verilator&32;public*/ or /*verilator&32;\npublic_flat*/, etc., metacomments. See also VPI Example.\nprofile_data -mtask \"<mtask_hash>\" -cost <cost_value>\nFeeds proﬁle-guided optimization data into the Verilator algorithms in order to improve model runtime perfor-\nmance. This option is not expected to be used by users directly. See Thread Proﬁle-Guided Optimization.\nsc_bv -module \"<modulename>\" [-task \"<taskname>\"] -var \"<signame>\"\nsc_bv -module \"<modulename>\" [-function \"<funcname>\"] -var \"<signame>\"\nSets the port to be of sc_bv<{width}> type, instead of bool, uint32_t, or uint64_t.\nSame as /\n*verilator&32;sc_bv*/ metacomment.\nsformat [-module \"<modulename>\"] [-task \"<taskname>\"] -var \"<signame>\"\nsformat [-module \"<modulename>\"] [-function \"<funcname>\"] -var \"<signame>\"\nMust be applied to the ﬁnal argument of type input string of a function or task to indicate that the function\n12.2. Conﬁguration Files\n95", "source": "verilator"}
{"script_name": "hierarchy", "definition_description": "This script checks the design hierarchy, ensuring that the correct top-level module is defined.", "parameters": {"check": "Flag to perform the check for hierarchy correctness", "top": "The name of the top-level module in the design"}, "values": "check: <true/false>, top: <top>", "script_paradigm": "hierarchy -check -top <top>", "examples": [{"query": "How to check hierarchy for a design with top module 'top'?", "answer": "hierarchy -check -top top"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nThe following commands are executed by this synthesis command:\nbegin:\nfamily:\nread_verilog -sv -lib +/intel/max10/cells_sim.v\nread_verilog -sv -lib +/intel/common/m9k_bb.v\nread_verilog -sv -lib +/intel/common/altpll_bb.v\nhierarchy -check -top <top>\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_bram:\n(skip if -nobram)\nmemory_bram -rules +/intel/common/brams_m9k.txt\n(if applicable for family)\ntechmap -map +/intel/common/brams_map_m9k.v\n(if applicable for family)\nmap_ffram:\nopt -fast -mux_undef -undriven -fine -full\nmemory_map\nopt -undriven -fine\ntechmap -map +/techmap.v\nopt -full\nclean -purge\nsetundef -undriven -zero\nabc -markgroups -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_PN0P_ 01\ntechmap -map +/intel/common/ff_map.v\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\niopadmap -bits -outpad $__outpad I:O -inpad $__inpad O:I\n(if -iopads)\ntechmap -map +/intel/max10/cells_map.v\nclean -purge\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n510\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "techmap", "definition_description": "This script is used to map the design's cells to specific technology libraries, ensuring proper cell compatibility.", "parameters": {"map_file": "The path to the file containing cell mappings"}, "values": "map_file: <+/intel/common/brams_map_m9k.v>", "script_paradigm": "techmap -map <map_file>", "examples": [{"query": "How to map the BRAM cells?", "answer": "techmap -map +/intel/common/brams_map_m9k.v"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nThe following commands are executed by this synthesis command:\nbegin:\nfamily:\nread_verilog -sv -lib +/intel/max10/cells_sim.v\nread_verilog -sv -lib +/intel/common/m9k_bb.v\nread_verilog -sv -lib +/intel/common/altpll_bb.v\nhierarchy -check -top <top>\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_bram:\n(skip if -nobram)\nmemory_bram -rules +/intel/common/brams_m9k.txt\n(if applicable for family)\ntechmap -map +/intel/common/brams_map_m9k.v\n(if applicable for family)\nmap_ffram:\nopt -fast -mux_undef -undriven -fine -full\nmemory_map\nopt -undriven -fine\ntechmap -map +/techmap.v\nopt -full\nclean -purge\nsetundef -undriven -zero\nabc -markgroups -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_PN0P_ 01\ntechmap -map +/intel/common/ff_map.v\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\niopadmap -bits -outpad $__outpad I:O -inpad $__inpad O:I\n(if -iopads)\ntechmap -map +/intel/max10/cells_map.v\nclean -purge\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n510\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "abc", "definition_description": "This script runs the ABC optimization tool, focusing on logic synthesis and optimization tasks.", "parameters": {"lut_size": "The size of the LUT to be used for logic synthesis", "markgroups": "Flag to enable grouping of marked flip-flops"}, "values": "lut_size: <4>, markgroups: <true>", "script_paradigm": "abc -lut <lut_size> -markgroups -dff -D 1", "examples": [{"query": "How to use ABC with 4-input LUT and mark groups?", "answer": "abc -lut 4 -markgroups -dff -D 1"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nThe following commands are executed by this synthesis command:\nbegin:\nfamily:\nread_verilog -sv -lib +/intel/max10/cells_sim.v\nread_verilog -sv -lib +/intel/common/m9k_bb.v\nread_verilog -sv -lib +/intel/common/altpll_bb.v\nhierarchy -check -top <top>\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_bram:\n(skip if -nobram)\nmemory_bram -rules +/intel/common/brams_m9k.txt\n(if applicable for family)\ntechmap -map +/intel/common/brams_map_m9k.v\n(if applicable for family)\nmap_ffram:\nopt -fast -mux_undef -undriven -fine -full\nmemory_map\nopt -undriven -fine\ntechmap -map +/techmap.v\nopt -full\nclean -purge\nsetundef -undriven -zero\nabc -markgroups -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_PN0P_ 01\ntechmap -map +/intel/common/ff_map.v\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\niopadmap -bits -outpad $__outpad I:O -inpad $__inpad O:I\n(if -iopads)\ntechmap -map +/intel/max10/cells_map.v\nclean -purge\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n510\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "dfflegalize", "definition_description": "This script legalizes the DFF cells in the design to match the target library's cells.", "parameters": {"cell_type": "The type of DFF cell to be legalized", "cell_value": "The specific instance of the DFF cell"}, "values": "cell_type: <$_DFFE_PN0P_>, cell_value: <01>", "script_paradigm": "dfflegalize -cell <cell_type> <cell_value>", "examples": [{"query": "How to legalize the DFFE_PN0P cell?", "answer": "dfflegalize -cell $_DFFE_PN0P_ 01"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nThe following commands are executed by this synthesis command:\nbegin:\nfamily:\nread_verilog -sv -lib +/intel/max10/cells_sim.v\nread_verilog -sv -lib +/intel/common/m9k_bb.v\nread_verilog -sv -lib +/intel/common/altpll_bb.v\nhierarchy -check -top <top>\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_bram:\n(skip if -nobram)\nmemory_bram -rules +/intel/common/brams_m9k.txt\n(if applicable for family)\ntechmap -map +/intel/common/brams_map_m9k.v\n(if applicable for family)\nmap_ffram:\nopt -fast -mux_undef -undriven -fine -full\nmemory_map\nopt -undriven -fine\ntechmap -map +/techmap.v\nopt -full\nclean -purge\nsetundef -undriven -zero\nabc -markgroups -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_PN0P_ 01\ntechmap -map +/intel/common/ff_map.v\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\niopadmap -bits -outpad $__outpad I:O -inpad $__inpad O:I\n(if -iopads)\ntechmap -map +/intel/max10/cells_map.v\nclean -purge\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n510\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "iopadmap", "definition_description": "This script is used to map input/output pads to the appropriate I/O cells in the design.", "parameters": {"bits": "The number of bits to map", "outpad": "The output pad used for I/O mapping", "inpad": "The input pad used for I/O mapping"}, "values": "bits: <>, outpad: <__outpad>, inpad: <__inpad>", "script_paradigm": "iopadmap -bits <bits> -outpad <outpad> I:O -inpad <inpad> O:I", "examples": [{"query": "How to map I/O pads to the design?", "answer": "iopadmap -bits <> -outpad $__outpad I:O -inpad $__inpad O:I"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n(continued from previous page)\nThe following commands are executed by this synthesis command:\nbegin:\nfamily:\nread_verilog -sv -lib +/intel/max10/cells_sim.v\nread_verilog -sv -lib +/intel/common/m9k_bb.v\nread_verilog -sv -lib +/intel/common/altpll_bb.v\nhierarchy -check -top <top>\nflatten:\n(unless -noflatten)\nproc\nflatten\ntribuf -logic\ndeminout\ncoarse:\nsynth -run coarse\nmap_bram:\n(skip if -nobram)\nmemory_bram -rules +/intel/common/brams_m9k.txt\n(if applicable for family)\ntechmap -map +/intel/common/brams_map_m9k.v\n(if applicable for family)\nmap_ffram:\nopt -fast -mux_undef -undriven -fine -full\nmemory_map\nopt -undriven -fine\ntechmap -map +/techmap.v\nopt -full\nclean -purge\nsetundef -undriven -zero\nabc -markgroups -dff -D 1\n(only if -retime)\nmap_ffs:\ndfflegalize -cell $_DFFE_PN0P_ 01\ntechmap -map +/intel/common/ff_map.v\nmap_luts:\nabc -lut 4\nclean\nmap_cells:\niopadmap -bits -outpad $__outpad I:O -inpad $__inpad O:I\n(if -iopads)\ntechmap -map +/intel/max10/cells_map.v\nclean -purge\ncheck:\nhierarchy -check\nstat\ncheck -noinit\nblackbox =A:whitebox\n(continues on next page)\n510\nChapter 10.\nCommand line reference", "source": "yosys_hq"}
{"script_name": "VerifyLayoutWithNetgen", "definition_description": "This script performs layout verification using netgen by comparing the routed design against the abstract LEF view.", "parameters": {"lef_file": "Path to the LEF file containing abstract standard cell views", "def_file": "Path to the DEF file containing the routed layout", "tech_file": "Path to the technology file for the design process"}, "values": "lef_file: <path_to_lef>, def_file: <path_to_def>, tech_file: <path_to_tech>", "script_paradigm": "magic -d XR; lef read <lef_file>; def read <def_file>; grid 1.6um 2.0um; source <load_tcl_script>; writeall force <top_level_design>", "examples": [{"query": "How to verify the layout with netgen using Magic for a design with the file map9v3.def?", "answer": "magic -d XR; lef read /usr/local/share/qflow/tech/osu035/osu035_stdcells.lef; def read map9v3.def; grid 1.6um 2.0um; source load.tcl; writeall force map9v3"}], "reference": "Verifying the Layout with Netgen\n\nA synthesized circuit is supposed to be correct by design, but it is always a good idea to check the circuit both by LVS and by simulation.\n\nTo run this tutorial, you will need to have the tool netgen 1.5 installed on your system. Make sure that it is compiled with Tcl/Tk support, or else you will have to refer to the netgen documentation for doing a comparison without using the \"lvs\" command.\n\nAfter running qflow through the detailed routing, use Magic to read in the circuit. There is a limitation of the layout tool in which it understands of the cell bounding boxes defined in the LEF file for standard cell placement, but this understanding does not transfer to layout files in the standard database format. The best way to ensure that the physical layout view matches the abstract LEF view is to do the following:\n\nMagic will need access to the technology file for the process used by the OSU035 standard cells, which is the scalable-CMOS rules from MOSIS with a few modifications. The modified technology file is included with the qflow distribution. More recent revisions of qflow (from 1.0.13) will install a startup script \".magicrc\" in the layout directory. This startup script is responsible for loading the correct technology file from the qflow install directory. For versions of qflow prior to 1.0.13, you will need to copy the techfile SCN4M_SUBM.20.tech from the qflow install directory (/usr/local/share/qflow/tech/osu035/) to the local layout directory.\n\nStart Magic, for example, \"magic -d XR\" in the layout directory (or just \"magic\" if you don't have libcairo support).\n\nLoad the abstract LEF views, using:\n\nlef read /usr/local/share/qflow/tech/osu035/osu035_stdcells.lef\n\nThere will be a number of warnings related to statements that the LEF reader in magic doesn't handle; these can be ignored.\n\nLoad the routed DEF file, using:\n\ndef read map9v3.def\n\nIf you wish to see the routing grid, use\n\ngrid 1.6um 2.0um\n\nAll of the steps from the \"lef read\" command up to and including the \"grid\" command are included in the script file \"load.tcl\" in the download sections at the top of the tutorial. If you downloaded this file, put it in the layout directory. Then, start Magic and type into the console:\n\nsource load.tcl\n\nand proceed from the next step.\n\nSave the top-level design. In this case, you do not want to save the abstract views, although it can be helpful to keep the database versions of the abstract files in a separate directory and use the \"addpath\" command (see below) to switch between the abstract and physical views. To write the database for just the top-level cell, do:\n\nwriteall force map9v3\n\nThe circuit above was routed with qflow version 1.1.55 using power striping as described above, and routing on the first three layers only.\n\nNow quit Magic to lose the abstract cell views (say \"Yes\" to the prompt, you really do want to exit!)\n\nIf you have downloaded the OSU standard cell set, skip this step and go to the next one. Otherwise, download the file osu035_stdcells.gds2 from the download list at the top of the page (put it in the layout subdirectory). I recommend downloading the OSU standard cell set from the OSU website to get the most up-to-date version. However, the version posted here will suffice for the tutorial.\n\nBecause there are a lot of standard cells, you may want to keep these layout views in a subdirectory of the layout directory, so from the layout directory, do:\n\nmkdir digital cp .magicrc digital cd digital\n\nStart magic without specifying a file to load:\n\nmagic -d XR\n\nThen load the GDS file, and save all of the standard cells:\n\ngds read osu035_stdcells.gds2 writeall force quit", "source": "qflow"}
{"script_name": "VerilogToRTLIL", "definition_description": "This script translates Verilog code into RTLIL format used by Yosys for logic synthesis.", "parameters": {"verilog_code": "The Verilog code to be translated into RTLIL"}, "values": "verilog_code: <Verilog code to be translated>", "script_paradigm": "yosys -p \"read_verilog <verilog_code>; write_rtlil <output_file>\"", "examples": [{"query": "How to translate the given Verilog code to RTLIL?", "answer": "yosys -p \"read_verilog -\" << EOF\n<Verilog code>\nEOF\nwrite_rtlil output_file"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n1\nalways @(posedge clock) begin\n2\nout1 = in1;\n3\nif (in2)\n4\nout1 = !out1;\n5\nout2 <= out1;\n6\nif (in3)\n7\nout2 <= out2;\n8\nif (in4)\n9\nif (in5)\n10\nout3 <= in6;\n11\nelse\n12\nout3 <= in7;\n13\nout1 = out1 ^ out2;\n14\nend\nThis is translated by the Verilog and AST frontends into the following RTLIL code (attributes, cell parameters\nand wire declarations not included):\n1\ncell $logic_not $logic_not$<input>:4$2\n2\nconnect \\A \\in1\n3\nconnect \\Y $logic_not$<input>:4$2_Y\n4\nend\n5\ncell $xor $xor$<input>:13$3\n6\nconnect \\A $1\\out1[0:0]\n7\nconnect \\B \\out2\n8\nconnect \\Y $xor$<input>:13$3_Y\n9\nend\n10\nprocess $proc$<input>:1$1\n11\nassign $0\\out3[0:0] \\out3\n12\nassign $0\\out2[0:0] $1\\out1[0:0]\n13\nassign $0\\out1[0:0] $xor$<input>:13$3_Y\n14\nswitch \\in2\n15\ncase 1'1\n16\nassign $1\\out1[0:0] $logic_not$<input>:4$2_Y\n17\ncase\n18\nassign $1\\out1[0:0] \\in1\n19\nend\n20\nswitch \\in3\n21\ncase 1'1\n22\nassign $0\\out2[0:0] \\out2\n23\ncase\n24\nend\n25\nswitch \\in4\n26\ncase 1'1\n27\nswitch \\in5\n28\ncase 1'1\n29\nassign $0\\out3[0:0] \\in6\n30\ncase\n31\nassign $0\\out3[0:0] \\in7\n32\nend\n33\ncase\n34\nend\n35\nsync posedge \\clock\n(continues on next page)\n134\nChapter 4.\nYosys internals", "source": "yosys_hq"}
{"script_name": "AssignSignal", "definition_description": "This script assigns a signal value to another signal in RTLIL format.", "parameters": {"destination": "The destination signal that receives the value", "source": "The source signal whose value is assigned"}, "values": "destination: <destination signal>, source: <source signal>", "script_paradigm": "assign <destination> <source>", "examples": [{"query": "How to assign signal out2 to out1 in RTLIL?", "answer": "assign $0\\out2[0:0] $1\\out1[0:0]"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n1\nalways @(posedge clock) begin\n2\nout1 = in1;\n3\nif (in2)\n4\nout1 = !out1;\n5\nout2 <= out1;\n6\nif (in3)\n7\nout2 <= out2;\n8\nif (in4)\n9\nif (in5)\n10\nout3 <= in6;\n11\nelse\n12\nout3 <= in7;\n13\nout1 = out1 ^ out2;\n14\nend\nThis is translated by the Verilog and AST frontends into the following RTLIL code (attributes, cell parameters\nand wire declarations not included):\n1\ncell $logic_not $logic_not$<input>:4$2\n2\nconnect \\A \\in1\n3\nconnect \\Y $logic_not$<input>:4$2_Y\n4\nend\n5\ncell $xor $xor$<input>:13$3\n6\nconnect \\A $1\\out1[0:0]\n7\nconnect \\B \\out2\n8\nconnect \\Y $xor$<input>:13$3_Y\n9\nend\n10\nprocess $proc$<input>:1$1\n11\nassign $0\\out3[0:0] \\out3\n12\nassign $0\\out2[0:0] $1\\out1[0:0]\n13\nassign $0\\out1[0:0] $xor$<input>:13$3_Y\n14\nswitch \\in2\n15\ncase 1'1\n16\nassign $1\\out1[0:0] $logic_not$<input>:4$2_Y\n17\ncase\n18\nassign $1\\out1[0:0] \\in1\n19\nend\n20\nswitch \\in3\n21\ncase 1'1\n22\nassign $0\\out2[0:0] \\out2\n23\ncase\n24\nend\n25\nswitch \\in4\n26\ncase 1'1\n27\nswitch \\in5\n28\ncase 1'1\n29\nassign $0\\out3[0:0] \\in6\n30\ncase\n31\nassign $0\\out3[0:0] \\in7\n32\nend\n33\ncase\n34\nend\n35\nsync posedge \\clock\n(continues on next page)\n134\nChapter 4.\nYosys internals", "source": "yosys_hq"}
{"script_name": "ConditionalAssignment", "definition_description": "This script performs a conditional assignment based on the value of a given signal in RTLIL format.", "parameters": {"signal": "The signal that will determine which assignment to execute", "condition_value": "The value that the signal must have to trigger the assignment", "destination": "The destination signal to be assigned", "true_assignment": "The value assigned if the condition is true", "false_assignment": "The value assigned if the condition is false"}, "values": "signal: <signal>, condition_value: <condition value>, destination: <destination signal>, true_assignment: <true value>, false_assignment: <false value>", "script_paradigm": "switch <signal>\ncase <condition_value>\nassign <destination> <true_assignment>\ncase\nassign <destination> <false_assignment>\nend", "examples": [{"query": "How to assign out1 to out2 when in2 is true, otherwise assign in1?", "answer": "switch \\in2\ncase 1'1\nassign $1\\out1[0:0] $logic_not$<input>:4$2_Y\ncase\nassign $1\\out1[0:0] \\in1\nend"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n1\nalways @(posedge clock) begin\n2\nout1 = in1;\n3\nif (in2)\n4\nout1 = !out1;\n5\nout2 <= out1;\n6\nif (in3)\n7\nout2 <= out2;\n8\nif (in4)\n9\nif (in5)\n10\nout3 <= in6;\n11\nelse\n12\nout3 <= in7;\n13\nout1 = out1 ^ out2;\n14\nend\nThis is translated by the Verilog and AST frontends into the following RTLIL code (attributes, cell parameters\nand wire declarations not included):\n1\ncell $logic_not $logic_not$<input>:4$2\n2\nconnect \\A \\in1\n3\nconnect \\Y $logic_not$<input>:4$2_Y\n4\nend\n5\ncell $xor $xor$<input>:13$3\n6\nconnect \\A $1\\out1[0:0]\n7\nconnect \\B \\out2\n8\nconnect \\Y $xor$<input>:13$3_Y\n9\nend\n10\nprocess $proc$<input>:1$1\n11\nassign $0\\out3[0:0] \\out3\n12\nassign $0\\out2[0:0] $1\\out1[0:0]\n13\nassign $0\\out1[0:0] $xor$<input>:13$3_Y\n14\nswitch \\in2\n15\ncase 1'1\n16\nassign $1\\out1[0:0] $logic_not$<input>:4$2_Y\n17\ncase\n18\nassign $1\\out1[0:0] \\in1\n19\nend\n20\nswitch \\in3\n21\ncase 1'1\n22\nassign $0\\out2[0:0] \\out2\n23\ncase\n24\nend\n25\nswitch \\in4\n26\ncase 1'1\n27\nswitch \\in5\n28\ncase 1'1\n29\nassign $0\\out3[0:0] \\in6\n30\ncase\n31\nassign $0\\out3[0:0] \\in7\n32\nend\n33\ncase\n34\nend\n35\nsync posedge \\clock\n(continues on next page)\n134\nChapter 4.\nYosys internals", "source": "yosys_hq"}
{"script_name": "SynchronizeEdge", "definition_description": "This script synchronizes signals on the rising edge of the clock.", "parameters": {"clock": "The clock signal on which the synchronization occurs", "signal": "The signal to be synchronized"}, "values": "clock: <clock signal>, signal: <signal to synchronize>", "script_paradigm": "sync posedge <clock>", "examples": [{"query": "How to synchronize the signal out3 with the rising edge of the clock?", "answer": "sync posedge \\clock"}], "reference": "YosysHQ Yosys, Version 0.48-dev\n1\nalways @(posedge clock) begin\n2\nout1 = in1;\n3\nif (in2)\n4\nout1 = !out1;\n5\nout2 <= out1;\n6\nif (in3)\n7\nout2 <= out2;\n8\nif (in4)\n9\nif (in5)\n10\nout3 <= in6;\n11\nelse\n12\nout3 <= in7;\n13\nout1 = out1 ^ out2;\n14\nend\nThis is translated by the Verilog and AST frontends into the following RTLIL code (attributes, cell parameters\nand wire declarations not included):\n1\ncell $logic_not $logic_not$<input>:4$2\n2\nconnect \\A \\in1\n3\nconnect \\Y $logic_not$<input>:4$2_Y\n4\nend\n5\ncell $xor $xor$<input>:13$3\n6\nconnect \\A $1\\out1[0:0]\n7\nconnect \\B \\out2\n8\nconnect \\Y $xor$<input>:13$3_Y\n9\nend\n10\nprocess $proc$<input>:1$1\n11\nassign $0\\out3[0:0] \\out3\n12\nassign $0\\out2[0:0] $1\\out1[0:0]\n13\nassign $0\\out1[0:0] $xor$<input>:13$3_Y\n14\nswitch \\in2\n15\ncase 1'1\n16\nassign $1\\out1[0:0] $logic_not$<input>:4$2_Y\n17\ncase\n18\nassign $1\\out1[0:0] \\in1\n19\nend\n20\nswitch \\in3\n21\ncase 1'1\n22\nassign $0\\out2[0:0] \\out2\n23\ncase\n24\nend\n25\nswitch \\in4\n26\ncase 1'1\n27\nswitch \\in5\n28\ncase 1'1\n29\nassign $0\\out3[0:0] \\in6\n30\ncase\n31\nassign $0\\out3[0:0] \\in7\n32\nend\n33\ncase\n34\nend\n35\nsync posedge \\clock\n(continues on next page)\n134\nChapter 4.\nYosys internals", "source": "yosys_hq"}
